#!/usr/bin/env python3
"""
ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯åˆ†æã‚¨ãƒ³ã‚¸ãƒ³

ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’åˆ†æã—ã€èˆˆå‘³ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æŠ½å‡ºã—ã¦
ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è¨­å®šã®æ”¹å–„ææ¡ˆã‚’ç”Ÿæˆã™ã‚‹ã€‚
"""

import json
import os
import re
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple
from collections import defaultdict, Counter
import logging

import google.generativeai as genai


class FeedbackAnalyzer:
    """ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ã® AI åˆ†æã‚¨ãƒ³ã‚¸ãƒ³"""
    
    def __init__(self, gemini_api_key: str = None, debug: bool = False):
        """
        Args:
            gemini_api_key: Gemini API ã‚­ãƒ¼
            debug: ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰
        """
        self.debug = debug
        self.logger = self._setup_logger()
        
        # Gemini API è¨­å®š
        api_key = gemini_api_key or os.getenv('GEMINI_API_KEY')
        if not api_key:
            raise ValueError("Gemini API key is required")
        
        genai.configure(api_key=api_key)
        self.model = genai.GenerativeModel('gemini-1.5-flash')
        
        # ãƒ‘ã‚¹è¨­å®š
        self.feedback_log_path = os.path.join(
            os.path.dirname(os.path.dirname(__file__)), 
            'data', 'feedback_log.jsonl'
        )
        self.filter_config_path = os.path.join(
            os.path.dirname(os.path.dirname(__file__)), 
            'data', 'filter_config.json'
        )
    
    def _setup_logger(self) -> logging.Logger:
        """ãƒ­ã‚¬ãƒ¼ã‚’è¨­å®š"""
        logger = logging.getLogger(__name__)
        logger.setLevel(logging.DEBUG if self.debug else logging.INFO)
        
        if not logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter(
                '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
            )
            handler.setFormatter(formatter)
            logger.addHandler(handler)
        
        return logger
    
    def load_feedback_data(self, days: int = 30) -> List[Dict]:
        """
        ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€
        
        Args:
            days: éå»ä½•æ—¥åˆ†ã®ãƒ‡ãƒ¼ã‚¿ã‚’å¯¾è±¡ã¨ã™ã‚‹ã‹
            
        Returns:
            ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ã®ãƒªã‚¹ãƒˆ
        """
        if not os.path.exists(self.feedback_log_path):
            self.logger.warning(f"Feedback log not found: {self.feedback_log_path}")
            return []
        
        feedback_data = []
        cutoff_date = datetime.now() - timedelta(days=days)
        
        try:
            with open(self.feedback_log_path, 'r', encoding='utf-8') as f:
                for line_num, line in enumerate(f, 1):
                    try:
                        data = json.loads(line.strip())
                        
                        # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ç¢ºèª
                        timestamp = datetime.fromisoformat(
                            data['timestamp'].replace('Z', '+00:00')
                        )
                        
                        if timestamp >= cutoff_date:
                            feedback_data.append(data)
                        
                    except (json.JSONDecodeError, KeyError, ValueError) as e:
                        self.logger.warning(f"Line {line_num} parsing error: {e}")
                        continue
            
            self.logger.info(f"Loaded {len(feedback_data)} feedback entries from last {days} days")
            return feedback_data
            
        except Exception as e:
            self.logger.error(f"Error loading feedback data: {e}")
            return []
    
    def extract_patterns(self, feedback_data: List[Dict]) -> Dict:
        """
        ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰åŸºæœ¬çš„ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æŠ½å‡º
        
        Args:
            feedback_data: ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿
            
        Returns:
            æŠ½å‡ºã•ã‚ŒãŸãƒ‘ã‚¿ãƒ¼ãƒ³æƒ…å ±
        """
        patterns = {
            'interested': {'titles': [], 'authors': [], 'journals': []},
            'not_interested': {'titles': [], 'authors': [], 'journals': []},
            'statistics': {
                'total_feedback': len(feedback_data),
                'interested_count': 0,
                'not_interested_count': 0
            }
        }
        
        for entry in feedback_data:
            feedback_type = entry['feedback']
            article = entry['article']
            
            # çµ±è¨ˆæƒ…å ±
            if feedback_type == 'interested':
                patterns['statistics']['interested_count'] += 1
            else:
                patterns['statistics']['not_interested_count'] += 1
            
            # ãƒ‘ã‚¿ãƒ¼ãƒ³æŠ½å‡º
            patterns[feedback_type]['titles'].append(article['title'])
            patterns[feedback_type]['authors'].extend(article.get('authors', []))
            patterns[feedback_type]['journals'].append(article.get('journal', ''))
        
        # é‡è¤‡å‰Šé™¤ã¨é›†è¨ˆ
        for feedback_type in ['interested', 'not_interested']:
            patterns[feedback_type]['author_counts'] = Counter(
                patterns[feedback_type]['authors']
            )
            patterns[feedback_type]['journal_counts'] = Counter(
                patterns[feedback_type]['journals']
            )
        
        self.logger.info(f"Extracted patterns: {patterns['statistics']}")
        return patterns
    
    def analyze_with_gemini(self, patterns: Dict) -> Dict:
        """
        Gemini API ã‚’ä½¿ç”¨ã—ã¦ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’åˆ†æ
        
        Args:
            patterns: æŠ½å‡ºã•ã‚ŒãŸãƒ‘ã‚¿ãƒ¼ãƒ³
            
        Returns:
            AI åˆ†æçµæœ
        """
        if patterns['statistics']['total_feedback'] < 3:
            self.logger.warning("Insufficient feedback data for AI analysis")
            return {'analysis': 'Insufficient data', 'recommendations': []}
        
        # èˆˆå‘³ã‚ã‚Šã‚¿ã‚¤ãƒˆãƒ«ã‚’åˆ†æ
        interested_titles = patterns['interested']['titles']
        not_interested_titles = patterns['not_interested']['titles']
        
        prompt = f"""
ä»¥ä¸‹ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†æã—ã€èˆˆå‘³ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ç‰¹å®šã—ã¦ãã ã•ã„ï¼š

ã€èˆˆå‘³ã‚ã‚Šã®è«–æ–‡ã‚¿ã‚¤ãƒˆãƒ«ã€‘
{chr(10).join(f"- {title}" for title in interested_titles)}

ã€èˆˆå‘³ãªã—ã®è«–æ–‡ã‚¿ã‚¤ãƒˆãƒ«ã€‘  
{chr(10).join(f"- {title}" for title in not_interested_titles)}

ä»¥ä¸‹ã®è¦³ç‚¹ã§åˆ†æã—ã€JSONå½¢å¼ã§å›ç­”ã—ã¦ãã ã•ã„ï¼š

1. èˆˆå‘³ã‚ã‚Šãƒ‘ã‚¿ãƒ¼ãƒ³ã®ç‰¹å¾´ï¼ˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã€ç ”ç©¶åˆ†é‡ã€æ‰‹æ³•ãªã©ï¼‰
2. èˆˆå‘³ãªã—ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ç‰¹å¾´  
3. æ–°ã—ã„ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰å€™è£œï¼ˆincludeç”¨ï¼‰
4. é™¤å¤–ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰å€™è£œï¼ˆexcludeç”¨ï¼‰
5. å…¨ä½“çš„ãªå‚¾å‘

å›ç­”å½¢å¼ï¼š
{{
  "interested_patterns": {{
    "keywords": ["ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰1", "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰2"],
    "fields": ["ç ”ç©¶åˆ†é‡1", "ç ”ç©¶åˆ†é‡2"],
    "characteristics": "ç‰¹å¾´ã®èª¬æ˜"
  }},
  "not_interested_patterns": {{
    "keywords": ["ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰1", "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰2"], 
    "characteristics": "ç‰¹å¾´ã®èª¬æ˜"
  }},
  "recommendations": {{
    "new_include_keywords": ["æ¨å¥¨ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰1", "æ¨å¥¨ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰2"],
    "new_exclude_keywords": ["é™¤å¤–ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰1", "é™¤å¤–ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰2"],
    "reasoning": "æ¨å¥¨ç†ç”±"
  }},
  "summary": "å…¨ä½“åˆ†æã®ã¾ã¨ã‚"
}}
"""
        
        try:
            self.logger.info("Sending analysis request to Gemini...")
            response = self.model.generate_content(prompt)
            
            # JSONæŠ½å‡º
            response_text = response.text
            if self.debug:
                self.logger.debug(f"Gemini response: {response_text}")
            
            # JSONéƒ¨åˆ†ã‚’æŠ½å‡º
            json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
            if json_match:
                json_str = json_match.group(0)
                analysis_result = json.loads(json_str)
                self.logger.info("Gemini analysis completed successfully")
                return analysis_result
            else:
                self.logger.error("No JSON found in Gemini response")
                return {'analysis': 'Parse error', 'recommendations': []}
                
        except Exception as e:
            self.logger.error(f"Gemini analysis error: {e}")
            return {'analysis': f'Error: {e}', 'recommendations': []}
    
    def load_current_filters(self) -> Dict:
        """ç¾åœ¨ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è¨­å®šã‚’èª­ã¿è¾¼ã‚€"""
        try:
            with open(self.filter_config_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except FileNotFoundError:
            self.logger.warning("Filter config not found, using defaults")
            return {"include": [], "exclude": []}
        except Exception as e:
            self.logger.error(f"Error loading filter config: {e}")
            return {"include": [], "exclude": []}
    
    def generate_filter_recommendations(self, analysis: Dict) -> Dict:
        """
        åˆ†æçµæœã‹ã‚‰ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ›´æ–°ã®æ¨å¥¨äº‹é …ã‚’ç”Ÿæˆ
        
        Args:
            analysis: AIåˆ†æçµæœ
            
        Returns:
            ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ›´æ–°æ¨å¥¨äº‹é …
        """
        current_filters = self.load_current_filters()
        recommendations = analysis.get('recommendations', {})
        
        # æ–°ã—ã„ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰å€™è£œ
        new_includes = recommendations.get('new_include_keywords', [])
        new_excludes = recommendations.get('new_exclude_keywords', [])
        
        # é‡è¤‡é™¤å»
        current_includes = set(current_filters.get('include', []))
        current_excludes = set(current_filters.get('exclude', []))
        
        suggested_includes = [kw for kw in new_includes if kw not in current_includes]
        suggested_excludes = [kw for kw in new_excludes if kw not in current_excludes]
        
        return {
            'current_filters': current_filters,
            'suggested_additions': {
                'include': suggested_includes,
                'exclude': suggested_excludes
            },
            'updated_filters': {
                'include': list(current_includes) + suggested_includes,
                'exclude': list(current_excludes) + suggested_excludes
            },
            'reasoning': recommendations.get('reasoning', ''),
            'confidence': len(analysis.get('interested_patterns', {}).get('keywords', [])) + 
                        len(analysis.get('not_interested_patterns', {}).get('keywords', []))
        }
    
    def run_analysis(self, days: int = 30, min_feedback: int = 3) -> Dict:
        """
        ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯åˆ†æã‚’å®Ÿè¡Œ
        
        Args:
            days: åˆ†æå¯¾è±¡æœŸé–“ï¼ˆæ—¥æ•°ï¼‰
            min_feedback: åˆ†æã«å¿…è¦ãªæœ€å°ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯æ•°
            
        Returns:
            åˆ†æçµæœã¨æ¨å¥¨äº‹é …
        """
        self.logger.info(f"Starting feedback analysis for last {days} days")
        
        # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        feedback_data = self.load_feedback_data(days)
        
        if len(feedback_data) < min_feedback:
            return {
                'status': 'insufficient_data',
                'message': f'Need at least {min_feedback} feedback entries, got {len(feedback_data)}',
                'data_count': len(feedback_data)
            }
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³æŠ½å‡º
        patterns = self.extract_patterns(feedback_data)
        
        # AIåˆ†æ
        ai_analysis = self.analyze_with_gemini(patterns)
        
        # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¨å¥¨äº‹é …ç”Ÿæˆ
        filter_recommendations = self.generate_filter_recommendations(ai_analysis)
        
        return {
            'status': 'success',
            'data_count': len(feedback_data),
            'analysis_period': f'{days} days',
            'patterns': patterns,
            'ai_analysis': ai_analysis,
            'filter_recommendations': filter_recommendations,
            'timestamp': datetime.now().isoformat()
        }


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•° - CLIãƒ†ã‚¹ãƒˆç”¨"""
    import argparse
    
    parser = argparse.ArgumentParser(description='Feedback Analysis Engine')
    parser.add_argument('--debug', action='store_true', help='Enable debug mode')
    parser.add_argument('--days', type=int, default=30, help='Analysis period in days')
    parser.add_argument('--min-feedback', type=int, default=3, help='Minimum feedback count')
    
    args = parser.parse_args()
    
    try:
        analyzer = FeedbackAnalyzer(debug=args.debug)
        result = analyzer.run_analysis(days=args.days, min_feedback=args.min_feedback)
        
        print("=" * 60)
        print("ğŸ“Š FEEDBACK ANALYSIS RESULTS")
        print("=" * 60)
        print(json.dumps(result, indent=2, ensure_ascii=False))
        
    except Exception as e:
        print(f"âŒ Error: {e}")
        return 1
    
    return 0


if __name__ == '__main__':
    exit(main())