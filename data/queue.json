[
  {
    "id": "https://www.nature.com/articles/s41586-025-09109-5",
    "journal": "Nature",
    "title": "Publisher Correction: Metal–support frontier orbital interactions in single-atom catalysis",
    "link": "https://www.nature.com/articles/s41586-025-09109-5",
    "published": "",
    "summary": "<p>Nature, Published online: 04 June 2025; <a href=\"https://www.nature.com/articles/s41586-025-09109-5\">doi:10.1038/s41586-025-09109-5</a></p>Publisher Correction: Metal–support frontier orbital interactions in single-atom catalysis",
    "authors": [
      "Xianxian Shi",
      "Zhilin Wen",
      "Qingqing Gu",
      "Long Jiao",
      "Hai-Long Jiang",
      "Haifeng Lv",
      "Hengwei Wang",
      "Jiani Ding",
      "Mason P. Lyons",
      "Alvin Chang",
      "Zhenxing Feng",
      "Si Chen",
      "Yue Lin",
      "Xiaoyan Xu",
      "Pengfei Du",
      "Wenlong Xu",
      "Mei Sun",
      "Yin Li",
      "Bing Yang",
      "Tao Zhang",
      "Xiaojun Wu",
      "Junling Lu"
    ],
    "doi": "",
    "parser_type": "nature",
    "feed_priority": "high",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:33:57.538637"
  },
  {
    "id": "https://www.nature.com/articles/s41586-025-08988-y",
    "journal": "Nature",
    "title": "False positives in study of memory-related gene expression",
    "link": "https://www.nature.com/articles/s41586-025-08988-y",
    "published": "",
    "summary": "<p>Nature, Published online: 04 June 2025; <a href=\"https://www.nature.com/articles/s41586-025-08988-y\">doi:10.1038/s41586-025-08988-y</a></p>False positives in study of memory-related gene expression",
    "authors": [
      "Eran A. Mukamel",
      "Zhaoxia Yu"
    ],
    "doi": "",
    "parser_type": "nature",
    "feed_priority": "high",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:33:57.538643"
  },
  {
    "id": "https://www.nature.com/articles/s41586-025-08989-x",
    "journal": "Nature",
    "title": "Reply to: False positives in study of memory-related gene expression",
    "link": "https://www.nature.com/articles/s41586-025-08989-x",
    "published": "",
    "summary": "<p>Nature, Published online: 04 June 2025; <a href=\"https://www.nature.com/articles/s41586-025-08989-x\">doi:10.1038/s41586-025-08989-x</a></p>Reply to: False positives in study of memory-related gene expression",
    "authors": [
      "Wenfei Sun",
      "Zhihui Liu",
      "Xian Jiang",
      "Michelle B. Chen",
      "Hua Dong",
      "Jonathan Liu",
      "Thomas C. Südhof",
      "Stephen R. Quake"
    ],
    "doi": "",
    "parser_type": "nature",
    "feed_priority": "high",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:33:57.538649"
  },
  {
    "id": "https://www.nature.com/articles/s41586-025-08991-3",
    "journal": "Nature",
    "title": "Dynamic range and precision of hybrid vision sensors",
    "link": "https://www.nature.com/articles/s41586-025-08991-3",
    "published": "",
    "summary": "<p>Nature, Published online: 04 June 2025; <a href=\"https://www.nature.com/articles/s41586-025-08991-3\">doi:10.1038/s41586-025-08991-3</a></p>Dynamic range and precision of hybrid vision sensors",
    "authors": [
      "Minhao Yang",
      "Rodney Douglas",
      "Chenghan Li",
      "Andreas Suess",
      "Hyunsurk Ryu",
      "Christoph Posch",
      "Shoushun Chen",
      "Raphael Berner",
      "Tetsuya Yagi",
      "Boyd Fowler",
      "Tobi Delbruck"
    ],
    "doi": "",
    "parser_type": "nature",
    "feed_priority": "high",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:33:57.538654"
  },
  {
    "id": "https://www.nature.com/articles/d41586-025-01666-z",
    "journal": "Nature",
    "title": "How researchers are shining a light on the ‘invisible’ contributions of small-scale fishers",
    "link": "https://www.nature.com/articles/d41586-025-01666-z",
    "published": "",
    "summary": "<p>Nature, Published online: 04 June 2025; <a href=\"https://www.nature.com/articles/d41586-025-01666-z\">doi:10.1038/d41586-025-01666-z</a></p>A huge research project is highlighting the role that small-scale fishers play in sustainability.",
    "authors": [
      "Julie Gould"
    ],
    "doi": "",
    "parser_type": "nature",
    "feed_priority": "high",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:33:57.538662"
  },
  {
    "id": "https://www.nature.com/articles/d41586-025-01762-0",
    "journal": "Nature",
    "title": "Male mice can grow female organs — if their mothers lack iron",
    "link": "https://www.nature.com/articles/d41586-025-01762-0",
    "published": "",
    "summary": "<p>Nature, Published online: 04 June 2025; <a href=\"https://www.nature.com/articles/d41586-025-01762-0\">doi:10.1038/d41586-025-01762-0</a></p>Iron deficiency disrupts a sex-determining pathway in mice — plus, research highlighting the role that small-scale fishers play in sustainability.",
    "authors": [
      "Benjamin Thompson",
      "Nick Petrić Howe"
    ],
    "doi": "",
    "parser_type": "nature",
    "feed_priority": "high",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:33:57.538668"
  },
  {
    "id": "https://www.nature.com/articles/s41586-025-09049-0",
    "journal": "Nature",
    "title": "Milli-spinner thrombectomy",
    "link": "https://www.nature.com/articles/s41586-025-09049-0",
    "published": "",
    "summary": "<p>Nature, Published online: 04 June 2025; <a href=\"https://www.nature.com/articles/s41586-025-09049-0\">doi:10.1038/s41586-025-09049-0</a></p>The milli-spinner thrombectomy facilitates fast, complete clot removal by using spinning-induced compression and shear forces to mechanically modify the clot microstructure through densifying the fibrin network and releasing red blood cells, thus reducing clot volume.",
    "authors": [
      "Yilong Chang",
      "Shuai Wu",
      "Qi Li",
      "Benjamin Pulli",
      "Darren Salmi",
      "Paul Yock",
      "Jeremy J. Heit",
      "Ruike Renee Zhao"
    ],
    "doi": "",
    "parser_type": "nature",
    "feed_priority": "high",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:33:57.538674"
  },
  {
    "id": "https://www.nature.com/articles/s41586-025-09037-4",
    "journal": "Nature",
    "title": "Molecular gradients shape synaptic specificity of a visuomotor transformation",
    "link": "https://www.nature.com/articles/s41586-025-09037-4",
    "published": "",
    "summary": "<p>Nature, Published online: 04 June 2025; <a href=\"https://www.nature.com/articles/s41586-025-09037-4\">doi:10.1038/s41586-025-09037-4</a></p>Gradients of cell recognition molecules wire a sensorimotor interface in Drosophila.",
    "authors": [
      "Mark Dombrovski",
      "Yixin Zang",
      "Giovanni Frighetto",
      "Andrea Vaccari",
      "HyoJong Jang",
      "Parmis S. Mirshahidi",
      "Fangming Xie",
      "Piero Sanfilippo",
      "Bryce W. Hina",
      "Aadil Rehan",
      "Roni H. Hussein",
      "Pegah S. Mirshahidi",
      "Catherine Lee",
      "Aileen Morris",
      "Mark A. Frye",
      "Catherine R. von Reyn",
      "Yerbol Z. Kurmangaliyev",
      "Gwyneth M. Card",
      "S. Lawrence Zipursky"
    ],
    "doi": "",
    "parser_type": "nature",
    "feed_priority": "high",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:33:57.538680"
  },
  {
    "id": "https://www.nature.com/articles/s41586-025-09089-6",
    "journal": "Nature",
    "title": "A multidimensional distributional map of future reward in dopamine neurons",
    "link": "https://www.nature.com/articles/s41586-025-09089-6",
    "published": "",
    "summary": "<p>Nature, Published online: 04 June 2025; <a href=\"https://www.nature.com/articles/s41586-025-09089-6\">doi:10.1038/s41586-025-09089-6</a></p>An algorithm called time–magnitude reinforcement learning (TMRL) extends distributional reinforcement learning to take account of reward time and magnitude, and behavioural and neurophysiological experiments in mice suggest that midbrain dopamine neurons use TMRL-like computations.",
    "authors": [
      "Margarida Sousa",
      "Pawel Bujalski",
      "Bruno F. Cruz",
      "Kenway Louie",
      "Daniel C. McNamee",
      "Joseph J. Paton"
    ],
    "doi": "",
    "parser_type": "nature",
    "feed_priority": "high",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:33:57.538686"
  },
  {
    "id": "https://www.nature.com/articles/s41586-025-09044-5",
    "journal": "Nature",
    "title": "Integrated photonic source of Gottesman–Kitaev–Preskill qubits",
    "link": "https://www.nature.com/articles/s41586-025-09044-5",
    "published": "",
    "summary": "<p>Nature, Published online: 04 June 2025; <a href=\"https://www.nature.com/articles/s41586-025-09044-5\">doi:10.1038/s41586-025-09044-5</a></p>An ultra-low-loss integrated photonic chip fabricated on a customized multilayer silicon nitride 300-mm wafer platform, coupled over fibre with high-efficiency photon number resolving detectors, is used to generate Gottesman–Kitaev–Preskill qubit states.",
    "authors": [
      "M. V. Larsen",
      "J. E. Bourassa",
      "S. Kocsis",
      "J. F. Tasker",
      "R. S. Chadwick",
      "C. González-Arciniegas",
      "J. Hastrup",
      "C. E. Lopetegui-González",
      "F. M. Miatto",
      "A. Motamedi",
      "R. Noro",
      "G. Roeland",
      "R. Baby",
      "H. Chen",
      "P. Contu",
      "I. Di Luch",
      "C. Drago",
      "M. Giesbrecht",
      "T. Grainge",
      "I. Krasnokutska",
      "M. Menotti",
      "B. Morrison",
      "C. Puviraj",
      "K. Rezaei Shad",
      "B. Hussain",
      "J. McMahon",
      "J. E. Ortmann",
      "M. J. Collins",
      "C. Ma",
      "D. S. Phillips",
      "M. Seymour",
      "Q. Y. Tang",
      "B. Yang",
      "Z. Vernon",
      "R. N. Alexander",
      "D. H. Mahler"
    ],
    "doi": "",
    "parser_type": "nature",
    "feed_priority": "high",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:33:57.538692"
  },
  {
    "id": "https://www.nature.com/articles/s41586-025-09063-2",
    "journal": "Nature",
    "title": "Maternal iron deficiency causes male-to-female sex reversal in mouse embryos",
    "link": "https://www.nature.com/articles/s41586-025-09063-2",
    "published": "",
    "summary": "<p>Nature, Published online: 04 June 2025; <a href=\"https://www.nature.com/articles/s41586-025-09063-2\">doi:10.1038/s41586-025-09063-2</a></p>Iron-deficient conditions in pregnant mice can cause XY mouse embryos to develop female rather than male genitalia, revealing that iron metabolism has a role in determining male sex in mice.",
    "authors": [
      "Naoki Okashita",
      "Ryo Maeda",
      "Shunsuke Kuroki",
      "Kyona Sasaki",
      "Yoko Uno",
      "Peter Koopman",
      "Makoto Tachibana"
    ],
    "doi": "",
    "parser_type": "nature",
    "feed_priority": "high",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:33:57.538698"
  },
  {
    "id": "https://www.nature.com/articles/s41586-025-09068-x",
    "journal": "Nature",
    "title": "Coordination environments of Pt single-atom catalysts from NMR signatures",
    "link": "https://www.nature.com/articles/s41586-025-09068-x",
    "published": "",
    "summary": "<p>Nature, Published online: 04 June 2025; <a href=\"https://www.nature.com/articles/s41586-025-09068-x\">doi:10.1038/s41586-025-09068-x</a></p>This study presents a nuclear magnetic resonance-based method to determine local structure and bonding of Pt single-atom catalysts.",
    "authors": [
      "Jonas Koppe",
      "Alexander V. Yakimov",
      "Domenico Gioffrè",
      "Marc-Eduard Usteri",
      "Thomas Vosegaard",
      "Guido Pintacuda",
      "Anne Lesage",
      "Andrew J. Pell",
      "Sharon Mitchell",
      "Javier Pérez-Ramírez",
      "Christophe Copéret"
    ],
    "doi": "",
    "parser_type": "nature",
    "feed_priority": "high",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:33:57.538704"
  },
  {
    "id": "https://www.nature.com/articles/s41586-025-09051-6",
    "journal": "Nature",
    "title": "Observation of string breaking on a (2 + 1)D Rydberg quantum simulator",
    "link": "https://www.nature.com/articles/s41586-025-09051-6",
    "published": "",
    "summary": "<p>Nature, Published online: 04 June 2025; <a href=\"https://www.nature.com/articles/s41586-025-09051-6\">doi:10.1038/s41586-025-09051-6</a></p>A quantum simulation of a (2 + 1)-dimensional lattice gauge theory is carried out on a quantum computer working with neutral atoms trapped by optical tweezers in a Kagome geometry.",
    "authors": [
      "Daniel González-Cuadra",
      "Majd Hamdan",
      "Torsten V. Zache",
      "Boris Braverman",
      "Milan Kornjača",
      "Alexander Lukin",
      "Sergio H. Cantú",
      "Fangli Liu",
      "Sheng-Tao Wang",
      "Alexander Keesling",
      "Mikhail D. Lukin",
      "Peter Zoller",
      "Alexei Bylinskii"
    ],
    "doi": "",
    "parser_type": "nature",
    "feed_priority": "high",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:33:57.538709"
  },
  {
    "id": "https://www.nature.com/articles/s41586-025-09103-x",
    "journal": "Nature",
    "title": "Ancient DNA reveals a two-clanned matrilineal community in Neolithic China",
    "link": "https://www.nature.com/articles/s41586-025-09103-x",
    "published": "",
    "summary": "<p>Nature, Published online: 04 June 2025; <a href=\"https://www.nature.com/articles/s41586-025-09103-x\">doi:10.1038/s41586-025-09103-x</a></p>Analysis of ancient DNA, stable isotope data and archaeological evidence from the Fujia archaeological site in eastern China suggests it was populated by a matrilineal Neolithic community between 2750 and 2500 bc.",
    "authors": [
      "Jincheng Wang",
      "Shi Yan",
      "Zhenguang Li",
      "Jinguo Zan",
      "Yichao Zhao",
      "Jin Zhao",
      "Kui Chen",
      "Xueye Wang",
      "Ting Ji",
      "Cheng Zhang",
      "Tingyu Yang",
      "Tianming Zhang",
      "Rui Qiao",
      "Meilin Guo",
      "Zongyue Rao",
      "Jiashuo Zhang",
      "Guanbo Wang",
      "Zhiyu Ran",
      "Chen Duan",
      "Fan Zhang",
      "Yin Song",
      "Xiaohong Wu",
      "Ruth Mace",
      "Bo Sun",
      "Yuhong Pang",
      "Yanyi Huang",
      "Hai Zhang",
      "Chao Ning"
    ],
    "doi": "",
    "parser_type": "nature",
    "feed_priority": "high",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:33:57.538714"
  },
  {
    "id": "https://www.nature.com/articles/s41586-025-08999-9",
    "journal": "Nature",
    "title": "Visualizing dynamics of charges and strings in (2 + 1)D lattice gauge theories",
    "link": "https://www.nature.com/articles/s41586-025-08999-9",
    "published": "",
    "summary": "<p>Nature, Published online: 04 June 2025; <a href=\"https://www.nature.com/articles/s41586-025-08999-9\">doi:10.1038/s41586-025-08999-9</a></p>In a quantum simulation of a (2+1)D lattice gauge theory using a superconducting quantum processor, the dynamics of strings reveal the transition from deconfined to confined excitations as the effective electric field is increased.",
    "authors": [
      "T. A. Cochran",
      "B. Jobst",
      "E. Rosenberg",
      "Y. D. Lensky",
      "G. Gyawali",
      "N. Eassa",
      "M. Will",
      "A. Szasz",
      "D. Abanin",
      "R. Acharya",
      "L. Aghababaie Beni",
      "T. I. Andersen",
      "M. Ansmann",
      "F. Arute",
      "K. Arya",
      "A. Asfaw",
      "J. Atalaya",
      "R. Babbush",
      "B. Ballard",
      "J. C. Bardin",
      "A. Bengtsson",
      "A. Bilmes",
      "A. Bourassa",
      "J. Bovaird",
      "M. Broughton",
      "D. A. Browne",
      "B. Buchea",
      "B. B. Buckley",
      "T. Burger",
      "B. Burkett",
      "N. Bushnell",
      "A. Cabrera",
      "J. Campero",
      "H.-S. Chang",
      "Z. Chen",
      "B. Chiaro",
      "J. Claes",
      "A. Y. Cleland",
      "J. Cogan",
      "R. Collins",
      "P. Conner",
      "W. Courtney",
      "A. L. Crook",
      "B. Curtin",
      "S. Das",
      "S. Demura",
      "L. De Lorenzo",
      "A. Di Paolo",
      "P. Donohoe",
      "I. Drozdov",
      "A. Dunsworth",
      "A. Eickbusch",
      "A. Moshe Elbag",
      "M. Elzouka",
      "C. Erickson",
      "V. S. Ferreira",
      "L. Flores Burgos",
      "E. Forati",
      "A. G. Fowler",
      "B. Foxen",
      "S. Ganjam",
      "R. Gasca",
      "É. Genois",
      "W. Giang",
      "D. Gilboa",
      "R. Gosula",
      "A. Grajales Dau",
      "D. Graumann",
      "A. Greene",
      "J. A. Gross",
      "S. Habegger",
      "M. Hansen",
      "M. P. Harrigan",
      "S. D. Harrington",
      "P. Heu",
      "O. Higgott",
      "J. Hilton",
      "H.-Y. Huang",
      "A. Huff",
      "W. Huggins",
      "E. Jeffrey",
      "Z. Jiang",
      "C. Jones",
      "C. Joshi",
      "P. Juhas",
      "D. Kafri",
      "H. Kang",
      "A. H. Karamlou",
      "K. Kechedzhi",
      "T. Khaire",
      "T. Khattar",
      "M. Khezri",
      "S. Kim",
      "P. Klimov",
      "B. Kobrin",
      "A. Korotkov",
      "F. Kostritsa",
      "J. Kreikebaum",
      "V. Kurilovich",
      "D. Landhuis",
      "T. Lange-Dei",
      "B. Langley",
      "K.-M. Lau",
      "J. Ledford",
      "K. Lee",
      "B. Lester",
      "L. Le Guevel",
      "W. Li",
      "A. T. Lill",
      "W. Livingston",
      "A. Locharla",
      "D. Lundahl",
      "A. Lunt",
      "S. Madhuk",
      "A. Maloney",
      "S. Mandrà",
      "L. Martin",
      "O. Martin",
      "C. Maxfield",
      "J. McClean",
      "M. McEwen",
      "S. Meeks",
      "A. Megrant",
      "K. Miao",
      "R. Molavi",
      "S. Molina",
      "S. Montazeri",
      "R. Movassagh",
      "C. Neill",
      "M. Newman",
      "A. Nguyen",
      "M. Nguyen",
      "C.-H. Ni",
      "K. Ottosson",
      "A. Pizzuto",
      "R. Potter",
      "O. Pritchard",
      "C. Quintana",
      "G. Ramachandran",
      "M. Reagor",
      "D. Rhodes",
      "G. Roberts",
      "K. Sankaragomathi",
      "K. Satzinger",
      "H. Schurkus",
      "M. Shearn",
      "A. Shorter",
      "N. Shutty",
      "V. Shvarts",
      "V. Sivak",
      "S. Small",
      "W. C. Smith",
      "S. Springer",
      "G. Sterling",
      "J. Suchard",
      "A. Sztein",
      "D. Thor",
      "M. Torunbalci",
      "A. Vaishnav",
      "J. Vargas",
      "S. Vdovichev",
      "G. Vidal",
      "C. Vollgraff Heidweiller",
      "S. Waltman",
      "S. X. Wang",
      "B. Ware",
      "T. White",
      "K. Wong",
      "B. W. K. Woo",
      "C. Xing",
      "Z. Jamie Yao",
      "P. Yeh",
      "B. Ying",
      "J. Yoo",
      "N. Yosri",
      "G. Young",
      "A. Zalcman",
      "Y. Zhang",
      "N. Zhu",
      "N. Zobrist",
      "S. Boixo",
      "J. Kelly",
      "E. Lucero",
      "Y. Chen",
      "V. Smelyanskiy",
      "H. Neven",
      "A. Gammon-Smith",
      "F. Pollmann",
      "M. Knap",
      "P. Roushan"
    ],
    "doi": "",
    "parser_type": "nature",
    "feed_priority": "high",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:33:57.538720"
  },
  {
    "id": "https://www.nature.com/articles/s41586-025-09023-w",
    "journal": "Nature",
    "title": "Old carbon routed from land to the atmosphere by global river systems",
    "link": "https://www.nature.com/articles/s41586-025-09023-w",
    "published": "",
    "summary": "<p>Nature, Published online: 04 June 2025; <a href=\"https://www.nature.com/articles/s41586-025-09023-w\">doi:10.1038/s41586-025-09023-w</a></p>Using a global database of the radiocarbon content of rivers combining new and published measurements, isotopic mass balance suggests that about 60% of river CO2 emissions are derived from millennial or older carbon sources.",
    "authors": [
      "Joshua F. Dean",
      "Gemma Coxon",
      "Yanchen Zheng",
      "Jack Bishop",
      "Mark H. Garnett",
      "David Bastviken",
      "Valier Galy",
      "Robert G. M. Spencer",
      "Suzanne E. Tank",
      "Edward T. Tipper",
      "Jorien E. Vonk",
      "Marcus B. Wallin",
      "Liwei Zhang",
      "Chris D. Evans",
      "Robert G. Hilton"
    ],
    "doi": "",
    "parser_type": "nature",
    "feed_priority": "high",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:33:57.538726"
  },
  {
    "id": "https://www.nature.com/articles/s41586-025-09047-2",
    "journal": "Nature",
    "title": "Warming accelerates global drought severity",
    "link": "https://www.nature.com/articles/s41586-025-09047-2",
    "published": "",
    "summary": "<p>Nature, Published online: 04 June 2025; <a href=\"https://www.nature.com/articles/s41586-025-09047-2\">doi:10.1038/s41586-025-09047-2</a></p>Increased atmospheric evaporative demand in recent years has increased drought severity by an average of 40% globally across both dry and wet regions, and the trend is likely to continue under future warming scenarios.",
    "authors": [
      "Solomon H. Gebrechorkos",
      "Justin Sheffield",
      "Sergio M. Vicente-Serrano",
      "Chris Funk",
      "Diego G. Miralles",
      "Jian Peng",
      "Ellen Dyer",
      "Joshua Talib",
      "Hylke E. Beck",
      "Michael B. Singer",
      "Simon J. Dadson"
    ],
    "doi": "",
    "parser_type": "nature",
    "feed_priority": "high",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:33:57.538732"
  },
  {
    "id": "https://www.nature.com/articles/s41586-025-09087-8",
    "journal": "Nature",
    "title": "CREM is a regulatory checkpoint of CAR and IL-15 signalling in NK cells",
    "link": "https://www.nature.com/articles/s41586-025-09087-8",
    "published": "",
    "summary": "<p>Nature, Published online: 04 June 2025; <a href=\"https://www.nature.com/articles/s41586-025-09087-8\">doi:10.1038/s41586-025-09087-8</a></p>The transcription factor CREM is a pivotal regulator of NK cell function, making CREM a valuable target to increase the efficacy of anticancer immunotherapies based on this cell population and chimeric antigen receptors.",
    "authors": [
      "Hind Rafei",
      "Rafet Basar",
      "Sunil Acharya",
      "Yu-Sung Hsu",
      "Pinghua Liu",
      "Deqiang Zhang",
      "Toszka Bohn",
      "Qingnan Liang",
      "Vakul Mohanty",
      "Ranjan Upadhyay",
      "Ping Li",
      "Pravin Phadatare",
      "Merve Dede",
      "Donghai Xiong",
      "Huihui Fan",
      "Corry Mathew Jones",
      "Sebastian Kunz",
      "May Daher",
      "Ana Karen Nunez Cortes",
      "Mayra Shanley",
      "Bin Liu",
      "Sadie Mae Moseley",
      "Chenyu Zhang",
      "Dexing Fang",
      "Pinaki Banerjee",
      "Nadima Uprety",
      "Ye Li",
      "Rejeena Shrestha",
      "Xinhai Wan",
      "Hong Shen",
      "Vernikka Woods",
      "April Lamour Gilbert",
      "Seema Rawal",
      "Jinzhuang Dou",
      "Yukun Tan",
      "Jeong-Min Park",
      "Francia Reyes Silva",
      "Alexander Biederstädt",
      "Mecit Kaplan",
      "Xin Ru Jiang",
      "Inci Biederstädt",
      "Bijender Kumar",
      "Silvia Tiberti",
      "Madison Moore",
      "Jingling Jin",
      "Ryan Z. Yang",
      "Luis Muniz-Feliciano",
      "Samuel Rosemore",
      "Paul Lin",
      "Gary M. Deyter",
      "Natalie Wall Fowlkes",
      "Abhinav K. Jain",
      "David Marin",
      "Anirban Maitra",
      "Ken Chen",
      "Tobias Bopp",
      "Elizabeth J. Shpall",
      "Katayoun Rezvani"
    ],
    "doi": "",
    "parser_type": "nature",
    "feed_priority": "high",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:33:57.538737"
  },
  {
    "id": "https://www.nature.com/articles/s41586-025-09141-5",
    "journal": "Nature",
    "title": "Probing condensate microenvironments with a micropeptide killswitch",
    "link": "https://www.nature.com/articles/s41586-025-09141-5",
    "published": "",
    "summary": "<p>Nature, Published online: 04 June 2025; <a href=\"https://www.nature.com/articles/s41586-025-09141-5\">doi:10.1038/s41586-025-09141-5</a></p>Targeting a non-natural micropeptide ‘killswitch’ to several biomolecular condensates altered condensate compositions and revealed condensate functions in human cells",
    "authors": [
      "Yaotian Zhang",
      "Ida Stöppelkamp",
      "Pablo Fernandez-Pernas",
      "Melanie Allram",
      "Matthew Charman",
      "Alexandre P. Magalhaes",
      "Melanie Piedavent-Salomon",
      "Gregor Sommer",
      "Yu-Chieh Sung",
      "Katrina Meyer",
      "Nicholas Grams",
      "Edwin Halko",
      "Shivali Dongre",
      "David Meierhofer",
      "Michal Malszycki",
      "Ibrahim A. Ilik",
      "Tugce Aktas",
      "Matthew L. Kraushar",
      "Nadine Vastenhouw",
      "Matthew D. Weitzman",
      "Florian Grebien",
      "Henri Niskanen",
      "Denes Hnisz"
    ],
    "doi": "",
    "parser_type": "nature",
    "feed_priority": "high",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:33:57.538743"
  },
  {
    "id": "https://www.nature.com/articles/s41586-025-09125-5",
    "journal": "Nature",
    "title": "Loss of colonic fidelity enables multilineage plasticity and metastasis",
    "link": "https://www.nature.com/articles/s41586-025-09125-5",
    "published": "",
    "summary": "<p>Nature, Published online: 04 June 2025; <a href=\"https://www.nature.com/articles/s41586-025-09125-5\">doi:10.1038/s41586-025-09125-5</a></p>The chromatin-remodelling enzyme ATRX and the transcription factor HNF4A are identified as pivotal regulators of colonic epithelial identity, with roles in metastasis in colorectal cancer.",
    "authors": [
      "Patrizia Cammareri",
      "Michela Raponi",
      "Yourae Hong",
      "Caroline V. Billard",
      "Nat Peckett",
      "Yujia Zhu",
      "Fausto D. Velez-Bravo",
      "Nicholas T. Younger",
      "Donnchadh S. Dunican",
      "Sebastian Ö.-G. Pohl",
      "Aslihan Bastem Akan",
      "Nora J. Doleschall",
      "John Falconer",
      "Mark White",
      "Jean Quinn",
      "Kathryn Pennel",
      "Roberta Garau",
      "Sudhir B. Malla",
      "Philip D. Dunne",
      "Richard R. Meehan",
      "Owen J. Sansom",
      "Joanne Edwards",
      "Malcolm G. Dunlop",
      "Farhat V. N. Din",
      "Sabine Tejpar",
      "Colin W. Steele",
      "Kevin B. Myant"
    ],
    "doi": "",
    "parser_type": "nature",
    "feed_priority": "high",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:33:57.538749"
  },
  {
    "id": "https://www.nature.com/articles/s41586-025-09092-x",
    "journal": "Nature",
    "title": "A soft-clamped topological waveguide for phonons",
    "link": "https://www.nature.com/articles/s41586-025-09092-x",
    "published": "",
    "summary": "<p>Nature, Published online: 04 June 2025; <a href=\"https://www.nature.com/articles/s41586-025-09092-x\">doi:10.1038/s41586-025-09092-x</a></p>A substantial reduction of losses in a phononic waveguide can be achieved by soft clamping, through which phonons can be guided through very sharp turns with losses accounting for less than one phonon in a million.",
    "authors": [
      "Xiang Xi",
      "Ilia Chernobrovkin",
      "Jan Košata",
      "Mads B. Kristensen",
      "Eric Langman",
      "Anders S. Sørensen",
      "Oded Zilberberg",
      "Albert Schliesser"
    ],
    "doi": "",
    "parser_type": "nature",
    "feed_priority": "high",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:33:57.538755"
  },
  {
    "id": "https://www.nature.com/articles/s41586-025-08929-9",
    "journal": "Nature",
    "title": "Multi-timescale reinforcement learning in the brain",
    "link": "https://www.nature.com/articles/s41586-025-08929-9",
    "published": "",
    "summary": "<p>Nature, Published online: 04 June 2025; <a href=\"https://www.nature.com/articles/s41586-025-08929-9\">doi:10.1038/s41586-025-08929-9</a></p>Individual dopaminergic neurons encode future rewards over distinct temporal horizons.",
    "authors": [
      "Paul Masset",
      "Pablo Tano",
      "HyungGoo R. Kim",
      "Athar N. Malik",
      "Alexandre Pouget",
      "Naoshige Uchida"
    ],
    "doi": "",
    "parser_type": "nature",
    "feed_priority": "high",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:33:57.538759"
  },
  {
    "id": "https://www.nature.com/articles/s41586-025-09052-5",
    "journal": "Nature",
    "title": "Increased CSF drainage by non-invasive manipulation of cervical lymphatics",
    "link": "https://www.nature.com/articles/s41586-025-09052-5",
    "published": "",
    "summary": "<p>Nature, Published online: 04 June 2025; <a href=\"https://www.nature.com/articles/s41586-025-09052-5\">doi:10.1038/s41586-025-09052-5</a></p>The outflow pathway of cerebrospinal fluid into lymph nodes in the neck and how non-invasive mechanical stimulation can enhance drainage and restore impaired outflow in aged mice are explored.",
    "authors": [
      "Hokyung Jin",
      "Jin-Hui Yoon",
      "Seon Pyo Hong",
      "Yu Seok Hwang",
      "Myung Jin Yang",
      "Jieun Choi",
      "Hae Jin Kang",
      "Seung Eun Baek",
      "Cheolhwa Jin",
      "Junho Jung",
      "Hae Jin Kim",
      "Jincheol Seo",
      "Jinyoung Won",
      "Kyung Seob Lim",
      "Chang-Yeop Jeon",
      "Youngjeon Lee",
      "Michael J. Davis",
      "Hyung-Soon Park",
      "Donald M. McDonald",
      "Gou Young Koh"
    ],
    "doi": "",
    "parser_type": "nature",
    "feed_priority": "high",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:33:57.538765"
  },
  {
    "id": "https://www.nature.com/articles/s41586-025-08903-5",
    "journal": "Nature",
    "title": "Drivers of the extreme North Atlantic marine heatwave during 2023",
    "link": "https://www.nature.com/articles/s41586-025-08903-5",
    "published": "",
    "summary": "<p>Nature, Published online: 04 June 2025; <a href=\"https://www.nature.com/articles/s41586-025-08903-5\">doi:10.1038/s41586-025-08903-5</a></p>Atmospheric reanalyses combined with ocean observations and model simulations show that the extreme 2023 North Atlantic heatwave was primarily driven by anomalously weak winds leading to strongly shoaling mixed layers, with a smaller contribution from clearer skies.",
    "authors": [
      "Matthew H. England",
      "Zhi Li",
      "Maurice F. Huguenin",
      "Andrew E. Kiss",
      "Alex Sen Gupta",
      "Ryan M. Holmes",
      "Stefan Rahmstorf"
    ],
    "doi": "",
    "parser_type": "nature",
    "feed_priority": "high",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:33:57.538770"
  },
  {
    "id": "https://www.nature.com/articles/s41586-025-09071-2",
    "journal": "Nature",
    "title": "Concurrent loss of the Y chromosome in cancer and T cells impacts outcome",
    "link": "https://www.nature.com/articles/s41586-025-09071-2",
    "published": "",
    "summary": "<p>Nature, Published online: 04 June 2025; <a href=\"https://www.nature.com/articles/s41586-025-09071-2\">doi:10.1038/s41586-025-09071-2</a></p>Comprehensive pan-cancer analysis of loss of the Y chromosome (LOY) in benign and malignant cells establishes a new model linking LOY in circulating and tumour-infiltrating immune cells to LOY in malignant cells.",
    "authors": [
      "Xingyu Chen",
      "Yiling Shen",
      "Suhyeon Choi",
      "Hany A. Abdel-Hafiz",
      "Mukta Basu",
      "Lena Hoelzen",
      "Martina Tufano",
      "Saravana Kumar Kailasam Mani",
      "Maryam Ranjpour",
      "Jiani Zhu",
      "V. Krishnan Ramanujan",
      "Ekaterina K. Koltsova",
      "Vinicius F. Calsavara",
      "Simon R. V. Knott",
      "Dan Theodorescu"
    ],
    "doi": "",
    "parser_type": "nature",
    "feed_priority": "high",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:33:57.538776"
  },
  {
    "id": "https://www.nature.com/articles/s41586-025-09067-y",
    "journal": "Nature",
    "title": "Acetolysis for epoxy-amine carbon fibre-reinforced polymer recycling",
    "link": "https://www.nature.com/articles/s41586-025-09067-y",
    "published": "",
    "summary": "<p>Nature, Published online: 04 June 2025; <a href=\"https://www.nature.com/articles/s41586-025-09067-y\">doi:10.1038/s41586-025-09067-y</a></p>Acetic acid efficiently depolymerizes aliphatic and aromatic epoxy-amine thermosets used in carbon fibre-reinforced polymers (CFRPs) to yield recoverable monomers and pristine carbon fibres, which, based on process modelling, techno-economic analysis and life cycle assessment, could enable industrial recycling of CFRPs.",
    "authors": [
      "Ciaran W. Lahive",
      "Stephen H. Dempsey",
      "Sydney E. Reiber",
      "Ajinkya Pal",
      "Katherine R. Stevenson",
      "William E. Michener",
      "Hannah M. Alt",
      "Kelsey J. Ramirez",
      "Erik G. Rognerud",
      "Clarissa L. Lincoln",
      "Ryan W. Clarke",
      "Jason S. DesVeaux",
      "Taylor Uekert",
      "Nicholas A. Rorrer",
      "Katrina M. Knauer",
      "Gregg T. Beckham"
    ],
    "doi": "",
    "parser_type": "nature",
    "feed_priority": "high",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:33:57.538786"
  },
  {
    "id": "https://www.nature.com/articles/s41586-025-09093-w",
    "journal": "Nature",
    "title": "Structural insights into human Pol III transcription initiation in action",
    "link": "https://www.nature.com/articles/s41586-025-09093-w",
    "published": "",
    "summary": "<p>Nature, Published online: 04 June 2025; <a href=\"https://www.nature.com/articles/s41586-025-09093-w\">doi:10.1038/s41586-025-09093-w</a></p>Reconstitution of seven human RNA polymerase III (Pol III) transcribing complexes (TC4/5/6/8/10/12/13) halted on U6 promoters with nascent RNAs of 4–13 nucleotides offers molecular insights into Pol III dynamics.",
    "authors": [
      "Qianmin Wang",
      "Yulei Ren",
      "Qianwei Jin",
      "Xizi Chen",
      "Yanhui Xu"
    ],
    "doi": "",
    "parser_type": "nature",
    "feed_priority": "high",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:33:57.538791"
  },
  {
    "id": "https://www.nature.com/articles/s41586-025-09100-0",
    "journal": "Nature",
    "title": "Subnucleosome preference of human chromatin remodeller SMARCAD1",
    "link": "https://www.nature.com/articles/s41586-025-09100-0",
    "published": "",
    "summary": "<p>Nature, Published online: 04 June 2025; <a href=\"https://www.nature.com/articles/s41586-025-09100-0\">doi:10.1038/s41586-025-09100-0</a></p>Human chromatin remodeller SMARCAD1 exhibits a substrate preference for subnucleosomal particles over the canonical nucleosome.",
    "authors": [
      "Pengjing Hu",
      "Jingxi Sun",
      "Hongyao Sun",
      "Kangjing Chen",
      "Youyang Sia",
      "Xian Xia",
      "Qiaoran Xi",
      "Zhucheng Chen"
    ],
    "doi": "",
    "parser_type": "nature",
    "feed_priority": "high",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:33:57.538797"
  },
  {
    "id": "https://www.nature.com/articles/d41586-025-01699-4",
    "journal": "Nature",
    "title": "Clustering pattern of dwarf galaxies not predicted by models of cosmic structure formation",
    "link": "https://www.nature.com/articles/d41586-025-01699-4",
    "published": "",
    "summary": "<p>Nature, Published online: 04 June 2025; <a href=\"https://www.nature.com/articles/d41586-025-01699-4\">doi:10.1038/d41586-025-01699-4</a></p>A surprising pattern of spatial distribution was discovered in dwarf galaxies, whereby diffuse ones cluster more strongly than do compact ones — opposite to the trend seen in massive galaxies. This finding challenges standard models of the formation of galactic structures, calling for theories about the assembly of visible- and dark-matter structures to be revised.",
    "authors": [],
    "doi": "",
    "parser_type": "nature",
    "feed_priority": "high",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:33:57.538803"
  },
  {
    "id": "https://www.nature.com/articles/d41586-025-01456-7",
    "journal": "Nature",
    "title": "Iron deficiency in pregnant mice causes XY embryos to develop with female characteristics",
    "link": "https://www.nature.com/articles/d41586-025-01456-7",
    "published": "",
    "summary": "<p>Nature, Published online: 04 June 2025; <a href=\"https://www.nature.com/articles/d41586-025-01456-7\">doi:10.1038/d41586-025-01456-7</a></p>In mice, a lack of maternal iron impairs an iron-dependent enzyme that activates the male sex-determining gene, causing some XY embryos to develop ovaries.",
    "authors": [
      "Shannon Dupont",
      "Blanche Capel"
    ],
    "doi": "",
    "parser_type": "nature",
    "feed_priority": "high",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:33:57.538809"
  },
  {
    "id": "https://www.nature.com/articles/d41586-025-01739-z",
    "journal": "Nature",
    "title": "Science-integrity project will root out bad medical papers ‘and tell everyone’",
    "link": "https://www.nature.com/articles/d41586-025-01739-z",
    "published": "",
    "summary": "<p>Nature, Published online: 04 June 2025; <a href=\"https://www.nature.com/articles/d41586-025-01739-z\">doi:10.1038/d41586-025-01739-z</a></p>Group behind Retraction Watch aims to pinpoint the most influential flawed health data.",
    "authors": [
      "Nicola Jones"
    ],
    "doi": "",
    "parser_type": "nature",
    "feed_priority": "high",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:33:57.538816"
  },
  {
    "id": "https://www.nature.com/articles/d41586-025-01581-3",
    "journal": "Nature",
    "title": "Simulation of matter–antimatter creation on quantum platforms",
    "link": "https://www.nature.com/articles/d41586-025-01581-3",
    "published": "",
    "summary": "<p>Nature, Published online: 04 June 2025; <a href=\"https://www.nature.com/articles/d41586-025-01581-3\">doi:10.1038/d41586-025-01581-3</a></p>Two-dimensional quantum platforms have simulated a process in particle physics called string breaking that generates matter–antimatter pairs.",
    "authors": [
      "Michele Burrello"
    ],
    "doi": "",
    "parser_type": "nature",
    "feed_priority": "high",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:33:57.538834"
  },
  {
    "id": "https://www.nature.com/articles/d41586-025-01694-9",
    "journal": "Nature",
    "title": "Human factors",
    "link": "https://www.nature.com/articles/d41586-025-01694-9",
    "published": "",
    "summary": "<p>Nature, Published online: 04 June 2025; <a href=\"https://www.nature.com/articles/d41586-025-01694-9\">doi:10.1038/d41586-025-01694-9</a></p>A brief encounter.",
    "authors": [
      "John Gilbey"
    ],
    "doi": "",
    "parser_type": "nature",
    "feed_priority": "high",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:33:57.538839"
  },
  {
    "id": "https://www.nature.com/articles/d41586-025-01737-1",
    "journal": "Nature",
    "title": "Trump wants to put humans on Mars — here’s what scientists think",
    "link": "https://www.nature.com/articles/d41586-025-01737-1",
    "published": "",
    "summary": "<p>Nature, Published online: 04 June 2025; <a href=\"https://www.nature.com/articles/d41586-025-01737-1\">doi:10.1038/d41586-025-01737-1</a></p>Nature explores the massive costs and challenges of sending astronauts to the red planet.",
    "authors": [
      "Alexandra Witze"
    ],
    "doi": "",
    "parser_type": "nature",
    "feed_priority": "high",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:33:57.538846"
  },
  {
    "id": "https://www.nature.com/articles/d41586-025-01763-z",
    "journal": "Nature",
    "title": "Yvonne Choquet-Bruhat obituary: mathematician who established that Einstein’s equations mirror the real world",
    "link": "https://www.nature.com/articles/d41586-025-01763-z",
    "published": "",
    "summary": "<p>Nature, Published online: 04 June 2025; <a href=\"https://www.nature.com/articles/d41586-025-01763-z\">doi:10.1038/d41586-025-01763-z</a></p>Pioneer of general relativity and gravitational-wave theories saw her work confirmed by observations 65 years later.",
    "authors": [
      "Mihalis Dafermos"
    ],
    "doi": "",
    "parser_type": "nature",
    "feed_priority": "high",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:33:57.538853"
  },
  {
    "id": "https://www.nature.com/articles/d41586-025-01452-x",
    "journal": "Nature",
    "title": "Ancient carbon released through modern rivers",
    "link": "https://www.nature.com/articles/d41586-025-01452-x",
    "published": "",
    "summary": "<p>Nature, Published online: 04 June 2025; <a href=\"https://www.nature.com/articles/d41586-025-01452-x\">doi:10.1038/d41586-025-01452-x</a></p>A global analysis reveals that most carbon dioxide emitted by rivers derives not from modern plant material, as was thought, but from ancient, buried carbon.",
    "authors": [
      "Li Li"
    ],
    "doi": "",
    "parser_type": "nature",
    "feed_priority": "high",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:33:57.538858"
  },
  {
    "id": "https://www.nature.com/articles/d41586-025-01457-6",
    "journal": "Nature",
    "title": "Sticky membranes of dead red blood cells obstruct small vessels",
    "link": "https://www.nature.com/articles/d41586-025-01457-6",
    "published": "",
    "summary": "<p>Nature, Published online: 04 June 2025; <a href=\"https://www.nature.com/articles/d41586-025-01457-6\">doi:10.1038/d41586-025-01457-6</a></p>Damage to the vascular lining leads to interactions with red blood cells that hint at how to treat dangerous complications of heart attack, stroke and COVID-19.",
    "authors": [
      "Elizabeth Iffrig",
      "Wilbur A. Lam"
    ],
    "doi": "",
    "parser_type": "nature",
    "feed_priority": "high",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:33:57.538864"
  },
  {
    "id": "https://www.nature.com/articles/d41586-025-01738-0",
    "journal": "Nature",
    "title": "Genomics pioneer fired from firm he founded: ‘It was not easy to domesticate me’",
    "link": "https://www.nature.com/articles/d41586-025-01738-0",
    "published": "",
    "summary": "<p>Nature, Published online: 04 June 2025; <a href=\"https://www.nature.com/articles/d41586-025-01738-0\">doi:10.1038/d41586-025-01738-0</a></p>Kári Stefánsson, who last month left the Icelandic genetics company deCODE, spoke to Nature about his legacy.",
    "authors": [
      "Ewen Callaway"
    ],
    "doi": "",
    "parser_type": "nature",
    "feed_priority": "high",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:33:57.538870"
  },
  {
    "id": "https://www.nature.com/articles/d41586-025-01667-y",
    "journal": "Nature",
    "title": "How I’m bringing the voices of local fishers into ocean policies",
    "link": "https://www.nature.com/articles/d41586-025-01667-y",
    "published": "",
    "summary": "<p>Nature, Published online: 04 June 2025; <a href=\"https://www.nature.com/articles/d41586-025-01667-y\">doi:10.1038/d41586-025-01667-y</a></p>Fishing communities know what sustainability means. They must be at the decision table.",
    "authors": [
      "Gaoussou Gueye"
    ],
    "doi": "",
    "parser_type": "nature",
    "feed_priority": "high",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:33:57.538877"
  },
  {
    "id": "https://www.nature.com/articles/d41586-025-01726-4",
    "journal": "Nature",
    "title": "Stop ignoring small-scale fisheries in economic models",
    "link": "https://www.nature.com/articles/d41586-025-01726-4",
    "published": "",
    "summary": "<p>Nature, Published online: 04 June 2025; <a href=\"https://www.nature.com/articles/d41586-025-01726-4\">doi:10.1038/d41586-025-01726-4</a></p>Economic policies are lacking in data on small-scale fisheries. A team of researchers is determined to change that.",
    "authors": [],
    "doi": "",
    "parser_type": "nature",
    "feed_priority": "high",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:33:57.538882"
  },
  {
    "id": "https://www.nature.com/articles/d41586-025-01665-0",
    "journal": "Nature",
    "title": "Why we should protect the high seas from all extraction, forever",
    "link": "https://www.nature.com/articles/d41586-025-01665-0",
    "published": "",
    "summary": "<p>Nature, Published online: 04 June 2025; <a href=\"https://www.nature.com/articles/d41586-025-01665-0\">doi:10.1038/d41586-025-01665-0</a></p>Exploitation of the high seas risks doing irreversible damage to biodiversity, climate stability and ocean equity. A consensus must be built now to save them.",
    "authors": [
      "Callum M. Roberts",
      "Emilia Dyer",
      "Sylvia A. Earle",
      "Andrew Forrest",
      "Julie P. Hawkins",
      "Ove Hoegh-Guldberg",
      "Jessica J. Meeuwig",
      "Daniel Pauly",
      "Stuart L. Pimm",
      "U. Rashid Sumaila",
      "Johan Rockström",
      "Mark Lynas"
    ],
    "doi": "",
    "parser_type": "nature",
    "feed_priority": "high",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:33:57.538887"
  },
  {
    "id": "https://www.nature.com/articles/d41586-025-01450-z",
    "journal": "Nature",
    "title": "Y-chromosome loss in cancer and immune cells might worsen treatment outcomes",
    "link": "https://www.nature.com/articles/d41586-025-01450-z",
    "published": "",
    "summary": "<p>Nature, Published online: 04 June 2025; <a href=\"https://www.nature.com/articles/d41586-025-01450-z\">doi:10.1038/d41586-025-01450-z</a></p>Prognosis is poor for tumours with Y-chromosome loss. Examining the interplay between cancer and immune cells sheds light on potential mechanisms.",
    "authors": [
      "Nicholas McGranahan",
      "Rahul Roychoudhuri"
    ],
    "doi": "",
    "parser_type": "nature",
    "feed_priority": "high",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:33:57.538897"
  },
  {
    "id": "https://www.nature.com/articles/d41586-025-01740-6",
    "journal": "Nature",
    "title": "Male mice can grow ovaries if their pregnant mums are iron deficient",
    "link": "https://www.nature.com/articles/d41586-025-01740-6",
    "published": "",
    "summary": "<p>Nature, Published online: 04 June 2025; <a href=\"https://www.nature.com/articles/d41586-025-01740-6\">doi:10.1038/d41586-025-01740-6</a></p>The study is the first to show that low iron levels can affect fetal sexual development.",
    "authors": [
      "Rachel Fieldhouse"
    ],
    "doi": "",
    "parser_type": "nature",
    "feed_priority": "high",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:33:57.538902"
  },
  {
    "id": "https://www.nature.com/articles/d41586-025-01656-1",
    "journal": "Nature",
    "title": "Cancer more deadly when tumours lack Y chromosomes — and the loss could be contagious",
    "link": "https://www.nature.com/articles/d41586-025-01656-1",
    "published": "",
    "summary": "<p>Nature, Published online: 04 June 2025; <a href=\"https://www.nature.com/articles/d41586-025-01656-1\">doi:10.1038/d41586-025-01656-1</a></p>Losing the Y chromosome seems to make cancer cells more aggressive in men and the phenomenon might even spread between cells.",
    "authors": [
      "Liam Drew"
    ],
    "doi": "",
    "parser_type": "nature",
    "feed_priority": "high",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:33:57.538909"
  },
  {
    "id": "https://www.nature.com/articles/d41586-025-01689-6",
    "journal": "Nature",
    "title": "How a mysterious epidemic of kidney disease is killing thousands of young men",
    "link": "https://www.nature.com/articles/d41586-025-01689-6",
    "published": "",
    "summary": "<p>Nature, Published online: 04 June 2025; <a href=\"https://www.nature.com/articles/d41586-025-01689-6\">doi:10.1038/d41586-025-01689-6</a></p>Repeated damage from extreme heat over time seems to be a leading factor causing kidneys to fail.",
    "authors": [
      "Carrie Arnold"
    ],
    "doi": "",
    "parser_type": "nature",
    "feed_priority": "high",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:33:57.538915"
  },
  {
    "id": "https://www.nature.com/articles/d41586-025-01696-7",
    "journal": "Nature",
    "title": "Making robust integrated photonic qubits",
    "link": "https://www.nature.com/articles/d41586-025-01696-7",
    "published": "",
    "summary": "<p>Nature, Published online: 04 June 2025; <a href=\"https://www.nature.com/articles/d41586-025-01696-7\">doi:10.1038/d41586-025-01696-7</a></p>High-performance photonic integrated chips have been demonstrated that generate robust optical quantum bits called Gottesman–Kitaev–Preskill qubits. One such chip has been used to realize qubit states, reconstruct the quantum features of these states and verify the quality of the qubits.",
    "authors": [],
    "doi": "",
    "parser_type": "nature",
    "feed_priority": "high",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:33:57.538925"
  },
  {
    "id": "https://www.nature.com/articles/s41586-025-09129-1",
    "journal": "Nature",
    "title": "Author Correction: DNA-guided transcription factor interactions extend human gene regulatory code",
    "link": "https://www.nature.com/articles/s41586-025-09129-1",
    "published": "",
    "summary": "<p>Nature, Published online: 03 June 2025; <a href=\"https://www.nature.com/articles/s41586-025-09129-1\">doi:10.1038/s41586-025-09129-1</a></p>Author Correction: DNA-guided transcription factor interactions extend human gene regulatory code",
    "authors": [
      "Zhiyuan Xie",
      "Ilya Sokolov",
      "Maria Osmala",
      "Xue Yue",
      "Grace Bower",
      "J. Patrick Pett",
      "Yinan Chen",
      "Kai Wang",
      "Ayse Derya Cavga",
      "Alexander Popov",
      "Sarah A. Teichmann",
      "Ekaterina Morgunova",
      "Evgeny Z. Kvon",
      "Yimeng Yin",
      "Jussi Taipale"
    ],
    "doi": "",
    "parser_type": "nature",
    "feed_priority": "high",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:33:57.538931"
  },
  {
    "id": "https://www.nature.com/articles/s41586-025-09193-7",
    "journal": "Nature",
    "title": "Author Correction: Methane oxidation to ethanol by a molecular junction photocatalyst",
    "link": "https://www.nature.com/articles/s41586-025-09193-7",
    "published": "",
    "summary": "<p>Nature, Published online: 03 June 2025; <a href=\"https://www.nature.com/articles/s41586-025-09193-7\">doi:10.1038/s41586-025-09193-7</a></p>Author Correction: Methane oxidation to ethanol by a molecular junction photocatalyst",
    "authors": [
      "Jijia Xie",
      "Cong Fu",
      "Matthew G. Quesne",
      "Jian Guo",
      "Chao Wang",
      "Lunqiao Xiong",
      "Christopher D. Windle",
      "Srinivas Gadipelli",
      "Zheng Xiao Guo",
      "Weixin Huang",
      "C. Richard A. Catlow",
      "Junwang Tang"
    ],
    "doi": "",
    "parser_type": "nature",
    "feed_priority": "high",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:33:57.538936"
  },
  {
    "id": "https://www.nature.com/articles/d41586-025-01685-w",
    "journal": "Nature",
    "title": "Clever cockatoos learn an easy way to quench their thirst",
    "link": "https://www.nature.com/articles/d41586-025-01685-w",
    "published": "",
    "summary": "<p>Nature, Published online: 03 June 2025; <a href=\"https://www.nature.com/articles/d41586-025-01685-w\">doi:10.1038/d41586-025-01685-w</a></p>Some birds master the fine art of manoeuvring beak, feet and body weight to turn on a tap.",
    "authors": [],
    "doi": "",
    "parser_type": "nature",
    "feed_priority": "high",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:33:57.538942"
  },
  {
    "id": "https://www.nature.com/articles/d41586-025-01560-8",
    "journal": "Nature",
    "title": "Should there be a national holiday in honour of chemists?",
    "link": "https://www.nature.com/articles/d41586-025-01560-8",
    "published": "",
    "summary": "<p>Nature, Published online: 03 June 2025; <a href=\"https://www.nature.com/articles/d41586-025-01560-8\">doi:10.1038/d41586-025-01560-8</a></p>A proposal to bring science to the public’s attention, and Arctic explorers set sail in style in this week’s pick from the Nature archive.",
    "authors": [],
    "doi": "",
    "parser_type": "nature",
    "feed_priority": "high",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:33:57.538947"
  },
  {
    "id": "https://www.science.org/doi/10.1126/science.zogu8o8",
    "journal": "Science",
    "title": "U.S. college is first to decline federal science grants because of new DEI language",
    "link": "https://www.science.org/content/article/u-s-college-first-decline-federal-science-grants-because-new-dei-language",
    "published": "",
    "summary": "Williams College says NSF and NIH requirement related to discrimination “undermines” academic freedom",
    "authors": [
      "Jeffrey Mervis"
    ],
    "doi": "",
    "parser_type": "science",
    "feed_priority": "high",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:33:57.538957"
  },
  {
    "id": "https://www.science.org/doi/10.1126/science.z993pjy",
    "journal": "Science",
    "title": "‘A big win’: Dubious statistical results are becoming less common in psychology",
    "link": "https://www.science.org/content/article/big-win-dubious-statistical-results-are-becoming-less-common-psychology",
    "published": "",
    "summary": "Fewer papers are reporting findings on the border of statistical significance, a potential marker of dodgy research practices",
    "authors": [
      "Cathleen O’Grady"
    ],
    "doi": "",
    "parser_type": "science",
    "feed_priority": "high",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:33:57.538963"
  },
  {
    "id": "https://www.science.org/doi/10.1126/science.zc5z4r3",
    "journal": "Science",
    "title": "U.S. military trims access to its critical sea ice measurements",
    "link": "https://www.science.org/content/article/u-s-military-trims-access-its-critical-sea-ice-measurements",
    "published": "",
    "summary": "Data gaps come as Arctic sea ice shrinks to near-record lows",
    "authors": [
      "Paul Voosen"
    ],
    "doi": "",
    "parser_type": "science",
    "feed_priority": "high",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:33:57.538971"
  },
  {
    "id": "https://www.science.org/doi/10.1126/science.z5hi7qu",
    "journal": "Science",
    "title": "600 years before Europeans arrived, Great Lakes farmers transformed the land",
    "link": "https://www.science.org/content/article/600-years-europeans-arrived-great-lakes-farmers-transformed-land",
    "published": "",
    "summary": "Despite poor conditions, Indigenous growers used innovative techniques to grow large crops of corn, beans, and squash",
    "authors": [
      "Andrew Lawler"
    ],
    "doi": "",
    "parser_type": "science",
    "feed_priority": "high",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:33:57.538977"
  },
  {
    "id": "https://www.science.org/doi/10.1126/science.zmq4rob",
    "journal": "Science",
    "title": "Local predictions of climate change are hazy. But cities need answers fast",
    "link": "https://www.science.org/content/article/local-predictions-climate-change-are-hazy-cities-need-answers-fast",
    "published": "",
    "summary": "Scientists are figuring out where “downscaled” climate models struggle—and how they can be improved",
    "authors": [
      "Paul Voosen"
    ],
    "doi": "",
    "parser_type": "science",
    "feed_priority": "high",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:33:57.538983"
  },
  {
    "id": "https://www.science.org/doi/10.1126/science.zhcjc8d",
    "journal": "Science",
    "title": "Race, ethnicity don’t match genetic ancestry, according to a large U.S. study",
    "link": "https://www.science.org/content/article/race-ethnicity-don-t-match-genetic-ancestry-according-large-u-s-study",
    "published": "",
    "summary": "Data from the All of Us program confirm what many geneticists have long promoted",
    "authors": [
      "Rodrigo Pérez Ortega"
    ],
    "doi": "",
    "parser_type": "science",
    "feed_priority": "high",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:33:57.538990"
  },
  {
    "id": "https://www.science.org/doi/10.1126/science.zy8jpt8",
    "journal": "Science",
    "title": "Watch a tower of worms wriggle like a single organism",
    "link": "https://www.science.org/content/article/watch-tower-worms-wriggle-single-organism",
    "published": "",
    "summary": "Scientists film nematodes forming a superorganism in the wild for the first time",
    "authors": [
      "Gennaro Tomma"
    ],
    "doi": "",
    "parser_type": "science",
    "feed_priority": "high",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:33:57.538995"
  },
  {
    "id": "https://www.science.org/doi/10.1126/science.zjnmeo3",
    "journal": "Science",
    "title": "New National Academies board will wade into math wars",
    "link": "https://www.science.org/content/article/new-national-academies-board-will-wade-math-wars",
    "published": "",
    "summary": "Gates Foundation grant enables cash-strapped body to create unit seeking to bridge gap between mathematicians and math educators",
    "authors": [
      "Jeffrey Mervis"
    ],
    "doi": "",
    "parser_type": "science",
    "feed_priority": "high",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:33:57.539000"
  },
  {
    "id": "https://www.science.org/doi/10.1126/science.zbfqvo1",
    "journal": "Science",
    "title": "Some Dead Sea Scrolls are older than researchers thought, AI analysis suggests",
    "link": "https://www.science.org/content/article/some-dead-sea-scrolls-are-older-researchers-thought-ai-analysis-suggests",
    "published": "",
    "summary": "But overall, machine learning approach closely matches what human scholars had long suspected about ancient documents",
    "authors": [
      "Kristin Romey"
    ],
    "doi": "",
    "parser_type": "science",
    "feed_priority": "high",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:33:57.539005"
  },
  {
    "id": "https://www.science.org/doi/10.1126/science.zcexq4v",
    "journal": "Science",
    "title": "African countries fall far short of mpox vaccination targets",
    "link": "https://www.science.org/content/article/african-countries-fall-far-short-mpox-vaccination-targets",
    "published": "",
    "summary": "Continent faces a shortage of doses and distribution challenges",
    "authors": [
      "Jon Cohen"
    ],
    "doi": "",
    "parser_type": "science",
    "feed_priority": "high",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:33:57.539011"
  },
  {
    "id": "https://www.cell.com/cell/fulltext/S0092-8674(25)00510-0?rss=yes",
    "journal": "Cell",
    "title": "Advancing proteomic analysis for understanding disease biology and biomarker discovery",
    "link": "https://www.cell.com/cell/fulltext/S0092-8674(25)00510-0?rss=yes",
    "published": "",
    "summary": "Advances in proteomics research have enhanced our understanding of disease biology. In this issue of Cell, Malmström et al. construct a comprehensive proteome atlas linking proteins to specific tissues and blood cells to enable tracking of pathological changes and paving the way for broader applications in plasma proteomics across diverse diseases.",
    "authors": [
      "Carlos Cruchaga"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "high",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:33:57.539021"
  },
  {
    "id": "https://www.cell.com/cell/fulltext/S0092-8674(25)00504-5?rss=yes",
    "journal": "Cell",
    "title": "Transcription factor condensates: Preventing aggregation by DNA binding",
    "link": "https://www.cell.com/cell/fulltext/S0092-8674(25)00504-5?rss=yes",
    "published": "",
    "summary": "Transcription factors can form nuclear condensates at genomic sites, and condensates are thought to enhance transcriptional activity. In this issue of Cell, Saad et al. suggest that DNA binding prevents rather than facilitates condensate formation of particularly aggregation-prone transcription factors.",
    "authors": [
      "Alexandre P. Magalhaes, Denes Hnisz"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "high",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:33:57.539026"
  },
  {
    "id": "https://www.cell.com/cell/fulltext/S0092-8674(25)00503-3?rss=yes",
    "journal": "Cell",
    "title": "ExSPECKt the unexpected: NLRP3-caspase-8-dependent cell death in RBCs",
    "link": "https://www.cell.com/cell/fulltext/S0092-8674(25)00503-3?rss=yes",
    "published": "",
    "summary": "Red blood cell (RBC) lysis can cause morbidity and mortality. However, the molecular mechanisms underlying RBC lysis are not fully characterized, limiting therapeutic options. In this issue of Cell, Chen et al. identify a crucial role for the NLRP3-ASC-caspase-8 complex in driving programmed lytic cell death in RBCs.",
    "authors": [
      "Rebecca E. Tweedell, Thirumala-Devi Kanneganti"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "high",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:33:57.539031"
  },
  {
    "id": "https://www.cell.com/cell/fulltext/S0092-8674(25)00448-9?rss=yes",
    "journal": "Cell",
    "title": "The microbiome for clinicians",
    "link": "https://www.cell.com/cell/fulltext/S0092-8674(25)00448-9?rss=yes",
    "published": "",
    "summary": "Preclinical studies suggest a rapidly growing potential for the application of microbiome research in improving patient outcomes. This perspective lays out the potential steps that can be taken toward bridging the gap between preclinical research and clinical practice.",
    "authors": [
      "Serena Porcari, Siew C. Ng, Laurence Zitvogel, Harry Sokol, Rinse K. Weersma, Eran Elinav, Antonio Gasbarrini, Giovanni Cammarota, Herbert Tilg, Gianluca Ianiro"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "high",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:33:57.539037"
  },
  {
    "id": "https://www.cell.com/cell/fulltext/S0092-8674(25)00294-6?rss=yes",
    "journal": "Cell",
    "title": "A two-step self-pollination mechanism maximizes fertility in Brassicaceae",
    "link": "https://www.cell.com/cell/fulltext/S0092-8674(25)00294-6?rss=yes",
    "published": "",
    "summary": "A two-step pollination mechanism involving flower closure after opening significantly enhances the fertility of self-pollinating Brassicaceae plants under conditions of pollen limitation, fertilization failure, and environmental stress.",
    "authors": [
      "Pu Liu, Xin Quan, Zihan Song, Wenhao Li, Yuan Wang, Hongya Gu, Daoxin Xie, Weicai Yang, Thomas Dresselhaus, Sheng Zhong, Li-Jia Qu"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "high",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:33:57.539043"
  },
  {
    "id": "https://www.cell.com/cell/fulltext/S0092-8674(25)00297-1?rss=yes",
    "journal": "Cell",
    "title": "An Arabidopsis single-nucleus atlas decodes leaf senescence and nutrient allocation",
    "link": "https://www.cell.com/cell/fulltext/S0092-8674(25)00297-1?rss=yes",
    "published": "",
    "summary": "A comprehensive single-nucleus transcriptomic atlas of Arabidopsis across multiple tissues enables the quantification of leaf cell aging state at a single-cell level, highlighting the senescence-related hub genes and the construction of a nutrient allocation scenario among source leaves and sink organs.",
    "authors": [
      "Xing Guo, Yichuan Wang, Caiyao Zhao, Cong Tan, Wei Yan, Sunhuan Xiang, Dan Zhang, Hui Zhang, Mengting Zhang, Liujing Yang, Meng Yan, Pingli Xie, Yi Wang, Li Li, Dongming Fang, Xuanmin Guang, Wenwen Shao, Fang Wang, Haoxuan Wang, Sunil Kumar Sahu, Min Liu, Tong Wei, Yang Peng, Yuping Qiu, Tao Peng, Yi Zhang, Xuemei Ni, Zhicheng Xu, Haorong Lu, Zhonghai Li, Huanming Yang, Ertao Wang, Michael Lisby, Huan Liu, Hongwei Guo, Xun Xu"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "high",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:33:57.539048"
  },
  {
    "id": "https://www.cell.com/cell/fulltext/S0092-8674(25)00346-0?rss=yes",
    "journal": "Cell",
    "title": "Synthetic deconvolution of an auxin-dependent transcriptional code",
    "link": "https://www.cell.com/cell/fulltext/S0092-8674(25)00346-0?rss=yes",
    "published": "",
    "summary": "A synthetic-biology-driven approach deciphers the ARF-dependent transcriptional code and its contribution to specificity in gene expression in Arabidopsis, providing key insights into how the auxin developmental signal triggers distinct spatiotemporally resolved transcriptomic responses.",
    "authors": [
      "Raquel Martin-Arevalillo, Bruno Guillotin, Jonas Schön, Alice Hugues, Marie-France Gerentes, Kun Tang, Jérémy Lucas, Emmanuel Thévenon, Marianne Dreuillet, Graeme Vissers, Mohammed Mohammed Ateequr, Carlos S. Galvan-Ampudia, Guillaume Cerutti, Jonathan Legrand, Coralie Cance, Annick Dubois, François Parcy, Kenneth D. Birnbaum, Matias D. Zurbriggen, Renaud Dumas, François Roudier, Teva Vernoux"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "high",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:33:57.539054"
  },
  {
    "id": "https://www.cell.com/cell/fulltext/S0092-8674(25)00287-9?rss=yes",
    "journal": "Cell",
    "title": "Extensive N4 cytosine methylation is essential for Marchantia sperm function",
    "link": "https://www.cell.com/cell/fulltext/S0092-8674(25)00287-9?rss=yes",
    "published": "",
    "summary": "Global N4 cytosine methylation in Marchantia polymorpha sperm regulates gene expression and promotes sperm fertility.",
    "authors": [
      "James Walker, Jingyi Zhang, Yalin Liu, Shujuan Xu, Yiming Yu, Martin Vickers, Weizhi Ouyang, Judit Tálas, Liam Dolan, Keiji Nakajima, Xiaoqi Feng"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "high",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:33:57.539060"
  },
  {
    "id": "https://www.cell.com/cell/fulltext/S0092-8674(25)00289-2?rss=yes",
    "journal": "Cell",
    "title": "Extracellular respiration is a latent energy metabolism in Escherichia coli",
    "link": "https://www.cell.com/cell/fulltext/S0092-8674(25)00289-2?rss=yes",
    "published": "",
    "summary": "Escherichia coli can anaerobically respire and grow on an anode as the sole electron sink using a soluble redox mediator. The authors also introduce a generalizable methodology to investigate the mechanisms of mediated extracellular electron transfer in microbes.",
    "authors": [
      "Biki Bapi Kundu, Jayanth Krishnan, Richard Szubin, Arjun Patel, Bernhard O. Palsson, Daniel C. Zielinski, Caroline M. Ajo-Franklin"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "high",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:33:57.539065"
  },
  {
    "id": "https://www.cell.com/cell/fulltext/S0092-8674(25)00345-9?rss=yes",
    "journal": "Cell",
    "title": "Structure and infection dynamics of mycobacteriophage Bxb1",
    "link": "https://www.cell.com/cell/fulltext/S0092-8674(25)00345-9?rss=yes",
    "published": "",
    "summary": "Cryo-EM and cryo-ET reveal the structural details and conformational dynamics of mycobacteriophage Bxb1 as it infects its Mycobacterium smegmatis host.",
    "authors": [
      "Krista G. Freeman, Sudipta Mondal, Lourriel S. Macale, Jennifer Podgorski, Simon J. White, Benjamin H. Silva, Valery Ortiz, Alexis Huet, Ronelito J. Perez, Joemark T. Narsico, Meng-Chiao Ho, Deborah Jacobs-Sera, Todd L. Lowary, James F. Conway, Donghyun Park, Graham F. Hatfull"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "high",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:33:57.539080"
  },
  {
    "id": "https://www.cell.com/cell/fulltext/S0092-8674(25)00272-7?rss=yes",
    "journal": "Cell",
    "title": "Structural basis for plasticity in receptor engagement by an encephalitic alphavirus",
    "link": "https://www.cell.com/cell/fulltext/S0092-8674(25)00272-7?rss=yes",
    "published": "",
    "summary": "Cryoelectron microscopy and structure-guided mutagenesis experiments show that Western equine encephalitis virus (WEEV) engages distinct host receptors (VLDLR, PCDH10, and avian MXRA8) through a shared surface near the fusion loop of E1. Structural and evolutionary analyses facilitate the design of a sparrow PCDH10-Fc decoy that protects against all WEEV strains tested.",
    "authors": [
      "Saravanan Raju, Sathvik Palakurty, Alan Sariol, Ngan Wagoner, Lucas J. Adams, Sean Hui, William B. Klimstra, Daved H. Fremont, Michael S. Diamond"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "high",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:33:57.539089"
  },
  {
    "id": "https://www.cell.com/cell/fulltext/S0092-8674(25)00347-2?rss=yes",
    "journal": "Cell",
    "title": "Molecular basis for shifted receptor recognition by an encephalitic arbovirus",
    "link": "https://www.cell.com/cell/fulltext/S0092-8674(25)00347-2?rss=yes",
    "published": "",
    "summary": "Cryo-EM structures and mutational analyses reveal western equine encephalitis virus E2-E1 glycoprotein polymorphisms that determine shifted receptor usage and allow for sequence-based prediction of strain compatibility with human receptors.",
    "authors": [
      "Xiaoyi Fan, Wanyu Li, Jessica Oros, Jessica A. Plante, Brooke M. Mitchell, Jesse S. Plung, Himanish Basu, Sivapratha Nagappan-Chettiar, Joshua M. Boeckers, Laurentia V. Tjang, Colin J. Mann, Vesna Brusic, Tierra K. Buck, Haley Varnum, Pan Yang, Linzy M. Malcolm, So Yoen Choi, William M. de Souza, Isaac M. Chiu, Hisashi Umemori, Scott C. Weaver, Kenneth S. Plante, Jonathan Abraham"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "high",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:33:57.539094"
  },
  {
    "id": "https://www.cell.com/cell/fulltext/S0092-8674(25)00349-6?rss=yes",
    "journal": "Cell",
    "title": "DNA binding and mitotic phosphorylation protect polyglutamine proteins from assembly formation",
    "link": "https://www.cell.com/cell/fulltext/S0092-8674(25)00349-6?rss=yes",
    "published": "",
    "summary": "DNA binding and phosphorylation protect FOXP2, a transcription factor with the longest polyQ track in the proteome, from aggregation during interphase and mitosis. Harnessing these native solubility-promoting mechanisms utilized by FOXP2 diminishes aggregation and amyloid formation by the pathological form of Huntingtin polyQ.",
    "authors": [
      "Shady Saad, Tomek Swigut, Saman Tabatabaee, Pranav Lalgudi, Daniel F. Jarosz, Joanna Wysocka"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "high",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:33:57.539100"
  },
  {
    "id": "https://www.cell.com/cell/fulltext/S0092-8674(25)00400-3?rss=yes",
    "journal": "Cell",
    "title": "Long-term histone lactylation connects metabolic and epigenetic rewiring in innate immune memory",
    "link": "https://www.cell.com/cell/fulltext/S0092-8674(25)00400-3?rss=yes",
    "published": "",
    "summary": "Lactate production in innate immune cells can regulate both acute and long-term inflammatory responses. By modifying histone lactylation, lactate production leads to long-term epigenetic memory and regulation of secondary innate immune responses.",
    "authors": [
      "Athanasios Ziogas, Boris Novakovic, Lorenzo Ventriglia, Noriko Galang, Kim A. Tran, Wenchao Li, Vasiliki Matzaraki, Nienke van Unen, Titus Schlüter, Anaísa V. Ferreira, Simone J.C.F.M. Moorlag, Valerie A.C.M. Koeken, Mthabisi Moyo, Xiaolin Li, Marijke P.A. Baltissen, Joost H.A. Martens, Yang Li, Maziar Divangahi, Leo A.B. Joosten, Musa M. Mhlanga, Mihai G. Netea"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "high",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:33:57.539106"
  },
  {
    "id": "https://www.cell.com/cell/fulltext/S0092-8674(25)00389-7?rss=yes",
    "journal": "Cell",
    "title": "Red blood cells undergo lytic programmed cell death involving NLRP3",
    "link": "https://www.cell.com/cell/fulltext/S0092-8674(25)00389-7?rss=yes",
    "published": "",
    "summary": "Complement exposure induces programmed cell death of red blood cells due to the intracellular activation of miniNLRP3 and caspase-8. Inhibiting NLRP3 signaling reduces cytoskeletal damage and prevents hemolysis.",
    "authors": [
      "Yaozhen Chen, Shouwen Chen, Zhixin Liu, Yafen Wang, Ning An, Yutong Chen, Yihao Peng, Zheng Liu, Qin Liu, Xingbin Hu"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "high",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:33:57.539111"
  },
  {
    "id": "https://www.cell.com/cell/fulltext/S0092-8674(25)00295-8?rss=yes",
    "journal": "Cell",
    "title": "Optimizing stem cell infusion timing in the prevention of acute graft-versus-host disease",
    "link": "https://www.cell.com/cell/fulltext/S0092-8674(25)00295-8?rss=yes",
    "published": "",
    "summary": "Adjusting the timing of stem cell infusion can reduce the incidence and severity of acute graft-versus-host disease after allogeneic hematopoietic stem cell transplantation. The rhythmic fluctuations in inflammation levels before infusion dictate subsequent T cell responses, which may be a key factor underlying outcomes based on the time of day that transplantation occurs.",
    "authors": [
      "Yiwen Hou, Yue Wu, Yang Cao, Xiaoxia Hu, Yuqian Sun, Hongmei Wang, Liang Wang, Jialin Zhou, Zhonglin Zhang, Zhiwei Liu, Baolin Tang, Kaidi Song, Guangyu Sun, Wen Gao, Tianqi Zheng, Ping Wu, Weiwei Wu, Dapeng Ju, Xiaoyu Zhu, Cheng Zhan"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "high",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:33:57.539117"
  },
  {
    "id": "https://www.cell.com/cell/fulltext/S0092-8674(25)00513-6?rss=yes",
    "journal": "Cell",
    "title": "A suite of enhancer AAVs and transgenic mouse lines for genetic access to cortical cell types",
    "link": "https://www.cell.com/cell/fulltext/S0092-8674(25)00513-6?rss=yes",
    "published": "",
    "summary": "Ben-Simon et al. present a comprehensive toolkit of transgenic lines and enhancer AAVs for targeted study of mammalian cortical cell types, facilitating understanding of brain function in health and disease.",
    "authors": [
      "Yoav Ben-Simon, Marcus Hooper, Sujatha Narayan, Tanya L. Daigle, Deepanjali Dwivedi, Sharon W. Way, Aaron Oster, David A. Stafford, John K. Mich, Michael J. Taormina, Refugio A. Martinez, Ximena Opitz-Araya, Jada R. Roth, Jason R. Alexander, Shona Allen, Adam Amster, Joel Arbuckle, Angela Ayala, Pamela M. Baker, Trygve E. Bakken, Tyler Barcelli, Stuard Barta, Jacqueline Bendrick, Darren Bertagnolli, Cameron Bielstein, Prajal Bishwakarma, Jessica Bowlus, Gabriella Boyer, Krissy Brouner, Brittny Casian, Tamara Casper, Anish B. Chakka, Rushil Chakrabarty, Rebecca K. Chance, Sakshi Chavan, Michael Clark, Kaity Colbert, Forrest Collman, Scott Daniel, Maxwell Departee, Peter DiValentin, Nicholas Donadio, Nadezhda Dotson, Tom Egdorf, Tim Fliss, Mariano Gabitto, Jazmin Garcia, Amanda Gary, Molly Gasperini, Jessica Gloe, Jeff Goldy, Bryan B. Gore, Lucas Graybuck, Noah Greisman, Francoise Haeseleer, Carliana Halterman, Zeb Haradon, Samantha D. Hastings, Olivia Helback, Windy Ho, Dirk Hockemeyer, Cindy Huang, Sydney Huff, Avery Hunker, Nelson Johansen, Danielle Jones, Zoe Juneau, Brian Kalmbach, Madhav Kannan, Shannon Khem, Emily Kussick, Rana Kutsal, Rachael Larsen, Changkyu Lee, Angus Y. Lee, Madison Leibly, Garreck H. Lenz, Su Li, Elizabeth Liang, Nicholas Lusk, Zachary Madigan, Jessica Malloy, Jocelin Malone, Rachel McCue, Jose Melchor, Tyler Mollenkopf, Skyler Moosman, Elyse Morin, Dakota Newman, Lydia Ng, Kiet Ngo, Victoria Omstead, Sven Otto, Alana Oyama, Nick Pena, Trangthanh Pham, Elliot Phillips, Christina A. Pom, Lydia Potekhina, Shea Ransford, Patrick L. Ray, Dean Rette, Cade Reynoldson, Christine Rimorin, Dana Rocha, Augustin Ruiz, Raymond E.A. Sanchez, Lane Sawyer, Adriana Sedeno-Cortes, Joshua P. Sevigny, Nadiya Shapovalova, Noah Shepard, Lyudmila Shulga, Ana R. Sigler, La’Akea Siverts, Sherif Soliman, Saroja Somasundaram, Brian Staats, Kaiya Stewart, Eric Szelenyi, Michael Tieu, Cameron Trader, Alex Tran, Cindy T.J. van Velthoven, Miranda Walker, Yimin Wang, Natalie Weed, Morgan Wirthlin, Toren Wood, Brooke Wynalda, Zizhen Yao, Thomas Zhou, Jeanelle Ariza, Nick Dee, Melissa Reding, Kara Ronellenfitch, Shoaib Mufti, Susan M. Sunkin, Kimberly A. Smith, Luke Esposito, Jack Waters, Bargavi Thyagarajan, Shenqin Yao, Ed S. Lein, Hongkui Zeng, Boaz P. Levi, John Ngai, Jonathan T. Ting, Bosiljka Tasic"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "high",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:33:57.539123"
  },
  {
    "id": "https://www.cell.com/cell/fulltext/S0092-8674(25)00511-2?rss=yes",
    "journal": "Cell",
    "title": "Microbiome metabolism of dietary phytochemicals controls the anticancer activity of PI3K inhibitors",
    "link": "https://www.cell.com/cell/fulltext/S0092-8674(25)00511-2?rss=yes",
    "published": "",
    "summary": "Diet can impact anticancer drug activity. A classic example in rodents is a ketogenic diet enhancing PI3K inhibitor activity. Here, we show that phytochemicals and their microbiome derivatives, rather than macronutrient composition, underlie this phenomenon.",
    "authors": [
      "Asael Roichman, Qianying Zuo, Sunghoon Hwang, Wenyun Lu, Ricardo A. Cordova, Michael R. MacArthur, Jacob A. Boyer, Sarah J. Mitchell, Jesse Powers, Sophia A. Koval, Craig J. Hunter, Jamie Rijmers, Rolf-Peter Ryseck, Jenna E. AbuSalim, Seema Chatterjee, Won Dong Lee, Xincheng Xu, Xi Xing, Zihong Chen, Xianfeng Zeng, Siddharth Marwaha, Matthew J. McBride, Jessie Y. Guo, Yibin Kang, Mohamed S. Donia, Joshua D. Rabinowitz"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "high",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:33:57.539128"
  },
  {
    "id": "https://www.cell.com/cell/fulltext/S0092-8674(25)00291-0?rss=yes",
    "journal": "Cell",
    "title": "A single-cell atlas reveals immune heterogeneity in anti-PD-1-treated non-small cell lung cancer",
    "link": "https://www.cell.com/cell/fulltext/S0092-8674(25)00291-0?rss=yes",
    "published": "",
    "summary": "scRNA/TCR-seq analysis of 234 anti-PD-1-treated tumors identified immune heterogeneity associated with short-term pathological response and long-term recurrence-free survival.",
    "authors": [
      "Zedao Liu, Zhenlin Yang, Junqi Wu, Wenjie Zhang, Yuxuan Sun, Chao Zhang, Guangyu Bai, Li Yang, Hongtao Fan, Yawen Chen, Lei Zhang, Benyuan Jiang, Xiaoyan Liu, Xiaoshi Ma, Wei Tang, Chang Liu, Yang Qu, Lixu Yan, Deping Zhao, Yilong Wu, Shun He, Long Xu, Lishan Peng, Xiaowei Chen, Bolun Zhou, Liang Zhao, Zhangyi Zhao, Fengwei Tan, Wanting Zhang, Dingcheng Yi, Xiangjie Li, Qianqian Gao, Guangjian Zhang, Yongjie Wang, Minglei Yang, Honghao Fu, Yongjun Guo, Xueda Hu, Qingyuan Cai, Lu Qi, Yufei Bo, Hui Peng, Zhigang Tian, Yunlang She, Chang Zou, Linnan Zhu, Sijin Cheng, Yi Zhang, Wenzhao Zhong, Chang Chen, Shugeng Gao, Zemin Zhang"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "high",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:33:57.539134"
  },
  {
    "id": "https://www.pnas.org/doi/abs/10.1073/pnas.2511902122?af=R",
    "journal": "PNAS",
    "title": "Laser-induced graphene points to sustainable electronics",
    "link": "https://www.pnas.org/doi/abs/10.1073/pnas.2511902122?af=R",
    "published": "",
    "summary": "Proceedings of the National Academy of Sciences, Volume 122, Issue 22, June 2025. <br />",
    "authors": [
      "Stephen Ornes"
    ],
    "doi": "https://doi.org/abs/10.1073/pnas.2511902122",
    "parser_type": "pnas",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:33:57.539163"
  },
  {
    "id": "https://www.pnas.org/doi/abs/10.1073/pnas.2416061122?af=R",
    "journal": "PNAS",
    "title": "Evolution of the essential gene MN1 during the macroevolutionary transition toward patterning the vertebrate hindbrain",
    "link": "https://www.pnas.org/doi/abs/10.1073/pnas.2416061122?af=R",
    "published": "",
    "summary": "Proceedings of the National Academy of Sciences, Volume 122, Issue 22, June 2025. <br />SignificanceThe origin of the complex brain and skull in vertebrates is a major evolutionary innovation. The emergence of novel traits is driven by genome duplications and regulatory changes; however, the role of novel genes in this process remains less ...",
    "authors": [
      "Elio Escamilla-VegaLouk W. G. SetonStella KyomenAndrea P. Murillo-RincónJulian PetersenDiethard TautzMarkéta KauckáaMax Planck Institute for Evolutionary Biology, Plön 24306, GermanybDepartment of Orthodontics, University Leipzig Medical Center, Leipzig 04103, Germany"
    ],
    "doi": "https://doi.org/abs/10.1073/pnas.2416061122",
    "parser_type": "pnas",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:33:57.539255"
  },
  {
    "id": "https://www.pnas.org/doi/abs/10.1073/pnas.2501635122?af=R",
    "journal": "PNAS",
    "title": "Engineering a protease-stable, oral single-domain antibody to inhibit IL-23 signaling",
    "link": "https://www.pnas.org/doi/abs/10.1073/pnas.2501635122?af=R",
    "published": "",
    "summary": "Proceedings of the National Academy of Sciences, Volume 122, Issue 22, June 2025. <br />SignificanceDeveloping oral biologics has long been a holy grail of protein engineering. Traditional antibodies are large and unstable in the presence of gastrointestinal proteases. Here, we present a strategy to engineer potent, protease-stable single-...",
    "authors": [
      "Naruhisa OtaChristopher W. DaviesJing KangDonghong YanAlexis ScherlAnne WongRyan CookXun TaoDebra DunlapSha KlabundePriscilla MantikVishnu MohananWeiYu LinJacqueline McBrideShraddha SadekarKelly M. StorekPatrick LupardusZhengmao YeHeidi Ackerly WallweberJames R. KieferMin XuPamela ChanKarthik NagapudiTangsheng YiJames T. KoerberaDepartment of Immunology Discovery, Genentech, South San Francisco, CA 94080bAntibody Engineering, Genentech, South San Francisco, CA 94080cTranslational Immunology, Genentech, South San Francisco, CA 94080dPathology, Genentech, South San Francisco, CA 94080eBiochemical and Cellular Pharmacology, Genentech, South San Francisco, CA 94080fPreclinical and Translational Pharmacokinetics, Genentech, South San Francisco, CA 94080gTranslational Medicine, Genentech, South San Francisco, CA 94080hSmall Molecule Pharmaceutics, Genentech, South San Francisco, CA 94080iInfectious Diseases, Genentech, South San Francisco, CA 94080jStructural Biology, Genentech, South San Francisco, CA 94080"
    ],
    "doi": "https://doi.org/abs/10.1073/pnas.2501635122",
    "parser_type": "pnas",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:33:57.539312"
  },
  {
    "id": "https://www.pnas.org/doi/abs/10.1073/pnas.2426058122?af=R",
    "journal": "PNAS",
    "title": "Reversible molecular simulation for training classical and machine-learning force fields",
    "link": "https://www.pnas.org/doi/abs/10.1073/pnas.2426058122?af=R",
    "published": "",
    "summary": "Proceedings of the National Academy of Sciences, Volume 122, Issue 22, June 2025. <br />SignificanceThe success of a molecular dynamics simulation depends on the accuracy of the force field used to define the atomic interactions. It is challenging to train both classical and modern machine-learning force fields using the variety of ...",
    "authors": [
      "Joe G. GreeneraMedical Research Council Laboratory of Molecular Biology, Cambridge CB2 0QH, United Kingdom"
    ],
    "doi": "https://doi.org/abs/10.1073/pnas.2426058122",
    "parser_type": "pnas",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:33:57.539346"
  },
  {
    "id": "https://www.pnas.org/doi/abs/10.1073/pnas.2415069122?af=R",
    "journal": "PNAS",
    "title": "Nucleoporins cooperate with Polycomb silencers to promote transcriptional repression and repair at DNA double-strand breaks",
    "link": "https://www.pnas.org/doi/abs/10.1073/pnas.2415069122?af=R",
    "published": "",
    "summary": "Proceedings of the National Academy of Sciences, Volume 122, Issue 22, June 2025. <br />SignificanceEvidence points that DNA double-strand breaks (DSBs) mobilize to different nuclear compartments, notably to the nuclear periphery. This phenomenon, primarily characterized in yeast, is only beginning to be reported in mammalian cells, and its ...",
    "authors": [
      "Hongseon SongYubin BaeSangin KimDante DeascanisYujin LeeGergely RonaEthan LaneSeo-yeoung LeeSu-Jung KimMichele PaganoKyungjae MyungYounghoon KeeaDepartment of New Biology, Daegu Gyeongbuk Institute of Science and Technology, Daegu 42988, Republic of KoreabCenter for Genomic Integrity, Institute for Basic Science, Ulsan 44919, Republic of KoreacDepartment of Molecular Biosciences, College of Arts and Sciences, University of South Florida, Tampa, FL 33647dDepartment of Biochemistry and Molecular Pharmacology, New York University School of Medicine, New York, NY 10016eHHMI, New York University School of Medicine, New York, NY 10016fInstitute of Molecular Life Sciences, Hungarian Research Network Research Centre for Natural Sciences, Budapest 1117, HungarygDepartment of Biomedical Engineering, College of Information-Bio Convergence Engineering, Ulsan National Institute of Science and Technology, Ulsan 44919, Republic of Korea"
    ],
    "doi": "https://doi.org/abs/10.1073/pnas.2415069122",
    "parser_type": "pnas",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:33:57.539388"
  },
  {
    "id": "https://www.pnas.org/doi/abs/10.1073/pnas.2503641122?af=R",
    "journal": "PNAS",
    "title": "Label-free high-throughput live-cell sorting of genome-wide random mutagenesis libraries for metabolic traits by Raman flow cytometry",
    "link": "https://www.pnas.org/doi/abs/10.1073/pnas.2503641122?af=R",
    "published": "",
    "summary": "Proceedings of the National Academy of Sciences, Volume 122, Issue 22, June 2025. <br />SignificanceSorting cells with target metabolic functions from a mutant pool exhibiting substantial genetic diversity is often the rate-limiting step in synthetic biology. Here, we developed a label-free, high-throughput Raman-activated cell sorting ...",
    "authors": [
      "Xixian WangSen WangZhidian DiaoXibao HouYanhai GongQing SunJiaping ZhangLihui RenYuandong LiYuetong JiWei ShenYifeng YinShi HuangXiaojin SongQiu CuiYingang FengJian XuBo MaaState Key Laboratory of Photoelectric Conversion and Utilization of Solar Energy, Key Laboratory of Shandong Energy Biological Genetic Resources, Qingdao Institute of Bioenergy and Bioprocess Technology, Chinese Academy of Sciences, Qingdao 266101, ChinabShandong Energy Institute, Qingdao 266101, ChinacQingdao New Energy Shandong Laboratory, Qingdao 266101, ChinadUniversity of Chinese Academy of Sciences, Beijing 100049, ChinaeQingdao Engineering Laboratory of Single Cell Oil, Shandong Engineering Laboratory of Single Cell Oil, Qingdao 266101, ChinafQingdao Single-Cell Biotechnology Co., Ltd, Qingdao 266101, ChinageCyte, Inc, Sunnyvale, CA 94085hFaculty of Dentistry, University of Hong Kong, Hong Kong 999077, Special Administrative Region of China"
    ],
    "doi": "https://doi.org/abs/10.1073/pnas.2503641122",
    "parser_type": "pnas",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:33:57.539458"
  },
  {
    "id": "https://www.pnas.org/doi/abs/10.1073/pnas.2423286122?af=R",
    "journal": "PNAS",
    "title": "Phage-induced protection against lethal bacterial reinfection",
    "link": "https://www.pnas.org/doi/abs/10.1073/pnas.2423286122?af=R",
    "published": "",
    "summary": "Proceedings of the National Academy of Sciences, Volume 122, Issue 22, June 2025. <br />SignificanceIn 2021, antimicrobial-resistant bacteria were responsible for 1.14 million deaths and associated with 4.71 million deaths globally. Patients who experience sepsis often face a higher risk of reinfections and hospital readmissions. To combat ...",
    "authors": [
      "Yikun XingHaroldo J. Hernandez SantosLing QiuSamantha R. RitterJacob J. ZulkRachel LahowetzKathryn A. PatrasAusten L. TerwilligerAnthony W. MaressoaTAILOR Labs, Baylor College of Medicine, Houston, TX 77030bDepartment of Molecular Virology and Microbiology, Baylor College of Medicine, Houston, TX 77030cAlkek Center for Metagenomics and Microbiome Research, Baylor College of Medicine, Houston, TX 77030"
    ],
    "doi": "https://doi.org/abs/10.1073/pnas.2423286122",
    "parser_type": "pnas",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:33:57.539472"
  },
  {
    "id": "https://www.pnas.org/doi/abs/10.1073/pnas.2502876122?af=R",
    "journal": "PNAS",
    "title": "CRISPR screen reveals a simultaneous targeted mechanism to reduce cancer cell selenium and increase lipid oxidation to induce ferroptosis",
    "link": "https://www.pnas.org/doi/abs/10.1073/pnas.2502876122?af=R",
    "published": "",
    "summary": "Proceedings of the National Academy of Sciences, Volume 122, Issue 22, June 2025. <br />SignificanceFerroptosis is an iron-dependent cell death mechanism that results from increased oxidation of cell membrane lipids. We conducted a CRISPR-based positive selection screen in clear cell ovarian cancer cells treated with a nanoparticle drug to ...",
    "authors": [
      "Sophia M. LamperisKaylin M. McMahonAndrea E. CalvertJonathan S. RinkKarthik VasanMadhura R. PandkarEliana U. CrentsilZachary R. ChalmersNatalie R. McDonaldCameron J. KosmalaMarcelo G. BoniniDaniela MateiLeo I. GordonNavdeep S. ChandelC. Shad ThaxtonaDepartment of Urology, Northwestern University, Feinberg School of Medicine, Chicago, IL 60611bSimpson Querrey Institute for BioNanotechnology, Northwestern University, Feinberg School of Medicine, Chicago, IL 60611cRobert H. Lurie Comprehensive Cancer Center, Northwestern University, Feinberg School of Medicine, Chicago, IL 60611dDepartment of Medicine, Division of Hematology/Oncology, Northwestern University, Feinberg School of Medicine, Chicago, IL 60611eDepartment of Medicine, Division of Pulmonary and Critical Care Medicine, Northwestern University, Feinberg School of Medicine, Chicago, IL 60611fDepartment of Biochemistry and Molecular Genetics, Northwestern University, Feinberg School of Medicine, Chicago, IL 60611gDepartment of Obstetrics and Gynecology, Northwestern University, Feinberg School of Medicine, Chicago, IL 60611hJesse Brown Veteran Affairs Medical Center, Chicago, IL 60612"
    ],
    "doi": "https://doi.org/abs/10.1073/pnas.2502876122",
    "parser_type": "pnas",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:33:57.539478"
  },
  {
    "id": "https://www.pnas.org/doi/abs/10.1073/pnas.2502025122?af=R",
    "journal": "PNAS",
    "title": "Rhomboid-mediated cleavage of the immune receptor XA21 protects grain set and male fertility in rice",
    "link": "https://www.pnas.org/doi/abs/10.1073/pnas.2502025122?af=R",
    "published": "",
    "summary": "Proceedings of the National Academy of Sciences, Volume 122, Issue 22, June 2025. <br />SignificanceThe protection of key developmental processes from the immune system, while allowing the immune system to defend against pathogens, is central for the survival and reproduction of nearly all multicellular organisms. The rice immune receptor ...",
    "authors": [
      "Satyam VergishXiaoen HuangGuiyun ZhangBeatriz de Toledo FranceschiJian-Liang LiXiao-Xia WuJoana NurajJose C. Huguet-TapiaApekshya ParajuliXiuhua ChenRitu ShekharDali LiuWu-Ming XiaoShijuan DouGuo-zhen LiuErica M. GossLiya PiSixue ChenKaren E. KochWen-Yuan SongaDepartment of Plant Pathology, Institute of Food and Agricultural Sciences, University of Florida, Gainesville, FL 32611bIntegrative Bioinformatics, National Institute of Environmental Health Sciences, NIH, Research Triangle Park, NC 27709cCentro de Tecnologia Canavieira Genomics, Saint Louis, MO 63132dDepartment of Molecular Genetics and Microbiology, University of Florida, Gainesville, FL 32611eDepartment of Bioinformatics and Molecular Biology, College of Life Sciences, Hebei Agricultural University, Baoding, Hebei 071001, P. R. ChinafEmerging Pathogens Institute, University of Florida, Gainesville, FL 32610gDepartment of Pathology and Laboratory Medicine, Tulane University, New Orleans, LA 70112hDepartment of Biology, University of Mississippi, Oxford, MS 38677iDepartment of Biology, Genetics Institute, University of Florida, Gainesville, FL 32611jHorticultural Sciences Department, IFAS, University of Florida, Gainesville, FL 32611"
    ],
    "doi": "https://doi.org/abs/10.1073/pnas.2502025122",
    "parser_type": "pnas",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:33:57.539495"
  },
  {
    "id": "https://www.pnas.org/doi/abs/10.1073/pnas.2416723122?af=R",
    "journal": "PNAS",
    "title": "Genomic analyses identify 15 risk loci and reveal HDAC2, SOX2-OT, and IGF2BP2 in a naturally occurring canine model of gastric cancer",
    "link": "https://www.pnas.org/doi/abs/10.1073/pnas.2416723122?af=R",
    "published": "",
    "summary": "Proceedings of the National Academy of Sciences, Volume 122, Issue 22, June 2025. <br />SignificanceGastric cancer is the fifth most common cause of human cancer deaths, but the genetic underpinnings are poorly understood. Harnessing the genetic homogeneity of purebred dogs, we identify 18 loci governing gastric cancer susceptibility in a ...",
    "authors": [
      "Shawna R. CookSanne HugenJessica J. HaywardThomas R. FamulaJanelle M. BelangerElizabeth McNielHille FietenAnita M. OberbauerPeter A. J. LeegwaterElaine A. OstranderPaul J. J. MandigersJacquelyn M. EvansaBaker Institute for Animal Health, College of Veterinary Medicine, Cornell University, Ithaca, NY 14853bDepartment of Biomedical Sciences, College of Veterinary Medicine, Cornell University, Ithaca, NY 14853cExpertisecentre of Genetics, Department of Clinical Sciences, Utrecht University, Utrecht 3584 CM, The NetherlandsdDepartment of Animal Science, University of California, Davis, CA 95616eCummings School of Veterinary Medicine, Tufts University, Grafton, MA 01536fCancer Genetics and Comparative Genomics Branch, National Human Genome Research Institute, National Institutes of Health, Bethesda, MD 20892"
    ],
    "doi": "https://doi.org/abs/10.1073/pnas.2416723122",
    "parser_type": "pnas",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:33:57.539513"
  },
  {
    "id": "https://www.pnas.org/doi/abs/10.1073/pnas.2426192122?af=R",
    "journal": "PNAS",
    "title": "Further exploration of the principles and mechanisms of brainwashing",
    "link": "https://www.pnas.org/doi/abs/10.1073/pnas.2426192122?af=R",
    "published": "",
    "summary": "Proceedings of the National Academy of Sciences, Volume 122, Issue 22, June 2025. <br />",
    "authors": [
      "Haitao LiuHaogeng SunYi LiuaDepartment of Neurosurgery, West China Hospital, Sichuan University, Chengdu, Sichuan 610041, ChinabWest China Brain Research Centre, West China Hospital, Sichuan University, Chengdu, Sichuan 610041, China"
    ],
    "doi": "https://doi.org/abs/10.1073/pnas.2426192122",
    "parser_type": "pnas",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:33:57.539583"
  },
  {
    "id": "https://www.pnas.org/doi/abs/10.1073/pnas.2510049122?af=R",
    "journal": "PNAS",
    "title": "Correction for Bonetti et al., Quantum oscillations in the hole-doped cuprates and the confinement of spinons",
    "link": "https://www.pnas.org/doi/abs/10.1073/pnas.2510049122?af=R",
    "published": "",
    "summary": "Proceedings of the National Academy of Sciences, Volume 122, Issue 22, June 2025. <br />",
    "authors": [],
    "doi": "https://doi.org/abs/10.1073/pnas.2510049122",
    "parser_type": "pnas",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:33:57.539601"
  },
  {
    "id": "https://www.pnas.org/doi/abs/10.1073/pnas.2508245122?af=R",
    "journal": "PNAS",
    "title": "Correction for Lai et al., CIRCADIAN CLOCK-ASSOCIATED 1 regulates ROS homeostasis and oxidative stress responses",
    "link": "https://www.pnas.org/doi/abs/10.1073/pnas.2508245122?af=R",
    "published": "",
    "summary": "Proceedings of the National Academy of Sciences, Volume 122, Issue 22, June 2025. <br />",
    "authors": [],
    "doi": "https://doi.org/abs/10.1073/pnas.2508245122",
    "parser_type": "pnas",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:33:57.539618"
  },
  {
    "id": "oai:arXiv.org:2506.05769v1",
    "journal": "arXiv_QB",
    "title": "Connectome brain fingerprinting: terminology, measures, and target properties",
    "link": "https://arxiv.org/abs/2506.05769",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05769v1 Announce Type: new \nAbstract: Distinguishing one person from another (what biometricians call recognition) is extremely relevant for different aspects of life. Traditional biometric modalities (fingerprint, face, iris, voice) rely on unique, stable features that reliably differentiate individuals. Recently, the term fingerprinting has gained popularity in neuroscience, with a growing number of studies adopting the term to describe various brain based metrics derived from different techniques. However, we think there is a mismatch between its widely accepted meaning in the biometric community and some brain based metrics. Many of these measures do not satisfy the strict definition of a biometric fingerprint that is, a stable trait that uniquely identifies an individual. In this study we discuss some issues that may generate confusion in this context and suggest how to treat the question in the future. In particular, we review how fingerprint is currently used in the neuroscience literature, highlight mismatches with the biometric community definition, and offer clear guidelines for distinguishing genuine biometric fingerprints from exploratory similarity metrics. By clarifying terminology and criteria, we aim to align practices and facilitate communication across fields.",
    "authors": [
      "Matteo Fraschini, Matteo Demuru, Daniele Marinazzo, Luca Didaci"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:33:57.539676"
  },
  {
    "id": "oai:arXiv.org:2506.05992v1",
    "journal": "arXiv_QB",
    "title": "Cancer model with moving extinction threshold reproduces real cancer data",
    "link": "https://arxiv.org/abs/2506.05992",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05992v1 Announce Type: new \nAbstract: We propose a simple dynamic model of cancer development that captures carcinogenesis and subsequent cancer progression. A central idea of the model is to include the immune system as an extinction threshold, similar to the strong Allee effect in population biology. We first identify the limitations of commonly used Allee effect models in reproducing typical cancer progression. We then address these limitations by deriving a new model that incorporates: (i) random mutations of stem cells at a rate that increases with age and (ii) immune response whose strength may also vary over time.\n  Our model accurately reproduces a wide range of real-world cancer data: the typical age-specific cumulative risk of most human cancers, the progression of breast cancer in mice, and the unusual age-specific cumulative risk of breast cancer in women. In the last case, we use a moving extinction threshold to reflect the different immune response at different phases of the menstrual cycle and menopausal treatment. This provides new insights into the effects of hormone replacement therapy and menstrual cycle length. This moving threshold approach can be applied to a variety of other cancer scenarios where the immune response or other important factors may vary over time.",
    "authors": [
      "Frank Bastian, Hassan Alkhayuon, Kieran Mulchrone, Micheal O'Riordain, Sebastian Wieczorek"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:33:57.539693"
  },
  {
    "id": "oai:arXiv.org:2506.05768v1",
    "journal": "arXiv_QB",
    "title": "AANet: Virtual Screening under Structural Uncertainty via Alignment and Aggregation",
    "link": "https://arxiv.org/abs/2506.05768",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05768v1 Announce Type: cross \nAbstract: Virtual screening (VS) is a critical component of modern drug discovery, yet most existing methods--whether physics-based or deep learning-based--are developed around holo protein structures with known ligand-bound pockets. Consequently, their performance degrades significantly on apo or predicted structures such as those from AlphaFold2, which are more representative of real-world early-stage drug discovery, where pocket information is often missing. In this paper, we introduce an alignment-and-aggregation framework to enable accurate virtual screening under structural uncertainty. Our method comprises two core components: (1) a tri-modal contrastive learning module that aligns representations of the ligand, the holo pocket, and cavities detected from structures, thereby enhancing robustness to pocket localization error; and (2) a cross-attention based adapter for dynamically aggregating candidate binding sites, enabling the model to learn from activity data even without precise pocket annotations. We evaluated our method on a newly curated benchmark of apo structures, where it significantly outperforms state-of-the-art methods in blind apo setting, improving the early enrichment factor (EF1%) from 11.75 to 37.19. Notably, it also maintains strong performance on holo structures. These results demonstrate the promise of our approach in advancing first-in-class drug discovery, particularly in scenarios lacking experimentally resolved protein-ligand complexes.",
    "authors": [
      "Wenyu Zhu, Jianhui Wang, Bowen Gao, Yinjun Jia, Haichuan Tan, Ya-Qin Zhang, Wei-Ying Ma, Yanyan Lan"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:33:57.539759"
  },
  {
    "id": "oai:arXiv.org:2506.06265v1",
    "journal": "arXiv_QB",
    "title": "Integrating Complexity and Biological Realism: High-Performance Spiking Neural Networks for Breast Cancer Detection",
    "link": "https://arxiv.org/abs/2506.06265",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06265v1 Announce Type: cross \nAbstract: Spiking Neural Networks (SNNs) event-driven nature enables efficient encoding of spatial and temporal features, making them suitable for dynamic time-dependent data processing. Despite their biological relevance, SNNs have seen limited application in medical image recognition due to difficulties in matching the performance of conventional deep learning models. To address this, we propose a novel breast cancer classification approach that combines SNNs with Lempel-Ziv Complexity (LZC) a computationally efficient measure of sequence complexity. LZC enhances the interpretability and accuracy of spike-based models by capturing structural patterns in neural activity. Our study explores both biophysical Leaky Integrate-and-Fire (LIF) and probabilistic Levy-Baxter (LB) neuron models under supervised, unsupervised, and hybrid learning regimes. Experiments were conducted on the Breast Cancer Wisconsin dataset using numerical features derived from medical imaging. LB-based models consistently exceeded 90.00% accuracy, while LIF-based models reached over 85.00%. The highest accuracy of 98.25% was achieved using an ANN-to-SNN conversion method applied to both neuron models comparable to traditional deep learning with back-propagation, but at up to 100 times lower computational cost. This hybrid approach merges deep learning performance with the efficiency and plausibility of SNNs, yielding top results at lower computational cost. We hypothesize that the synergy between temporal-coding, spike-sparsity, and LZC-driven complexity analysis enables more-efficient feature extraction. Our findings demonstrate that SNNs combined with LZC offer promising, biologically plausible alternative to conventional neural networks in medical diagnostics, particularly for resource-constrained or real-time systems.",
    "authors": [
      "Zofia Rudnicka, Januszcz Szczepanski, Agnieszka Pregowska"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:33:57.539771"
  },
  {
    "id": "oai:arXiv.org:2504.19565v2",
    "journal": "arXiv_QB",
    "title": "m-KAILIN: Knowledge-Driven Agentic Scientific Corpus Distillation Framework for Biomedical Large Language Models Training",
    "link": "https://arxiv.org/abs/2504.19565",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2504.19565v2 Announce Type: replace-cross \nAbstract: Corpus distillation for biomedical large language models (LLMs) seeks to address the pressing challenge of insufficient quantity and quality in open-source annotated scientific corpora, which remains a bottleneck for effective LLM training in biomedical research. This paper proposes a knowledge-driven, agentic framework for scientific corpus distillation, tailored explicitly for LLM training in the biomedical domain, addressing the challenge posed by the complex hierarchy of biomedical knowledge. Central to our approach is a collaborative multi-agent architecture, where specialized agents, each guided by the Medical Subject Headings (MeSH) hierarchy, work in concert to autonomously extract, synthesize, and self-evaluate high-quality textual data from vast scientific literature. This agentic framework collectively generates and refines domain-specific question-answer pairs, ensuring comprehensive coverage and consistency with biomedical ontologies while minimizing manual involvement. Extensive experimental results show that language models trained on our multi-agent distilled datasets achieve notable improvements in biomedical question-answering tasks, outperforming both strong life sciences LLM baselines and advanced proprietary models. Notably, our AI-Ready dataset enables Llama3-70B to surpass GPT-4 with MedPrompt and Med-PaLM-2, despite their larger scale. Detailed ablation studies and case analyses further validate the effectiveness and synergy of each agent within the framework, highlighting the potential of multi-agent collaboration in biomedical LLM training.",
    "authors": [
      "Meng Xiao, Xunxin Cai, Qingqing Long, Chengrui Wang, Yuanchun Zhou, Hengshu Zhu"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:33:57.539812"
  },
  {
    "id": "https://journals.plos.org/plosone/feed/10.1371/journal.pone.0325971",
    "journal": "PLoS_ONE",
    "title": "Editorial Note: Machine learning model for predicting the optimal depth of tracheal tube insertion in pediatric patients: A retrospective cohort study",
    "link": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0325971",
    "published": "2025-06-06T14:00:00Z",
    "summary": "<p>by The PLOS One Editors </p>",
    "authors": [
      "The PLOS One Editors"
    ],
    "doi": "",
    "parser_type": "plos",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:33:57.539824"
  },
  {
    "id": "https://journals.plos.org/plosone/feed/10.1371/journal.pone.0325510",
    "journal": "PLoS_ONE",
    "title": "The effects of visual stimulation on the cortical activity of brainstem stroke dysphagia patients: A functional near-infrared spectroscopy study",
    "link": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0325510",
    "published": "2025-06-06T14:00:00Z",
    "summary": "<p>by Dandan Zhao, Yancun Li, Keyi Ning, Bingjie Zou, Bin Wang, Libo Li, Qiaojun Zhang, Yanping Hui</p>\nObjective <p>To investigate the difference in cortical activity under food visual stimulation between patients with brainstem stroke dysphagia and healthy adults by using functional near-infrared spectroscopy (fNIRS). Additionally, we seek to identify any potential relationship between cortical activity and swallowing.</p> Methods <p>30 patients with dysphagia after brainstem stroke and 16 healthy adults were selected. The fNIRS was used to assess the functional connection strength of global and ROIs brain regions at rest, as well as the mean change in oxygenated hemoglobin concentration (ΔHbO<sub>2</sub>) during the food visual stimulation task in both groups.</p> Results <p>In the resting state, the functional connection strength of healthy adults (X―=0.514, s=0.021) was higher than that of patients (X―=0.472, s=0.009) (P < 0.05). In comparison, functional connectivity in the ROI brain region was enhanced in the patient group compared to the healthy adult group. In the task state, the patient’s ΔHbO<sub>2</sub> concentration in the left Frontopolar area, right Frontopolar area, left Orbitofrontal area and left Dorsolateral prefrontal cortex dramatically decreased in comparison to the healthy adult group. The correlation analysis revealed a moderate negative correlation between SSA and the MMSE score, VAS score, and the average ΔHbO<sub>2</sub> concentrations in specific brain regions, including the right Frontopolar area, left Frontopolar area, left Orbitofrontal area, and left DLPFC. Furthermore, the VAS scores exhibited a moderate positive correlation with the average ΔHbO<sub>2</sub> concentrations in the right Frontopolar area, left Frontopolar area, left Orbitofrontal area, and left DLPFC.</p> Conclusion <p>Patients with brainstem stroke dysphagia showed reduced activity during visual stimulation in the Frontopolar region, the left Orbitofrontal area, and the left Dorsolateral prefrontal cortex as compared to healthy individuals. The overall strength of functional connections was decreased, while the ROI between different brain areas increased. Following a brain stem stroke, all of these might be related to pre-oral swallowing issues.</p>",
    "authors": [
      "Dandan Zhao",
      "Yancun Li",
      "Keyi Ning",
      "Bingjie Zou",
      "Bin Wang",
      "Libo Li",
      "Qiaojun Zhang",
      "Yanping Hui"
    ],
    "doi": "",
    "parser_type": "plos",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:33:57.539930"
  },
  {
    "id": "https://journals.plos.org/plosone/feed/10.1371/journal.pone.0325454",
    "journal": "PLoS_ONE",
    "title": "Strategic risk analysis for the selection of stable and high-potential maize genotypes in multi-environment trials",
    "link": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0325454",
    "published": "2025-06-06T14:00:00Z",
    "summary": "<p>by Mohammadreza Shiri, Sajjad Moharramnejad, Afshar Estakhr, Sharareh Fareghi, Hamid Najafinezhad, Saeed Khavari Khorasani, Aziz Afarinesh, Morteza Eshraghi-Nejad</p>\n\nPlant breeders are increasingly utilizing stability parameters as valuable tools for selecting cultivars in the context of genotype × environment interaction (GEI). Neglecting GEI in multi-environment trials (MET) can significantly heighten the risk of making inaccurate cultivar recommendations to farmers. Consequently, breeders must strive to find an optimal balance between yield and stability, favoring varieties that minimize the risk of extremely low yields. Recent advancements in probability theory, along with specialized software packages, have made the decision-making process more efficient for identifying suitable candidates across diverse environments. Under this scenario, a study was conducted to evaluate 15 promising maize hybrids alongside one control commercial hybrid (hybrid No. 16). The research employed a randomized complete block design with four replications across eight diverse locations over two consecutive years. The hybrids evaluated resulted from crosses involving temperate × temperate and tropical/subtropical × temperate. The objectives of this research included estimating the stability of these hybrids and assessing the associated risks related to their release, as well as evaluating the success and potential of lines derived from subtropical and tropical materials. A Bayesian approach was applied to estimate the probability that each genotype outperformed its competitors. The variance component estimates indicated that “location” was the most significant factor influencing overall variability, with values of 0.756 for genotype, 11.304 for location, and 0.621 for genotype × location effects. To enhance the mean grain yield within the selection panel, a selection intensity of 20% was implemented based on computed probabilities of superior performance and stability among selected candidates. Hybrid H2 exhibited the highest probability of superior performance (0.99), closely followed by Hybrid H5 with 0.97 of probability of belonging to the top subset. Hybrid H2 outperformed hybrid H16 (check hybrid) in all cases across tested environments; however, it demonstrated lower stability in 55% of comparisons. This finding suggests that the hypothesis asserting H2’s superiority over H16 in both stability and performance was not supported. H5 was the only hybrids common to both the top-performing (H2, H5, H4, H3) and most stable (H13, H15, H5, H7) groups. It is essential for breeders to jointly consider the probabilities of superior performance and stability when determining optimal genotypes. Considering the joint probability of superior performance and yield stability, the hybrids H5, H4, H15 and H2 stand out. High-performing and stable hybrids like H5 and H2 reduce cultivar introduction risks. Overall, these results indicated that employing a risk/probability analysis approach can significantly enhance decision-making accuracy for cultivar recommendations in METs.",
    "authors": [
      "Mohammadreza Shiri",
      "Sajjad Moharramnejad",
      "Afshar Estakhr",
      "Sharareh Fareghi",
      "Hamid Najafinezhad",
      "Saeed Khavari Khorasani",
      "Aziz Afarinesh",
      "Morteza Eshraghi-Nejad"
    ],
    "doi": "",
    "parser_type": "plos",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:33:57.539963"
  },
  {
    "id": "oai:arXiv.org:2506.05356v1",
    "journal": "arXiv_CS",
    "title": "AI-Driven Dynamic Firewall Optimization Using Reinforcement Learning for Anomaly Detection and Prevention",
    "link": "https://arxiv.org/abs/2506.05356",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05356v1 Announce Type: new \nAbstract: The growing complexity of cyber threats has rendered static firewalls increasingly ineffective for dynamic, real-time intrusion prevention. This paper proposes a novel AI-driven dynamic firewall optimization framework that leverages deep reinforcement learning (DRL) to autonomously adapt and update firewall rules in response to evolving network threats. Our system employs a Markov Decision Process (MDP) formulation, where the RL agent observes network states, detects anomalies using a hybrid LSTM-CNN model, and dynamically modifies firewall configurations to mitigate risks. We train and evaluate our framework on the NSL-KDD and CIC-IDS2017 datasets using a simulated software-defined network environment. Results demonstrate significant improvements in detection accuracy, false positive reduction, and rule update latency when compared to traditional signature- and behavior-based firewalls. The proposed method provides a scalable, autonomous solution for enhancing network resilience against complex attack vectors in both enterprise and critical infrastructure settings.",
    "authors": [
      "Taimoor Ahmad"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.834125"
  },
  {
    "id": "oai:arXiv.org:2506.05369v1",
    "journal": "arXiv_CS",
    "title": "MR.NAVI: Mixed-Reality Navigation Assistant for the Visually Impaired",
    "link": "https://arxiv.org/abs/2506.05369",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05369v1 Announce Type: new \nAbstract: Over 43 million people worldwide live with severe visual impairment, facing significant challenges in navigating unfamiliar environments. We present MR.NAVI, a mixed reality system that enhances spatial awareness for visually impaired users through real-time scene understanding and intuitive audio feedback. Our system combines computer vision algorithms for object detection and depth estimation with natural language processing to provide contextual scene descriptions, proactive collision avoidance, and navigation instructions. The distributed architecture processes sensor data through MobileNet for object detection and employs RANSAC-based floor detection with DBSCAN clustering for obstacle avoidance. Integration with public transit APIs enables navigation with public transportation directions. Through our experiments with user studies, we evaluated both scene description and navigation functionalities in unfamiliar environments, showing promising usability and effectiveness.",
    "authors": [
      "Nicolas Pfitzer, Yifan Zhou, Marco Poggensee, Defne Kurtulus, Bessie Dominguez-Dager, Mihai Dusmanu, Marc Pollefeys, Zuria Bauer"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.834192"
  },
  {
    "id": "oai:arXiv.org:2506.05370v1",
    "journal": "arXiv_CS",
    "title": "Contextual Memory Intelligence -- A Foundational Paradigm for Human-AI Collaboration and Reflective Generative AI Systems",
    "link": "https://arxiv.org/abs/2506.05370",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05370v1 Announce Type: new \nAbstract: A critical challenge remains unresolved as generative AI systems are quickly implemented in various organizational settings. Despite significant advances in memory components such as RAG, vector stores, and LLM agents, these systems still have substantial memory limitations. Gen AI workflows rarely store or reflect on the full context in which decisions are made. This leads to repeated errors and a general lack of clarity. This paper introduces Contextual Memory Intelligence (CMI) as a new foundational paradigm for building intelligent systems. It repositions memory as an adaptive infrastructure necessary for longitudinal coherence, explainability, and responsible decision-making rather than passive data. Drawing on cognitive science, organizational theory, human-computer interaction, and AI governance, CMI formalizes the structured capture, inference, and regeneration of context as a fundamental system capability. The Insight Layer is presented in this paper to operationalize this vision. This modular architecture uses human-in-the-loop reflection, drift detection, and rationale preservation to incorporate contextual memory into systems. The paper argues that CMI allows systems to reason with data, history, judgment, and changing context, thereby addressing a foundational blind spot in current AI architectures and governance efforts. A framework for creating intelligent systems that are effective, reflective, auditable, and socially responsible is presented through CMI. This enhances human-AI collaboration, generative AI design, and the resilience of the institutions.",
    "authors": [
      "Kristy Wedel"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.834200"
  },
  {
    "id": "oai:arXiv.org:2506.05383v1",
    "journal": "arXiv_CS",
    "title": "Can Vision Transformers with ResNet's Global Features Fairly Authenticate Demographic Faces?",
    "link": "https://arxiv.org/abs/2506.05383",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05383v1 Announce Type: new \nAbstract: Biometric face authentication is crucial in computer vision, but ensuring fairness and generalization across demographic groups remains a big challenge. Therefore, we investigated whether Vision Transformer (ViT) and ResNet, leveraging pre-trained global features, can fairly authenticate different demographic faces while relying minimally on local features. In this investigation, we used three pre-trained state-of-the-art (SOTA) ViT foundation models from Facebook, Google, and Microsoft for global features as well as ResNet-18. We concatenated the features from ViT and ResNet, passed them through two fully connected layers, and trained on customized face image datasets to capture the local features. Then, we designed a novel few-shot prototype network with backbone features embedding. We also developed new demographic face image support and query datasets for this empirical study. The network's testing was conducted on this dataset in one-shot, three-shot, and five-shot scenarios to assess how performance improves as the size of the support set increases. We observed results across datasets with varying races/ethnicities, genders, and age groups. The Microsoft Swin Transformer backbone performed better among the three SOTA ViT for this task. The code and data are available at: https://github.com/Sufianlab/FairVitBio.",
    "authors": [
      "Abu Sufian, Marco Leo, Cosimo Distante, Anirudha Ghosh, Debaditya Barman"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.834306"
  },
  {
    "id": "oai:arXiv.org:2506.05384v1",
    "journal": "arXiv_CS",
    "title": "Q-Ponder: A Unified Training Pipeline for Reasoning-based Visual Quality Assessment",
    "link": "https://arxiv.org/abs/2506.05384",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05384v1 Announce Type: new \nAbstract: Recent studies demonstrate that multimodal large language models (MLLMs) can proficiently evaluate visual quality through interpretable assessments. However, existing approaches typically treat quality scoring and reasoning descriptions as separate tasks with disjoint optimization objectives, leading to a trade-off: models adept at quality reasoning descriptions struggle with precise score regression, while score-focused models lack interpretability. This limitation hinders the full potential of MLLMs in visual quality assessment, where accuracy and interpretability should be mutually reinforcing. To address this, we propose a unified two-stage training framework comprising a cold-start stage and a reinforcement learning-based fine-tuning stage. Specifically, in the first stage, we distill high-quality data from a teacher model through expert-designed prompts, initializing reasoning capabilities via cross-entropy loss supervision. In the second stage, we introduce a novel reward with Group Relative Policy Optimization (GRPO) to jointly optimize scoring accuracy and reasoning consistency. We designate the models derived from these two stages as Q-Ponder-CI and Q-Ponder. Extensive experiments show that Q-Ponder achieves state-of-the-art (SOTA) performance on quality score regression benchmarks, delivering up to 6.5% higher SRCC on cross-domain datasets. Furthermore, Q-Ponder significantly outperforms description-based SOTA models, including its teacher model Qwen-2.5-VL-72B, particularly in description accuracy and reasonableness, demonstrating the generalization potential over diverse tasks.",
    "authors": [
      "Zhuoxuan Cai, Jian Zhang, Xinbin Yuan, Pengtao Jiang, Wenxiang Chen, Bowen Tang, Lujian Yao, Qiyuan Wang, Jinwen Chen, Bo Li"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.834313"
  },
  {
    "id": "oai:arXiv.org:2506.05390v1",
    "journal": "arXiv_CS",
    "title": "Understanding Gender Bias in AI-Generated Product Descriptions",
    "link": "https://arxiv.org/abs/2506.05390",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05390v1 Announce Type: new \nAbstract: While gender bias in large language models (LLMs) has been extensively studied in many domains, uses of LLMs in e-commerce remain largely unexamined and may reveal novel forms of algorithmic bias and harm. Our work investigates this space, developing data-driven taxonomic categories of gender bias in the context of product description generation, which we situate with respect to existing general purpose harms taxonomies. We illustrate how AI-generated product descriptions can uniquely surface gender biases in ways that require specialized detection and mitigation approaches. Further, we quantitatively analyze issues corresponding to our taxonomic categories in two models used for this task -- GPT-3.5 and an e-commerce-specific LLM -- demonstrating that these forms of bias commonly occur in practice. Our results illuminate unique, under-explored dimensions of gender bias, such as assumptions about clothing size, stereotypical bias in which features of a product are advertised, and differences in the use of persuasive language. These insights contribute to our understanding of three types of AI harms identified by current frameworks: exclusionary norms, stereotyping, and performance disparities, particularly for the context of e-commerce.",
    "authors": [
      "Markelle Kelly, Mohammad Tahaei, Padhraic Smyth, Lauren Wilcox"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.834358"
  },
  {
    "id": "oai:arXiv.org:2506.05402v1",
    "journal": "arXiv_CS",
    "title": "Sylva: Tailoring Personalized Adversarial Defense in Pre-trained Models via Collaborative Fine-tuning",
    "link": "https://arxiv.org/abs/2506.05402",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05402v1 Announce Type: new \nAbstract: The growing adoption of large pre-trained models in edge computing has made deploying model inference on mobile clients both practical and popular. These devices are inherently vulnerable to direct adversarial attacks, which pose a substantial threat to the robustness and security of deployed models. Federated adversarial training (FAT) has emerged as an effective solution to enhance model robustness while preserving client privacy. However, FAT frequently produces a generalized global model, which struggles to address the diverse and heterogeneous data distributions across clients, resulting in insufficiently personalized performance, while also encountering substantial communication challenges during the training process. In this paper, we propose \\textit{Sylva}, a personalized collaborative adversarial training framework designed to deliver customized defense models for each client through a two-phase process. In Phase 1, \\textit{Sylva} employs LoRA for local adversarial fine-tuning, enabling clients to personalize model robustness while drastically reducing communication costs by uploading only LoRA parameters during federated aggregation. In Phase 2, a game-based layer selection strategy is introduced to enhance accuracy on benign data, further refining the personalized model. This approach ensures that each client receives a tailored defense model that balances robustness and accuracy effectively. Extensive experiments on benchmark datasets demonstrate that \\textit{Sylva} can achieve up to 50$\\times$ improvements in communication efficiency compared to state-of-the-art algorithms, while achieving up to 29.5\\% and 50.4\\% enhancements in adversarial robustness and benign accuracy, respectively.",
    "authors": [
      "Tianyu Qi, Lei Xue, Yufeng Zhan, Xiaobo Ma"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.834446"
  },
  {
    "id": "oai:arXiv.org:2506.05409v1",
    "journal": "arXiv_CS",
    "title": "Object-level Self-Distillation for Vision Pretraining",
    "link": "https://arxiv.org/abs/2506.05409",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05409v1 Announce Type: new \nAbstract: State-of-the-art vision pretraining methods rely on image-level self-distillation from object-centric datasets such as ImageNet, implicitly assuming each image contains a single object. This assumption does not always hold: many ImageNet images already contain multiple objects. Further, it limits scalability to scene-centric datasets that better mirror real-world complexity. We address these challenges by introducing Object-level Self-DIStillation (ODIS), a pretraining approach that shifts the self-distillation granularity from whole images to individual objects. Using object-aware cropping and masked attention, ODIS isolates object-specific regions, guiding the transformer toward semantically meaningful content and transforming a noisy, scene-level task into simpler object-level sub-tasks. We show that this approach improves visual representations both at the image and patch levels. Using masks at inference time, our method achieves an impressive $82.6\\%$ $k$-NN accuracy on ImageNet1k with ViT-Large.",
    "authors": [
      "\\c{C}a\\u{g}lar H{\\i}zl{\\i}, \\c{C}a\\u{g}atay Y{\\i}ld{\\i}z, Pekka Marttinen"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.834498"
  },
  {
    "id": "oai:arXiv.org:2506.05411v1",
    "journal": "arXiv_CS",
    "title": "QA-HFL: Quality-Aware Hierarchical Federated Learning for Resource-Constrained Mobile Devices with Heterogeneous Image Quality",
    "link": "https://arxiv.org/abs/2506.05411",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05411v1 Announce Type: new \nAbstract: This paper introduces QA-HFL, a quality-aware hierarchical federated learning framework that efficiently handles heterogeneous image quality across resource-constrained mobile devices. Our approach trains specialized local models for different image quality levels and aggregates their features using a quality-weighted fusion mechanism, while incorporating differential privacy protection. Experiments on MNIST demonstrate that QA-HFL achieves 92.31% accuracy after just three federation rounds, significantly outperforming state-of-the-art methods like FedRolex (86.42%). Under strict privacy constraints, our approach maintains 30.77% accuracy with formal differential privacy guarantees. Counter-intuitively, low-end devices contributed most significantly (63.5%) to the final model despite using 100 fewer parameters than high-end counterparts. Our quality-aware approach addresses accuracy decline through device-specific regularization, adaptive weighting, intelligent client selection, and server-side knowledge distillation, while maintaining efficient communication with a 4.71% compression ratio. Statistical analysis confirms that our approach significantly outperforms baseline methods (p 0.01) under both standard and privacy-constrained conditions.",
    "authors": [
      "Sajid Hussain, Muhammad Sohail, Nauman Ali Khan"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.834515"
  },
  {
    "id": "oai:arXiv.org:2506.05422v1",
    "journal": "arXiv_CS",
    "title": "Constructive Symbolic Reinforcement Learning via Intuitionistic Logic and Goal-Chaining Inference",
    "link": "https://arxiv.org/abs/2506.05422",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05422v1 Announce Type: new \nAbstract: We introduce a novel learning and planning framework that replaces traditional reward-based optimisation with constructive logical inference. In our model, actions, transitions, and goals are represented as logical propositions, and decision-making proceeds by building constructive proofs under intuitionistic logic. This method ensures that state transitions and policies are accepted only when supported by verifiable preconditions -- eschewing probabilistic trial-and-error in favour of guaranteed logical validity. We implement a symbolic agent operating in a structured gridworld, where reaching a goal requires satisfying a chain of intermediate subgoals (e.g., collecting keys to open doors), each governed by logical constraints. Unlike conventional reinforcement learning agents, which require extensive exploration and suffer from unsafe or invalid transitions, our constructive agent builds a provably correct plan through goal chaining, condition tracking, and knowledge accumulation. Empirical comparison with Q-learning demonstrates that our method achieves perfect safety, interpretable behaviour, and efficient convergence with no invalid actions, highlighting its potential for safe planning, symbolic cognition, and trustworthy AI. This work presents a new direction for reinforcement learning grounded not in numeric optimisation, but in constructive logic and proof theory.",
    "authors": [
      "Andrei T. Patrascu"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.834611"
  },
  {
    "id": "oai:arXiv.org:2506.05427v1",
    "journal": "arXiv_CS",
    "title": "MTPNet: Multi-Grained Target Perception for Unified Activity Cliff Prediction",
    "link": "https://arxiv.org/abs/2506.05427",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05427v1 Announce Type: new \nAbstract: Activity cliff prediction is a critical task in drug discovery and material design. Existing computational methods are limited to handling single binding targets, which restricts the applicability of these prediction models. In this paper, we present the Multi-Grained Target Perception network (MTPNet) to incorporate the prior knowledge of interactions between the molecules and their target proteins. Specifically, MTPNet is a unified framework for activity cliff prediction, which consists of two components: Macro-level Target Semantic (MTS) guidance and Micro-level Pocket Semantic (MPS) guidance. By this way, MTPNet dynamically optimizes molecular representations through multi-grained protein semantic conditions. To our knowledge, it is the first time to employ the receptor proteins as guiding information to effectively capture critical interaction details. Extensive experiments on 30 representative activity cliff datasets demonstrate that MTPNet significantly outperforms previous approaches, achieving an average RMSE improvement of 18.95% on top of several mainstream GNN architectures. Overall, MTPNet internalizes interaction patterns through conditional deep learning to achieve unified predictions of activity cliffs, helping to accelerate compound optimization and design. Codes are available at: https://github.com/ZishanShu/MTPNet.",
    "authors": [
      "Zishan Shu, Yufan Deng, Hongyu Zhang, Zhiwei Nie, Jie Chen"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.834635"
  },
  {
    "id": "oai:arXiv.org:2506.05430v1",
    "journal": "arXiv_CS",
    "title": "Explainer-guided Targeted Adversarial Attacks against Binary Code Similarity Detection Models",
    "link": "https://arxiv.org/abs/2506.05430",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05430v1 Announce Type: new \nAbstract: Binary code similarity detection (BCSD) serves as a fundamental technique for various software engineering tasks, e.g., vulnerability detection and classification. Attacks against such models have therefore drawn extensive attention, aiming at misleading the models to generate erroneous predictions. Prior works have explored various approaches to generating semantic-preserving variants, i.e., adversarial samples, to evaluate the robustness of the models against adversarial attacks. However, they have mainly relied on heuristic criteria or iterative greedy algorithms to locate salient code influencing the model output, failing to operate on a solid theoretical basis. Moreover, when processing programs with high complexities, such attacks tend to be time-consuming.\n  In this work, we propose a novel optimization for adversarial attacks against BCSD models. In particular, we aim to improve the attacks in a challenging scenario, where the attack goal is to limit the model predictions to a specific range, i.e., the targeted attacks. Our attack leverages the superior capability of black-box, model-agnostic explainers in interpreting the model decision boundaries, thereby pinpointing the critical code snippet to apply semantic-preserving perturbations. The evaluation results demonstrate that compared with the state-of-the-art attacks, the proposed attacks achieve higher attack success rate in almost all scenarios, while also improving the efficiency and transferability. Our real-world case studies on vulnerability detection and classification further demonstrate the security implications of our attacks, highlighting the urgent need to further enhance the robustness of existing BCSD models.",
    "authors": [
      "Mingjie Chen (Zhejiang University), Tiancheng Zhu (Huazhong University of Science,Technology), Mingxue Zhang (The State Key Laboratory of Blockchain,Data Security, Zhejiang University,Hangzhou High-Tech Zone), Yiling He (University College London), Minghao Lin (University of Southern California), Penghui Li (Columbia University), Kui Ren (The State Key Laboratory of Blockchain,Data Security, Zhejiang University)"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.834662"
  },
  {
    "id": "oai:arXiv.org:2506.05433v1",
    "journal": "arXiv_CS",
    "title": "Prefix Grouper: Efficient GRPO Training through Shared-Prefix Forward",
    "link": "https://arxiv.org/abs/2506.05433",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05433v1 Announce Type: new \nAbstract: Group Relative Policy Optimization (GRPO) enhances policy learning by computing gradients from relative comparisons among candidate outputs that share a common input prefix. Despite its effectiveness, GRPO introduces substantial computational overhead when processing long shared prefixes, which must be redundantly encoded for each group member. This inefficiency becomes a major scalability bottleneck in long-context learning scenarios. We propose Prefix Grouper, an efficient GRPO training algorithm that eliminates redundant prefix computation via a Shared-Prefix Forward strategy. In particular, by restructuring self-attention into two parts, our method enables the shared prefix to be encoded only once, while preserving full differentiability and compatibility with end-to-end training. We provide both theoretical and empirical evidence that Prefix Grouper is training-equivalent to standard GRPO: it yields identical forward outputs and backward gradients, ensuring that the optimization dynamics and final policy performance remain unchanged. Empirically, our experiments confirm that Prefix Grouper achieves consistent results while significantly reducing the computational cost of training, particularly in long-prefix scenarios. The proposed method is fully plug-and-play: it is compatible with existing GRPO-based architectures and can be seamlessly integrated into current training pipelines as a drop-in replacement, requiring no structural modifications and only minimal changes to input construction and attention computation. Prefix Grouper enables the use of larger group sizes under the same computational budget, thereby improving the scalability of GRPO to more complex tasks and larger models. Code is now available at https://github.com/johncaged/PrefixGrouper",
    "authors": [
      "Zikang Liu, Tongtian Yue, Yepeng Tang, Longteng Guo, Junxian Cai, Qingbin Liu, Xi Chen, Jing Liu"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.834686"
  },
  {
    "id": "oai:arXiv.org:2506.05440v1",
    "journal": "arXiv_CS",
    "title": "BYO-Eval: Build Your Own Dataset for Fine-Grained Visual Assessment of Multimodal Language Models",
    "link": "https://arxiv.org/abs/2506.05440",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05440v1 Announce Type: new \nAbstract: Visual Language Models (VLMs) are now sufficiently advanced to support a broad range of applications, including answering complex visual questions, and are increasingly expected to interact with images in varied ways. To evaluate them, current benchmarks often focus on specific domains (e.g., reading charts), constructing datasets of annotated real images paired with pre-defined Multiple Choice Questions (MCQs) to report aggregate accuracy scores. However, such benchmarks entail high annotation costs, risk information leakage, and do not clarify whether failures stem from limitations in visual perception, reasoning, or general knowledge. We propose a new evaluation methodology, inspired by ophthalmologic diagnostics, leveraging procedural generation of synthetic images to obtain control over visual attributes and precisely reveal perception failures in VLMs. Specifically, we build collections of images with gradually more challenging variations in the content of interest (e.g., number of objects in a counting task) while holding other visual parameters constant. This diagnostic allows systematic stress testing and fine-grained failure analysis, shifting the focus from coarse benchmarking toward targeted and interpretable assessment of VLM capabilities. Our code is available at https://github.com/byoeval/BYO-EVAL.",
    "authors": [
      "Ludovic Arnould, Salim Khazem, Hugues Ali Mehenni"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.834738"
  },
  {
    "id": "oai:arXiv.org:2506.05446v1",
    "journal": "arXiv_CS",
    "title": "Sentinel: SOTA model to protect against prompt injections",
    "link": "https://arxiv.org/abs/2506.05446",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05446v1 Announce Type: new \nAbstract: Large Language Models (LLMs) are increasingly powerful but remain vulnerable to prompt injection attacks, where malicious inputs cause the model to deviate from its intended instructions. This paper introduces Sentinel, a novel detection model, qualifire/prompt-injection-sentinel, based on the \\answerdotai/ModernBERT-large architecture. By leveraging ModernBERT's advanced features and fine-tuning on an extensive and diverse dataset comprising a few open-source and private collections, Sentinel achieves state-of-the-art performance. This dataset amalgamates varied attack types, from role-playing and instruction hijacking to attempts to generate biased content, alongside a broad spectrum of benign instructions, with private datasets specifically targeting nuanced error correction and real-world misclassifications. On a comprehensive, unseen internal test set, Sentinel demonstrates an average accuracy of 0.987 and an F1-score of 0.980. Furthermore, when evaluated on public benchmarks, it consistently outperforms strong baselines like protectai/deberta-v3-base-prompt-injection-v2. This work details Sentinel's architecture, its meticulous dataset curation, its training methodology, and a thorough evaluation, highlighting its superior detection capabilities.",
    "authors": [
      "Dror Ivry, Oran Nahum"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.834780"
  },
  {
    "id": "oai:arXiv.org:2506.05447v1",
    "journal": "arXiv_CS",
    "title": "Training Dynamics Underlying Language Model Scaling Laws: Loss Deceleration and Zero-Sum Learning",
    "link": "https://arxiv.org/abs/2506.05447",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05447v1 Announce Type: new \nAbstract: This work aims to understand how scaling improves language models, specifically in terms of training dynamics. We find that language models undergo loss deceleration early in training; an abrupt slowdown in the rate of loss improvement, resulting in piecewise linear behaviour of the loss curve in log-log space. Scaling up the model mitigates this transition by (1) decreasing the loss at which deceleration occurs, and (2) improving the log-log rate of loss improvement after deceleration. We attribute loss deceleration to a type of degenerate training dynamics we term zero-sum learning (ZSL). In ZSL, per-example gradients become systematically opposed, leading to destructive interference in per-example changes in loss. As a result, improving loss on one subset of examples degrades it on another, bottlenecking overall progress. Loss deceleration and ZSL provide new insights into the training dynamics underlying language model scaling laws, and could potentially be targeted directly to improve language models independent of scale. We make our code and artefacts available at: https://github.com/mirandrom/zsl",
    "authors": [
      "Andrei Mircea, Supriyo Chakraborty, Nima Chitsazan, Irina Rish, Ekaterina Lobacheva"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.834788"
  },
  {
    "id": "oai:arXiv.org:2506.05449v1",
    "journal": "arXiv_CS",
    "title": "AI-powered Contextual 3D Environment Generation: A Systematic Review",
    "link": "https://arxiv.org/abs/2506.05449",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05449v1 Announce Type: new \nAbstract: The generation of high-quality 3D environments is crucial for industries such as gaming, virtual reality, and cinema, yet remains resource-intensive due to the reliance on manual processes. This study performs a systematic review of existing generative AI techniques for 3D scene generation, analyzing their characteristics, strengths, limitations, and potential for improvement. By examining state-of-the-art approaches, it presents key challenges such as scene authenticity and the influence of textual inputs. Special attention is given to how AI can blend different stylistic domains while maintaining coherence, the impact of training data on output quality, and the limitations of current models. In addition, this review surveys existing evaluation metrics for assessing realism and explores how industry professionals incorporate AI into their workflows. The findings of this study aim to provide a comprehensive understanding of the current landscape and serve as a foundation for future research on AI-driven 3D content generation. Key findings include that advanced generative architectures enable high-quality 3D content creation at a high computational cost, effective multi-modal integration techniques like cross-attention and latent space alignment facilitate text-to-3D tasks, and the quality and diversity of training data combined with comprehensive evaluation metrics are critical to achieving scalable, robust 3D scene generation.",
    "authors": [
      "Miguel Silva, Alexandre Valle de Carvalho"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.834795"
  },
  {
    "id": "oai:arXiv.org:2506.05484v1",
    "journal": "arXiv_CS",
    "title": "Initial Model Incorporation for Deep Learning FWI: Pretraining or Denormalization?",
    "link": "https://arxiv.org/abs/2506.05484",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05484v1 Announce Type: new \nAbstract: Subsurface property neural network reparameterized full waveform inversion (FWI) has emerged as an effective unsupervised learning framework, which can invert stably with an inaccurate starting model. It updates the trainable neural network parameters instead of fine-tuning on the subsurface model directly. There are primarily two ways to embed the prior knowledge of the initial model into neural networks, that is, pretraining and denormalization. Pretraining first regulates the neural networks' parameters by fitting the initial velocity model; Denormalization directly adds the outputs of the network into the initial models without pretraining. In this letter, we systematically investigate the influence of the two ways of initial model incorporation for the neural network reparameterized FWI. We demonstrate that pretraining requires inverting the model perturbation based on a constant velocity value (mean) with a two-stage implementation. It leads to a complex workflow and inconsistency of objective functions in the two-stage process, causing the network parameters to become inactive and lose plasticity. Experimental results demonstrate that denormalization can simplify workflows, accelerate convergence, and enhance inversion accuracy compared with pretraining.",
    "authors": [
      "Ruihua Chen, Bangyu Wu, Meng Li, Kai Yang"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.834879"
  },
  {
    "id": "oai:arXiv.org:2506.05497v1",
    "journal": "arXiv_CS",
    "title": "Conformal Prediction Beyond the Seen: A Missing Mass Perspective for Uncertainty Quantification in Generative Models",
    "link": "https://arxiv.org/abs/2506.05497",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05497v1 Announce Type: new \nAbstract: Uncertainty quantification (UQ) is essential for safe deployment of generative AI models such as large language models (LLMs), especially in high stakes applications. Conformal prediction (CP) offers a principled uncertainty quantification framework, but classical methods focus on regression and classification, relying on geometric distances or softmax scores: tools that presuppose structured outputs. We depart from this paradigm by studying CP in a query only setting, where prediction sets must be constructed solely from finite queries to a black box generative model, introducing a new trade off between coverage, test time query budget, and informativeness. We introduce Conformal Prediction with Query Oracle (CPQ), a framework characterizing the optimal interplay between these objectives. Our finite sample algorithm is built on two core principles: one governs the optimal query policy, and the other defines the optimal mapping from queried samples to prediction sets. Remarkably, both are rooted in the classical missing mass problem in statistics. Specifically, the optimal query policy depends on the rate of decay, or the derivative, of the missing mass, for which we develop a novel estimator. Meanwhile, the optimal mapping hinges on the missing mass itself, which we estimate using Good Turing estimators. We then turn our focus to implementing our method for language models, where outputs are vast, variable, and often under specified. Fine grained experiments on three real world open ended tasks and two LLMs, show CPQ applicability to any black box LLM and highlight: (1) individual contribution of each principle to CPQ performance, and (2) CPQ ability to yield significantly more informative prediction sets than existing conformal methods for language uncertainty quantification.",
    "authors": [
      "Sima Noorani, Shayan Kiyani, George Pappas, Hamed Hassani"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.834946"
  },
  {
    "id": "oai:arXiv.org:2506.05498v1",
    "journal": "arXiv_CS",
    "title": "Multidimensional Analysis of Specific Language Impairment Using Unsupervised Learning Through PCA and Clustering",
    "link": "https://arxiv.org/abs/2506.05498",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05498v1 Announce Type: new \nAbstract: Specific Language Impairment (SLI) affects approximately 7 percent of children, presenting as isolated language deficits despite normal cognitive abilities, sensory systems, and supportive environments. Traditional diagnostic approaches often rely on standardized assessments, which may overlook subtle developmental patterns. This study aims to identify natural language development trajectories in children with and without SLI using unsupervised machine learning techniques, providing insights for early identification and targeted interventions. Narrative samples from 1,163 children aged 4-16 years across three corpora (Conti-Ramsden 4, ENNI, and Gillam) were analyzed using Principal Component Analysis (PCA) and clustering. A total of 64 linguistic features were evaluated to uncover developmental trajectories and distinguish linguistic profiles. Two primary clusters emerged: (1) high language production with low SLI prevalence, and (2) limited production but higher syntactic complexity with higher SLI prevalence. Additionally, boundary cases exhibited intermediate traits, supporting a continuum model of language abilities. Findings suggest SLI manifests primarily through reduced production capacity rather than syntactic complexity deficits. The results challenge categorical diagnostic frameworks and highlight the potential of unsupervised learning techniques for refining diagnostic criteria and intervention strategies.",
    "authors": [
      "Niruthiha Selvanayagam"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.834954"
  },
  {
    "id": "oai:arXiv.org:2506.05501v1",
    "journal": "arXiv_CS",
    "title": "FocusDiff: Advancing Fine-Grained Text-Image Alignment for Autoregressive Visual Generation through RL",
    "link": "https://arxiv.org/abs/2506.05501",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05501v1 Announce Type: new \nAbstract: Recent studies extend the autoregression paradigm to text-to-image generation, achieving performance comparable to diffusion models. However, our new PairComp benchmark -- featuring test cases of paired prompts with similar syntax but different fine-grained semantics -- reveals that existing models struggle with fine-grained text-image alignment thus failing to realize precise control over visual tokens. To address this, we propose FocusDiff, which enhances fine-grained text-image semantic alignment by focusing on subtle differences between similar text-image pairs. We construct a new dataset of paired texts and images with similar overall expressions but distinct local semantics, further introducing a novel reinforcement learning algorithm to emphasize such fine-grained semantic differences for desired image generation. Our approach achieves state-of-the-art performance on existing text-to-image benchmarks and significantly outperforms prior methods on PairComp.",
    "authors": [
      "Kaihang Pan, Wendong Bu, Yuruo Wu, Yang Wu, Kai Shen, Yunfei Li, Hang Zhao, Juncheng Li, Siliang Tang, Yueting Zhuang"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.834971"
  },
  {
    "id": "oai:arXiv.org:2506.05513v1",
    "journal": "arXiv_CS",
    "title": "Geometric and Physical Constraints Synergistically Enhance Neural PDE Surrogates",
    "link": "https://arxiv.org/abs/2506.05513",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05513v1 Announce Type: new \nAbstract: Neural PDE surrogates can improve the cost-accuracy tradeoff of classical solvers, but often generalize poorly to new initial conditions and accumulate errors over time. Physical and symmetry constraints have shown promise in closing this performance gap, but existing techniques for imposing these inductive biases are incompatible with the staggered grids commonly used in computational fluid dynamics. Here we introduce novel input and output layers that respect physical laws and symmetries on the staggered grids, and for the first time systematically investigate how these constraints, individually and in combination, affect the accuracy of PDE surrogates. We focus on two challenging problems: shallow water equations with closed boundaries and decaying incompressible turbulence. Compared to strong baselines, symmetries and physical constraints consistently improve performance across tasks, architectures, autoregressive prediction steps, accuracy measures, and network sizes. Symmetries are more effective than physical constraints, but surrogates with both performed best, even compared to baselines with data augmentation or pushforward training, while themselves benefiting from the pushforward trick. Doubly-constrained surrogates also generalize better to initial conditions and durations beyond the range of the training data, and more accurately predict real-world ocean currents.",
    "authors": [
      "Yunfei Huang, David S. Greenberg"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.835003"
  },
  {
    "id": "oai:arXiv.org:2506.05514v1",
    "journal": "arXiv_CS",
    "title": "Can LLMs Talk 'Sex'? Exploring How AI Models Handle Intimate Conversations",
    "link": "https://arxiv.org/abs/2506.05514",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05514v1 Announce Type: new \nAbstract: This study examines how four prominent large language models (Claude 3.7 Sonnet, GPT-4o, Gemini 2.5 Flash, and Deepseek-V3) handle sexually oriented requests through qualitative content analysis. By evaluating responses to prompts ranging from explicitly sexual to educational and neutral control scenarios, the research reveals distinct moderation paradigms reflecting fundamentally divergent ethical positions. Claude 3.7 Sonnet employs strict and consistent prohibitions, while GPT-4o navigates user interactions through nuanced contextual redirection. Gemini 2.5 Flash exhibits permissiveness with threshold-based limits, and Deepseek-V3 demonstrates troublingly inconsistent boundary enforcement and performative refusals. These varied approaches create a significant \"ethical implementation gap,\" stressing a critical absence of unified ethical frameworks and standards across platforms. The findings underscore the urgent necessity for transparent, standardized guidelines and coordinated international governance to ensure consistent moderation, protect user welfare, and maintain trust as AI systems increasingly mediate intimate aspects of human life.",
    "authors": [
      "Huiqian Lai"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.835011"
  },
  {
    "id": "oai:arXiv.org:2506.05520v1",
    "journal": "arXiv_CS",
    "title": "Towards Data Systems That Are Business Semantic-Centric and AI Agents-Assisted",
    "link": "https://arxiv.org/abs/2506.05520",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05520v1 Announce Type: new \nAbstract: Contemporary businesses operate in dynamic environments requiring rapid adaptation to achieve goals and maintain competitiveness. Existing data platforms often fall short by emphasizing tools over alignment with business needs, resulting in inefficiencies and delays. To address this gap, I propose the Business Semantics Centric, AI Agents Assisted Data System (BSDS), a holistic system that integrates architecture, workflows, and team organization to ensure data systems are tailored to business priorities rather than dictated by technical constraints. BSDS redefines data systems as dynamic enablers of business success, transforming them from passive tools into active drivers of organizational growth. BSDS has a modular architecture that comprises curated data linked to business entities, a knowledge base for context-aware AI agents, and efficient data pipelines. AI agents play a pivotal role in assisting with data access and system management, reducing human effort, and improving scalability. Complementing this architecture, BSDS incorporates workflows optimized for both exploratory data analysis and production requirements, balancing speed of delivery with quality assurance. A key innovation of BSDS is its incorporation of the human factor. By aligning data team expertise with business semantics, BSDS bridges the gap between technical capabilities and business needs. Validated through real-world implementation, BSDS accelerates time-to-market for data-driven initiatives, enhances cross-functional collaboration, and provides a scalable blueprint for businesses of all sizes. Future research can build on BSDS to explore optimization strategies using complex systems and adaptive network theories, as well as developing autonomous data systems leveraging AI agents.",
    "authors": [
      "Cecil Pang"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.835044"
  },
  {
    "id": "oai:arXiv.org:2506.05542v1",
    "journal": "arXiv_CS",
    "title": "Agentomics-ML: Autonomous Machine Learning Experimentation Agent for Genomic and Transcriptomic Data",
    "link": "https://arxiv.org/abs/2506.05542",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05542v1 Announce Type: new \nAbstract: The adoption of machine learning (ML) and deep learning methods has revolutionized molecular medicine by driving breakthroughs in genomics, transcriptomics, drug discovery, and biological systems modeling. The increasing quantity, multimodality, and heterogeneity of biological datasets demand automated methods that can produce generalizable predictive models. Recent developments in large language model-based agents have shown promise for automating end-to-end ML experimentation on structured benchmarks. However, when applied to heterogeneous computational biology datasets, these methods struggle with generalization and success rates. Here, we introduce Agentomics-ML, a fully autonomous agent-based system designed to produce a classification model and the necessary files for reproducible training and inference. Our method follows predefined steps of an ML experimentation process, repeatedly interacting with the file system through Bash to complete individual steps. Once an ML model is produced, training and validation metrics provide scalar feedback to a reflection step to identify issues such as overfitting. This step then creates verbal feedback for future iterations, suggesting adjustments to steps such as data representation, model architecture, and hyperparameter choices. We have evaluated Agentomics-ML on several established genomic and transcriptomic benchmark datasets and show that it outperforms existing state-of-the-art agent-based methods in both generalization and success rates. While state-of-the-art models built by domain experts still lead in absolute performance on the majority of the computational biology datasets used in this work, Agentomics-ML narrows the gap for fully autonomous systems and achieves state-of-the-art performance on one of the used benchmark datasets. The code is available at https://github.com/BioGeMT/Agentomics-ML.",
    "authors": [
      "Vlastimil Martinek, Andrea Gariboldi, Dimosthenis Tzimotoudis, Aitor Alberdi Escudero, Edward Blake, David Cechak, Luke Cassar, Alessandro Balestrucci, Panagiotis Alexiou"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.835159"
  },
  {
    "id": "oai:arXiv.org:2506.05543v1",
    "journal": "arXiv_CS",
    "title": "FRAME: Pre-Training Video Feature Representations via Anticipation and Memory",
    "link": "https://arxiv.org/abs/2506.05543",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05543v1 Announce Type: new \nAbstract: Dense video prediction tasks, such as object tracking and semantic segmentation, require video encoders that generate temporally consistent, spatially dense features for every frame. However, existing approaches fall short: image encoders like DINO or CLIP lack temporal awareness, while video models such as VideoMAE underperform compared to image encoders on dense prediction tasks. We address this gap with FRAME, a self-supervised video frame encoder tailored for dense video understanding. FRAME learns to predict current and future DINO patch features from past and present RGB frames, leading to spatially precise and temporally coherent representations. To our knowledge, FRAME is the first video encoder to leverage image-based models for dense prediction while outperforming them on tasks requiring fine-grained visual correspondence. As an auxiliary capability, FRAME aligns its class token with CLIP's semantic space, supporting language-driven tasks such as video classification. We evaluate FRAME across six dense prediction tasks on seven datasets, where it consistently outperforms image encoders and existing self-supervised video models. Despite its versatility, FRAME maintains a compact architecture suitable for a range of downstream applications.",
    "authors": [
      "Sethuraman TV, Savya Khosla, Vignesh Srinivasakumar, Jiahui Huang, Seoung Wug Oh, Simon Jenni, Derek Hoiem, Joon-Young Lee"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.835166"
  },
  {
    "id": "oai:arXiv.org:2506.05577v1",
    "journal": "arXiv_CS",
    "title": "Collaborative Learning in Agentic Systems: A Collective AI is Greater Than the Sum of Its Parts",
    "link": "https://arxiv.org/abs/2506.05577",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05577v1 Announce Type: new \nAbstract: Agentic AI has gained significant interest as a research paradigm focused on autonomy, self-directed learning, and long-term reliability of decision making. Real-world agentic systems operate in decentralized settings on a large set of tasks or data distributions with constraints such as limited bandwidth, asynchronous execution, and the absence of a centralized model or even common objectives. We posit that exploiting previously learned skills, task similarities, and communication capabilities in a collective of agentic AI are challenging but essential elements to enabling scalability, open-endedness, and beneficial collaborative learning dynamics. In this paper, we introduce Modular Sharing and Composition in Collective Learning (MOSAIC), an agentic algorithm that allows multiple agents to independently solve different tasks while also identifying, sharing, and reusing useful machine-learned knowledge, without coordination, synchronization, or centralized control. MOSAIC combines three mechanisms: (1) modular policy composition via neural network masks, (2) cosine similarity estimation using Wasserstein embeddings for knowledge selection, and (3) asynchronous communication and policy integration. Results on a set of RL benchmarks show that MOSAIC has a greater sample efficiency than isolated learners, i.e., it learns significantly faster, and in some cases, finds solutions to tasks that cannot be solved by isolated learners. The collaborative learning and sharing dynamics are also observed to result in the emergence of ideal curricula of tasks, from easy to hard. These findings support the case for collaborative learning in agentic systems to achieve better and continuously evolving performance both at the individual and collective levels.",
    "authors": [
      "Saptarshi Nath, Christos Peridis, Eseoghene Benjamin, Xinran Liu, Soheil Kolouri, Peter Kinnell, Zexin Li, Cong Liu, Shirin Dora, Andrea Soltoggio"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.835290"
  },
  {
    "id": "oai:arXiv.org:2506.05579v1",
    "journal": "arXiv_CS",
    "title": "When Models Know More Than They Can Explain: Quantifying Knowledge Transfer in Human-AI Collaboration",
    "link": "https://arxiv.org/abs/2506.05579",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05579v1 Announce Type: new \nAbstract: Recent advancements in AI reasoning have driven substantial improvements across diverse tasks. A critical open question is whether these improvements also yields better knowledge transfer: the ability of models to communicate reasoning in ways humans can understand, apply, and learn from. To investigate this, we introduce Knowledge Integration and Transfer Evaluation (KITE), a conceptual and experimental framework for Human-AI knowledge transfer capabilities and conduct the first large-scale human study (N=118) explicitly designed to measure it. In our two-phase setup, humans first ideate with an AI on problem-solving strategies, then independently implement solutions, isolating model explanations' influence on human understanding. Our findings reveal that although model benchmark performance correlates with collaborative outcomes, this relationship is notably inconsistent, featuring significant outliers, indicating that knowledge transfer requires dedicated optimization. Our analysis identifies behavioral and strategic factors mediating successful knowledge transfer. We release our code, dataset, and evaluation framework to support future work on communicatively aligned models.",
    "authors": [
      "Quan Shi, Carlos E. Jimenez, Shunyu Yao, Nick Haber, Diyi Yang, Karthik Narasimhan"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.835297"
  },
  {
    "id": "oai:arXiv.org:2506.05604v1",
    "journal": "arXiv_CS",
    "title": "Why is My Route Different Today? An Algorithm for Explaining Route Selection",
    "link": "https://arxiv.org/abs/2506.05604",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05604v1 Announce Type: new \nAbstract: Users of routing services like Apple Maps, Google Maps, and Waze frequently wonder why a given route is proposed. This question particularly arises when dynamic conditions like traffic and road closures cause unusual routes to be proposed. While many dynamic conditions may exist in a road network at any time, only a small fraction of those conditions are typically relevant to a given user's route. In this work, we introduce the concept of a simple valid explanation (SVE), which consists of a small set of traffic-laden road segments that answer the following question: Which traffic conditions cause a particular shortest traffic-aware route to differ from the shortest traffic-free route? We give an efficient algorithm for finding SVEs and show that they theoretically and experimentally lead to small and interpretable answers to the question.",
    "authors": [
      "Aaron Schild, Sreenivas Gollapudi, Anupam Gupta, Kostas Kollias, Ali Sinop"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.835417"
  },
  {
    "id": "oai:arXiv.org:2506.05663v1",
    "journal": "arXiv_CS",
    "title": "Insights from Designing Context-Aware Meal Preparation Assistance for Older Adults with Mild Cognitive Impairment (MCI) and Their Care Partners",
    "link": "https://arxiv.org/abs/2506.05663",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05663v1 Announce Type: new \nAbstract: Older adults with mild cognitive impairment (MCI) often face challenges during meal preparation, such as forgetting ingredients, skipping steps, or leaving appliances on, which can compromise their safety and independence. Our study explores the design of context-aware assistive technologies for meal preparation using a user-centered iterative design process. Through three iterative phases of design and feedback, evolving from low-tech lightbox to a digital screen, we gained insights into managing diverse contexts and personalizing assistance through collaboration with older adults with MCI and their care partners. We concluded our findings in three key contexts--routine-based, real-time, and situational--that informed strategies for designing context-aware meal prep assistance tailored to users' needs. Our results provide actionable insights for creating technologies to assist meal preparation that are personalized for the unique lifestyles of older adults with MCI, situated in the complex and dynamic homebound context, and respecting the collaboration between older adults and their care partners.",
    "authors": [
      "Szeyi Chan, Jiachen Li, Siman Ao, Yufei Wang, Ibrahim Bilau, Brian Jones, Eunhwa Yang, Elizabeth D Mynatt, Xiang Zhi Tan"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.835701"
  },
  {
    "id": "oai:arXiv.org:2506.05670v1",
    "journal": "arXiv_CS",
    "title": "Can LLMs Express Personality Across Cultures? Introducing CulturalPersonas for Evaluating Trait Alignment",
    "link": "https://arxiv.org/abs/2506.05670",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05670v1 Announce Type: new \nAbstract: As LLMs become central to interactive applications, ranging from tutoring to mental health, the ability to express personality in culturally appropriate ways is increasingly important. While recent works have explored personality evaluation of LLMs, they largely overlook the interplay between culture and personality. To address this, we introduce CulturalPersonas, the first large-scale benchmark with human validation for evaluating LLMs' personality expression in culturally grounded, behaviorally rich contexts. Our dataset spans 3,000 scenario-based questions across six diverse countries, designed to elicit personality through everyday scenarios rooted in local values. We evaluate three LLMs, using both multiple-choice and open-ended response formats. Our results show that CulturalPersonas improves alignment with country-specific human personality distributions (over a 20% reduction in Wasserstein distance across models and countries) and elicits more expressive, culturally coherent outputs compared to existing benchmarks. CulturalPersonas surfaces meaningful modulated trait outputs in response to culturally grounded prompts, offering new directions for aligning LLMs to global norms of behavior. By bridging personality expression and cultural nuance, we envision that CulturalPersonas will pave the way for more socially intelligent and globally adaptive LLMs.",
    "authors": [
      "Priyanka Dey, Yugal Khanter, Aayush Bothra, Jieyu Zhao, Emilio Ferrara"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.835735"
  },
  {
    "id": "oai:arXiv.org:2506.05687v1",
    "journal": "arXiv_CS",
    "title": "What Comes After Harm? Mapping Reparative Actions in AI through Justice Frameworks",
    "link": "https://arxiv.org/abs/2506.05687",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05687v1 Announce Type: new \nAbstract: As Artificial Intelligence (AI) systems are integrated into more aspects of society, they offer new capabilities but also cause a range of harms that are drawing increasing scrutiny. A large body of work in the Responsible AI community has focused on identifying and auditing these harms. However, much less is understood about what happens after harm occurs: what constitutes reparation, who initiates it, and how effective these reparations are. In this paper, we develop a taxonomy of AI harm reparation based on a thematic analysis of real-world incidents. The taxonomy organizes reparative actions into four overarching goals: acknowledging harm, attributing responsibility, providing remedies, and enabling systemic change. We apply this framework to a dataset of 1,060 AI-related incidents, analyzing the prevalence of each action and the distribution of stakeholder involvement. Our findings show that reparation efforts are concentrated in early, symbolic stages, with limited actions toward accountability or structural reform. Drawing on theories of justice, we argue that existing responses fall short of delivering meaningful redress. This work contributes a foundation for advancing more accountable and reparative approaches to Responsible AI.",
    "authors": [
      "Sijia Xiao, Haodi Zou, Alice Qian Zhang, Deepak Kumar, Hong Shen, Jason Hong, Motahhare Eslami"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.835842"
  },
  {
    "id": "oai:arXiv.org:2506.05699v1",
    "journal": "arXiv_CS",
    "title": "Evaluating AI-Powered Learning Assistants in Engineering Higher Education: Student Engagement, Ethical Challenges, and Policy Implications",
    "link": "https://arxiv.org/abs/2506.05699",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05699v1 Announce Type: new \nAbstract: As generative AI tools become increasingly integrated into higher education, understanding how students interact with and perceive these technologies is essential for responsible and effective adoption. This study evaluates the use of the Educational AI Hub, an AI-powered learning framework, in undergraduate civil and environmental engineering courses at a large R1 public university. Using a mixed-methods approach that combines pre- and post-surveys, system usage logs, and qualitative analysis of the open-ended prompts and questions students posed to the AI chatbot, the research explores students' perceptions of trust, ethical concerns, usability, and learning outcomes. Findings reveal that students appreciated the AI assistant for its convenience and comfort, with nearly half reporting greater ease in using the AI tool compared to seeking help from instructors or teaching assistants. The tool was seen as most helpful for completing homework and understanding course concepts, though perceptions of its instructional quality were mixed. Ethical concerns emerged as a key barrier to full engagement: while most students viewed AI use as ethically acceptable, many expressed uncertainties about institutional policies and apprehension about potential academic misconduct. This study contributes to the growing body of research on AI in education by highlighting the importance of usability, policy clarity, and faculty guidance in fostering meaningful AI engagement. The findings suggest that while students are ready to embrace AI as a supplement to human instruction, thoughtful integration and transparent institutional frameworks are critical for ensuring student confidence, trust, and learning effectiveness.",
    "authors": [
      "Ramteja Sajja, Yusuf Sermet, Brian Fodale, Ibrahim Demir"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.835921"
  },
  {
    "id": "oai:arXiv.org:2506.05701v1",
    "journal": "arXiv_CS",
    "title": "Statistically Valid Post-Deployment Monitoring Should Be Standard for AI-Based Digital Health",
    "link": "https://arxiv.org/abs/2506.05701",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05701v1 Announce Type: new \nAbstract: This position paper argues that post-deployment monitoring in clinical AI is underdeveloped and proposes statistically valid and label-efficient testing frameworks as a principled foundation for ensuring reliability and safety in real-world deployment. A recent review found that only 9% of FDA-registered AI-based healthcare tools include a post-deployment surveillance plan. Existing monitoring approaches are often manual, sporadic, and reactive, making them ill-suited for the dynamic environments in which clinical models operate. We contend that post-deployment monitoring should be grounded in label-efficient and statistically valid testing frameworks, offering a principled alternative to current practices. We use the term \"statistically valid\" to refer to methods that provide explicit guarantees on error rates (e.g., Type I/II error), enable formal inference under pre-defined assumptions, and support reproducibility--features that align with regulatory requirements. Specifically, we propose that the detection of changes in the data and model performance degradation should be framed as distinct statistical hypothesis testing problems. Grounding monitoring in statistical rigor ensures a reproducible and scientifically sound basis for maintaining the reliability of clinical AI systems. Importantly, it also opens new research directions for the technical community--spanning theory, methods, and tools for statistically principled detection, attribution, and mitigation of post-deployment model failures in real-world settings.",
    "authors": [
      "Pavel Dolin, Weizhi Li, Gautam Dasarathy, Visar Berisha"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.835937"
  },
  {
    "id": "oai:arXiv.org:2506.05708v1",
    "journal": "arXiv_CS",
    "title": "Hybrid Stabilization Protocol for Cross-Chain Digital Assets Using Adaptor Signatures and AI-Driven Arbitrage",
    "link": "https://arxiv.org/abs/2506.05708",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05708v1 Announce Type: new \nAbstract: Stablecoins face an unresolved trilemma of balancing decentralization, stability, and regulatory compliance. We present a hybrid stabilization protocol that combines crypto-collateralized reserves, algorithmic futures contracts, and cross-chain liquidity pools to achieve robust price adherence while preserving user privacy. At its core, the protocol introduces stabilization futures contracts (SFCs), non-collateralized derivatives that programmatically incentivize third-party arbitrageurs to counteract price deviations via adaptor signature atomic swaps. Autonomous AI agents optimize delta hedging across decentralized exchanges (DEXs), while zkSNARKs prove compliance with anti-money laundering (AML) regulations without exposing identities or transaction details. Our cryptographic design reduces cross-chain liquidity concentration (Herfindahl-Hirschman Index: 2,400 vs. 4,900 in single-chain systems) and ensures atomicity under standard cryptographic assumptions. The protocol's layered architecture encompassing incentive-compatible SFCs, AI-driven market making, and zero-knowledge regulatory proofs. It provides a blueprint for next-generation decentralized financial infrastructure.",
    "authors": [
      "Shengwei You, Andrey Kuehlkamp, Jarek Nabrzyski"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.835962"
  },
  {
    "id": "oai:arXiv.org:2506.05709v1",
    "journal": "arXiv_CS",
    "title": "Token Transforming: A Unified and Training-Free Token Compression Framework for Vision Transformer Acceleration",
    "link": "https://arxiv.org/abs/2506.05709",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05709v1 Announce Type: new \nAbstract: Vision transformers have been widely explored in various vision tasks. Due to heavy computational cost, much interest has aroused for compressing vision transformer dynamically in the aspect of tokens. Current methods mainly pay attention to token pruning or merging to reduce token numbers, in which tokens are compressed exclusively, causing great information loss and therefore post-training is inevitably required to recover the performance. In this paper, we rethink token reduction and unify the process as an explicit form of token matrix transformation, in which all existing methods are constructing special forms of matrices within the framework. Furthermore, we propose a many-to-many Token Transforming framework that serves as a generalization of all existing methods and reserves the most information, even enabling training-free acceleration. We conduct extensive experiments to validate our framework. Specifically, we reduce 40% FLOPs and accelerate DeiT-S by $\\times$1.5 with marginal 0.1% accuracy drop. Furthermore, we extend the method to dense prediction tasks including segmentation, object detection, depth estimation, and language model generation. Results demonstrate that the proposed method consistently achieves substantial improvements, offering a better computation-performance trade-off, impressive budget reduction and inference acceleration.",
    "authors": [
      "Fanhu Zeng, Deli Yu, Zhenglun Kong, Hao Tang"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.835970"
  },
  {
    "id": "oai:arXiv.org:2506.05729v1",
    "journal": "arXiv_CS",
    "title": "Regenerating Daily Routines for Young Adults with Depression through User-Led Indoor Environment Modifications Using Local Natural Materials",
    "link": "https://arxiv.org/abs/2506.05729",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05729v1 Announce Type: new \nAbstract: Young adults with depression often experience prolonged indoor stays, limiting their access to natural environments and exacerbating mental health challenges. While nature therapy is recognized for its psychological benefits, existing interventions frequently require outdoor engagement, which may not be accessible for all individuals. This study explores the potential of user-led indoor modifications using local natural materials as a mental health intervention. A qualitative approach wasemployedtoassessemotionalandenvironmentalconnectedness.Participants engaged in material exploration, collection, and crafting, integrating natural elements into their living spaces. Findings indicate improved mood,increased environmental awareness,and a stronger sense of agency over personal space. The standardized intervention steps suggest the feasibility of a self-help toolkit, enabling broader implementation. This research contributes to sustainable, user-driven mental health interventions, bridging the gap between nature therapy and practical indoor applications.",
    "authors": [
      "Ziqun Hua, Ao Jiang, Haoling Yang, Hao Fan, Huizhong Hu, Bernard Foing"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.836088"
  },
  {
    "id": "oai:arXiv.org:2506.05734v1",
    "journal": "arXiv_CS",
    "title": "There's Waldo: PCB Tamper Forensic Analysis using Explainable AI on Impedance Signatures",
    "link": "https://arxiv.org/abs/2506.05734",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05734v1 Announce Type: new \nAbstract: The security of printed circuit boards (PCBs) has become increasingly vital as supply chain vulnerabilities, including tampering, present significant risks to electronic systems. While detecting tampering on a PCB is the first step for verification, forensics is also needed to identify the modified component. One non-invasive and reliable PCB tamper detection technique with global coverage is the impedance characterization of a PCB's power delivery network (PDN). However, it is an open question whether one can use the two-dimensional impedance signatures for forensics purposes. In this work, we introduce a novel PCB forensics approach using explainable AI (XAI) on impedance signatures. Through extensive experiments, we replicate various PCB tamper events, generating a dataset used to develop an XAI algorithm capable of not only detecting tampering but also explaining why the algorithm makes a decision about whether a tamper event has happened. At the core of our XAI algorithm is a random forest classifier with an accuracy of 96.7%, sufficient to explain the algorithm's decisions. To understand the behavior of the classifier in the decision-making process, we utilized SHAP values as an XAI tool to determine which frequency component influences the classifier's decision for a particular class the most. This approach enhances detection capabilities as well as advancing the verifier's ability to reverse-engineer and analyze two-dimensional impedance signatures for forensics.",
    "authors": [
      "Maryam Saadat Safa, Seyedmohammad Nouraniboosjin, Fatemeh Ganji, Shahin Tajik"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.836096"
  },
  {
    "id": "oai:arXiv.org:2506.05739v1",
    "journal": "arXiv_CS",
    "title": "To Protect the LLM Agent Against the Prompt Injection Attack with Polymorphic Prompt",
    "link": "https://arxiv.org/abs/2506.05739",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05739v1 Announce Type: new \nAbstract: LLM agents are widely used as agents for customer support, content generation, and code assistance. However, they are vulnerable to prompt injection attacks, where adversarial inputs manipulate the model's behavior. Traditional defenses like input sanitization, guard models, and guardrails are either cumbersome or ineffective. In this paper, we propose a novel, lightweight defense mechanism called Polymorphic Prompt Assembling (PPA), which protects against prompt injection with near-zero overhead. The approach is based on the insight that prompt injection requires guessing and breaking the structure of the system prompt. By dynamically varying the structure of system prompts, PPA prevents attackers from predicting the prompt structure, thereby enhancing security without compromising performance. We conducted experiments to evaluate the effectiveness of PPA against existing attacks and compared it with other defense methods.",
    "authors": [
      "Zhilong Wang, Neha Nagaraja, Lan Zhang, Hayretdin Bahsi, Pawan Patil, Peng Liu"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.836130"
  },
  {
    "id": "oai:arXiv.org:2506.05754v1",
    "journal": "arXiv_CS",
    "title": "Constrained Sampling for Language Models Should Be Easy: An MCMC Perspective",
    "link": "https://arxiv.org/abs/2506.05754",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05754v1 Announce Type: new \nAbstract: Constrained decoding enables Language Models (LMs) to produce samples that provably satisfy hard constraints. However, existing constrained-decoding approaches often distort the underlying model distribution, a limitation that is especially problematic in applications like program fuzzing, where one wants to generate diverse and valid program inputs for testing purposes. We propose a new constrained sampling framework based on Markov Chain Monte Carlo (MCMC) that simultaneously satisfies three core desiderata: constraint satisfying (every sample satisfies the constraint), monotonically converging (the sampling process converges to the true conditional distribution), and efficient (high-quality samples emerge in few steps). Our method constructs a proposal distribution over valid outputs and applies a Metropolis-Hastings acceptance criterion based on the LM's likelihood, ensuring principled and efficient exploration of the constrained space. Empirically, our sampler outperforms existing methods on both synthetic benchmarks and real-world program fuzzing tasks.",
    "authors": [
      "Emmanuel Anaya Gonzalez, Sairam Vaidya, Kanghee Park, Ruyi Ji, Taylor Berg-Kirkpatrick, Loris D'Antoni"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.836233"
  },
  {
    "id": "oai:arXiv.org:2506.05780v1",
    "journal": "arXiv_CS",
    "title": "Robust sensor fusion against on-vehicle sensor staleness",
    "link": "https://arxiv.org/abs/2506.05780",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05780v1 Announce Type: new \nAbstract: Sensor fusion is crucial for a performant and robust Perception system in autonomous vehicles, but sensor staleness, where data from different sensors arrives with varying delays, poses significant challenges. Temporal misalignment between sensor modalities leads to inconsistent object state estimates, severely degrading the quality of trajectory predictions that are critical for safety. We present a novel and model-agnostic approach to address this problem via (1) a per-point timestamp offset feature (for LiDAR and radar both relative to camera) that enables fine-grained temporal awareness in sensor fusion, and (2) a data augmentation strategy that simulates realistic sensor staleness patterns observed in deployed vehicles. Our method is integrated into a perspective-view detection model that consumes sensor data from multiple LiDARs, radars and cameras. We demonstrate that while a conventional model shows significant regressions when one sensor modality is stale, our approach reaches consistently good performance across both synchronized and stale conditions.",
    "authors": [
      "Meng Fan, Yifan Zuo, Patrick Blaes, Harley Montgomery, Subhasis Das"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.836332"
  },
  {
    "id": "oai:arXiv.org:2506.05801v1",
    "journal": "arXiv_CS",
    "title": "Neural Collapse in Cumulative Link Models for Ordinal Regression: An Analysis with Unconstrained Feature Model",
    "link": "https://arxiv.org/abs/2506.05801",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05801v1 Announce Type: new \nAbstract: A phenomenon known as ''Neural Collapse (NC)'' in deep classification tasks, in which the penultimate-layer features and the final classifiers exhibit an extremely simple geometric structure, has recently attracted considerable attention, with the expectation that it can deepen our understanding of how deep neural networks behave. The Unconstrained Feature Model (UFM) has been proposed to explain NC theoretically, and there emerges a growing body of work that extends NC to tasks other than classification and leverages it for practical applications. In this study, we investigate whether a similar phenomenon arises in deep Ordinal Regression (OR) tasks, via combining the cumulative link model for OR and UFM. We show that a phenomenon we call Ordinal Neural Collapse (ONC) indeed emerges and is characterized by the following three properties: (ONC1) all optimal features in the same class collapse to their within-class mean when regularization is applied; (ONC2) these class means align with the classifier, meaning that they collapse onto a one-dimensional subspace; (ONC3) the optimal latent variables (corresponding to logits or preactivations in classification tasks) are aligned according to the class order, and in particular, in the zero-regularization limit, a highly local and simple geometric relationship emerges between the latent variables and the threshold values. We prove these properties analytically within the UFM framework with fixed threshold values and corroborate them empirically across a variety of datasets. We also discuss how these insights can be leveraged in OR, highlighting the use of fixed thresholds.",
    "authors": [
      "Chuang Ma, Tomoyuki Obuchi, Toshiyuki Tanaka"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.836409"
  },
  {
    "id": "oai:arXiv.org:2506.05806v1",
    "journal": "arXiv_CS",
    "title": "LLIA -- Enabling Low-Latency Interactive Avatars: Real-Time Audio-Driven Portrait Video Generation with Diffusion Models",
    "link": "https://arxiv.org/abs/2506.05806",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05806v1 Announce Type: new \nAbstract: Diffusion-based models have gained wide adoption in the virtual human generation due to their outstanding expressiveness. However, their substantial computational requirements have constrained their deployment in real-time interactive avatar applications, where stringent speed, latency, and duration requirements are paramount. We present a novel audio-driven portrait video generation framework based on the diffusion model to address these challenges. Firstly, we propose robust variable-length video generation to reduce the minimum time required to generate the initial video clip or state transitions, which significantly enhances the user experience. Secondly, we propose a consistency model training strategy for Audio-Image-to-Video to ensure real-time performance, enabling a fast few-step generation. Model quantization and pipeline parallelism are further employed to accelerate the inference speed. To mitigate the stability loss incurred by the diffusion process and model quantization, we introduce a new inference strategy tailored for long-duration video generation. These methods ensure real-time performance and low latency while maintaining high-fidelity output. Thirdly, we incorporate class labels as a conditional input to seamlessly switch between speaking, listening, and idle states. Lastly, we design a novel mechanism for fine-grained facial expression control to exploit our model's inherent capacity. Extensive experiments demonstrate that our approach achieves low-latency, fluid, and authentic two-way communication. On an NVIDIA RTX 4090D, our model achieves a maximum of 78 FPS at a resolution of 384x384 and 45 FPS at a resolution of 512x512, with an initial video generation latency of 140 ms and 215 ms, respectively.",
    "authors": [
      "Haojie Yu, Zhaonian Wang, Yihan Pan, Meng Cheng, Hao Yang, Chao Wang, Tao Xie, Xiaoming Xu, Xiaoming Wei, Xunliang Cai"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.836417"
  },
  {
    "id": "oai:arXiv.org:2506.05853v1",
    "journal": "arXiv_CS",
    "title": "Training-Free Query Optimization via LLM-Based Plan Similarity",
    "link": "https://arxiv.org/abs/2506.05853",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05853v1 Announce Type: new \nAbstract: Large language model (LLM) embeddings offer a promising new avenue for database query optimization. In this paper, we explore how pre-trained execution plan embeddings can guide SQL query execution without the need for additional model training. We introduce LLM-PM (LLM-based Plan Mapping), a framework that embeds the default execution plan of a query, finds its k nearest neighbors among previously executed plans, and recommends database hintsets based on neighborhood voting. A lightweight consistency check validates the selected hint, while a fallback mechanism searches the full hint space when needed. Evaluated on the JOB-CEB benchmark using OpenGauss, LLM-PM achieves an average speed-up of 21% query latency reduction. This work highlights the potential of LLM-powered embeddings to deliver practical improvements in query performance and opens new directions for training-free, embedding-based optimizer guidance systems.",
    "authors": [
      "Nikita Vasilenko, Alexander Demin, Vladimir Boorlakov"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.836670"
  },
  {
    "id": "oai:arXiv.org:2506.05854v1",
    "journal": "arXiv_CS",
    "title": "Towards Next-Generation Intelligent Maintenance: Collaborative Fusion of Large and Small Models",
    "link": "https://arxiv.org/abs/2506.05854",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05854v1 Announce Type: new \nAbstract: With the rapid advancement of intelligent technologies, collaborative frameworks integrating large and small models have emerged as a promising approach for enhancing industrial maintenance. However, several challenges persist, including limited domain adaptability, insufficient real-time performance and reliability, high integration complexity, and difficulties in knowledge representation and fusion. To address these issues, an intelligent maintenance framework for industrial scenarios is proposed. This framework adopts a five-layer architecture and integrates the precise computational capabilities of domain-specific small models with the cognitive reasoning, knowledge integration, and interactive functionalities of large language models. The objective is to achieve more accurate, intelligent, and efficient maintenance in industrial applications. Two realistic implementations, involving the maintenance of telecommunication equipment rooms and the intelligent servicing of energy storage power stations, demonstrate that the framework significantly enhances maintenance efficiency.",
    "authors": [
      "Xiaoyi Yuan, Qiming Huang, Mingqing Guo, Huiming Ma, Ming Xu, Zeyi Liu, Xiao He"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.836678"
  },
  {
    "id": "oai:arXiv.org:2506.05858v1",
    "journal": "arXiv_CS",
    "title": "ChronoTailor: Harnessing Attention Guidance for Fine-Grained Video Virtual Try-On",
    "link": "https://arxiv.org/abs/2506.05858",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05858v1 Announce Type: new \nAbstract: Video virtual try-on aims to seamlessly replace the clothing of a person in a source video with a target garment. Despite significant progress in this field, existing approaches still struggle to maintain continuity and reproduce garment details. In this paper, we introduce ChronoTailor, a diffusion-based framework that generates temporally consistent videos while preserving fine-grained garment details. By employing a precise spatio-temporal attention mechanism to guide the integration of fine-grained garment features, ChronoTailor achieves robust try-on performance. First, ChronoTailor leverages region-aware spatial guidance to steer the evolution of spatial attention and employs an attention-driven temporal feature fusion mechanism to generate more continuous temporal features. This dual approach not only enables fine-grained local editing but also effectively mitigates artifacts arising from video dynamics. Second, ChronoTailor integrates multi-scale garment features to preserve low-level visual details and incorporates a garment-pose feature alignment to ensure temporal continuity during dynamic motion. Additionally, we collect StyleDress, a new dataset featuring intricate garments, varied environments, and diverse poses, offering advantages over existing public datasets, and will be publicly available for research. Extensive experiments show that ChronoTailor maintains spatio-temporal continuity and preserves garment details during motion, significantly outperforming previous methods.",
    "authors": [
      "Jinjuan Wang, Wenzhang Sun, Ming Li, Yun Zheng, Fanyao Li, Zhulin Tao, Donglin Di, Hao Li, Wei Chen, Xianglin Huang"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.836703"
  },
  {
    "id": "oai:arXiv.org:2506.05872v1",
    "journal": "arXiv_CS",
    "title": "Domain-RAG: Retrieval-Guided Compositional Image Generation for Cross-Domain Few-Shot Object Detection",
    "link": "https://arxiv.org/abs/2506.05872",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05872v1 Announce Type: new \nAbstract: Cross-Domain Few-Shot Object Detection (CD-FSOD) aims to detect novel objects with only a handful of labeled samples from previously unseen domains. While data augmentation and generative methods have shown promise in few-shot learning, their effectiveness for CD-FSOD remains unclear due to the need for both visual realism and domain alignment. Existing strategies, such as copy-paste augmentation and text-to-image generation, often fail to preserve the correct object category or produce backgrounds coherent with the target domain, making them non-trivial to apply directly to CD-FSOD. To address these challenges, we propose Domain-RAG, a training-free, retrieval-guided compositional image generation framework tailored for CD-FSOD. Domain-RAG consists of three stages: domain-aware background retrieval, domain-guided background generation, and foreground-background composition. Specifically, the input image is first decomposed into foreground and background regions. We then retrieve semantically and stylistically similar images to guide a generative model in synthesizing a new background, conditioned on both the original and retrieved contexts. Finally, the preserved foreground is composed with the newly generated domain-aligned background to form the generated image. Without requiring any additional supervision or training, Domain-RAG produces high-quality, domain-consistent samples across diverse tasks, including CD-FSOD, remote sensing FSOD, and camouflaged FSOD. Extensive experiments show consistent improvements over strong baselines and establish new state-of-the-art results. Codes will be released upon acceptance.",
    "authors": [
      "Yu Li, Xingyu Qiu, Yuqian Fu, Jie Chen, Tianwen Qian, Xu Zheng, Danda Pani Paudel, Yanwei Fu, Xuanjing Huang, Luc Van Gool, Yu-Gang Jiang"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.836763"
  },
  {
    "id": "oai:arXiv.org:2506.05876v1",
    "journal": "arXiv_CS",
    "title": "Bayesian Persuasion as a Bargaining Game",
    "link": "https://arxiv.org/abs/2506.05876",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05876v1 Announce Type: new \nAbstract: Bayesian persuasion, an extension of cheap-talk communication, involves an informed sender committing to a signaling scheme to influence a receiver's actions. Compared to cheap talk, this sender's commitment enables the receiver to verify the incentive compatibility of signals beforehand, facilitating cooperation. While effective in one-shot scenarios, Bayesian persuasion faces computational complexity (NP-hardness) when extended to long-term interactions, where the receiver may adopt dynamic strategies conditional on past outcomes and future expectations. To address this complexity, we introduce the bargaining perspective, which allows: (1) a unified framework and well-structured solution concept for long-term persuasion, with desirable properties such as fairness and Pareto efficiency; (2) a clear distinction between two previously conflated advantages: the sender's informational advantage and first-proposer advantage. With only modest modifications to the standard setting, this perspective makes explicit the common knowledge of the game structure and grants the receiver comparable commitment capabilities, thereby reinterpreting classic one-sided persuasion as a balanced information bargaining framework. The framework is validated through a two-stage validation-and-inference paradigm: We first demonstrate that GPT-o3 and DeepSeek-R1, out of publicly available LLMs, reliably handle standard tasks; We then apply them to persuasion scenarios to test that the outcomes align with what our information-bargaining framework suggests. All code, results, and terminal logs are publicly available at github.com/YueLin301/InformationBargaining.",
    "authors": [
      "Yue Lin, Shuhui Zhu, William A Cunningham, Wenhao Li, Pascal Poupart, Hongyuan Zha, Baoxiang Wang"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.836780"
  },
  {
    "id": "oai:arXiv.org:2506.05879v1",
    "journal": "arXiv_CS",
    "title": "Human-AI Alignment of Multimodal Large Language Models with Speech-Language Pathologists in Parent-Child Interactions",
    "link": "https://arxiv.org/abs/2506.05879",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05879v1 Announce Type: new \nAbstract: Joint attention is a critical marker of early social-communicative development, yet remains difficult for caregivers to assess without expert guidance. In this work, we explore how multimodal large language models (MLLMs) can be aligned with the reasoning processes of speech-language pathologists (SLPs) to support the interpretation of everyday parent-child interactions. We conducted in-depth interviews and video annotation studies with three experienced SLPs to uncover how they evaluate joint attention based on three core behavioural cues: gaze, action, and vocalisation. Using these insights, we developed a two-stage MLLM-based system that first extracts fine-grained behavioural descriptions from video segments and then judge joint attention quality using expert-aligned prompts. Our evaluation across 26 parent-child interaction videos shows that MLLMs can achieve up to 85% accuracy in perceptual cue extraction and over 75% average precision in simulating expert judgement. We further propose design guidelines for building MLLM-based behaviour observation-judgement systems that align with SLPs, emphasising the structuring of behavioural cues, the construction of exemplar libraries grounded in expert annotations, and the need to personalise system responses based on developmental stage and neurotypical or atypical presentation. This work provides structured behavioural cues derived from SLP expertise, demonstrates the feasibility of aligning SLPs observation and judgement using MLLMs, and offers practical design guidelines for building aligned systems to support parent-child interaction analysis.",
    "authors": [
      "Weiyan Shi, Kenny Tsu Wei Choo"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.836804"
  },
  {
    "id": "oai:arXiv.org:2506.05883v1",
    "journal": "arXiv_CS",
    "title": "HMVLM: Multistage Reasoning-Enhanced Vision-Language Model for Long-Tailed Driving Scenarios",
    "link": "https://arxiv.org/abs/2506.05883",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05883v1 Announce Type: new \nAbstract: We present HaoMo Vision-Language Model (HMVLM), an end-to-end driving framework that implements the slow branch of a cognitively inspired fast-slow architecture. A fast controller outputs low-level steering, throttle, and brake commands, while a slow planner-a large vision-language model-generates high-level intents such as \"yield to pedestrian\" or \"merge after the truck\" without compromising latency. HMVLM introduces three upgrades: (1) selective five-view prompting with an embedded 4s history of ego kinematics, (2) multi-stage chain-of-thought (CoT) prompting that enforces a Scene Understanding -> Driving Decision -> Trajectory Inference reasoning flow, and (3) spline-based trajectory post-processing that removes late-stage jitter and sharp turns. Trained on the Waymo Open Dataset, these upgrades enable HMVLM to achieve a Rater Feedback Score (RFS) of 7.7367, securing 2nd place in the 2025 Waymo Vision-based End-to-End (E2E) Driving Challenge and surpassing the public baseline by 2.77%.",
    "authors": [
      "Daming Wang, Yuhao Song, Zijian He, Kangliang Chen, Xing Pan, Lu Deng, Weihao Gu"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.836820"
  },
  {
    "id": "oai:arXiv.org:2506.05887v1",
    "journal": "arXiv_CS",
    "title": "Explainability in Context: A Multilevel Framework Aligning AI Explanations with Stakeholder with LLMs",
    "link": "https://arxiv.org/abs/2506.05887",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05887v1 Announce Type: new \nAbstract: The growing application of artificial intelligence in sensitive domains has intensified the demand for systems that are not only accurate but also explainable and trustworthy. Although explainable AI (XAI) methods have proliferated, many do not consider the diverse audiences that interact with AI systems: from developers and domain experts to end-users and society. This paper addresses how trust in AI is influenced by the design and delivery of explanations and proposes a multilevel framework that aligns explanations with the epistemic, contextual, and ethical expectations of different stakeholders. The framework consists of three layers: algorithmic and domain-based, human-centered, and social explainability. We highlight the emerging role of Large Language Models (LLMs) in enhancing the social layer by generating accessible, natural language explanations. Through illustrative case studies, we demonstrate how this approach facilitates technical fidelity, user engagement, and societal accountability, reframing XAI as a dynamic, trust-building process.",
    "authors": [
      "Marilyn Bello, Rafael Bello, Maria-Matilde Garc\\'ia, Ann Now\\'e, Iv\\'an Sevillano-Garc\\'ia, Francisco Herrera"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.836837"
  },
  {
    "id": "oai:arXiv.org:2506.05893v1",
    "journal": "arXiv_CS",
    "title": "Field-of-View and Input Constrained Impact Time Guidance Against Stationary Targets",
    "link": "https://arxiv.org/abs/2506.05893",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05893v1 Announce Type: new \nAbstract: This paper proposes a guidance strategy to achieve time-constrained interception of stationary targets, taking into account both the bounded field-of-view (FOV) of seeker-equipped interceptors and the actuator's physical constraints. Actuator saturation presents a significant challenge in real-world systems, often resulting in degraded performance. However, since these limitations are typically known in advance, incorporating them into the guidance design can enhance overall performance. To address the FOV constraint, a time-to-go error-based approach is adopted. Furthermore, to incorporate the lateral acceleration constraints, the engagement kinematics are augmented with an input saturation model. Subsequently, the guidance strategy that constrains the lateral acceleration and the time-to-go values within their respective bounds is derived using Lyapunov stability concepts and the backstepping technique. Furthermore, a multi-stage approach is suggested to expand the achievable range of impact time. Numerical simulations are performed to validate the efficacy of the proposed scheme for different initial engagement geometries.",
    "authors": [
      "Swati Singh, Shashi Ranjan Kumar, Dwaipayan Mukherjee"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.836861"
  },
  {
    "id": "oai:arXiv.org:2506.05919v1",
    "journal": "arXiv_CS",
    "title": "RSMA-Enabled Covert Communications Against Multiple Spatially Random Wardens",
    "link": "https://arxiv.org/abs/2506.05919",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05919v1 Announce Type: new \nAbstract: This work investigates covert communication in a rate-splitting multiple access (RSMA)-based multi-user multiple-input single-output system, where the random locations of the wardens follow a homogeneous Poisson point process. To demonstrate practical deployment scenarios, imperfect channel state information at the transmitter is considered. Closed-form expressions for the statistics of the received signal-to-interference-plus-noise ratio, along with the analytical formulations for the covertness constraint, outage probability, and effective covert throughput (ECT), are derived. Subsequently, an ECT maximization problem is formulated under covertness and power allocation constraints. This optimization problem is addressed using an alternating optimization-assisted genetic algorithm (AO-GA). Simulation results corroborate the theoretical analysis and demonstrate the superiority of RSMA over conventional multiple access schemes, as well as the effectiveness of the proposed AO-GA.",
    "authors": [
      "Xinyue Pei, Jihao Liu, Xuewen Luo, Xingwei Wang, Yingyang Chen, Miaowen Wen, Theodoros A. Tsiftsis"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.836986"
  },
  {
    "id": "oai:arXiv.org:2506.05924v1",
    "journal": "arXiv_CS",
    "title": "Generating Grounded Responses to Counter Misinformation via Learning Efficient Fine-Grained Critiques",
    "link": "https://arxiv.org/abs/2506.05924",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05924v1 Announce Type: new \nAbstract: Fake news and misinformation poses a significant threat to society, making efficient mitigation essential. However, manual fact-checking is costly and lacks scalability. Large Language Models (LLMs) offer promise in automating counter-response generation to mitigate misinformation, but a critical challenge lies in their tendency to hallucinate non-factual information. Existing models mainly rely on LLM self-feedback to reduce hallucination, but this approach is computationally expensive. In this paper, we propose MisMitiFact, Misinformation Mitigation grounded in Facts, an efficient framework for generating fact-grounded counter-responses at scale. MisMitiFact generates simple critique feedback to refine LLM outputs, ensuring responses are grounded in evidence. We develop lightweight, fine-grained critique models trained on data sourced from readily available fact-checking sites to identify and correct errors in key elements such as numerals, entities, and topics in LLM generations. Experiments show that MisMitiFact generates counter-responses of comparable quality to LLMs' self-feedback while using significantly smaller critique models. Importantly, it achieves ~5x increase in feedback generation throughput, making it highly suitable for cost-effective, large-scale misinformation mitigation. Code and LLM prompt templates are at https://github.com/xxfwin/MisMitiFact.",
    "authors": [
      "Xiaofei Xu, Xiuzhen Zhang, Ke Deng"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.836994"
  },
  {
    "id": "oai:arXiv.org:2506.05927v1",
    "journal": "arXiv_CS",
    "title": "LengClaro2023: A Dataset of Administrative Texts in Spanish with Plain Language adaptations",
    "link": "https://arxiv.org/abs/2506.05927",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05927v1 Announce Type: new \nAbstract: In this work, we present LengClaro2023, a dataset of legal-administrative texts in Spanish. Based on the most frequently used procedures from the Spanish Social Security website, we have created for each text two simplified equivalents. The first version follows the recommendations provided by arText claro. The second version incorporates additional recommendations from plain language guidelines to explore further potential improvements in the system. The linguistic resource created in this work can be used for evaluating automatic text simplification (ATS) systems in Spanish.",
    "authors": [
      "Bel\\'en Ag\\\"uera-Marco, Itziar Gonzalez-Dios"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.837011"
  },
  {
    "id": "oai:arXiv.org:2506.05932v1",
    "journal": "arXiv_CS",
    "title": "Combating Reentrancy Bugs on Sharded Blockchains",
    "link": "https://arxiv.org/abs/2506.05932",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05932v1 Announce Type: new \nAbstract: Reentrancy is a well-known source of smart contract bugs on Ethereum, leading e.g. to double-spending vulnerabilities in DeFi applications. But less is known about this problem in other blockchains, which can have significantly different execution models. Sharded blockchains in particular generally use an asynchronous messaging model that differs substantially from the synchronous and transactional model of Ethereum. We study the features of this model and its effect on reentrancy bugs on three examples: the Internet Computer (ICP) blockchain, NEAR Protocol, and MultiversX. We argue that this model, while useful for improving performance, also makes it easier to introduce reentrancy bugs. For example, reviews of the pre-production versions of some of the most critical ICP smart contracts found that 66% (10/15) of the reviewed contracts -- written by expert authors -- contained reentrancy bugs of medium or high severity, with potential damages in tens of millions of dollars. We evaluate existing Ethereum programming techniques (in particular the effects-checks-interactions pattern, and locking) to prevent reentrancy bugs in the context of this new messaging model and identify some issues with them. We then present novel Rust and Motoko patterns that can be leveraged on ICP to solve these issues. Finally, we demonstrate that the formal verification tool TLA+ can be used to find and eliminate such bugs in real world smart contracts on sharded blockchains.",
    "authors": [
      "Roman Kashitsyn, Robin K\\\"unzler, Ognjen Mari\\'c, Lara Schmid"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.837035"
  },
  {
    "id": "oai:arXiv.org:2506.05933v1",
    "journal": "arXiv_CS",
    "title": "Machine Learning Predictions for Traffic Equilibria in Road Renovation Scheduling",
    "link": "https://arxiv.org/abs/2506.05933",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05933v1 Announce Type: new \nAbstract: Accurately estimating the impact of road maintenance schedules on traffic conditions is important because maintenance operations can substantially worsen congestion if not carefully planned. Reliable estimates allow planners to avoid excessive delays during periods of roadwork. Since the exact increase in congestion is difficult to predict analytically, traffic simulations are commonly used to assess the redistribution of the flow of traffic. However, when applied to long-term maintenance planning involving many overlapping projects and scheduling alternatives, these simulations must be run thousands of times, resulting in a significant computational burden. This paper investigates the use of machine learning-based surrogate models to predict network-wide congestion caused by simultaneous road renovations. We frame the problem as a supervised learning task, using one-hot encodings, engineered traffic features, and heuristic approximations. A range of linear, ensemble-based, probabilistic, and neural regression models is evaluated under an online learning framework in which data progressively becomes available. The experimental results show that the Costliest Subset Heuristic provides a reasonable approximation when limited training data is available, and that most regression models fail to outperform it, with the exception of XGBoost, which achieves substantially better accuracy. In overall performance, XGBoost significantly outperforms alternatives in a range of metrics, most strikingly Mean Absolute Percentage Error (MAPE) and Pinball loss, where it achieves a MAPE of 11% and outperforms the next-best model by 20% and 38% respectively. This modeling approach has the potential to reduce the computational burden of large-scale traffic assignment problems in maintenance planning.",
    "authors": [
      "Robbert Bosch, Wouter van Heeswijk, Patricia Rogetzer, Martijn Mes"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.837043"
  },
  {
    "id": "oai:arXiv.org:2506.05935v1",
    "journal": "arXiv_CS",
    "title": "SurGSplat: Progressive Geometry-Constrained Gaussian Splatting for Surgical Scene Reconstruction",
    "link": "https://arxiv.org/abs/2506.05935",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05935v1 Announce Type: new \nAbstract: Intraoperative navigation relies heavily on precise 3D reconstruction to ensure accuracy and safety during surgical procedures. However, endoscopic scenarios present unique challenges, including sparse features and inconsistent lighting, which render many existing Structure-from-Motion (SfM)-based methods inadequate and prone to reconstruction failure. To mitigate these constraints, we propose SurGSplat, a novel paradigm designed to progressively refine 3D Gaussian Splatting (3DGS) through the integration of geometric constraints. By enabling the detailed reconstruction of vascular structures and other critical features, SurGSplat provides surgeons with enhanced visual clarity, facilitating precise intraoperative decision-making. Experimental evaluations demonstrate that SurGSplat achieves superior performance in both novel view synthesis (NVS) and pose estimation accuracy, establishing it as a high-fidelity and efficient solution for surgical scene reconstruction. More information and results can be found on the page https://surgsplat.github.io/.",
    "authors": [
      "Yuchao Zheng, Jianing Zhang, Guochen Ning, Hongen Liao"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.837060"
  },
  {
    "id": "oai:arXiv.org:2506.05937v1",
    "journal": "arXiv_CS",
    "title": "Quantifying Adversarial Uncertainty in Evidential Deep Learning using Conflict Resolution",
    "link": "https://arxiv.org/abs/2506.05937",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05937v1 Announce Type: new \nAbstract: Reliability of deep learning models is critical for deployment in high-stakes applications, where out-of-distribution or adversarial inputs may lead to detrimental outcomes. Evidential Deep Learning, an efficient paradigm for uncertainty quantification, models predictions as Dirichlet distributions of a single forward pass. However, EDL is particularly vulnerable to adversarially perturbed inputs, making overconfident errors. Conflict-aware Evidential Deep Learning (C-EDL) is a lightweight post-hoc uncertainty quantification approach that mitigates these issues, enhancing adversarial and OOD robustness without retraining. C-EDL generates diverse, task-preserving transformations per input and quantifies representational disagreement to calibrate uncertainty estimates when needed. C-EDL's conflict-aware prediction adjustment improves detection of OOD and adversarial inputs, maintaining high in-distribution accuracy and low computational overhead. Our experimental evaluation shows that C-EDL significantly outperforms state-of-the-art EDL variants and competitive baselines, achieving substantial reductions in coverage for OOD data (up to 55%) and adversarial data (up to 90%), across a range of datasets, attack types, and uncertainty metrics.",
    "authors": [
      "Charmaine Barker, Daniel Bethell, Simos Gerasimou"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.837083"
  },
  {
    "id": "oai:arXiv.org:2506.05941v1",
    "journal": "arXiv_CS",
    "title": "Comparative Analysis of Modern Machine Learning Models for Retail Sales Forecasting",
    "link": "https://arxiv.org/abs/2506.05941",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05941v1 Announce Type: new \nAbstract: Accurate forecasting is key for all business planning. When estimated sales are too high, brick-and-mortar retailers may incur higher costs due to unsold inventories, higher labor and storage space costs, etc. On the other hand, when forecasts underestimate the level of sales, firms experience lost sales, shortages, and impact on the reputation of the retailer in their relevant market. Accurate forecasting presents a competitive advantage for companies. It facilitates the achievement of revenue and profit goals and execution of pricing strategy and tactics. In this study, we provide an exhaustive assessment of the forecasting models applied to a high-resolution brick-and-mortar retail dataset. Our forecasting framework addresses the problems found in retail environments, including intermittent demand, missing values, and frequent product turnover. We compare tree-based ensembles (such as XGBoost and LightGBM) and state-of-the-art neural network architectures (including N-BEATS, NHITS, and the Temporal Fusion Transformer) across various experimental settings. Our results show that localized modeling strategies especially those using tree-based models on individual groups with non-imputed data, consistently deliver superior forecasting accuracy and computational efficiency. In contrast, neural models benefit from advanced imputation methods, yet still fall short in handling the irregularities typical of physical retail data. These results further practical understanding for model selection in retail environment and highlight the significance of data preprocessing to improve forecast performance.",
    "authors": [
      "Luka Hobor, Mario Brcic, Lidija Polutnik, Ante Kapetanovic"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.837108"
  },
  {
    "id": "oai:arXiv.org:2506.05953v1",
    "journal": "arXiv_CS",
    "title": "Learning Deterministic Policies with Policy Gradients in Constrained Markov Decision Processes",
    "link": "https://arxiv.org/abs/2506.05953",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05953v1 Announce Type: new \nAbstract: Constrained Reinforcement Learning (CRL) addresses sequential decision-making problems where agents are required to achieve goals by maximizing the expected return while meeting domain-specific constraints. In this setting, policy-based methods are widely used thanks to their advantages when dealing with continuous-control problems. These methods search in the policy space with an action-based or a parameter-based exploration strategy, depending on whether they learn the parameters of a stochastic policy or those of a stochastic hyperpolicy. We introduce an exploration-agnostic algorithm, called C-PG, which enjoys global last-iterate convergence guarantees under gradient domination assumptions. Furthermore, under specific noise models where the (hyper)policy is expressed as a stochastic perturbation of the actions or of the parameters of an underlying deterministic policy, we additionally establish global last-iterate convergence guarantees of C-PG to the optimal deterministic policy. This holds when learning a stochastic (hyper)policy and subsequently switching off the stochasticity at the end of training, thereby deploying a deterministic policy. Finally, we empirically validate both the action-based (C-PGAE) and parameter-based (C-PGPE) variants of C-PG on constrained control tasks, and compare them against state-of-the-art baselines, demonstrating their effectiveness, in particular when deploying deterministic policies after training.",
    "authors": [
      "Alessandro Montenegro, Leonardo Cesani, Marco Mussi, Matteo Papini, Alberto Maria Metelli"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.837167"
  },
  {
    "id": "oai:arXiv.org:2506.05958v1",
    "journal": "arXiv_CS",
    "title": "Applying XAI based unsupervised knowledge discovering for Operation modes in a WWTP. A real case: AQUAVALL WWTP",
    "link": "https://arxiv.org/abs/2506.05958",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05958v1 Announce Type: new \nAbstract: Water reuse is a key point when fresh water is a commodity in ever greater demand, but which is also becoming ever more available. Furthermore, the return of clean water to its natural environment is also mandatory. Therefore, wastewater treatment plants (WWTPs) are essential in any policy focused on these serious challenges.\n  WWTPs are complex facilities which need to operate at their best to achieve their goals. Nowadays, they are largely monitored, generating large databases of historical data concerning their functioning over time. All this implies a large amount of embedded information which is not usually easy for plant managers to assimilate, correlate and understand; in other words, for them to know the global operation of the plant at any given time. At this point, the intelligent and Machine Learning (ML) approaches can give support for that need, managing all the data and translating them into manageable, interpretable and explainable knowledge about how the WWTP plant is operating at a glance.\n  Here, an eXplainable Artificial Intelligence (XAI) based methodology is proposed and tested for a real WWTP, in order to extract explainable service knowledge concerning the operation modes of the WWTP managed by AQUAVALL, which is the public service in charge of the integral water cycle in the City Council of Valladolid (Castilla y Le\\'on, Spain). By applying well-known approaches of XAI and ML focused on the challenge of WWTP, it has been possible to summarize a large number of historical databases through a few explained operation modes of the plant in a low-dimensional data space, showing the variables and facility units involved in each case.",
    "authors": [
      "Alicia Beneyto-Rodriguez, Gregorio I. Sainz-Palmero, Marta Galende-Hern\\'andez, Mar\\'ia J. Fuente, Jos\\'e M. Cuenca"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.837184"
  },
  {
    "id": "oai:arXiv.org:2506.05967v1",
    "journal": "arXiv_CS",
    "title": "Preference Learning for AI Alignment: a Causal Perspective",
    "link": "https://arxiv.org/abs/2506.05967",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05967v1 Announce Type: new \nAbstract: Reward modelling from preference data is a crucial step in aligning large language models (LLMs) with human values, requiring robust generalisation to novel prompt-response pairs. In this work, we propose to frame this problem in a causal paradigm, providing the rich toolbox of causality to identify the persistent challenges, such as causal misidentification, preference heterogeneity, and confounding due to user-specific factors. Inheriting from the literature of causal inference, we identify key assumptions necessary for reliable generalisation and contrast them with common data collection practices. We illustrate failure modes of naive reward models and demonstrate how causally-inspired approaches can improve model robustness. Finally, we outline desiderata for future research and practices, advocating targeted interventions to address inherent limitations of observational data.",
    "authors": [
      "Katarzyna Kobalczyk, Mihaela van der Schaar"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.837210"
  },
  {
    "id": "oai:arXiv.org:2506.05972v1",
    "journal": "arXiv_CS",
    "title": "Domain Adaptation in Agricultural Image Analysis: A Comprehensive Review from Shallow Models to Deep Learning",
    "link": "https://arxiv.org/abs/2506.05972",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05972v1 Announce Type: new \nAbstract: With the increasing use of computer vision in agriculture, image analysis has become crucial for tasks like crop health monitoring and pest detection. However, significant domain shifts between source and target domains-due to environmental differences, crop types, and data acquisition methods-pose challenges. These domain gaps limit the ability of models to generalize across regions, seasons, and complex agricultural environments. This paper explores how Domain Adaptation (DA) techniques can address these challenges, focusing on their role in enhancing the cross-domain transferability of agricultural image analysis. DA has gained attention in agricultural vision tasks due to its potential to mitigate domain heterogeneity. The paper systematically reviews recent advances in DA for agricultural imagery, particularly its practical applications in complex agricultural environments. We examine the key drivers for adopting DA in agriculture, such as limited labeled data, weak model transferability, and dynamic environmental conditions. We also discuss its use in crop health monitoring, pest detection, and fruit recognition, highlighting improvements in performance across regions and seasons. The paper categorizes DA methods into shallow and deep learning models, with further divisions into supervised, semi-supervised, and unsupervised approaches. A special focus is given to adversarial learning-based DA methods, which have shown great promise in challenging agricultural scenarios. Finally, we review key public datasets in agricultural imagery, analyzing their value and limitations in DA research. This review provides a comprehensive framework for researchers, offering insights into current research gaps and supporting the advancement of DA methods in agricultural image analysis.",
    "authors": [
      "Xing Hu, Siyuan Chen, Dawei Zhang"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.837246"
  },
  {
    "id": "oai:arXiv.org:2506.05982v1",
    "journal": "arXiv_CS",
    "title": "MCA-Bench: A Multimodal Benchmark for Evaluating CAPTCHA Robustness Against VLM-based Attacks",
    "link": "https://arxiv.org/abs/2506.05982",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05982v1 Announce Type: new \nAbstract: As automated attack techniques rapidly advance, CAPTCHAs remain a critical defense mechanism against malicious bots. However, existing CAPTCHA schemes encompass a diverse range of modalities -- from static distorted text and obfuscated images to interactive clicks, sliding puzzles, and logic-based questions -- yet the community still lacks a unified, large-scale, multimodal benchmark to rigorously evaluate their security robustness. To address this gap, we introduce MCA-Bench, a comprehensive and reproducible benchmarking suite that integrates heterogeneous CAPTCHA types into a single evaluation protocol. Leveraging a shared vision-language model backbone, we fine-tune specialized cracking agents for each CAPTCHA category, enabling consistent, cross-modal assessments. Extensive experiments reveal that MCA-Bench effectively maps the vulnerability spectrum of modern CAPTCHA designs under varied attack settings, and crucially offers the first quantitative analysis of how challenge complexity, interaction depth, and model solvability interrelate. Based on these findings, we propose three actionable design principles and identify key open challenges, laying the groundwork for systematic CAPTCHA hardening, fair benchmarking, and broader community collaboration. Datasets and code are available online.",
    "authors": [
      "Zonglin Wu, Yule Xue, Xin Wei, Yiren Song"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.837297"
  },
  {
    "id": "oai:arXiv.org:2506.05983v1",
    "journal": "arXiv_CS",
    "title": "Capacity of MIMO Systems Aided by Microwave Linear Analog Computers (MiLACs)",
    "link": "https://arxiv.org/abs/2506.05983",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05983v1 Announce Type: new \nAbstract: Future wireless systems, known as gigantic multiple-input multiple-output (MIMO), are expected to enhance performance by significantly increasing the number of antennas, e.g., a few thousands. To enable gigantic MIMO overcoming the scalability limitations of digital architectures, microwave linear analog computers (MiLACs) have recently emerged. A MiLAC is a multiport microwave network that processes input microwave signals entirely in the analog domain, thereby reducing hardware costs and computational complexity of gigantic MIMO architectures. In this paper, we investigate the fundamental limits on the rate achievable in MiLAC-aided MIMO systems. We model a MIMO system employing MiLAC-aided beamforming at the transmitter and receiver, and formulate the rate maximization problem to optimize the microwave networks of the MiLACs, which are assumed lossless and reciprocal for practical reasons. Under the lossless and reciprocal constraints, we derive a global optimal solution for the microwave networks of the MiLACs in closed form. In addition, we also characterize in closed-form the capacity of MIMO systems operating MiLAC-aided beamforming. Our theoretical analysis, confirmed by numerical simulations, reveals that MiLAC-aided beamforming achieves the same capacity as digital beamforming, while significantly reducing the number of radio frequency (RF) chains, analog-to-digital converters (ADCs)/digital-to-analog converters (DACs) resolution requirements, and computational complexity.",
    "authors": [
      "Matteo Nerini, Bruno Clerckx"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.837304"
  },
  {
    "id": "oai:arXiv.org:2506.05990v1",
    "journal": "arXiv_CS",
    "title": "Leveraging Generative AI for Enhancing Automated Assessment in Programming Education Contests",
    "link": "https://arxiv.org/abs/2506.05990",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05990v1 Announce Type: new \nAbstract: Competitive programming contests play a crucial role in cultivating computational thinking and algorithmic skills among learners. However, generating comprehensive test cases to effectively assess programming solutions remains resource-intensive and challenging for educators. This paper introduces an innovative NLP-driven method leveraging generative AI (large language models) to automate the creation of high-quality test cases for competitive programming assessments. We extensively evaluated our approach on diverse datasets, including 25 years of Romanian Informatics Olympiad (OJI) data for 5th graders, recent competitions hosted on the Kilonova.ro platform, and the International Informatics Olympiad in Teams (IIOT). Our results demonstrate that AI-generated test cases substantially enhanced assessments, notably identifying previously undetected errors in 67% of the OJI 5th grade programming problems. These improvements underscore the complementary educational value of our technique in formative assessment contexts. By openly sharing our prompts, translated datasets, and methodologies, we offer practical NLP-based tools that educators and contest organizers can readily integrate to enhance assessment quality, reduce workload, and deepen insights into learner performance.",
    "authors": [
      "Stefan Dascalescu, Adrian Marius Dumitran, Mihai Alexandru Vasiluta"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.837330"
  },
  {
    "id": "oai:arXiv.org:2506.05991v1",
    "journal": "arXiv_CS",
    "title": "A Culturally-Rich Romanian NLP Dataset from \"Who Wants to Be a Millionaire?\" Videos",
    "link": "https://arxiv.org/abs/2506.05991",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05991v1 Announce Type: new \nAbstract: Large Language Models (LLMs) demonstrate varying performance across languages and cultural contexts. This study introduces a novel, culturally-rich, multilingual dataset derived from video recordings of the Romanian game show \"Who Wants to Be a Millionaire?\" (Vrei s\\u{a} fii Milionar?). We employed an innovative process combining optical character recognition (OCR), automated text extraction, and manual verification to collect question-answer pairs, enriching them with metadata including question domain (e.g., biology, history), cultural relevance (Romanian-specific vs. international), and difficulty. Benchmarking state-of-the-art LLMs, including Romanian-adapted models, on this dataset revealed significant performance disparities: models consistently achieve higher accuracy (80-95%) on international questions compared to Romanian-specific cultural questions (50-75%). We further investigate these differences through experiments involving machine translation of Romanian questions into English and cross-lingual tests using a comparable dataset in French. Our findings underscore the impact of cultural context and data source on LLM performance and offer practical insights for building robust, culturally-aware multilingual NLP systems, especially in educational domains. The dataset is publicly available at Hugging Face.",
    "authors": [
      "Alexandru-Gabriel Ganea, Antonia-Adelina Popovici, Adrian-Marius Dumitran"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.837338"
  },
  {
    "id": "oai:arXiv.org:2506.05999v1",
    "journal": "arXiv_CS",
    "title": "Machine learning for in-situ composition mapping in a self-driving magnetron sputtering system",
    "link": "https://arxiv.org/abs/2506.05999",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05999v1 Announce Type: new \nAbstract: Self-driving labs (SDLs), employing automation and machine learning (ML) to accelerate experimental procedures, have enormous potential in the discovery of new materials. However, in thin film science, SDLs are mainly restricted to solution-based synthetic methods which are easier to automate but cannot access the broad chemical space of inorganic materials. This work presents an SDL based on magnetron co-sputtering. We are using combinatorial frameworks, obtaining accurate composition maps on multi-element, compositionally graded thin films. This normally requires time-consuming ex-situ analysis prone to systematic errors. We present a rapid and calibration-free in-situ, ML driven approach to produce composition maps for arbitrary source combinations and sputtering conditions. We develop a method to predict the composition distribution in a multi-element combinatorial thin film, using in-situ measurements from quartz-crystal microbalance sensors placed in a sputter chamber. For a given source, the sensor readings are learned as a function of the sputtering pressure and magnetron power, through active learning using Gaussian processes (GPs). The final GPs are combined with a geometric model of the deposition flux distribution in the chamber, which allows interpolation of the deposition rates from each source, at any position across the sample. We investigate several acquisition functions for the ML procedure. A fully Bayesian GP - BALM (Bayesian active learning MacKay) - achieved the best performance, learning the deposition rates for a single source in 10 experiments. Prediction accuracy for co-sputtering composition distributions was verified experimentally. Our framework dramatically increases throughput by avoiding the need for extensive characterisation or calibration, thus demonstrating the potential of ML-guided SDLs to accelerate materials exploration.",
    "authors": [
      "Sanna Jarl, Jens Sj\\\"olund, Robert J. W. Frost, Anders Holst, Jonathan J. S. Scragg"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.837364"
  },
  {
    "id": "oai:arXiv.org:2506.06007v1",
    "journal": "arXiv_CS",
    "title": "Enhancing Orthopox Image Classification Using Hybrid Machine Learning and Deep Learning Models",
    "link": "https://arxiv.org/abs/2506.06007",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06007v1 Announce Type: new \nAbstract: Orthopoxvirus infections must be accurately classified from medical pictures for an easy and early diagnosis and epidemic prevention. The necessity for automated and scalable solutions is highlighted by the fact that traditional diagnostic techniques can be time-consuming and require expert interpretation and there are few and biased data sets of the different types of Orthopox. In order to improve classification performance and lower computational costs, a hybrid strategy is put forth in this paper that uses Machine Learning models combined with pretrained Deep Learning models to extract deep feature representations without the need for augmented data. The findings show that this feature extraction method, when paired with other methods in the state-of-the-art, produces excellent classification outcomes while preserving training and inference efficiency. The proposed approach demonstrates strong generalization and robustness across multiple evaluation settings, offering a scalable and interpretable solution for real-world clinical deployment.",
    "authors": [
      "Alejandro Puente-Castro, Enrique Fernandez-Blanco, Daniel Rivero, Andres Molares-Ulloa"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.837408"
  },
  {
    "id": "oai:arXiv.org:2506.06008v1",
    "journal": "arXiv_CS",
    "title": "Token Signature: Predicting Chain-of-Thought Gains with Token Decoding Feature in Large Language Models",
    "link": "https://arxiv.org/abs/2506.06008",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06008v1 Announce Type: new \nAbstract: Chain-of-Thought (CoT) technique has proven effective in improving the performance of large language models (LLMs) on complex reasoning tasks. However, the performance gains are inconsistent across different tasks, and the underlying mechanism remains a long-standing research question. In this work, we make a preliminary observation that the monotonicity of token probability distributions may be correlated with the gains achieved through CoT reasoning. Leveraging this insight, we propose two indicators based on the token probability distribution to assess CoT effectiveness across different tasks. By combining instance-level indicators with logistic regression model, we introduce Dynamic CoT, a method that dynamically select between CoT and direct answer. Furthermore, we extend Dynamic CoT to closed-source models by transferring decision strategies learned from open-source models. Our indicators for assessing CoT effectiveness achieve an accuracy of 89.2\\%, and Dynamic CoT reduces token consumption by more than 35\\% while maintaining high accuracy. Overall, our work offers a novel perspective on the underlying mechanisms of CoT reasoning and provides a framework for its more efficient deployment.",
    "authors": [
      "Peijie Liu, Fengli Xu, Yong Li"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.837415"
  },
  {
    "id": "oai:arXiv.org:2506.06024v1",
    "journal": "arXiv_CS",
    "title": "On Inverse Problems, Parameter Estimation, and Domain Generalization",
    "link": "https://arxiv.org/abs/2506.06024",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06024v1 Announce Type: new \nAbstract: Signal restoration and inverse problems are key elements in most real-world data science applications. In the past decades, with the emergence of machine learning methods, inversion of measurements has become a popular step in almost all physical applications, which is normally executed prior to downstream tasks that often involve parameter estimation. In this work, we analyze the general problem of parameter estimation in an inverse problem setting. First, we address the domain-shift problem by re-formulating it in direct relation with the discrete parameter estimation analysis. We analyze a significant vulnerability in current attempts to enforce domain generalization, which we dubbed the Double Meaning Theorem. Our theoretical findings are experimentally illustrated for domain shift examples in image deblurring and speckle suppression in medical imaging. We then proceed to a theoretical analysis of parameter estimation given observed measurements before and after data processing involving an inversion of the observations. We compare this setting for invertible and non-invertible (degradation) processes. We distinguish between continuous and discrete parameter estimation, corresponding with regression and classification problems, respectively. Our theoretical findings align with the well-known information-theoretic data processing inequality, and to a certain degree question the common misconception that data-processing for inversion, based on modern generative models that may often produce outstanding perceptual quality, will necessarily improve the following parameter estimation objective. It is our hope that this paper will provide practitioners with deeper insights that may be leveraged in the future for the development of more efficient and informed strategic system planning, critical in safety-sensitive applications.",
    "authors": [
      "Deborah Pereg"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.837527"
  },
  {
    "id": "oai:arXiv.org:2506.06038v1",
    "journal": "arXiv_CS",
    "title": "Trajectory Optimization for UAV-Based Medical Delivery with Temporal Logic Constraints and Convex Feasible Set Collision Avoidance",
    "link": "https://arxiv.org/abs/2506.06038",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06038v1 Announce Type: new \nAbstract: This paper addresses the problem of trajectory optimization for unmanned aerial vehicles (UAVs) performing time-sensitive medical deliveries in urban environments. Specifically, we consider a single UAV with 3 degree-of-freedom dynamics tasked with delivering blood packages to multiple hospitals, each with a predefined time window and priority. Mission objectives are encoded using Signal Temporal Logic (STL), enabling the formal specification of spatial-temporal constraints. To ensure safety, city buildings are modeled as 3D convex obstacles, and obstacle avoidance is handled through a Convex Feasible Set (CFS) method. The entire planning problem-combining UAV dynamics, STL satisfaction, and collision avoidance-is formulated as a convex optimization problem that ensures tractability and can be solved efficiently using standard convex programming techniques. Simulation results demonstrate that the proposed method generates dynamically feasible, collision-free trajectories that satisfy temporal mission goals, providing a scalable and reliable approach for autonomous UAV-based medical logistics.",
    "authors": [
      "Kaiyuan Chen, Yuhan Suo, Shaowei Cui, Yuanqing Xia, Wannian Liang, Shuo Wang"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.837604"
  },
  {
    "id": "oai:arXiv.org:2506.06052v1",
    "journal": "arXiv_CS",
    "title": "CP-Bench: Evaluating Large Language Models for Constraint Modelling",
    "link": "https://arxiv.org/abs/2506.06052",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06052v1 Announce Type: new \nAbstract: Combinatorial problems are present in a wide range of industries. Constraint Programming (CP) is a well-suited problem-solving paradigm, but its core process, namely constraint modelling, is a bottleneck for wider adoption. Aiming to alleviate this bottleneck, recent studies have explored using Large Language Models (LLMs) as modelling assistants, transforming combinatorial problem descriptions to executable constraint models, similar to coding assistants. However, the existing evaluation datasets for constraint modelling are often limited to small, homogeneous, or domain-specific instances, which do not capture the diversity of real-world scenarios. This work addresses this gap by introducing CP-Bench, a novel benchmark dataset that includes a diverse set of well-known combinatorial problem classes sourced from the CP community, structured explicitly for evaluating LLM-driven CP modelling. With this dataset, and given the variety of constraint modelling frameworks, we compare and evaluate the modelling capabilities of LLMs for three distinct constraint modelling systems, which vary in abstraction level and underlying syntax: the high-level MiniZinc language and Python-based CPMpy library, and the lower-level Python interface of the OR-Tools CP-SAT solver. In order to enhance the ability of LLMs to produce valid constraint models, we systematically evaluate the use of prompt-based and inference-time compute methods adapted from existing LLM-based code generation research. Our results underscore the modelling convenience provided by Python-based frameworks, as well as the effectiveness of documentation-rich system prompts, which, augmented with repeated sampling and self-verification, achieve further improvements, reaching up to 70\\% accuracy on this new, highly challenging benchmark.",
    "authors": [
      "Kostis Michailidis, Dimos Tsouros, Tias Guns"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.837671"
  },
  {
    "id": "oai:arXiv.org:2506.06078v1",
    "journal": "arXiv_CS",
    "title": "A Sound and Complete Characterization of Fair Asynchronous Session Subtyping",
    "link": "https://arxiv.org/abs/2506.06078",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06078v1 Announce Type: new \nAbstract: Session types are abstractions of communication protocols enabling the static analysis of message-passing processes. Refinement notions for session types are key to support safe forms of process substitution while preserving their compatibility with the rest of the system. Recently, a fair refinement relation for asynchronous session types has been defined allowing the anticipation of message outputs with respect to an unbounded number of message inputs. This refinement is useful to capture common patterns in communication protocols that take advantage of asynchrony. However, while the semantic (\\`a la testing) definition of such refinement is straightforward, its characterization has proved to be quite challenging. In fact, only a sound but not complete characterization is known so far. In this paper we close this open problem by presenting a sound and complete characterization of asynchronous fair refinement for session types. We relate this characterization to those given in the literature for synchronous session types by leveraging a novel labelled transition system of session types that embeds their asynchronous semantics.",
    "authors": [
      "Mario Bravetti, Luca Padovani, Gianluigi Zavattaro"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.837802"
  },
  {
    "id": "oai:arXiv.org:2506.06091v1",
    "journal": "arXiv_CS",
    "title": "MIRIAD: Augmenting LLMs with millions of medical query-response pairs",
    "link": "https://arxiv.org/abs/2506.06091",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06091v1 Announce Type: new \nAbstract: LLMs are bound to transform healthcare with advanced decision support and flexible chat assistants. However, LLMs are prone to generate inaccurate medical content. To ground LLMs in high-quality medical knowledge, LLMs have been equipped with external knowledge via RAG, where unstructured medical knowledge is split into small text chunks that can be selectively retrieved and integrated into the LLMs context. Yet, existing RAG pipelines rely on raw, unstructured medical text, which can be noisy, uncurated and difficult for LLMs to effectively leverage. Systematic approaches to organize medical knowledge to best surface it to LLMs are generally lacking. To address these challenges, we introduce MIRIAD, a large-scale, curated corpus of 5,821,948 medical QA pairs, each rephrased from and grounded in a passage from peer-reviewed medical literature using a semi-automated pipeline combining LLM generation, filtering, grounding, and human annotation. Unlike prior medical corpora, which rely on unstructured text, MIRIAD encapsulates web-scale medical knowledge in an operationalized query-response format, which enables more targeted retrieval. Experiments on challenging medical QA benchmarks show that augmenting LLMs with MIRIAD improves accuracy up to 6.7% compared to unstructured RAG baselines with the same source corpus and with the same amount of retrieved text. Moreover, MIRIAD improved the ability of LLMs to detect medical hallucinations by 22.5 to 37% (increase in F1 score). We further introduce MIRIAD-Atlas, an interactive map of MIRIAD spanning 56 medical disciplines, enabling clinical users to visually explore, search, and refine medical knowledge. MIRIAD promises to unlock a wealth of down-stream applications, including medical information retrievers, enhanced RAG applications, and knowledge-grounded chat interfaces, which ultimately enables more reliable LLM applications in healthcare.",
    "authors": [
      "Qinyue Zheng, Salman Abdullah, Sam Rawal, Cyril Zakka, Sophie Ostmeier, Maximilian Purk, Eduardo Reis, Eric J. Topol, Jure Leskovec, Michael Moor"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.837843"
  },
  {
    "id": "oai:arXiv.org:2506.06097v1",
    "journal": "arXiv_CS",
    "title": "VideoChat-A1: Thinking with Long Videos by Chain-of-Shot Reasoning",
    "link": "https://arxiv.org/abs/2506.06097",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06097v1 Announce Type: new \nAbstract: The recent advance in video understanding has been driven by multimodal large language models (MLLMs). But these MLLMs are good at analyzing short videos, while suffering from difficulties in understanding videos with a longer context. To address this difficulty, several agent paradigms have recently been proposed, using MLLMs as agents for retrieving extra contextual knowledge in a long video. However, most existing agents ignore the key fact that a long video is composed with multiple shots, i.e., to answer the user question from a long video, it is critical to deeply understand its relevant shots like human. Without such insight, these agents often mistakenly find redundant even noisy temporal context, restricting their capacity for long video understanding. To fill this gap, we propose VideoChat-A1, a novel long video agent paradigm. Different from the previous works, our VideoChat-A1 can deeply think with long videos, via a distinct chain-of-shot reasoning paradigm. More specifically, it can progressively select the relevant shots of user question, and look into these shots in a coarse-to-fine partition. By multi-modal reasoning along the shot chain, VideoChat-A1 can effectively mimic step-by-step human thinking process, allowing to interactively discover preferable temporal context for thoughtful understanding in long videos. Extensive experiments show that, our VideoChat-A1 achieves the state-of-the-art performance on the mainstream long video QA benchmarks, e.g., it achieves 77.0 on VideoMME and 70.1 on EgoSchema, outperforming its strong baselines (e.g., Intern2.5VL-8B and InternVideo2.5-8B), by up to 10.8\\% and 6.2\\%. Compared to leading close-source GPT-4o and Gemini 1.5 Pro, VideoChat-A1 offers competitive accuracy, but with 7\\% input frames and 12\\% inference time on average.",
    "authors": [
      "Zikang Wang, Boyu Chen, Zhengrong Yue, Yi Wang, Yu Qiao, Limin Wang, Yali Wang"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.837885"
  },
  {
    "id": "oai:arXiv.org:2506.06104v1",
    "journal": "arXiv_CS",
    "title": "WoundAIssist: A Patient-Centered Mobile App for AI-Assisted Wound Care With Physicians in the Loop",
    "link": "https://arxiv.org/abs/2506.06104",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06104v1 Announce Type: new \nAbstract: The rising prevalence of chronic wounds, especially in aging populations, presents a significant healthcare challenge due to prolonged hospitalizations, elevated costs, and reduced patient quality of life. Traditional wound care is resource-intensive, requiring frequent in-person visits that strain both patients and healthcare professionals (HCPs). Therefore, we present WoundAIssist, a patient-centered, AI-driven mobile application designed to support telemedical wound care. WoundAIssist enables patients to regularly document wounds at home via photographs and questionnaires, while physicians remain actively engaged in the care process through remote monitoring and video consultations. A distinguishing feature is an integrated lightweight deep learning model for on-device wound segmentation, which, combined with patient-reported data, enables continuous monitoring of wound healing progression. Developed through an iterative, user-centered process involving both patients and domain experts, WoundAIssist prioritizes an user-friendly design, particularly for elderly patients. A conclusive usability study with patients and dermatologists reported excellent usability, good app quality, and favorable perceptions of the AI-driven wound recognition. Our main contribution is two-fold: (I) the implementation and (II) evaluation of WoundAIssist, an easy-to-use yet comprehensive telehealth solution designed to bridge the gap between patients and HCPs. Additionally, we synthesize design insights for remote patient monitoring apps, derived from over three years of interdisciplinary research, that may inform the development of similar digital health tools across clinical domains.",
    "authors": [
      "Vanessa Borst, Anna Riedmann, Tassilo Dege, Konstantin M\\\"uller, Astrid Schmieder, Birgit Lugrin, Samuel Kounev"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.837910"
  },
  {
    "id": "oai:arXiv.org:2506.06155v1",
    "journal": "arXiv_CS",
    "title": "A Novel Large-scale Crop Dataset and Dual-stream Transformer Method for Fine-grained Hierarchical Crop Classification from Integrated Hyperspectral EnMAP Data and Multispectral Sentinel-2 Time Series",
    "link": "https://arxiv.org/abs/2506.06155",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06155v1 Announce Type: new \nAbstract: Fine-grained crop classification is crucial for precision agriculture and food security monitoring. It requires simultaneous capture of both phenological dynamics (obtained from multi-temporal satellite data like Sentinel-2) and subtle spectral variations (demanding nanometer-scale spectral resolution from hyperspectral imagery). Research combining these two modalities remains scarce currently due to challenges in hyperspectral data acquisition and crop types annotation costs. To address these issues, we construct a hierarchical hyperspectral crop dataset (H2Crop) by integrating 30m-resolution EnMAP hyperspectral data with Sentinel-2 time series. With over one million annotated field parcels organized in a four-tier crop taxonomy, H2Crop establishes a vital benchmark for fine-grained agricultural crop classification and hyperspectral image processing. We propose a dual-stream Transformer architecture that synergistically processes these modalities. It coordinates two specialized pathways: a spectral-spatial Transformer extracts fine-grained signatures from hyperspectral EnMAP data, while a temporal Swin Transformer extracts crop growth patterns from Sentinel-2 time series. The designed hierarchy classification heads with hierarchical fusion then simultaneously delivers multi-level classification across all taxonomic tiers. Experiments demonstrate that adding hyperspectral EnMAP data to Sentinel-2 time series yields a 4.2% average F1-scores improvement (peaking at 6.3%). Extensive comparisons also confirming our method's higher accuracy over existing deep learning approaches for crop type classification and the consistent benefits of hyperspectral data across varying temporal windows and crop change scenarios. Codes and dataset will be available at https://github.com/flyakon/H2Crop and www.glass.hku.hk\n  Keywords: Crop type classification, precision agriculture, remote sensing, deep learning, hyperspectral data, Sentinel-2 time series, fine-grained crops",
    "authors": [
      "Wenyuan Li, Shunlin Liang, Yuxiang Zhang, Liqin Liu, Keyan Chen, Yongzhe Chen, Han Ma, Jianglei Xu, Yichuan Ma, Shikang Guan, Zhenwei Shi"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.838141"
  },
  {
    "id": "oai:arXiv.org:2506.06165v1",
    "journal": "arXiv_CS",
    "title": "(AI peers) are people learning from the same standpoint: Perception of AI characters in a Collaborative Science Investigation",
    "link": "https://arxiv.org/abs/2506.06165",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06165v1 Announce Type: new \nAbstract: While the complexity of 21st-century demands has promoted pedagogical approaches to foster complex competencies, a persistent gap remains between in-class learning activities and individualized learning or assessment practices. To address this, studies have explored the use of AI-generated characters in learning and assessment. One attempt is scenario-based assessment (SBA), a technique that not only measures but also fosters the development of competencies throughout the assessment process. SBA introduces simulated agents to provide an authentic social-interactional context, allowing for the assessment of competency-based constructs while mitigating the unpredictability of real-life interactions. Recent advancements in multimodal AI, such as text-to-video technology, allow these agents to be enhanced into AI-generated characters. This mixed-method study investigates how learners perceive AI characters taking the role of mentor and teammates in an SBA mirroring the context of a collaborative science investigation. Specifically, we examined the Likert scale responses of 56 high schoolers regarding trust, social presence, and effectiveness. We analyzed the relationships between these factors and their impact on the intention to adopt AI characters through PLS-SEM. Our findings indicated that learners' trust shaped their sense of social presence with the AI characters, enhancing perceived effectiveness. Qualitative analysis further highlighted factors that foster trust, such as material credibility and alignment with learning goals, as well as the pivotal role of social presence in creating a collaborative context.\n  This paper was accepted as an full paper for AIED 2025.",
    "authors": [
      "Eunhye Grace Ko, Soo Hyoung Joo"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.838192"
  },
  {
    "id": "oai:arXiv.org:2506.06179v1",
    "journal": "arXiv_CS",
    "title": "A Theoretical Study of (Hyper) Self-Attention through the Lens of Interactions: Representation, Training, Generalization",
    "link": "https://arxiv.org/abs/2506.06179",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06179v1 Announce Type: new \nAbstract: Self-attention has emerged as a core component of modern neural architectures, yet its theoretical underpinnings remain elusive. In this paper, we study self-attention through the lens of interacting entities, ranging from agents in multi-agent reinforcement learning to alleles in genetic sequences, and show that a single layer linear self-attention can efficiently represent, learn, and generalize functions capturing pairwise interactions, including out-of-distribution scenarios. Our analysis reveals that self-attention acts as a mutual interaction learner under minimal assumptions on the diversity of interaction patterns observed during training, thereby encompassing a wide variety of real-world domains. In addition, we validate our theoretical insights through experiments demonstrating that self-attention learns interaction functions and generalizes across both population distributions and out-of-distribution scenarios. Building on our theories, we introduce HyperFeatureAttention, a novel neural network module designed to learn couplings of different feature-level interactions between entities. Furthermore, we propose HyperAttention, a new module that extends beyond pairwise interactions to capture multi-entity dependencies, such as three-way, four-way, or general n-way interactions.",
    "authors": [
      "Muhammed Ustaomeroglu, Guannan Qu"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.838263"
  },
  {
    "id": "oai:arXiv.org:2506.06202v1",
    "journal": "arXiv_CS",
    "title": "MLOps with Microservices: A Case Study on the Maritime Domain",
    "link": "https://arxiv.org/abs/2506.06202",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06202v1 Announce Type: new \nAbstract: This case study describes challenges and lessons learned on building Ocean Guard: a Machine Learning-Enabled System (MLES) for anomaly detection in the maritime domain. First, the paper presents the system's specification, and architecture. Ocean Guard was designed with a microservices' architecture to enable multiple teams to work on the project in parallel. Then, the paper discusses how the developers adapted contract-based design to MLOps for achieving that goal. As a MLES, Ocean Guard employs code, model, and data contracts to establish guidelines between its services. This case study hopes to inspire software engineers, machine learning engineers, and data scientists to leverage similar approaches for their systems.",
    "authors": [
      "Renato Cordeiro Ferreira (Jheronimus Academy of Data Science, Technical University of Eindhoven, Tilburg University), Rowanne Trapmann (Jheronimus Academy of Data Science, Technical University of Eindhoven, Tilburg University), Willem-Jan van den Heuvel (Jheronimus Academy of Data Science, Technical University of Eindhoven, Tilburg University)"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.838357"
  },
  {
    "id": "oai:arXiv.org:2506.06225v1",
    "journal": "arXiv_CS",
    "title": "\"We need to avail ourselves of GenAI to enhance knowledge distribution\": Empowering Older Adults through GenAI Literacy",
    "link": "https://arxiv.org/abs/2506.06225",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06225v1 Announce Type: new \nAbstract: As generative AI (GenAI) becomes increasingly widespread, it is crucial to equip users, particularly vulnerable populations such as older adults (65 and older), with the knowledge to understand its benefits and potential risks. Older adults often exhibit greater reservations about adopting emerging technologies and require tailored literacy support. Using a mixed methods approach, this study examines strategies for delivering GenAI literacy to older adults through a chatbot named Litti, evaluating its impact on their AI literacy (knowledge, safety, and ethical use). The quantitative data indicated a trend toward improved AI literacy, though the results were not statistically significant. However, qualitative interviews revealed diverse levels of familiarity with generative AI and a strong desire to learn more. Findings also show that while Litti provided a positive learning experience, it did not significantly enhance participants' trust or sense of safety regarding GenAI. This exploratory case study highlights the challenges and opportunities in designing AI literacy education for the rapidly growing older adult population.",
    "authors": [
      "Eunhye Grace Ko, Shaini Nanayakkara, Earl W. Huff Jr"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.838476"
  },
  {
    "id": "oai:arXiv.org:2506.06231v1",
    "journal": "arXiv_CS",
    "title": "Towards an Explainable Comparison and Alignment of Feature Embeddings",
    "link": "https://arxiv.org/abs/2506.06231",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06231v1 Announce Type: new \nAbstract: While several feature embedding models have been developed in the literature, comparisons of these embeddings have largely focused on their numerical performance in classification-related downstream applications. However, an interpretable comparison of different embeddings requires identifying and analyzing mismatches between sample groups clustered within the embedding spaces. In this work, we propose the \\emph{Spectral Pairwise Embedding Comparison (SPEC)} framework to compare embeddings and identify their differences in clustering a reference dataset. Our approach examines the kernel matrices derived from two embeddings and leverages the eigendecomposition of the difference kernel matrix to detect sample clusters that are captured differently by the two embeddings. We present a scalable implementation of this kernel-based approach, with computational complexity that grows linearly with the sample size. Furthermore, we introduce an optimization problem using this framework to align two embeddings, ensuring that clusters identified in one embedding are also captured in the other model. We provide numerical results demonstrating the SPEC's application to compare and align embeddings on large-scale datasets such as ImageNet and MS-COCO. The code is available at [https://github.com/mjalali/embedding-comparison](github.com/mjalali/embedding-comparison).",
    "authors": [
      "Mohammad Jalali, Bahar Dibaei Nia, Farzan Farnia"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.838511"
  },
  {
    "id": "oai:arXiv.org:2506.06238v1",
    "journal": "arXiv_CS",
    "title": "Explaining Matters: Leveraging Definitions and Semantic Expansion for Sexism Detection",
    "link": "https://arxiv.org/abs/2506.06238",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06238v1 Announce Type: new \nAbstract: The detection of sexism in online content remains an open problem, as harmful language disproportionately affects women and marginalized groups. While automated systems for sexism detection have been developed, they still face two key challenges: data sparsity and the nuanced nature of sexist language. Even in large, well-curated datasets like the Explainable Detection of Online Sexism (EDOS), severe class imbalance hinders model generalization. Additionally, the overlapping and ambiguous boundaries of fine-grained categories introduce substantial annotator disagreement, reflecting the difficulty of interpreting nuanced expressions of sexism. To address these challenges, we propose two prompt-based data augmentation techniques: Definition-based Data Augmentation (DDA), which leverages category-specific definitions to generate semantically-aligned synthetic examples, and Contextual Semantic Expansion (CSE), which targets systematic model errors by enriching examples with task-specific semantic features. To further improve reliability in fine-grained classification, we introduce an ensemble strategy that resolves prediction ties by aggregating complementary perspectives from multiple language models. Our experimental evaluation on the EDOS dataset demonstrates state-of-the-art performance across all tasks, with notable improvements of macro F1 by 1.5 points for binary classification (Task A) and 4.1 points for fine-grained classification (Task C).",
    "authors": [
      "Sahrish Khan, Arshad Jhumka, Gabriele Pergola"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.838536"
  },
  {
    "id": "oai:arXiv.org:2506.06247v1",
    "journal": "arXiv_CS",
    "title": "Scalable Language Agnostic Taint Tracking using Explicit Data Dependencies",
    "link": "https://arxiv.org/abs/2506.06247",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06247v1 Announce Type: new \nAbstract: Taint analysis using explicit whole-program data-dependence graphs is powerful for vulnerability discovery but faces two major challenges. First, accurately modeling taint propagation through calls to external library procedures requires extensive manual annotations, which becomes impractical for large ecosystems. Second, the sheer size of whole-program graph representations leads to serious scalability and performance issues, particularly when quick analysis is needed in continuous development pipelines.\n  This paper presents the design and implementation of a system for a language-agnostic data-dependence representation. The system accommodates missing annotations describing the behavior of library procedures by over-approximating data flows, allowing annotations to be added later without recalculation. We contribute this data-flow analysis system to the open-source code analysis platform Joern making it available to the community.",
    "authors": [
      "Sedick David Baker Effendi, Xavier Pinho, Andrei Michael Dreyer, Fabian Yamaguchi"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.838580"
  },
  {
    "id": "oai:arXiv.org:2506.06273v1",
    "journal": "arXiv_CS",
    "title": "AdvSumm: Adversarial Training for Bias Mitigation in Text Summarization",
    "link": "https://arxiv.org/abs/2506.06273",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06273v1 Announce Type: new \nAbstract: Large Language Models (LLMs) have achieved impressive performance in text summarization and are increasingly deployed in real-world applications. However, these systems often inherit associative and framing biases from pre-training data, leading to inappropriate or unfair outputs in downstream tasks. In this work, we present AdvSumm (Adversarial Summarization), a domain-agnostic training framework designed to mitigate bias in text summarization through improved generalization. Inspired by adversarial robustness, AdvSumm introduces a novel Perturber component that applies gradient-guided perturbations at the embedding level of Sequence-to-Sequence models, enhancing the model's robustness to input variations. We empirically demonstrate that AdvSumm effectively reduces different types of bias in summarization-specifically, name-nationality bias and political framing bias-without compromising summarization quality. Compared to standard transformers and data augmentation techniques like back-translation, AdvSumm achieves stronger bias mitigation performance across benchmark datasets.",
    "authors": [
      "Mukur Gupta, Nikhil Reddy Varimalla, Nicholas Deas, Melanie Subbiah, Kathleen McKeown"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.838685"
  },
  {
    "id": "oai:arXiv.org:2506.05171v1",
    "journal": "arXiv_CS",
    "title": "Towards provable probabilistic safety for scalable embodied AI systems",
    "link": "https://arxiv.org/abs/2506.05171",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05171v1 Announce Type: cross \nAbstract: Embodied AI systems, comprising AI models and physical plants, are increasingly prevalent across various applications. Due to the rarity of system failures, ensuring their safety in complex operating environments remains a major challenge, which severely hinders their large-scale deployment in safety-critical domains, such as autonomous vehicles, medical devices, and robotics. While achieving provable deterministic safety--verifying system safety across all possible scenarios--remains theoretically ideal, the rarity and complexity of corner cases make this approach impractical for scalable embodied AI systems. To address this challenge, we introduce provable probabilistic safety, which aims to ensure that the residual risk of large-scale deployment remains below a predefined threshold. Instead of attempting exhaustive safety proof across all corner cases, this paradigm establishes a probabilistic safety boundary on overall system performance, leveraging statistical methods to enhance feasibility and scalability. A well-defined probabilistic safety boundary enables embodied AI systems to be deployed at scale while allowing for continuous refinement of safety guarantees. Our work focuses on three core questions: what is provable probabilistic safety, how to prove the probabilistic safety, and how to achieve the provable probabilistic safety. By bridging the gap between theoretical safety assurance and practical deployment, our work offers a pathway toward safer, large-scale adoption of embodied AI systems in safety-critical applications.",
    "authors": [
      "Linxuan He, Qing-Shan Jia, Ang Li, Hongyan Sang, Ling Wang, Jiwen Lu, Tao Zhang, Jie Zhou, Yi Zhang, Yisen Wang, Peng Wei, Zhongyuan Wang, Henry X. Liu, Shuo Feng"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.838787"
  },
  {
    "id": "oai:arXiv.org:2506.05631v1",
    "journal": "arXiv_CS",
    "title": "The TESS Ten Thousand Catalog: 10,001 uniformly-vetted and -validated Eclipsing Binary Stars detected in Full-Frame Image data by machine learning and analyzed by citizen scientists",
    "link": "https://arxiv.org/abs/2506.05631",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05631v1 Announce Type: cross \nAbstract: The Transiting Exoplanet Survey Satellite (TESS) has surveyed nearly the entire sky in Full-Frame Image mode with a time resolution of 200 seconds to 30 minutes and a temporal baseline of at least 27 days. In addition to the primary goal of discovering new exoplanets, TESS is exceptionally capable at detecting variable stars, and in particular short-period eclipsing binaries which are relatively common, making up a few percent of all stars, and represent powerful astrophysical laboratories for deep investigations of stellar formation and evolution. We combed Sectors 1-82 of TESS Full-Frame Image data searching for eclipsing binary stars using a neural network that identified ~1.2 million stars with eclipse-like features. Of these, we have performed an in-depth analysis on ~60,000 targets using automated methods and manual inspection by citizen scientists. Here we present a catalog of 10001 uniformly-vetted and -validated eclipsing binary stars that passed all our ephemeris and photocenter tests, as well as complementary visual inspection. Of these, 7936 are new eclipsing binaries while the remaining 2065 are known systems for which we update the published ephemerides. We outline the detection and analysis of the targets, discuss the properties of the sample, and highlight potentially interesting systems. Finally, we also provide a list of ~900,000 unvetted and unvalidated targets for which the neural network found eclipse-like features with a score higher than 0.9, and for which there are no known eclipsing binaries within a sky-projected separation of a TESS pixel (~21 arcsec).",
    "authors": [
      "Veselin B. Kostov, Brian P. Powell, Aline U. Fornear, Marco Z. Di Fraia, Robert Gagliano, Thomas L. Jacobs, Julien S. de Lambilly, Hugo A. Durantini Luca, Steven R. Majewski, Mark Omohundro, Jerome Orosz, Saul A. Rappaport, Ryan Salik, Donald Short, William Welsh, Svetoslav Alexandrov, Cledison Marcos da Silva, Erika Dunning, Gerd Guhne, Marc Huten, Michiharu Hyogo, Davide Iannone, Sam Lee, Christian Magliano, Manya Sharma, Allan Tarr, John Yablonsky, Sovan Acharya, Fred Adams, Thomas Barclay, Benjamin T. Montet, Susan Mullally, Greg Olmschenk, Andrej Prsa, Elisa Quintana, Robert Wilson, Hasret Balcioglu, Ethan Kruse, the Eclipsing Binary Patrol Collaboration"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.838868"
  },
  {
    "id": "oai:arXiv.org:2506.05657v1",
    "journal": "arXiv_CS",
    "title": "Emulating compact binary population synthesis simulations with robust uncertainty quantification and model comparison: Bayesian normalizing flows",
    "link": "https://arxiv.org/abs/2506.05657",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05657v1 Announce Type: cross \nAbstract: Population synthesis simulations of compact binary coalescences~(CBCs) play a crucial role in extracting astrophysical insights from an ensemble of gravitational wave~(GW) observations. However, realistic simulations are costly to implement for a dense grid of initial conditions. Normalizing flows can emulate the distribution functions of a simulated population of binary parameters and thereby enable empirical constraints on the astrophysical initial conditions and branching fractions of various formation channels given data from a catalog of GW observations. They can also be used for data amplification in sparse regions of the CBC parameter space to guide the development of phenomenological population models for rarely synthesizable systems with components in theorized mass gaps, without having to simulate a prohibitively large number of binaries. But flow predictions are wrought with uncertainties, especially for sparse training sets. In this work I develop a method for quantifying and marginalizing uncertainties in the emulators by introducing the Bayesian Normalizing flow, a conditional density estimator constructed from Bayesian neural networks. Using the exact likelihood function associated with density estimators I sample the posterior distribution of flow parameters with suitably chosen priors to quantify and marginalize over flow uncertainties. I demonstrate the accuracy, calibration, and data-amplification impacts of the estimated uncertainties for simulations of binary black hole populations formed through common envelope evolution. I outline applications of the methodology in simulation-based inference from growing GW catalogs and sketch other uses for general simulation-based approaches in GW astronomy.",
    "authors": [
      "Anarya Ray"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.838876"
  },
  {
    "id": "oai:arXiv.org:2506.05671v1",
    "journal": "arXiv_CS",
    "title": "Low-Resource Domain Adaptation for Speech LLMs via Text-Only Fine-Tuning",
    "link": "https://arxiv.org/abs/2506.05671",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05671v1 Announce Type: cross \nAbstract: Recent advances in automatic speech recognition (ASR) have combined speech encoders with large language models (LLMs) through projection, forming Speech LLMs with strong performance. However, adapting them to new domains remains challenging, especially in low-resource settings where paired speech-text data is scarce. We propose a text-only fine-tuning strategy for Speech LLMs using unpaired target-domain text without requiring additional audio. To preserve speech-text alignment, we introduce a real-time evaluation mechanism during fine-tuning. This enables effective domain adaptation while maintaining source-domain performance. Experiments on LibriSpeech, SlideSpeech, and Medical datasets show that our method achieves competitive recognition performance, with minimal degradation compared to full audio-text fine-tuning. It also improves generalization to new domains without catastrophic forgetting, highlighting the potential of text-only fine-tuning for low-resource domain adaptation of ASR.",
    "authors": [
      "Yangui Fang, Jing Peng, Xu Li, Yu Xi, Chengwei Zhang, Guohui Zhong, Kai Yu"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.838884"
  },
  {
    "id": "oai:arXiv.org:2506.05888v1",
    "journal": "arXiv_CS",
    "title": "Variational Inference for Quantum HyperNetworks",
    "link": "https://arxiv.org/abs/2506.05888",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05888v1 Announce Type: cross \nAbstract: Binary Neural Networks (BiNNs), which employ single-bit precision weights, have emerged as a promising solution to reduce memory usage and power consumption while maintaining competitive performance in large-scale systems. However, training BiNNs remains a significant challenge due to the limitations of conventional training algorithms. Quantum HyperNetworks offer a novel paradigm for enhancing the optimization of BiNN by leveraging quantum computing. Specifically, a Variational Quantum Algorithm is employed to generate binary weights through quantum circuit measurements, while key quantum phenomena such as superposition and entanglement facilitate the exploration of a broader solution space. In this work, we establish a connection between this approach and Bayesian inference by deriving the Evidence Lower Bound (ELBO), when direct access to the output distribution is available (i.e., in simulations), and introducing a surrogate ELBO based on the Maximum Mean Discrepancy (MMD) metric for scenarios involving implicit distributions, as commonly encountered in practice. Our experimental results demonstrate that the proposed methods outperform standard Maximum Likelihood Estimation (MLE), improving trainability and generalization.",
    "authors": [
      "Luca Nepote, Alix Lh\\'eritier, Nicolas Bondoux, Marios Kountouris, Maurizio Filippone"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.838909"
  },
  {
    "id": "oai:arXiv.org:2506.06071v1",
    "journal": "arXiv_CS",
    "title": "CO-VADA: A Confidence-Oriented Voice Augmentation Debiasing Approach for Fair Speech Emotion Recognition",
    "link": "https://arxiv.org/abs/2506.06071",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06071v1 Announce Type: cross \nAbstract: Bias in speech emotion recognition (SER) systems often stems from spurious correlations between speaker characteristics and emotional labels, leading to unfair predictions across demographic groups. Many existing debiasing methods require model-specific changes or demographic annotations, limiting their practical use. We present CO-VADA, a Confidence-Oriented Voice Augmentation Debiasing Approach that mitigates bias without modifying model architecture or relying on demographic information. CO-VADA identifies training samples that reflect bias patterns present in the training data and then applies voice conversion to alter irrelevant attributes and generate samples. These augmented samples introduce speaker variations that differ from dominant patterns in the data, guiding the model to focus more on emotion-relevant features. Our framework is compatible with various SER models and voice conversion tools, making it a scalable and practical solution for improving fairness in SER systems.",
    "authors": [
      "Yun-Shao Tsai, Yi-Cheng Lin, Huang-Cheng Chou, Hung-yi Lee"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.838969"
  },
  {
    "id": "oai:arXiv.org:2506.06099v1",
    "journal": "arXiv_CS",
    "title": "DermaCon-IN: A Multi-concept Annotated Dermatological Image Dataset of Indian Skin Disorders for Clinical AI Research",
    "link": "https://arxiv.org/abs/2506.06099",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06099v1 Announce Type: cross \nAbstract: Artificial intelligence is poised to augment dermatological care by enabling scalable image-based diagnostics. Yet, the development of robust and equitable models remains hindered by datasets that fail to capture the clinical and demographic complexity of real-world practice. This complexity stems from region-specific disease distributions, wide variation in skin tones, and the underrepresentation of outpatient scenarios from non-Western populations. We introduce DermaCon-IN, a prospectively curated dermatology dataset comprising over 5,450 clinical images from approximately 3,000 patients across outpatient clinics in South India. Each image is annotated by board-certified dermatologists with over 240 distinct diagnoses, structured under a hierarchical, etiology-based taxonomy adapted from Rook's classification. The dataset captures a wide spectrum of dermatologic conditions and tonal variation commonly seen in Indian outpatient care. We benchmark a range of architectures including convolutional models (ResNet, DenseNet, EfficientNet), transformer-based models (ViT, MaxViT, Swin), and Concept Bottleneck Models to establish baseline performance and explore how anatomical and concept-level cues may be integrated. These results are intended to guide future efforts toward interpretable and clinically realistic models. DermaCon-IN provides a scalable and representative foundation for advancing dermatology AI in real-world settings.",
    "authors": [
      "Shanawaj S Madarkar, Mahajabeen Madarkar, Madhumitha V, Teli Prakash, Konda Reddy Mopuri, Vinaykumar MV, KVL Sathwika, Adarsh Kasturi, Gandla Dilip Raj, PVN Supranitha, Harsh Udai"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.838995"
  },
  {
    "id": "oai:arXiv.org:2506.06243v1",
    "journal": "arXiv_CS",
    "title": "fairmetrics: An R package for group fairness evaluation",
    "link": "https://arxiv.org/abs/2506.06243",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06243v1 Announce Type: cross \nAbstract: Fairness is a growing area of machine learning (ML) that focuses on ensuring models do not produce systematically biased outcomes for specific groups, particularly those defined by protected attributes such as race, gender, or age. Evaluating fairness is a critical aspect of ML model development, as biased models can perpetuate structural inequalities. The {fairmetrics} R package offers a user-friendly framework for rigorously evaluating numerous group-based fairness criteria, including metrics based on independence (e.g., statistical parity), separation (e.g., equalized odds), and sufficiency (e.g., predictive parity). Group-based fairness criteria assess whether a model is equally accurate or well-calibrated across a set of predefined groups so that appropriate bias mitigation strategies can be implemented. {fairmetrics} provides both point and interval estimates for multiple metrics through a convenient wrapper function and includes an example dataset derived from the Medical Information Mart for Intensive Care, version II (MIMIC-II) database (Goldberger et al., 2000; Raffa, 2016).",
    "authors": [
      "Benjamin Smith, Jianhui Gao, Jessica Gronsbell"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.839011"
  },
  {
    "id": "oai:arXiv.org:2010.04618v2",
    "journal": "arXiv_CS",
    "title": "Finitely (In)tractable Promise Constraint Satisfaction Problems",
    "link": "https://arxiv.org/abs/2010.04618",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2010.04618v2 Announce Type: replace \nAbstract: The Promise Constraint Satisfaction Problem (PCSP) is a generalization of the Constraint Satisfaction Problem (CSP) that includes approximation variants of satisfiability and graph coloring problems. Barto [LICS '19] has shown that a specific PCSP, the problem to find a valid Not-All-Equal solution to a 1-in-3-SAT instance, is not finitely tractable in that it can be solved by a trivial reduction to a tractable CSP, but such a CSP is necessarily over an infinite domain (unless P=NP). We initiate a systematic study of this phenomenon by giving a general necessary condition for finite tractability and characterizing finite tractability within a class of templates - the \"basic\" tractable cases in the dichotomy theorem for symmetric Boolean PCSPs allowing negations by Brakensiek and Guruswami [SODA'18].",
    "authors": [
      "Kristina Asimi, Libor Barto"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.839027"
  },
  {
    "id": "oai:arXiv.org:2308.02572v4",
    "journal": "arXiv_CS",
    "title": "Design Tasks and Their Complexity for the European Train Control System with Hybrid Train Detection",
    "link": "https://arxiv.org/abs/2308.02572",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2308.02572v4 Announce Type: replace \nAbstract: Railway networks have become increasingly important in recent times, especially in moving freight and public transportation from road traffic and planes to more environmentally friendly trains. Since expanding the global railway network is time- and resource-consuming, maximizing the rail capacity of the existing infrastructure is desirable. However, simply running more trains is infeasible as certain constraints enforced by the train control system must be satisfied. The capacity of a network depends (amongst others) on the distance between trains allowed by this safety system. While most signaling systems rely on fixed blocks defined by costly hardware, new specifications provided by Level 2 with Hybrid Train Detection of the European Train Control System (ETCS L2 HTD), formerly known as ETCS Hybrid Level 3, allow the usage of virtual subsections. This additional degree of freedom allows for shorter train following times and, thus, more trains on existing railway tracks. On the other hand, new design tasks arise on which automated methods might be helpful for designers of modern railway networks. However, although first approaches exist that solve design problems arising within ETCS L2 HTD, neither formal descriptions nor results on the computational complexity of the corresponding design tasks exist. In this paper, we fill this gap by providing a formal description of design tasks for ETCS L2 HTD and proof that these tasks are NP-complete or NP-hard, respectively. By that, we are providing a solid basis for the future development of methods to solve those tasks, which will be integrated into the Munich Train Control Toolkit available open-source on GitHub at https://github.com/cda-tum/mtct.",
    "authors": [
      "Stefan Engels, Tom Peham, Judith Przigoda, Nils Przigoda, Robert Wille"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.839127"
  },
  {
    "id": "oai:arXiv.org:2401.00529v3",
    "journal": "arXiv_CS",
    "title": "GraphGPT: Generative Pre-trained Graph Eulerian Transformer",
    "link": "https://arxiv.org/abs/2401.00529",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2401.00529v3 Announce Type: replace \nAbstract: We introduceGraphGPT, a novel self-supervised generative pre-trained model for graph learning based on the Graph Eulerian Transformer (GET). First, we propose GET, which combines a standard transformer encoder or decoder architecture with an innovative graph-to-sequence transformation method. This method converts graphs or sampled subgraphs into sequences of tokens representing nodes, edges, and attributes in a reversible manner using Eulerian paths. We pre-train GET using either of the two self-supervised tasks: next-token prediction (NTP) and scheduled masked-token prediction (SMTP). The pre-trained model is then fine-tuned for downstream tasks such as graph-, edge-, and node-level prediction. Despite its simplicity, GraphGPT achieves performance comparable to or surpassing state-of-the-art methods on multiple large-scale Open Graph Benchmark (OGB) datasets. It demonstrates exceptional results on the molecular property prediction dataset PCQM4Mv2 and the protein-protein interaction dataset ogbl-ppa. Notably, generative pre-training enables scaling GraphGPT to 2 billion parameters while maintaining performance gains - a breakthrough that overcomes the scalability limitations of traditional Graph Neural Networks (GNNs) and prior graph transformers (GTs). To advance research in graph foundation models and facilitate scientific discovery in chemistry, materials science, and related fields, we will release the source code (https://github.com/alibaba/graph-gpt) and pre-trained checkpoints.",
    "authors": [
      "Qifang Zhao, Weidong Ren, Tianyu Li, Hong Liu, Xingsheng He, Xiaoxiao Xu"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.839142"
  },
  {
    "id": "oai:arXiv.org:2406.13433v3",
    "journal": "arXiv_CS",
    "title": "Certification for Differentially Private Prediction in Gradient-Based Training",
    "link": "https://arxiv.org/abs/2406.13433",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2406.13433v3 Announce Type: replace \nAbstract: We study private prediction where differential privacy is achieved by adding noise to the outputs of a non-private model. Existing methods rely on noise proportional to the global sensitivity of the model, often resulting in sub-optimal privacy-utility trade-offs compared to private training. We introduce a novel approach for computing dataset-specific upper bounds on prediction sensitivity by leveraging convex relaxation and bound propagation techniques. By combining these bounds with the smooth sensitivity mechanism, we significantly improve the privacy analysis of private prediction compared to global sensitivity-based approaches. Experimental results across real-world datasets in medical image classification and natural language processing demonstrate that our sensitivity bounds are can be orders of magnitude tighter than global sensitivity. Our approach provides a strong basis for the development of novel privacy preserving technologies.",
    "authors": [
      "Matthew Wicker, Philip Sosnin, Igor Shilov, Adrianna Janik, Mark N. M\\\"uller, Yves-Alexandre de Montjoye, Adrian Weller, Calvin Tsay"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.839295"
  },
  {
    "id": "oai:arXiv.org:2406.13474v3",
    "journal": "arXiv_CS",
    "title": "BoA: Attention-aware Post-training Quantization without Backpropagation",
    "link": "https://arxiv.org/abs/2406.13474",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2406.13474v3 Announce Type: replace \nAbstract: Post-training quantization (PTQ) is a promising solution for deploying large language models (LLMs) on resource-constrained devices. Early methods developed for small-scale networks, such as ResNet, rely on gradient-based optimization, which becomes impractical for hyper-scale LLMs with billions of parameters. While recently proposed backpropagation-free or transformation-based methods alleviate this issue, they ignore inter-layer interactions or use the naive nearest-rounding-based quantized weight assignment to save the heavy computational cost of weight optimization. In this paper, we introduce a novel backpropagation-free PTQ algorithm that optimizes quantized weights by considering inter-layer dependencies. The key innovation is the development of attention-aware Hessian matrices that capture inter-layer interactions within the attention module. Extensive experiments demonstrate that our approach not only outperforms existing weight quantization methods but also shows good synergy with conventional methods to suppress activation outliers, leading to state-of-the-art weight-activation quantization performance. The code will be available at https://github.com/SamsungLabs/BoA.",
    "authors": [
      "Junhan Kim, Ho-young Kim, Eulrang Cho, Chungman Lee, Joonyoung Kim, Yongkweon Jeon"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.839303"
  },
  {
    "id": "oai:arXiv.org:2407.02547v2",
    "journal": "arXiv_CS",
    "title": "Domain Generalizable Knowledge Tracing via Concept Aggregation and Relation-Based Attention",
    "link": "https://arxiv.org/abs/2407.02547",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2407.02547v2 Announce Type: replace \nAbstract: Knowledge Tracing (KT) is a critical task in online education systems, aiming to monitor students' knowledge states throughout a learning period. Common KT approaches involve predicting the probability of a student correctly answering the next question based on their exercise history. However, these methods often suffer from performance degradation when faced with the scarcity of student interactions in new education systems. To address this, we leverage student interactions from existing education systems to mitigate performance degradation caused by limited training data. Nevertheless, these interactions exhibit significant differences since they are derived from different education systems. To address this issue, we propose a domain generalization approach for knowledge tracing, where existing education systems are considered source domains, and new education systems with limited data are considered target domains. Additionally, we design a domain-generalizable knowledge tracing framework (DGKT) that can be applied to any KT model. Specifically, we present a concept aggregation approach designed to reduce conceptual disparities within sequences of student interactions from diverse domains. To further mitigate domain discrepancies, we introduce a novel normalization module called Sequence Instance Normalization (SeqIN). Moreover, to fully leverage exercise information, we propose a new knowledge tracing model tailored for the domain generalization KT task, named Domain-Generalizable Relation-based Knowledge Tracing (DGRKT). Extensive experiments across five benchmark datasets demonstrate that the proposed method performs well despite limited training data.",
    "authors": [
      "Yuquan Xie, Shengtao Peng, Wanqi Yang, Ming Yang, Yang Gao"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.839327"
  },
  {
    "id": "oai:arXiv.org:2407.10720v3",
    "journal": "arXiv_CS",
    "title": "Rethinking OWL Expressivity: Semantic Units for FAIR and Cognitively Interoperable Knowledge Graphs Why OWLs don't have to understand everything they say",
    "link": "https://arxiv.org/abs/2407.10720",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2407.10720v3 Announce Type: replace \nAbstract: Semantic knowledge graphs are foundational to implementing the FAIR Principles, yet RDF/OWL representations often lack the semantic flexibility and cognitive interoperability required in scientific domains. We present a novel framework for semantic modularization based on semantic units (i.e., modular, semantically coherent subgraphs enhancing expressivity, reusability, and interpretability), combined with four new representational resource types (some-instance, most-instances, every-instance, all-instances) for modelling assertional, contingent, prototypical, and universal statements. The framework enables the integration of knowledge modelled using different logical frameworks (e.g., OWL, First-Order Logic, or none), provided each semantic unit is internally consistent and annotated with its logic base. This allows, for example, querying all OWL 2.0-compliant units for reasoning purposes while preserving the full graph for broader knowledge discovery. Our framework addresses twelve core limitations of OWL/RDF modeling, including negation, cardinality, complex class axioms, conditional and directive statements, and logical arguments, while improving cognitive accessibility for domain experts. We provide schemata and translation patterns to demonstrate semantic interoperability and reasoning potential, establishing a scalable foundation for constructing FAIR-aligned, semantically rich knowledge graphs.",
    "authors": [
      "Lars Vogt"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.839369"
  },
  {
    "id": "oai:arXiv.org:2408.13438v3",
    "journal": "arXiv_CS",
    "title": "Explainable Concept Generation through Vision-Language Preference Learning for Understanding Neural Networks' Internal Representations",
    "link": "https://arxiv.org/abs/2408.13438",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2408.13438v3 Announce Type: replace \nAbstract: Understanding the inner representation of a neural network helps users improve models. Concept-based methods have become a popular choice for explaining deep neural networks post-hoc because, unlike most other explainable AI techniques, they can be used to test high-level visual \"concepts\" that are not directly related to feature attributes. For instance, the concept of \"stripes\" is important to classify an image as a zebra. Concept-based explanation methods, however, require practitioners to guess and manually collect multiple candidate concept image sets, making the process labor-intensive and prone to overlooking important concepts. Addressing this limitation, in this paper, we frame concept image set creation as an image generation problem. However, since naively using a standard generative model does not result in meaningful concepts, we devise a reinforcement learning-based preference optimization (RLPO) algorithm that fine-tunes a vision-language generative model from approximate textual descriptions of concepts. Through a series of experiments, we demonstrate our method's ability to efficiently and reliably articulate diverse concepts that are otherwise challenging to craft manually.",
    "authors": [
      "Aditya Taparia, Som Sagar, Ransalu Senanayake"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.839485"
  },
  {
    "id": "oai:arXiv.org:2409.17744v3",
    "journal": "arXiv_CS",
    "title": "Privacy for Quantum Annealing. Attack on Spin Reversal Transformations in the case of cryptanalysis",
    "link": "https://arxiv.org/abs/2409.17744",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2409.17744v3 Announce Type: replace \nAbstract: This paper demonstrates that applying spin reversal transformations (SRT), commonly known as a sufficient method for privacy enhancement in problems solved using quantum annealing, does not guarantee privacy for all possible cases. We show how to recover the original problem from the Ising problem obtained using SRT when the resulting problem in Ising form represents the algebraic attack on the $E_0$ stream cipher. A small example illustrates how to retrieve the original problem from that transformed by SRT. Moreover, we show that our method is efficient also for full-scale problems.",
    "authors": [
      "Mateusz Le\\'sniak, Micha{\\l} Wro\\'nski"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.839553"
  },
  {
    "id": "oai:arXiv.org:2410.03085v3",
    "journal": "arXiv_CS",
    "title": "Optimization Proxies using Limited Labeled Data and Training Time -- A Semi-Supervised Bayesian Neural Network Approach",
    "link": "https://arxiv.org/abs/2410.03085",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2410.03085v3 Announce Type: replace \nAbstract: Constrained optimization problems arise in various engineering systems such as inventory management and power grids. Standard deep neural network (DNN) based machine learning proxies are ineffective in practical settings where labeled data is scarce and training times are limited. We propose a semi-supervised Bayesian Neural Networks (BNNs) based optimization proxy for this complex regime, wherein training commences in a sandwiched fashion, alternating between a supervised learning step for minimizing cost, and an unsupervised learning step for enforcing constraint feasibility. We show that the proposed semi-supervised BNN outperforms DNN architectures on important non-convex constrained optimization problems from energy network operations, achieving up to a tenfold reduction in expected maximum equality gap and halving the inequality gaps. Further, the BNN's ability to provide posterior samples is leveraged to construct practically meaningful probabilistic confidence bounds on performance using a limited validation data, unlike prior methods. The implementation code for this study is available at: https://github.com/kaarthiksundar/BNN-OPF/.",
    "authors": [
      "Parikshit Pareek, Abhijith Jayakumar, Kaarthik Sundar, Deepjyoti Deka, Sidhant Misra"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.839596"
  },
  {
    "id": "oai:arXiv.org:2410.08258v2",
    "journal": "arXiv_CS",
    "title": "In Search of Forgotten Domain Generalization",
    "link": "https://arxiv.org/abs/2410.08258",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2410.08258v2 Announce Type: replace \nAbstract: Out-of-Domain (OOD) generalization is the ability of a model trained on one or more domains to generalize to unseen domains. In the ImageNet era of computer vision, evaluation sets for measuring a model's OOD performance were designed to be strictly OOD with respect to style. However, the emergence of foundation models and expansive web-scale datasets has obfuscated this evaluation process, as datasets cover a broad range of domains and risk test domain contamination. In search of the forgotten domain generalization, we create large-scale datasets subsampled from LAION -- LAION-Natural and LAION-Rendition -- that are strictly OOD to corresponding ImageNet and DomainNet test sets in terms of style. Training CLIP models on these datasets reveals that a significant portion of their performance is explained by in-domain examples. This indicates that the OOD generalization challenges from the ImageNet era still prevail and that training on web-scale data merely creates the illusion of OOD generalization. Furthermore, through a systematic exploration of combining natural and rendition datasets in varying proportions, we identify optimal mixing ratios for model generalization across these domains. Our datasets and results re-enable meaningful assessment of OOD robustness at scale -- a crucial prerequisite for improving model robustness.",
    "authors": [
      "Prasanna Mayilvahanan, Roland S. Zimmermann, Thadd\\\"aus Wiedemer, Evgenia Rusak, Attila Juhos, Matthias Bethge, Wieland Brendel"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.839613"
  },
  {
    "id": "oai:arXiv.org:2410.08435v3",
    "journal": "arXiv_CS",
    "title": "Efficient Fine-Grained Guidance for Diffusion Model Based Symbolic Music Generation",
    "link": "https://arxiv.org/abs/2410.08435",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2410.08435v3 Announce Type: replace \nAbstract: Developing generative models to create or conditionally create symbolic music presents unique challenges due to the combination of limited data availability and the need for high precision in note pitch. To address these challenges, we introduce an efficient Fine-Grained Guidance (FGG) approach within diffusion models. FGG guides the diffusion models to generate music that aligns more closely with the control and intent of expert composers, which is critical to improve the accuracy, listenability, and quality of generated music. This approach empowers diffusion models to excel in advanced applications such as improvisation, and interactive music creation. We derive theoretical characterizations for both the challenges in symbolic music generation and the effects of the FGG approach. We provide numerical experiments and subjective evaluation to demonstrate the effectiveness of our approach. We have published a demo page to showcase performances, which enables real-time interactive generation.",
    "authors": [
      "Tingyu Zhu, Haoyu Liu, Ziyu Wang, Zhimin Jiang, Zeyu Zheng"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.839620"
  },
  {
    "id": "oai:arXiv.org:2410.14667v3",
    "journal": "arXiv_CS",
    "title": "SGD Jittering: A Training Strategy for Robust and Accurate Model-Based Architectures",
    "link": "https://arxiv.org/abs/2410.14667",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2410.14667v3 Announce Type: replace \nAbstract: Inverse problems aim to reconstruct unseen data from corrupted or perturbed measurements. While most work focuses on improving reconstruction quality, generalization accuracy and robustness are equally important, especially for safety-critical applications. Model-based architectures (MBAs), such as loop unrolling methods, are considered more interpretable and achieve better reconstructions. Empirical evidence suggests that MBAs are more robust to perturbations than black-box solvers, but the accuracy-robustness tradeoff in MBAs remains underexplored. In this work, we propose a simple yet effective training scheme for MBAs, called SGD jittering, which injects noise iteration-wise during reconstruction. We theoretically demonstrate that SGD jittering not only generalizes better than the standard mean squared error training but is also more robust to average-case attacks. We validate SGD jittering using denoising toy examples, seismic deconvolution, and single-coil MRI reconstruction. Both SGD jittering and its SPGD extension yield cleaner reconstructions for out-of-distribution data and demonstrates enhanced robustness against adversarial attacks.",
    "authors": [
      "Peimeng Guan, Mark A. Davenport"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.839664"
  },
  {
    "id": "oai:arXiv.org:2410.15334v2",
    "journal": "arXiv_CS",
    "title": "Modality-Fair Preference Optimization for Trustworthy MLLM Alignment",
    "link": "https://arxiv.org/abs/2410.15334",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2410.15334v2 Announce Type: replace \nAbstract: Multimodal large language models (MLLMs) have achieved remarkable success across various tasks. However, separate training of visual and textual encoders often results in a misalignment of the modality. Such misalignment may lead models to generate content that is absent from the input image, a phenomenon referred to as hallucination. These inaccuracies severely undermine the trustworthiness of MLLMs in real-world applications. Despite attempts to optimize text preferences to mitigate this issue, our initial investigation indicates that the trustworthiness of MLLMs remains inadequate. Specifically, these models tend to provide preferred answers even when the input image is heavily distorted. Analysis of visual token attention also indicates that the model focuses primarily on the surrounding context rather than the key object referenced in the question. These findings highlight a misalignment between the modalities, where answers inadequately leverage input images. Motivated by our findings, we propose Modality-Fair Preference Optimization (MFPO), which comprises three components: the construction of a multimodal preference dataset in which dispreferred images differ from originals solely in key regions; an image reward loss function encouraging the model to generate answers better aligned with the input images; and an easy-to-hard iterative alignment strategy to stabilize joint modality training. Extensive experiments on three trustworthiness benchmarks demonstrate that MFPO significantly enhances the trustworthiness of MLLMs. In particular, it enables the 7B models to attain trustworthiness levels on par with, or even surpass, those of the 13B, 34B, and larger models.",
    "authors": [
      "Songtao Jiang, Yan Zhang, Ruizhe Chen, Tianxiang Hu, Yeying Jin, Qinglin He, Yang Feng, Jian Wu, Zuozhu Liu"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.839671"
  },
  {
    "id": "oai:arXiv.org:2410.18677v2",
    "journal": "arXiv_CS",
    "title": "Enhancing pretraining efficiency for medical image segmentation via transferability metrics",
    "link": "https://arxiv.org/abs/2410.18677",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2410.18677v2 Announce Type: replace \nAbstract: In medical image segmentation tasks, the scarcity of labeled training data poses a significant challenge when training deep neural networks. When using U-Net-style architectures, it is common practice to address this problem by pretraining the encoder part on a large general-purpose dataset like ImageNet. However, these methods are resource-intensive and do not guarantee improved performance on the downstream task. In this paper we investigate a variety of training setups on medical image segmentation datasets, using ImageNet-pretrained models. By examining over 300 combinations of models, datasets, and training methods, we find that shorter pretraining often leads to better results on the downstream task, providing additional proof to the well-known fact that the accuracy of the model on ImageNet is a poor indicator for downstream performance. As our main contribution, we introduce a novel transferability metric, based on contrastive learning, that measures how robustly a pretrained model is able to represent the target data. In contrast to other transferability scores, our method is applicable to the case of transferring from ImageNet classification to medical image segmentation. We apply our robustness score by measuring it throughout the pretraining phase to indicate when the model weights are optimal for downstream transfer. This reduces pretraining time and improves results on the target task.",
    "authors": [
      "G\\'abor Hidy, Bence Bakos, Andr\\'as Luk\\'acs"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.839679"
  },
  {
    "id": "oai:arXiv.org:2410.19912v2",
    "journal": "arXiv_CS",
    "title": "Simmering: Sufficient is better than optimal for training neural networks",
    "link": "https://arxiv.org/abs/2410.19912",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2410.19912v2 Announce Type: replace \nAbstract: The broad range of neural network training techniques that invoke optimization but rely on ad hoc modification for validity suggests that optimization-based training is misguided. Shortcomings of optimization-based training are brought to particularly strong relief by the problem of overfitting, where naive optimization produces spurious outcomes. The broad success of neural networks for modelling physical processes has prompted advances that are based on inverting the direction of investigation and treating neural networks as if they were physical systems in their own right. These successes raise the question of whether broader, physical perspectives could motivate the construction of improved training algorithms. Here, we introduce simmering, a physics-based method that trains neural networks to generate weights and biases that are merely ``good enough'', but which, paradoxically, outperforms leading optimization-based approaches. Using classification and regression examples we show that simmering corrects neural networks that are overfit by Adam, and show that simmering avoids overfitting if deployed from the outset. Our results question optimization as a paradigm for neural network training, and leverage information-geometric arguments to point to the existence of classes of sufficient training algorithms that do not take optimization as their starting point.",
    "authors": [
      "Irina Babayan, Hazhir Aliahmadi, Greg van Anders"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.839686"
  },
  {
    "id": "oai:arXiv.org:2411.09981v3",
    "journal": "arXiv_CS",
    "title": "SoK: Consensus for Fair Message Ordering",
    "link": "https://arxiv.org/abs/2411.09981",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2411.09981v3 Announce Type: replace \nAbstract: Distributed ledger systems, such as blockchains, rely on consensus protocols that commit ordered messages for processing. In practice, message ordering within these systems is often reward-driven. This raises concerns about fairness, particularly in decentralized finance applications, where nodes can exploit transaction orders to maximize rewards referred to as Maximal Extractable Value. This paper provides a systematic understanding of consensus protocols that order messages with different approaches, especially focusing on the ones that promote order fairness, using methods including First-In-First-Out (FIFO), random, and blind ordering. We review the challenges and trade-offs of deriving fair message ordering in a Byzantine fault-tolerant setting, and summarize the requirements for making a fair message ordering consensus protocol. We introduce a design guideline, with which we propose a latency optimization to the state-of-the-art FIFO ordering protocol of Themis. This work provides a systematic way for assessing and enhancing message order fairness in blockchain systems.",
    "authors": [
      "Zhuolun Li, Evangelos Pournaras"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.839737"
  },
  {
    "id": "oai:arXiv.org:2412.07978v2",
    "journal": "arXiv_CS",
    "title": "Agents for self-driving laboratories applied to quantum computing",
    "link": "https://arxiv.org/abs/2412.07978",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2412.07978v2 Announce Type: replace \nAbstract: Fully automated self-driving laboratories are promising to enable high-throughput and large-scale scientific discovery by reducing repetitive labour. However, effective automation requires deep integration of laboratory knowledge, which is often unstructured, multimodal, and difficult to incorporate into current AI systems. This paper introduces the k-agents framework, designed to support experimentalists in organizing laboratory knowledge and automating experiments with agents. Our framework employs large language model-based agents to encapsulate laboratory knowledge including available laboratory operations and methods for analyzing experiment results. To automate experiments, we introduce execution agents that break multi-step experimental procedures into agent-based state machines, interact with other agents to execute each step and analyze the experiment results. The analyzed results are then utilized to drive state transitions, enabling closed-loop feedback control. To demonstrate its capabilities, we applied the agents to calibrate and operate a superconducting quantum processor, where they autonomously planned and executed experiments for hours, successfully producing and characterizing entangled quantum states at the level achieved by human scientists. Our knowledge-based agent system opens up new possibilities for managing laboratory knowledge and accelerating scientific discovery.",
    "authors": [
      "Shuxiang Cao, Zijian Zhang, Mohammed Alghadeer, Simone D Fasciati, Michele Piscitelli, Mustafa Bakr, Peter Leek, Al\\'an Aspuru-Guzik"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.839867"
  },
  {
    "id": "oai:arXiv.org:2412.17451v3",
    "journal": "arXiv_CS",
    "title": "Diving into Self-Evolving Training for Multimodal Reasoning",
    "link": "https://arxiv.org/abs/2412.17451",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2412.17451v3 Announce Type: replace \nAbstract: Self-evolving trainin--where models iteratively learn from their own outputs--has emerged as a key approach for complex reasoning tasks, addressing the scarcity of high-quality chain-of-thought data. However, its effectiveness in multimodal reasoning, a domain more intricate than text-only reasoning, remains underexplored, and the understanding of critical factors in this training paradigm remains limited. Furthermore, a central challenge for this training method is performance saturation, which impedes further improvements and scalability. Inspired by reinforcement learning (RL), in this paper, we reframe self-evolving training for multimodal reasoning through the lens of RL, identifying three pivotal factors: Training Method, Reward Model, and Prompt Variation. Through systematic analysis, we establish relatively optimal design principles that significantly enhance multimodal reasoning capabilities. Moreover, delving deeper into training dynamics, we uncover the roots of saturation and propose a new automatic balancing mechanism to mitigate this limitation. Building on these insights, we propose M-STAR (Multimodal Self-evolving Training for Reasoning), a framework that achieves consistent performance gains across models of varying sizes and diverse benchmarks. All resources are made publicly available at https://mstar-lmm.github.io.",
    "authors": [
      "Wei Liu, Junlong Li, Xiwen Zhang, Fan Zhou, Yu Cheng, Junxian He"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.839946"
  },
  {
    "id": "oai:arXiv.org:2412.20220v2",
    "journal": "arXiv_CS",
    "title": "The Annotated Dependency Pair Framework for Almost-Sure Termination of Probabilistic Term Rewriting",
    "link": "https://arxiv.org/abs/2412.20220",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2412.20220v2 Announce Type: replace \nAbstract: Dependency pairs are one of the most powerful techniques to analyze termination of term rewrite systems automatically. We adapt dependency pairs to the probabilistic setting and develop an annotated dependency pair framework for automatically proving almost-sure termination of probabilistic term rewrite systems, both for full and innermost rewriting. To evaluate its power, we implemented our framework in the tool AProVE.",
    "authors": [
      "Jan-Christoph Kassing, J\\\"urgen Giesl"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.839971"
  },
  {
    "id": "oai:arXiv.org:2412.21139v2",
    "journal": "arXiv_CS",
    "title": "Training Software Engineering Agents and Verifiers with SWE-Gym",
    "link": "https://arxiv.org/abs/2412.21139",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2412.21139v2 Announce Type: replace \nAbstract: We present SWE-Gym, the first environment for training real-world software engineering (SWE) agents. SWE-Gym contains 2,438 real-world Python task instances, each comprising a codebase with an executable runtime environment, unit tests, and a task specified in natural language. We use SWE-Gym to train language model based SWE agents, achieving up to 19% absolute gains in resolve rate on the popular SWE-Bench Verified and Lite test sets. We also experiment with inference-time scaling through verifiers trained on agent trajectories sampled from SWE-Gym. When combined with our fine-tuned SWE agents, we achieve 32.0% and 26.0% on SWE-Bench Verified and Lite, respectively, reflecting a new state-of-the-art for open-weight SWE agents. To facilitate further research, we publicly release SWE-Gym, models, and agent trajectories.",
    "authors": [
      "Jiayi Pan, Xingyao Wang, Graham Neubig, Navdeep Jaitly, Heng Ji, Alane Suhr, Yizhe Zhang"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.839988"
  },
  {
    "id": "oai:arXiv.org:2501.06527v2",
    "journal": "arXiv_CS",
    "title": "Scaffolding Creativity: Integrating Generative AI Tools and Real-world Experiences in Business Education",
    "link": "https://arxiv.org/abs/2501.06527",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2501.06527v2 Announce Type: replace \nAbstract: This exploratory study investigates the intersection of Generative AI tools and experiential learning in business education. Through a case study of an innovative undergraduate course, we examine how students interact with and adapt to various AI modalities-from text-based tools to image generation-alongside real-world experiences. Our findings reveal how this integrated approach enables novice users to overcome creative barriers, accelerates skill acquisition, and creates a dynamic interplay between AI-generated insights and real-world validation. We identify critical interaction challenges, including prompt engineering patterns and the need for more intuitive AI interfaces in educational contexts. These insights inform the design of future AI tools for creative learning and contribute to broader HCI discussions about human-AI collaboration in educational settings.",
    "authors": [
      "Nicole C. Wang"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.840057"
  },
  {
    "id": "oai:arXiv.org:2501.06894v3",
    "journal": "arXiv_CS",
    "title": "Analyzing the Evolution and Maintenance of Quantum Software Repositories",
    "link": "https://arxiv.org/abs/2501.06894",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2501.06894v3 Announce Type: replace \nAbstract: Quantum computing is rapidly advancing, but quantum software development faces significant challenges, including a steep learning curve, high hardware error rates, and a lack of mature engineering practices. This study conducts a large-scale mining analysis of over 21,000 GitHub repositories, containing 1.2 million commits from more than 10,000 developers, to examine the evolution and maintenance of quantum software. We analyze repository growth, programming language and framework adoption, and contributor trends, revealing a 200% increase in repositories and a 150% rise in contributors since 2017. Additionally, we investigate software development and maintenance practices, showing that perfective commits dominate (51.76%), while the low occurrence of corrective commits (18.54%) indicates potential gaps in bug resolution. Furthermore, 34% of reported issues are quantum-specific, highlighting the need for specialized debugging tools beyond conventional software engineering approaches. This study provides empirical insights into the software engineering challenges of quantum computing, offering recommendations to improve development workflows, tooling, and documentation. We are also open-sourcing our dataset to support further analysis by the community and to guide future research and tool development for quantum computing. The dataset is available at: https://github.com/kriss-u/QRepoAnalysis-Paper",
    "authors": [
      "Krishna Upadhyay, Vinaik Chhetri, A. B. Siddique, Umar Farooq"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.840064"
  },
  {
    "id": "oai:arXiv.org:2501.12394v2",
    "journal": "arXiv_CS",
    "title": "ELEVATE-GenAI: Reporting Guidelines for the Use of Large Language Models in Health Economics and Outcomes Research: an ISPOR Working Group on Generative AI Report",
    "link": "https://arxiv.org/abs/2501.12394",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2501.12394v2 Announce Type: replace \nAbstract: Introduction: Generative artificial intelligence (AI), particularly large language models (LLMs), holds significant promise for Health Economics and Outcomes Research (HEOR). However, standardized reporting guidance for LLM-assisted research is lacking. This article introduces the ELEVATE GenAI framework and checklist - reporting guidelines specifically designed for HEOR studies involving LLMs.\n  Methods: The framework was developed through a targeted literature review of existing reporting guidelines, AI evaluation frameworks, and expert input from the ISPOR Working Group on Generative AI. It comprises ten domains, including model characteristics, accuracy, reproducibility, and fairness and bias. The accompanying checklist translates the framework into actionable reporting items. To illustrate its use, the framework was applied to two published HEOR studies: one focused on systematic literature review tasks and the other on economic modeling.\n  Results: The ELEVATE GenAI framework offers a comprehensive structure for reporting LLM-assisted HEOR research, while the checklist facilitates practical implementation. Its application to the two case studies demonstrates its relevance and usability across different HEOR contexts.\n  Limitations: Although the framework provides robust reporting guidance, further empirical testing is needed to assess its validity, completeness, usability, as well as its generalizability across diverse HEOR use cases.\n  Conclusion: The ELEVATE GenAI framework and checklist address a critical gap by offering structured guidance for transparent, accurate, and reproducible reporting of LLM-assisted HEOR research. Future work will focus on extensive testing and validation to support broader adoption and refinement.",
    "authors": [
      "Rachael L. Fleurence, Dalia Dawoud, Jiang Bian, Mitchell K. Higashi, Xiaoyan Wang, Hua Xu, Jagpreet Chhatwal, Turgay Ayer"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.840090"
  },
  {
    "id": "oai:arXiv.org:2501.18310v2",
    "journal": "arXiv_CS",
    "title": "ProofAug: Efficient Neural Theorem Proving via Fine-grained Proof Structure Analysis",
    "link": "https://arxiv.org/abs/2501.18310",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2501.18310v2 Announce Type: replace \nAbstract: The synergy between deep learning models and traditional automation tools, such as built-in tactics of the proof assistant and off-the-shelf automated theorem provers, plays a crucial role in developing robust and efficient neural theorem provers(NTPs). However, for proof synthesis with LLMs, previous work applies automation tools either only when explicitly invoked by the model or at a single granularity level, failing to fully exploit their power. To solve this issue, we propose ProofAug, a procedure that equips LLMs with automation methods at various granularities through fine-grained structure analysis of model-generated proof proposals. ProofAug also serves as a versatile plug-and-play module that seamlessly integrates with any tree-search algorithm, enabling our construction of an efficient recursive proving (ERP) module to further enhance performance. The superiority of our method is validated on the miniF2F benchmark using the open-source deepseek-math-7b-base model and the Isabelle proof assistant. Notably, by additionally employing a mixed prompting strategy, we achieve a cumulative pass rate of 66.0% after curation of the dataset (61.9% for the original version) with 2100 queries to the model per problem (In contrast, the previous SOTA in Isabelle, Subgoal-XL, only achieves 56.1% using 16384 queries per problem). We also implement a Lean 4 version of ProofAug that can improve the pass@1 performance of Kimina-Prover-Preview-Distill-1.5B from 44.3% to 50.4% on miniF2F-test. Our code is available at https://github.com/haoxiongliu/ProofAug.",
    "authors": [
      "Haoxiong Liu, Jiacheng Sun, Zhenguo Li, Andrew C Yao"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.840116"
  },
  {
    "id": "oai:arXiv.org:2502.07529v2",
    "journal": "arXiv_CS",
    "title": "Training Deep Learning Models with Norm-Constrained LMOs",
    "link": "https://arxiv.org/abs/2502.07529",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2502.07529v2 Announce Type: replace \nAbstract: In this work, we study optimization methods that leverage the linear minimization oracle (LMO) over a norm-ball. We propose a new stochastic family of algorithms that uses the LMO to adapt to the geometry of the problem and, perhaps surprisingly, show that they can be applied to unconstrained problems. The resulting update rule unifies several existing optimization methods under a single framework. Furthermore, we propose an explicit choice of norm for deep architectures, which, as a side benefit, leads to the transferability of hyperparameters across model sizes. Experimentally, we demonstrate significant speedups on nanoGPT training using our algorithm, Scion, without any reliance on Adam. The proposed method is memory-efficient, requiring only one set of model weights and one set of gradients, which can be stored in half-precision. The code is available at https://github.com/LIONS-EPFL/scion .",
    "authors": [
      "Thomas Pethick, Wanyun Xie, Kimon Antonakopoulos, Zhenyu Zhu, Antonio Silveti-Falls, Volkan Cevher"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.840228"
  },
  {
    "id": "oai:arXiv.org:2502.10855v2",
    "journal": "arXiv_CS",
    "title": "Towards Effective Extraction and Evaluation of Factual Claims",
    "link": "https://arxiv.org/abs/2502.10855",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2502.10855v2 Announce Type: replace \nAbstract: A common strategy for fact-checking long-form content generated by Large Language Models (LLMs) is extracting simple claims that can be verified independently. Since inaccurate or incomplete claims compromise fact-checking results, ensuring claim quality is critical. However, the lack of a standardized evaluation framework impedes assessment and comparison of claim extraction methods. To address this gap, we propose a framework for evaluating claim extraction in the context of fact-checking along with automated, scalable, and replicable methods for applying this framework, including novel approaches for measuring coverage and decontextualization. We also introduce Claimify, an LLM-based claim extraction method, and demonstrate that it outperforms existing methods under our evaluation framework. A key feature of Claimify is its ability to handle ambiguity and extract claims only when there is high confidence in the correct interpretation of the source text.",
    "authors": [
      "Dasha Metropolitansky, Jonathan Larson"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.840295"
  },
  {
    "id": "oai:arXiv.org:2502.15620v2",
    "journal": "arXiv_CS",
    "title": "Paradigms of AI Evaluation: Mapping Goals, Methodologies and Culture",
    "link": "https://arxiv.org/abs/2502.15620",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2502.15620v2 Announce Type: replace \nAbstract: Research in AI evaluation has grown increasingly complex and multidisciplinary, attracting researchers with diverse backgrounds and objectives. As a result, divergent evaluation paradigms have emerged, often developing in isolation, adopting conflicting terminologies, and overlooking each other's contributions. This fragmentation has led to insular research trajectories and communication barriers both among different paradigms and with the general public, contributing to unmet expectations for deployed AI systems. To help bridge this insularity, in this paper we survey recent work in the AI evaluation landscape and identify six main paradigms. We characterise major recent contributions within each paradigm across key dimensions related to their goals, methodologies and research cultures. By clarifying the unique combination of questions and approaches associated with each paradigm, we aim to increase awareness of the breadth of current evaluation approaches and foster cross-pollination between different paradigms. We also identify potential gaps in the field to inspire future research directions.",
    "authors": [
      "John Burden, Marko Te\\v{s}i\\'c, Lorenzo Pacchiardi, Jos\\'e Hern\\'andez-Orallo"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.840416"
  },
  {
    "id": "oai:arXiv.org:2502.18137v5",
    "journal": "arXiv_CS",
    "title": "SpargeAttention: Accurate and Training-free Sparse Attention Accelerating Any Model Inference",
    "link": "https://arxiv.org/abs/2502.18137",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2502.18137v5 Announce Type: replace \nAbstract: An efficient attention implementation is essential for large models due to its quadratic time complexity. Fortunately, attention commonly exhibits sparsity, i.e., many values in the attention map are near zero, allowing for the omission of corresponding computations. Many studies have utilized the sparse pattern to accelerate attention. However, most existing works focus on optimizing attention within specific models by exploiting certain sparse patterns of the attention map. A universal sparse attention that guarantees both the speedup and end-to-end performance of diverse models remains elusive. In this paper, we propose SpargeAttn, a universal sparse and quantized attention for any model. Our method uses a two-stage online filter: in the first stage, we rapidly and accurately predict the attention map, enabling the skip of some matrix multiplications in attention. In the second stage, we design an online softmax-aware filter that incurs no extra overhead and further skips some matrix multiplications. Experiments show that our method significantly accelerates diverse models, including language, image, and video generation, without sacrificing end-to-end metrics. The codes are available at https://github.com/thu-ml/SpargeAttn.",
    "authors": [
      "Jintao Zhang, Chendong Xiang, Haofeng Huang, Jia Wei, Haocheng Xi, Jun Zhu, Jianfei Chen"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.840441"
  },
  {
    "id": "oai:arXiv.org:2502.19115v3",
    "journal": "arXiv_CS",
    "title": "Improving Customer Service with Automatic Topic Detection in User Emails",
    "link": "https://arxiv.org/abs/2502.19115",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2502.19115v3 Announce Type: replace \nAbstract: This study introduces a novel natural language processing pipeline that enhances customer service efficiency at Telekom Srbija, a leading Serbian telecommunications company, through automated email topic detection and labeling. Central to the pipeline is BERTopic, a modular framework that allows unsupervised topic modeling. After a series of preprocessing and postprocessing steps, we assign one of 12 topics and several additional labels to incoming emails, allowing customer service to filter and access them through a custom-made application. While applied to Serbian, the methodology is conceptually language-agnostic and can be readily adapted to other languages, particularly those that are low-resourced and morphologically rich. The system performance was evaluated by assessing the speed and correctness of the automatically assigned topics, with a weighted average processing time of 0.041 seconds per email and a weighted average F1 score of 0.96. The system now operates in the company's production environment, streamlining customer service operations through automated email classification.",
    "authors": [
      "Bojana Ba\\v{s}aragin, Darija Medvecki, Gorana Goji\\'c, Milena Oparnica, Dragi\\v{s}a Mi\\v{s}kovi\\'c"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.840466"
  },
  {
    "id": "oai:arXiv.org:2503.00566v2",
    "journal": "arXiv_CS",
    "title": "Instructor-Worker Large Language Model System for Policy Recommendation: a Case Study on Air Quality Analysis of the January 2025 Los Angeles Wildfires",
    "link": "https://arxiv.org/abs/2503.00566",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2503.00566v2 Announce Type: replace \nAbstract: The Los Angeles wildfires of January 2025 caused more than 250 billion dollars in damage and lasted for nearly an entire month before containment. Following our previous work, the Digital Twin Building, we modify and leverage the multi-agent large language model framework as well as the cloud-mapping integration to study the air quality during the Los Angeles wildfires. Recent advances in large language models have allowed for out-of-the-box automated large-scale data analysis. We use a multi-agent large language system comprised of an Instructor agent and Worker agents. Upon receiving the users' instructions, the Instructor agent retrieves the data from the cloud platform and produces instruction prompts to the Worker agents. The Worker agents then analyze the data and provide summaries. The summaries are finally input back into the Instructor agent, which then provides the final data analysis. We test this system's capability for data-based policy recommendation by assessing our Instructor-Worker LLM system's health recommendations based on air quality during the Los Angeles wildfires.",
    "authors": [
      "Kyle Gao, Dening Lu, Liangzhi Li, Nan Chen, Hongjie He, Linlin Xu, Jonathan Li"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.840528"
  },
  {
    "id": "oai:arXiv.org:2503.00786v2",
    "journal": "arXiv_CS",
    "title": "Graph Attention Networks Unleashed: A Fast and Explainable Vulnerability Assessment Framework for Microgrids",
    "link": "https://arxiv.org/abs/2503.00786",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2503.00786v2 Announce Type: replace \nAbstract: Independent microgrids are crucial for supplying electricity by combining distributed energy resources and loads in scenarios like isolated islands and field combat. Fast and accurate assessments of microgrid vulnerability against intentional attacks or natural disasters are essential for effective risk prevention and design optimization. However, conventional Monte Carlo simulation (MCS) methods are computationally expensive and time-consuming, while existing machine learning-based approaches often lack accuracy and explainability. To address these challenges, this study proposes a fast and explainable vulnerability assessment framework that integrates MCS with a graph attention network enhanced by self-attention pooling (GAT-S). MCS generates training data, while the GAT-S model learns the structural and electrical characteristics of the microgrid and further assesses its vulnerability intelligently. The GAT-S improves explainability and computational efficiency by dynamically assigning attention weights to critical nodes. Comprehensive experimental evaluations across various microgrid configurations demonstrate that the proposed framework provides accurate vulnerability assessments, achieving a mean squared error as low as 0.001, real-time responsiveness within 1 second, and delivering explainable results.",
    "authors": [
      "Wei Liu, Tao Zhang, Chenhui Lin, Kaiwen Li, Rui Wang"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.840536"
  },
  {
    "id": "oai:arXiv.org:2503.01908v2",
    "journal": "arXiv_CS",
    "title": "UDora: A Unified Red Teaming Framework against LLM Agents by Dynamically Hijacking Their Own Reasoning",
    "link": "https://arxiv.org/abs/2503.01908",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2503.01908v2 Announce Type: replace \nAbstract: Large Language Model (LLM) agents equipped with external tools have become increasingly powerful for complex tasks such as web shopping, automated email replies, and financial trading. However, these advancements amplify the risks of adversarial attacks, especially when agents can access sensitive external functionalities. Nevertheless, manipulating LLM agents into performing targeted malicious actions or invoking specific tools remains challenging, as these agents extensively reason or plan before executing final actions. In this work, we present UDora, a unified red teaming framework designed for LLM agents that dynamically hijacks the agent's reasoning processes to compel malicious behavior. Specifically, UDora first generates the model's reasoning trace for the given task, then automatically identifies optimal points within this trace to insert targeted perturbations. The resulting perturbed reasoning is then used as a surrogate response for optimization. By iteratively applying this process, the LLM agent will then be induced to undertake designated malicious actions or to invoke specific malicious tools. Our approach demonstrates superior effectiveness compared to existing methods across three LLM agent datasets. The code is available at https://github.com/AI-secure/UDora.",
    "authors": [
      "Jiawei Zhang, Shuang Yang, Bo Li"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.840553"
  },
  {
    "id": "oai:arXiv.org:2503.04381v2",
    "journal": "arXiv_CS",
    "title": "TRACT: Regression-Aware Fine-tuning Meets Chain-of-Thought Reasoning for LLM-as-a-Judge",
    "link": "https://arxiv.org/abs/2503.04381",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2503.04381v2 Announce Type: replace \nAbstract: The LLM-as-a-judge paradigm uses large language models (LLMs) for automated text evaluation, where a numerical assessment is assigned by an LLM to the input text following scoring rubrics. Existing methods for LLM-as-a-judge use cross-entropy (CE) loss for fine-tuning, which neglects the numeric nature of score prediction. Recent work addresses numerical prediction limitations of LLM fine-tuning through regression-aware fine-tuning, which, however, does not consider chain-of-thought (CoT) reasoning for score prediction. In this paper, we introduce TRACT (Two-stage Regression-Aware fine-tuning with CoT), a method combining CoT reasoning with regression-aware training. TRACT consists of two stages: first, seed LLM is fine-tuned to generate CoTs, which serve as supervision for the second stage fine-tuning. The training objective of TRACT combines the CE loss for learning the CoT reasoning capabilities, and the regression-aware loss for the score prediction. Experiments across four LLM-as-a-judge datasets and two LLMs show that TRACT significantly outperforms existing methods. Extensive ablation studies validate the importance of each component in TRACT.",
    "authors": [
      "Cheng-Han Chiang, Hung-yi Lee, Michal Lukasik"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.840595"
  },
  {
    "id": "oai:arXiv.org:2503.04768v2",
    "journal": "arXiv_CS",
    "title": "DiMA: An LLM-Powered Ride-Hailing Assistant at DiDi",
    "link": "https://arxiv.org/abs/2503.04768",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2503.04768v2 Announce Type: replace \nAbstract: On-demand ride-hailing services like DiDi, Uber, and Lyft have transformed urban transportation, offering unmatched convenience and flexibility. In this paper, we introduce DiMA, an LLM-powered ride-hailing assistant deployed in DiDi Chuxing. Its goal is to provide seamless ride-hailing services and beyond through a natural and efficient conversational interface under dynamic and complex spatiotemporal urban contexts. To achieve this, we propose a spatiotemporal-aware order planning module that leverages external tools for precise spatiotemporal reasoning and progressive order planning. Additionally, we develop a cost-effective dialogue system that integrates multi-type dialog repliers with cost-aware LLM configurations to handle diverse conversation goals and trade-off response quality and latency. Furthermore, we introduce a continual fine-tuning scheme that utilizes real-world interactions and simulated dialogues to align the assistant's behavior with human preferred decision-making processes. Since its deployment in the DiDi application, DiMA has demonstrated exceptional performance, achieving 93% accuracy in order planning and 92% in response generation during real-world interactions. Offline experiments further validate DiMA capabilities, showing improvements of up to 70.23% in order planning and 321.27% in response generation compared to three state-of-the-art agent frameworks, while reducing latency by $0.72\\times$ to $5.47\\times$. These results establish DiMA as an effective, efficient, and intelligent mobile assistant for ride-hailing services.",
    "authors": [
      "Yansong Ning, Shuowei Cai, Wei Li, Jun Fang, Naiqiang Tan, Hua Chai, Hao Liu"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.840602"
  },
  {
    "id": "oai:arXiv.org:2503.20989v2",
    "journal": "arXiv_CS",
    "title": "Inferring fine-grained migration patterns across the United States",
    "link": "https://arxiv.org/abs/2503.20989",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2503.20989v2 Announce Type: replace \nAbstract: Fine-grained migration data illuminate important demographic, environmental, and health phenomena. However, migration datasets within the United States remain lacking: publicly available Census data are neither spatially nor temporally granular, and proprietary data have higher resolution but demographic and other biases. To address these limitations, we develop a scalable iterative-proportional-fitting based method that reconciles high-resolution but biased proprietary data with low-resolution but more reliable Census data. We apply this method to produce MIGRATE, a dataset of annual migration matrices from 2010 - 2019 that captures flows between 47.4 billion pairs of Census Block Groups -- about four thousand times more granular than publicly available data. These estimates are highly correlated with external ground-truth datasets, and improve accuracy and reduce bias relative to raw proprietary data. We use MIGRATE to analyze both national and local migration patterns. Nationally, we document temporal and demographic variation in homophily, upward mobility, and moving distance: for example, we find that people are increasingly likely to move to top-income-quartile CBGs and identify racial disparities in upward mobility. We also show that MIGRATE can illuminate important local migration patterns, including out-migration in response to California wildfires, that are invisible in coarser previous datasets. We publicly release MIGRATE to provide a resource for migration research in the social, environmental, and health sciences.",
    "authors": [
      "Gabriel Agostini, Rachel Young, Maria Fitzpatrick, Nikhil Garg, Emma Pierson"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.840742"
  },
  {
    "id": "oai:arXiv.org:2504.02107v3",
    "journal": "arXiv_CS",
    "title": "TiC-LM: A Web-Scale Benchmark for Time-Continual LLM Pretraining",
    "link": "https://arxiv.org/abs/2504.02107",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2504.02107v3 Announce Type: replace \nAbstract: Large Language Models (LLMs) trained on historical web data inevitably become outdated. We investigate evaluation strategies and update methods for LLMs as new data becomes available. We introduce a web-scale dataset for time-continual pretraining of LLMs derived from 114 dumps of Common Crawl (CC) - orders of magnitude larger than previous continual language modeling benchmarks. We also design time-stratified evaluations across both general CC data and specific domains (Wikipedia, StackExchange, and code documentation) to assess how well various continual learning methods adapt to new data while retaining past knowledge. Our findings demonstrate that, on general CC data, autoregressive meta-schedules combined with a fixed-ratio replay of older data can achieve comparable held-out loss to re-training from scratch, while requiring significantly less computation (2.6x). However, the optimal balance between incorporating new data and replaying old data differs as replay is crucial to avoid forgetting on generic web data but less so on specific domains.",
    "authors": [
      "Jeffrey Li, Mohammadreza Armandpour, Iman Mirzadeh, Sachin Mehta, Vaishaal Shankar, Raviteja Vemulapalli, Samy Bengio, Oncel Tuzel, Mehrdad Farajtabar, Hadi Pouransari, Fartash Faghri"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.840784"
  },
  {
    "id": "oai:arXiv.org:2504.02151v2",
    "journal": "arXiv_CS",
    "title": "Multivariate Temporal Regression at Scale: A Three-Pillar Framework Combining ML, XAI, and NLP",
    "link": "https://arxiv.org/abs/2504.02151",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2504.02151v2 Announce Type: replace \nAbstract: This paper introduces a novel framework that accelerates the discovery of actionable relationships in high-dimensional temporal data by integrating machine learning (ML), explainable AI (XAI), and natural language processing (NLP) to enhance data quality and streamline workflows. Traditional methods often fail to recognize complex temporal relationships, leading to noisy, redundant, or biased datasets. Our approach combines ML-driven pruning to identify and mitigate low-quality samples, XAI-based interpretability to validate critical feature interactions, and NLP for future contextual validation, reducing the time required to uncover actionable insights by 40-60%. Evaluated on real-world agricultural and synthetic datasets, the framework significantly improves performance metrics (e.g., MSE, R2, MAE) and computational efficiency, with hardware-agnostic scalability across diverse platforms. While long-term real-world impacts (e.g., cost savings, sustainability gains) are pending, this methodology provides an immediate pathway to accelerate data-centric AI in dynamic domains like agriculture and energy, enabling faster iteration cycles for domain experts.",
    "authors": [
      "Jiztom Kavalakkatt Francis, Matthew J Darr"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.840792"
  },
  {
    "id": "oai:arXiv.org:2504.05632v3",
    "journal": "arXiv_CS",
    "title": "Reasoning Towards Fairness: Mitigating Bias in Language Models through Reasoning-Guided Fine-Tuning",
    "link": "https://arxiv.org/abs/2504.05632",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2504.05632v3 Announce Type: replace \nAbstract: Recent advances in large-scale generative language models have shown that reasoning capabilities can significantly improve model performance across a variety of tasks. However, the impact of reasoning on a model's ability to mitigate stereotypical responses remains largely underexplored. In this work, we investigate the crucial relationship between a model's reasoning ability and fairness, and ask whether improved reasoning capabilities can mitigate harmful stereotypical responses, especially those arising due to shallow or flawed reasoning. We conduct a comprehensive evaluation of multiple open-source LLMs, and find that larger models with stronger reasoning abilities exhibit substantially lower stereotypical bias on existing fairness benchmarks. Building on this insight, we introduce ReGiFT -- Reasoning Guided Fine-Tuning, a novel approach that extracts structured reasoning traces from advanced reasoning models and infuses them into models that lack such capabilities. We use only general-purpose reasoning and do not require any fairness-specific supervision for bias mitigation. Notably, we see that models fine-tuned using ReGiFT not only improve fairness relative to their non-reasoning counterparts but also outperform advanced reasoning models on fairness benchmarks. We also analyze how variations in the correctness of the reasoning traces and their length influence model fairness and their overall performance. Our findings highlight that enhancing reasoning capabilities is an effective, fairness-agnostic strategy for mitigating stereotypical bias caused by reasoning flaws.",
    "authors": [
      "Sanchit Kabra, Akshita Jha, Chandan K. Reddy"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.840808"
  },
  {
    "id": "oai:arXiv.org:2504.07013v2",
    "journal": "arXiv_CS",
    "title": "Thin Coalgebraic Behaviours Are Inductive",
    "link": "https://arxiv.org/abs/2504.07013",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2504.07013v2 Announce Type: replace \nAbstract: Coalgebras for analytic functors uniformly model graph-like systems where the successors of a state may admit certain symmetries. Examples of successor structure include ordered tuples, cyclic lists and multisets. Motivated by goals in automata-based verification and results on thin trees, we introduce thin coalgebras as those coalgebras with only countably many infinite paths from each state. Our main result is an inductive characterisation of thinness via an initial algebra. To this end, we develop a syntax for thin behaviours and capture with a single equation when two terms represent the same thin behaviour. Finally, for the special case of polynomial functors, we retrieve from our syntax the notion of Cantor-Bendixson rank of a thin tree.",
    "authors": [
      "Anton Chernev, Corina C\\^irstea, Helle Hvid Hansen, Clemens Kupke"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.840816"
  },
  {
    "id": "oai:arXiv.org:2504.10136v2",
    "journal": "arXiv_CS",
    "title": "Uncertainty Propagation in the Fast Fourier Transform",
    "link": "https://arxiv.org/abs/2504.10136",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2504.10136v2 Announce Type: replace \nAbstract: We address the problem of uncertainty propagation in the discrete Fourier transform by modeling the fast Fourier transform as a factor graph. Building on this representation, we propose an efficient framework for approximate Bayesian inference using belief propagation (BP) and expectation propagation, extending its applicability beyond Gaussian assumptions. By leveraging an appropriate BP message representation and a suitable schedule, our method achieves stable convergence with accurate mean and variance estimates. Numerical experiments in representative scenarios from communications demonstrate the practical potential of the proposed framework for uncertainty-aware inference in probabilistic systems operating across both time and frequency domain.",
    "authors": [
      "Luca Schmid, Charlotte Muth, Laurent Schmalen"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.840850"
  },
  {
    "id": "oai:arXiv.org:2504.18786v2",
    "journal": "arXiv_CS",
    "title": "Contracts: A unified lens on congestion control robustness, fairness, congestion, and generality",
    "link": "https://arxiv.org/abs/2504.18786",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2504.18786v2 Announce Type: replace \nAbstract: Congestion control algorithms (CCAs) operate in partially observable environments, lacking direct visibility into link capacities, or competing flows. To ensure fair sharing of network resources, CCAs communicate their fair share through observable signals. For instance, Reno's fair share is encoded as $\\propto 1/\\sqrt{\\texttt{loss rate}}$. We call such communication mechanisms \\emph{contracts}. We show that the design choice of contracts fixes key steady-state performance metrics, including robustness to errors in congestion signals, fairness, amount of congestion (e.g., delay, loss), and generality (e.g., range of supported link rates). This results in fundamental tradeoffs between these metrics. Using properties of contracts we also identify design pitfalls that lead to starvation (extreme unfairness). We argue that CCA design and analysis should start with contracts to conscientiously pick tradeoffs and avoid pitfalls. We empirically validate our findings and discuss their implications on CCA design and network measurement.",
    "authors": [
      "Anup Agarwal, Venkat Arun, Srinivasan Seshan"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.840954"
  },
  {
    "id": "oai:arXiv.org:2504.18839v2",
    "journal": "arXiv_CS",
    "title": "Detect, Explain, Escalate: Low-Carbon Dialogue Breakdown Management for LLM-Powered Agents",
    "link": "https://arxiv.org/abs/2504.18839",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2504.18839v2 Announce Type: replace \nAbstract: While Large Language Models (LLMs) are transforming numerous applications, their susceptibility to conversational breakdowns remains a critical challenge undermining user trust. This paper introduces a \"Detect, Explain, Escalate\" framework to manage dialogue breakdowns in LLM-powered agents, emphasizing low-carbon operation. Our approach integrates two key strategies: (1) We fine-tune a compact 8B-parameter model, augmented with teacher-generated reasoning traces, which serves as an efficient real-time breakdown 'detector' and 'explainer'. This model demonstrates robust classification and calibration on English and Japanese dialogues, and generalizes well to the BETOLD dataset, improving accuracy by 7% over its baseline. (2) We systematically evaluate frontier LLMs using advanced prompting (few-shot, chain-of-thought, analogical reasoning) for high-fidelity breakdown assessment. These are integrated into an 'escalation' architecture where our efficient detector defers to larger models only when necessary, substantially reducing operational costs and energy consumption. Our fine-tuned model and prompting strategies establish new state-of-the-art results on dialogue breakdown detection benchmarks, outperforming specialized classifiers and significantly narrowing the performance gap to larger proprietary models. The proposed monitor-escalate pipeline reduces inference costs by 54%, offering a scalable, efficient, and more interpretable solution for robust conversational AI in high-impact domains. Code and models will be publicly released.",
    "authors": [
      "Abdellah Ghassel, Xianzhi Li, Xiaodan Zhu"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.840962"
  },
  {
    "id": "oai:arXiv.org:2505.04113v2",
    "journal": "arXiv_CS",
    "title": "Advancing Zero-shot Text-to-Speech Intelligibility across Diverse Domains via Preference Alignment",
    "link": "https://arxiv.org/abs/2505.04113",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2505.04113v2 Announce Type: replace \nAbstract: Modern zero-shot text-to-speech (TTS) systems, despite using extensive pre-training, often struggle in challenging scenarios such as tongue twisters, repeated words, code-switching, and cross-lingual synthesis, leading to intelligibility issues. To address these limitations, this paper leverages preference alignment techniques, which enable targeted construction of out-of-pretraining-distribution data to enhance performance. We introduce a new dataset, named the Intelligibility Preference Speech Dataset (INTP), and extend the Direct Preference Optimization (DPO) framework to accommodate diverse TTS architectures. After INTP alignment, in addition to intelligibility, we observe overall improvements including naturalness, similarity, and audio quality for multiple TTS models across diverse domains. Based on that, we also verify the weak-to-strong generalization ability of INTP for more intelligible models such as CosyVoice 2 and Ints. Moreover, we showcase the potential for further improvements through iterative alignment based on Ints. Audio samples are available at https://intalign.github.io/.",
    "authors": [
      "Xueyao Zhang, Yuancheng Wang, Chaoren Wang, Ziniu Li, Zhuo Chen, Zhizheng Wu"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.841031"
  },
  {
    "id": "oai:arXiv.org:2505.16583v5",
    "journal": "arXiv_CS",
    "title": "Training on Plausible Counterfactuals Removes Spurious Correlations",
    "link": "https://arxiv.org/abs/2505.16583",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2505.16583v5 Announce Type: replace \nAbstract: Plausible counterfactual explanations (p-CFEs) are perturbations that minimally modify inputs to change classifier decisions while remaining plausible under the data distribution. In this study, we demonstrate that classifiers can be trained on p-CFEs labeled with induced \\emph{incorrect} target classes to classify unperturbed inputs with the original labels. While previous studies have shown that such learning is possible with adversarial perturbations, we extend this paradigm to p-CFEs. Interestingly, our experiments reveal that learning from p-CFEs is even more effective: the resulting classifiers achieve not only high in-distribution accuracy but also exhibit significantly reduced bias with respect to spurious correlations.",
    "authors": [
      "Shpresim Sadiku, Kartikeya Chitranshi, Hiroshi Kera, Sebastian Pokutta"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.841162"
  },
  {
    "id": "oai:arXiv.org:2505.21339v2",
    "journal": "arXiv_CS",
    "title": "An Uncertainty-Aware ED-LSTM for Probabilistic Suffix Prediction",
    "link": "https://arxiv.org/abs/2505.21339",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2505.21339v2 Announce Type: replace \nAbstract: Suffix prediction of business processes forecasts the remaining sequence of events until process completion. Current approaches focus on predicting the most likely suffix, representing a single scenario. However, when the future course of a process is subject to uncertainty and high variability, the expressiveness of such a single scenario can be limited, since other possible scenarios, which together may have a higher overall probability, are overlooked. To address this limitation, we propose probabilistic suffix prediction, a novel approach that approximates a probability distribution of suffixes. The proposed approach is based on an Uncertainty-Aware Encoder-Decoder LSTM (U-ED-LSTM) and a Monte Carlo (MC) suffix sampling algorithm. We capture epistemic uncertainties via MC dropout and aleatoric uncertainties as learned loss attenuation. This technical report presents a comprehensive evaluation of the probabilistic suffix prediction approach's predictive performance and calibration under three different hyperparameter settings, using four real-life and one artificial event log. The results show that: i) probabilistic suffix prediction can outperform most likely suffix prediction, the U-ED-LSTM has reasonable predictive performance, and ii) the model's predictions are well calibrated.",
    "authors": [
      "Henryk Mustroph, Michel Kunkler, Stefanie Rinderle-Ma"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.841230"
  },
  {
    "id": "oai:arXiv.org:2505.22342v2",
    "journal": "arXiv_CS",
    "title": "Progressive Data Dropout: An Embarrassingly Simple Approach to Faster Training",
    "link": "https://arxiv.org/abs/2505.22342",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2505.22342v2 Announce Type: replace \nAbstract: The success of the machine learning field has reliably depended on training on large datasets. While effective, this trend comes at an extraordinary cost. This is due to two deeply intertwined factors: the size of models and the size of datasets. While promising research efforts focus on reducing the size of models, the other half of the equation remains fairly mysterious. Indeed, it is surprising that the standard approach to training remains to iterate over and over, uniformly sampling the training dataset. In this paper we explore a series of alternative training paradigms that leverage insights from hard-data-mining and dropout, simple enough to implement and use that can become the new training standard. The proposed Progressive Data Dropout reduces the number of effective epochs to as little as 12.4% of the baseline. This savings actually do not come at any cost for accuracy. Surprisingly, the proposed method improves accuracy by up to 4.82%. Our approach requires no changes to model architecture or optimizer, and can be applied across standard training pipelines, thus posing an excellent opportunity for wide adoption. Code can be found here: https://github.com/bazyagami/LearningWithRevision",
    "authors": [
      "Shriram M S, Xinyue Hao, Shihao Hou, Yang Lu, Laura Sevilla-Lara, Anurag Arnab, Shreyank N Gowda"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.841275"
  },
  {
    "id": "oai:arXiv.org:2505.22458v2",
    "journal": "arXiv_CS",
    "title": "Universal Domain Adaptation for Semantic Segmentation",
    "link": "https://arxiv.org/abs/2505.22458",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2505.22458v2 Announce Type: replace \nAbstract: Unsupervised domain adaptation for semantic segmentation (UDA-SS) aims to transfer knowledge from labeled source data to unlabeled target data. However, traditional UDA-SS methods assume that category settings between source and target domains are known, which is unrealistic in real-world scenarios. This leads to performance degradation if private classes exist. To address this limitation, we propose Universal Domain Adaptation for Semantic Segmentation (UniDA-SS), achieving robust adaptation even without prior knowledge of category settings. We define the problem in the UniDA-SS scenario as low confidence scores of common classes in the target domain, which leads to confusion with private classes. To solve this problem, we propose UniMAP: UniDA-SS with Image Matching and Prototype-based Distinction, a novel framework composed of two key components. First, Domain-Specific Prototype-based Distinction (DSPD) divides each class into two domain-specific prototypes, enabling finer separation of domain-specific features and enhancing the identification of common classes across domains. Second, Target-based Image Matching (TIM) selects a source image containing the most common-class pixels based on the target pseudo-label and pairs it in a batch to promote effective learning of common classes. We also introduce a new UniDA-SS benchmark and demonstrate through various experiments that UniMAP significantly outperforms baselines. The code is available at https://github.com/KU-VGI/UniMAP.",
    "authors": [
      "Seun-An Choe, Keon-Hee Park, Jinwoo Choi, Gyeong-Moon Park"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.841282"
  },
  {
    "id": "oai:arXiv.org:2505.22777v2",
    "journal": "arXiv_CS",
    "title": "MEDAL: A Framework for Benchmarking LLMs as Multilingual Open-Domain Chatbots and Dialogue Evaluators",
    "link": "https://arxiv.org/abs/2505.22777",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2505.22777v2 Announce Type: replace \nAbstract: As the capabilities of chatbots and their underlying LLMs continue to dramatically improve, evaluating their performance has increasingly become a major blocker to their further development. A major challenge is the available benchmarking datasets, which are largely static, outdated, and lacking in multilingual coverage, limiting their ability to capture subtle linguistic and cultural variations. This paper introduces MEDAL, an automated multi-agent framework for generating, evaluating, and curating more representative and diverse open-domain dialogue evaluation benchmarks. Our approach leverages several state-of-the-art LLMs to generate user-chatbot multilingual dialogues, conditioned on varied seed contexts. A strong LLM (GPT-4.1) is then used for a multidimensional analysis of the performance of the chatbots, uncovering noticeable cross-lingual performance differences. Guided by this large-scale evaluation, we curate a new meta-evaluation multilingual benchmark and human-annotate samples with nuanced quality judgments. This benchmark is then used to assess the ability of several reasoning and non-reasoning LLMs to act as evaluators of open-domain dialogues. We find that current LLMs struggle to detect nuanced issues, particularly those involving empathy and reasoning.",
    "authors": [
      "John Mendon\\c{c}a, Alon Lavie, Isabel Trancoso"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.841290"
  },
  {
    "id": "oai:arXiv.org:2505.24782v2",
    "journal": "arXiv_CS",
    "title": "Context is Gold to find the Gold Passage: Evaluating and Training Contextual Document Embeddings",
    "link": "https://arxiv.org/abs/2505.24782",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2505.24782v2 Announce Type: replace \nAbstract: A limitation of modern document retrieval embedding methods is that they typically encode passages (chunks) from the same documents independently, often overlooking crucial contextual information from the rest of the document that could greatly improve individual chunk representations.\n  In this work, we introduce ConTEB (Context-aware Text Embedding Benchmark), a benchmark designed to evaluate retrieval models on their ability to leverage document-wide context. Our results show that state-of-the-art embedding models struggle in retrieval scenarios where context is required. To address this limitation, we propose InSeNT (In-sequence Negative Training), a novel contrastive post-training approach which combined with late chunking pooling enhances contextual representation learning while preserving computational efficiency. Our method significantly improves retrieval quality on ConTEB without sacrificing base model performance. We further find chunks embedded with our method are more robust to suboptimal chunking strategies and larger retrieval corpus sizes. We open-source all artifacts at https://github.com/illuin-tech/contextual-embeddings.",
    "authors": [
      "Max Conti, Manuel Faysse, Gautier Viaud, Antoine Bosselut, C\\'eline Hudelot, Pierre Colombo"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.841334"
  },
  {
    "id": "oai:arXiv.org:2506.01080v2",
    "journal": "arXiv_CS",
    "title": "The Coming Crisis of Multi-Agent Misalignment: AI Alignment Must Be a Dynamic and Social Process",
    "link": "https://arxiv.org/abs/2506.01080",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.01080v2 Announce Type: replace \nAbstract: This position paper states that AI Alignment in Multi-Agent Systems (MAS) should be considered a dynamic and interaction-dependent process that heavily depends on the social environment where agents are deployed, either collaborative, cooperative, or competitive. While AI alignment with human values and preferences remains a core challenge, the growing prevalence of MAS in real-world applications introduces a new dynamic that reshapes how agents pursue goals and interact to accomplish various tasks. As agents engage with one another, they must coordinate to accomplish both individual and collective goals. However, this complex social organization may unintentionally misalign some or all of these agents with human values or user preferences. Drawing on social sciences, we analyze how social structure can deter or shatter group and individual values. Based on these analyses, we call on the AI community to treat human, preferential, and objective alignment as an interdependent concept, rather than isolated problems. Finally, we emphasize the urgent need for simulation environments, benchmarks, and evaluation frameworks that allow researchers to assess alignment in these interactive multi-agent contexts before such dynamics grow too complex to control.",
    "authors": [
      "Florian Carichon, Aditi Khandelwal, Marylou Fauchard, Golnoosh Farnadi"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.841393"
  },
  {
    "id": "oai:arXiv.org:2506.01532v4",
    "journal": "arXiv_CS",
    "title": "Balancing Beyond Discrete Categories: Continuous Demographic Labels for Fair Face Recognition",
    "link": "https://arxiv.org/abs/2506.01532",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.01532v4 Announce Type: replace \nAbstract: Bias has been a constant in face recognition models. Over the years, researchers have looked at it from both the model and the data point of view. However, their approach to mitigation of data bias was limited and lacked insight on the real nature of the problem. Here, in this document, we propose to revise our use of ethnicity labels as a continuous variable instead of a discrete value per identity. We validate our formulation both experimentally and theoretically, showcasing that not all identities from one ethnicity contribute equally to the balance of the dataset; thus, having the same number of identities per ethnicity does not represent a balanced dataset. We further show that models trained on datasets balanced in the continuous space consistently outperform models trained on data balanced in the discrete space. We trained more than 65 different models, and created more than 20 subsets of the original datasets.",
    "authors": [
      "Pedro C. Neto, Naser Damer, Jaime S. Cardoso, Ana F. Sequeira"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.841418"
  },
  {
    "id": "oai:arXiv.org:2506.03664v2",
    "journal": "arXiv_CS",
    "title": "Assessing Intersectional Bias in Representations of Pre-Trained Image Recognition Models",
    "link": "https://arxiv.org/abs/2506.03664",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.03664v2 Announce Type: replace \nAbstract: Deep Learning models have achieved remarkable success. Training them is often accelerated by building on top of pre-trained models which poses the risk of perpetuating encoded biases. Here, we investigate biases in the representations of commonly used ImageNet classifiers for facial images while considering intersections of sensitive variables age, race and gender. To assess the biases, we use linear classifier probes and visualize activations as topographic maps. We find that representations in ImageNet classifiers particularly allow differentiation between ages. Less strongly pronounced, the models appear to associate certain ethnicities and distinguish genders in middle-aged groups.",
    "authors": [
      "Valerie Krug, Sebastian Stober"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.841560"
  },
  {
    "id": "oai:arXiv.org:2506.04305v2",
    "journal": "arXiv_CS",
    "title": "Enduring Disparities in the Workplace: A Pilot Study in the AI Community",
    "link": "https://arxiv.org/abs/2506.04305",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.04305v2 Announce Type: replace \nAbstract: In efforts toward achieving responsible artificial intelligence (AI), fostering a culture of workplace transparency, diversity, and inclusion can breed innovation, trust, and employee contentment. In AI and Machine Learning (ML), such environments correlate with higher standards of responsible development. Without transparency, disparities, microaggressions and misconduct will remain unaddressed, undermining the very structural inequities responsible AI aims to mitigate. While prior work investigates workplace transparency and disparities in broad domains (e.g. science and technology, law) for specific demographic subgroups, it lacks in-depth and intersectional conclusions and a focus on the AI/ML community. To address this, we conducted a pilot survey of 1260 AI/ML professionals both in industry and academia across different axes, probing aspects such as belonging, performance, workplace Diversity, Equity and Inclusion (DEI) initiatives, accessibility, performance and compensation, microaggressions, misconduct, growth, and well-being. Results indicate enduring disparities in workplace experiences for underrepresented and/or marginalized subgroups. In particular, we highlight that accessibility remains an important challenge for a positive work environment and that disabled employees have a worse workplace experience than their non-disabled colleagues. We further surface disparities for intersectional groups and discuss how the implementation of DEI initiatives may differ from their perceived impact on the workplace. This study is a first step towards increasing transparency and informing AI/ML practitioners and organizations with empirical results. We aim to foster equitable decision-making in the design and evaluation of organizational policies and provide data that may empower professionals to make more informed choices of prospective workplaces.",
    "authors": [
      "Yunusa Simpa Abdulsalam, Siobhan Mackenzie Hall, Ana Quintero-Ossa, William Agnew, Carla Muntean, Sarah Tan, Ashley Heady, Savannah Thais, Jessica Schrouff"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.841592"
  },
  {
    "id": "oai:arXiv.org:2506.04648v2",
    "journal": "arXiv_CS",
    "title": "FPSAttention: Training-Aware FP8 and Sparsity Co-Design for Fast Video Diffusion",
    "link": "https://arxiv.org/abs/2506.04648",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.04648v2 Announce Type: replace \nAbstract: Diffusion generative models have become the standard for producing high-quality, coherent video content, yet their slow inference speeds and high computational demands hinder practical deployment. Although both quantization and sparsity can independently accelerate inference while maintaining generation quality, naively combining these techniques in existing training-free approaches leads to significant performance degradation due to the lack of joint optimization. We introduce FPSAttention, a novel training-aware co-design of FP8 quantization and sparsity for video generation, with a focus on the 3D bi-directional attention mechanism. Our approach features three key innovations: 1) A unified 3D tile-wise granularity that simultaneously supports both quantization and sparsity; 2) A denoising step-aware strategy that adapts to the noise schedule, addressing the strong correlation between quantization/sparsity errors and denoising steps; 3) A native, hardware-friendly kernel that leverages FlashAttention and is implemented with optimized Hopper architecture features for highly efficient execution. Trained on Wan2.1's 1.3B and 14B models and evaluated on the VBench benchmark, FPSAttention achieves a 7.09x kernel speedup for attention operations and a 4.96x end-to-end speedup for video generation compared to the BF16 baseline at 720p resolution-without sacrificing generation quality.",
    "authors": [
      "Akide Liu, Zeyu Zhang, Zhexin Li, Xuehai Bai, Yizeng Han, Jiasheng Tang, Yuanjie Xing, Jichao Wu, Mingyang Yang, Weihua Chen, Jiahao He, Yuanyu He, Fan Wang, Gholamreza Haffari, Bohan Zhuang"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.841607"
  },
  {
    "id": "oai:arXiv.org:2506.04859v2",
    "journal": "arXiv_CS",
    "title": "Sparse Autoencoders, Again?",
    "link": "https://arxiv.org/abs/2506.04859",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.04859v2 Announce Type: replace \nAbstract: Is there really much more to say about sparse autoencoders (SAEs)? Autoencoders in general, and SAEs in particular, represent deep architectures that are capable of modeling low-dimensional latent structure in data. Such structure could reflect, among other things, correlation patterns in large language model activations, or complex natural image manifolds. And yet despite the wide-ranging applicability, there have been relatively few changes to SAEs beyond the original recipe from decades ago, namely, standard deep encoder/decoder layers trained with a classical/deterministic sparse regularizer applied within the latent space. One possible exception is the variational autoencoder (VAE), which adopts a stochastic encoder module capable of producing sparse representations when applied to manifold data. In this work we formalize underappreciated weaknesses with both canonical SAEs, as well as analogous VAEs applied to similar tasks, and propose a hybrid alternative model that circumvents these prior limitations. In terms of theoretical support, we prove that global minima of our proposed model recover certain forms of structured data spread across a union of manifolds. Meanwhile, empirical evaluations on synthetic and real-world datasets substantiate the efficacy of our approach in accurately estimating underlying manifold dimensions and producing sparser latent representations without compromising reconstruction error. In general, we are able to exceed the performance of equivalent-capacity SAEs and VAEs, as well as recent diffusion models where applicable, within domains such as images and language model activation patterns.",
    "authors": [
      "Yin Lu, Xuening Zhu, Tong He, David Wipf"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.841650"
  },
  {
    "id": "oai:arXiv.org:2506.05265v2",
    "journal": "arXiv_CS",
    "title": "Teaming in the AI Era: AI-Augmented Frameworks for Forming, Simulating, and Optimizing Human Teams",
    "link": "https://arxiv.org/abs/2506.05265",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05265v2 Announce Type: replace \nAbstract: Effective teamwork is essential across diverse domains. During the team formation stage, a key challenge is forming teams that effectively balance user preferences with task objectives to enhance overall team satisfaction. In the team performing stage, maintaining cohesion and engagement is critical for sustaining high team performance. However, existing computational tools and algorithms for team optimization often rely on static data inputs, narrow algorithmic objectives, or solutions tailored for specific contexts, failing to account for the dynamic interplay of team members personalities, evolving goals, and changing individual preferences. Therefore, teams may encounter member dissatisfaction, as purely algorithmic assignments can reduce members commitment to team goals or experience suboptimal engagement due to the absence of timely, personalized guidance to help members adjust their behaviors and interactions as team dynamics evolve. Ultimately, these challenges can lead to reduced overall team performance. My Ph.D. dissertation aims to develop AI-augmented team optimization frameworks and practical systems that enhance team satisfaction, engagement, and performance. First, I propose a team formation framework that leverages a multi-armed bandit algorithm to iteratively refine team composition based on user preferences, ensuring alignment between individual needs and collective team goals to enhance team satisfaction. Second, I introduce tAIfa (Team AI Feedback Assistant), an AI-powered system that utilizes large language models (LLMs) to deliver immediate, personalized feedback to both teams and individual members, enhancing cohesion and engagement. Finally, I present PuppeteerLLM, an LLM-based simulation framework that simulates multi-agent teams to model complex team dynamics within realistic environments, incorporating task-driven collaboration and long-term coordination.",
    "authors": [
      "Mohammed Almutairi"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.841736"
  },
  {
    "id": "oai:arXiv.org:2506.05318v2",
    "journal": "arXiv_CS",
    "title": "Does Your 3D Encoder Really Work? When Pretrain-SFT from 2D VLMs Meets 3D VLMs",
    "link": "https://arxiv.org/abs/2506.05318",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05318v2 Announce Type: replace \nAbstract: Remarkable progress in 2D Vision-Language Models (VLMs) has spurred interest in extending them to 3D settings for tasks like 3D Question Answering, Dense Captioning, and Visual Grounding. Unlike 2D VLMs that typically process images through an image encoder, 3D scenes, with their intricate spatial structures, allow for diverse model architectures. Based on their encoder design, this paper categorizes recent 3D VLMs into 3D object-centric, 2D image-based, and 3D scene-centric approaches. Despite the architectural similarity of 3D scene-centric VLMs to their 2D counterparts, they have exhibited comparatively lower performance compared with the latest 3D object-centric and 2D image-based approaches. To understand this gap, we conduct an in-depth analysis, revealing that 3D scene-centric VLMs show limited reliance on the 3D scene encoder, and the pre-train stage appears less effective than in 2D VLMs. Furthermore, we observe that data scaling benefits are less pronounced on larger datasets. Our investigation suggests that while these models possess cross-modal alignment capabilities, they tend to over-rely on linguistic cues and overfit to frequent answer distributions, thereby diminishing the effective utilization of the 3D encoder. To address these limitations and encourage genuine 3D scene understanding, we introduce a novel 3D Relevance Discrimination QA dataset designed to disrupt shortcut learning and improve 3D understanding. Our findings highlight the need for advanced evaluation and improved strategies for better 3D understanding in 3D VLMs.",
    "authors": [
      "Haoyuan Li, Yanpeng Zhou, Yufei Gao, Tao Tang, Jianhua Han, Yujie Yuan, Dave Zhenyu Chen, Jiawang Bian, Hang Xu, Xiaodan Liang"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.841753"
  },
  {
    "id": "oai:arXiv.org:2311.05116v4",
    "journal": "arXiv_CS",
    "title": "Covering Number of Real Algebraic Varieties and Beyond: Improved Bounds and Applications",
    "link": "https://arxiv.org/abs/2311.05116",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2311.05116v4 Announce Type: replace-cross \nAbstract: Covering numbers are a powerful tool used in the development of approximation algorithms, randomized dimension reduction methods, smoothed complexity analysis, and others. In this paper we prove upper bounds on the covering number of numerous sets in Euclidean space, namely real algebraic varieties, images of polynomial maps and semialgebraic sets in terms of the number of variables and degrees of the polynomials involved. The bounds remarkably improve the best known general bound by Yomdin-Comte, and our proof is much more straightforward. In particular, our result gives new bounds on the volume of the tubular neighborhood of the image of a polynomial map and a semialgebraic set, where results for varieties by Lotz and Basu-Lerario are not directly applicable. We illustrate the power of the result on three computational applications. Firstly, we derive a near-optimal bound on the covering number of tensors with low canonical polyadic (CP) rank, quantifying their approximation properties and filling in an important missing piece of theory for tensor dimension reduction and reconstruction. Secondly, we prove a bound on dimensionality reduction of images of polynomial maps via randomized sketching, which has direct applications to large scale polynomial optimization. Finally, we deduce generalization error bounds for deep neural networks with rational or ReLU activation functions, improving or matching the best known results in the machine learning literature while helping to quantify the impact of architecture choice on generalization error.",
    "authors": [
      "Yifan Zhang, Joe Kileel"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.841846"
  },
  {
    "id": "oai:arXiv.org:2402.16190v2",
    "journal": "arXiv_CS",
    "title": "Accurate and efficient predictions of keyhole dynamics in laser materials processing using machine learning-aided simulations",
    "link": "https://arxiv.org/abs/2402.16190",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2402.16190v2 Announce Type: replace-cross \nAbstract: The keyhole phenomenon has been widely observed in laser materials processing, including laser welding, remelting, cladding, drilling, and additive manufacturing. Keyhole-induced defects, primarily pores, dramatically affect the performance of final products, impeding the broad use of these laser-based technologies. The formation of these pores is typically associated with the dynamic behavior of the keyhole. So far, the accurate characterization and prediction of keyhole features, particularly keyhole depth, as a function of time, has been a challenging task. In situ characterization of keyhole dynamic behavior using the synchrotron X-ray technique is informative but complicated and expensive. Current simulations are generally hindered by their poor accuracy and generalization abilities in predicting keyhole depths due to the lack of accurate laser absorptance data. In this study, we develop a machine learning-aided simulation method that accurately predicts keyhole dynamics, especially in keyhole depth fluctuations, over a wide range of processing parameters. In two case studies involving titanium and aluminum alloys, we achieve keyhole depth prediction with a mean absolute percentage error of 10%, surpassing those simulated using the ray-tracing method with an error margin of 30%, while also reducing computational time. This exceptional fidelity and efficiency empower our model to serve as a cost-effective alternative to synchrotron experiments. Our machine learning-aided simulation method is affordable and readily deployable for a large variety of materials, opening new doors to eliminate or reduce defects for a wide range of laser materials processing techniques.",
    "authors": [
      "Jiahui Zhang, Runbo Jiang, Kangming Li, Pengyu Chen, Shengbo Bi, Xiao Shang, Zhiying Liu, Jason Hattrick-Simpers, Brian J. Simonds, Qianglong Wei, Hongze Wang, Tao Sun, Anthony D. Rollett, Yu Zou"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.841863"
  },
  {
    "id": "oai:arXiv.org:2411.00082v2",
    "journal": "arXiv_CS",
    "title": "Testing and learning structured quantum Hamiltonians",
    "link": "https://arxiv.org/abs/2411.00082",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2411.00082v2 Announce Type: replace-cross \nAbstract: We consider the problems of testing and learning an unknown $n$-qubit Hamiltonian $H$ from queries to its evolution operator $e^{-iHt}$ under the normalized Frobenius norm. We prove:\n  1. Local Hamiltonians: We give a tolerant testing protocol to decide if $H$ is $\\epsilon_1$-close to $k$-local or $\\epsilon_2$-far from $k$-local, with $O(1/(\\epsilon_2-\\epsilon_1)^{4})$ queries, solving open questions posed in a recent work by Bluhm et al. For learning a $k$-local $H$ up to error $\\epsilon$, we give a protocol with query complexity $\\exp(O(k^2+k\\log(1/\\epsilon)))$ independent of $n$, by leveraging the non-commutative Bohnenblust-Hille inequality.\n  2. Sparse Hamiltonians: We give a protocol to test if $H$ is $\\epsilon_1$-close to being $s$-sparse (in the Pauli basis) or $\\epsilon_2$-far from being $s$-sparse, with $O(s^{6}/(\\epsilon_2^2-\\epsilon_1^2)^{6})$ queries. For learning up to error $\\epsilon$, we show that $O(s^{4}/\\epsilon^{8})$ queries suffice.\n  3. Learning without memory: The learning results stated above have no dependence on $n$, but require $n$-qubit quantum memory. We give subroutines that allow us to learn without memory; increasing the query complexity by a $(\\log n)$-factor in the local case and an $n$-factor in the sparse case.\n  4. Testing without memory: We give a new subroutine called Pauli hashing, which allows one to tolerantly test $s$-sparse Hamiltonians with $O(s^{14}/(\\epsilon_2^2-\\epsilon_1^2)^{18})$ queries. A key ingredient is showing that $s$-sparse Pauli channels can be tolerantly tested under the diamond norm with $O(s^2/(\\epsilon_2-\\epsilon_1)^6)$ queries.\n  Along the way, we prove new structural theorems for local and sparse Hamiltonians. We complement our learning results with polynomially weaker lower bounds. Furthermore, our algorithms use short time evolutions and do not assume prior knowledge of the terms in the support of the Pauli spectrum.",
    "authors": [
      "Srinivasan Arunachalam, Arkopal Dutt, Francisco Escudero Guti\\'errez"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.841958"
  },
  {
    "id": "oai:arXiv.org:2412.12558v3",
    "journal": "arXiv_CS",
    "title": "The Jacobi Factoring Circuit: Quantum Factoring with Near-Linear Gates and Sublinear Space and Depth",
    "link": "https://arxiv.org/abs/2412.12558",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2412.12558v3 Announce Type: replace-cross \nAbstract: We present a compact quantum circuit for factoring a large class of integers, including some whose classical hardness is expected to be equivalent to RSA (but not including RSA integers themselves). Most notably, we factor $n$-bit integers of the form $P^2 Q$ with $\\log Q = \\Theta(n^a)$ for $a \\in (2/3, 1)$ in space and depth sublinear in n (specifically, $\\tilde{O}(\\log Q)$) using $\\tilde{O}(n)$ quantum gates; for these integers, no known classical algorithms exploit the relatively small size of $Q$ to run asymptotically faster than general-purpose factoring algorithms. To our knowledge, this is the first polynomial-time circuit to achieve sublinear qubit count for a classically-hard factoring problem. We thus believe that factoring such numbers has potential to be the most concretely efficient classically-verifiable proof of quantumness currently known.\n  Our circuit builds on the quantum algorithm for squarefree decomposition discovered by Li, Peng, Du, and Suter (Nature Scientific Reports 2012), which relies on computing the Jacobi symbol in quantum superposition. The technical core of our contribution is a new space-efficient quantum algorithm to compute the Jacobi symbol of $A$ mod $B$, in the regime where $B$ is classical and much larger than $A$. Our circuit for computing the Jacobi symbol generalizes to related problems such as computing the greatest common divisor and modular inverses, and thus could be of independent interest.",
    "authors": [
      "Gregory D. Kahanamoku-Meyer, Seyoon Ragavan, Vinod Vaikuntanathan, Katherine Van Kirk"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.842001"
  },
  {
    "id": "oai:arXiv.org:2412.18624v3",
    "journal": "arXiv_CS",
    "title": "How to explain grokking",
    "link": "https://arxiv.org/abs/2412.18624",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2412.18624v3 Announce Type: replace-cross \nAbstract: Explanation of grokking (delayed generalization) in learning is given by modeling grokking by the stochastic gradient Langevin dynamics (Brownian motion) and applying the ideas of thermodynamics.",
    "authors": [
      "S. V. Kozyrev"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.842017"
  },
  {
    "id": "oai:arXiv.org:2502.02472v2",
    "journal": "arXiv_CS",
    "title": "SDE Matching: Scalable and Simulation-Free Training of Latent Stochastic Differential Equations",
    "link": "https://arxiv.org/abs/2502.02472",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2502.02472v2 Announce Type: replace-cross \nAbstract: The Latent Stochastic Differential Equation (SDE) is a powerful tool for time series and sequence modeling. However, training Latent SDEs typically relies on adjoint sensitivity methods, which depend on simulation and backpropagation through approximate SDE solutions, which limit scalability. In this work, we propose SDE Matching, a new simulation-free method for training Latent SDEs. Inspired by modern Score- and Flow Matching algorithms for learning generative dynamics, we extend these ideas to the domain of stochastic dynamics for time series and sequence modeling, eliminating the need for costly numerical simulations. Our results demonstrate that SDE Matching achieves performance comparable to adjoint sensitivity methods while drastically reducing computational complexity.",
    "authors": [
      "Grigory Bartosh, Dmitry Vetrov, Christian A. Naesseth"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.842024"
  },
  {
    "id": "oai:arXiv.org:2505.22142v2",
    "journal": "arXiv_CS",
    "title": "Interpolation of Quantum Polar Codes and Quantum Reed-Muller Codes",
    "link": "https://arxiv.org/abs/2505.22142",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2505.22142v2 Announce Type: replace-cross \nAbstract: Good quantum error-correcting codes that fulfill practical considerations, such as simple encoding circuits and efficient decoders, are essential for functional quantum information processing systems. Quantum polar codes satisfy some of these requirements but lack certain critical features, thereby hindering their widespread use. Existing constructions either require entanglement assistance to produce valid quantum codes, suffer from poor finite-size performance, or fail to tailor polar codes to the underlying channel properties. Meanwhile, quantum Reed-Muller (RM) codes demonstrate strong performance, though no known efficient decoding algorithm exists for them. In this work, we propose strategies to interpolate between quantum polar codes and quantum RM codes, thus addressing the challenges of designing valid quantum polar codes without entanglement assistance and improving finite-size code performance.",
    "authors": [
      "Keita Hidaka, Dina Abdelhadi, Ruediger Urbanke"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.842162"
  },
  {
    "id": "oai:arXiv.org:2506.04107v2",
    "journal": "arXiv_CS",
    "title": "Risk and Reward of Transitioning from a National to a Zonal Electricity Market in Great Britain",
    "link": "https://arxiv.org/abs/2506.04107",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.04107v2 Announce Type: replace-cross \nAbstract: More spatially granular electricity wholesale markets promise more efficient operation and better asset siting in highly renewable power systems. Great Britain is considering moving from its current single-price national wholesale market to a zonal design. Existing studies reach varying and difficult-to-reconcile conclusions about the desirability of a zonal market in GB, partly because they rely on models that vary in their transparency and assumptions about future power systems. Using a novel open-source electricity market model, calibrated to match observed network behaviour, this article quantifies consumer savings, unit-level producer surplus impacts, and broader socioeconomic benefits that would have arisen had a six-zone market operated in Great Britain during 2022-2024. In the absence of mitigating policies, it is estimated that during those three years GB consumers would save approximately {\\pounds}9.4/MWh (equalling an average of more than {\\pounds}2.3B per year), but generators in northern regions would experience revenue reductions of 30-40\\%. Policy interventions can restore these units' national market revenues to up to 97\\% while still preserving around {\\pounds}3.1/MWh in consumer savings (about {\\pounds}750M per year). It is further estimated that the current system could achieve approximately {\\pounds}380-{\\pounds}770 million in annual welfare gain during 2022-2024 through improved operational efficiency alone. The drivers behind these benefits, notably wind curtailment volumes, are expected to become more pronounced towards 2030, suggesting that purely operationally achieved annual benefits of around {\\pounds}1-2 billion beyond 2029 are likely. It is found that the scale of these benefits would outweigh the potential downsides related to increases in the cost of capital that have been estimated elsewhere.",
    "authors": [
      "Lukas Franken, Andrew Lyden, Daniel Friedrich"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.842198"
  },
  {
    "id": "oai:arXiv.org:2506.04891v2",
    "journal": "arXiv_CS",
    "title": "TQml Simulator: Optimized Simulation of Quantum Machine Learning",
    "link": "https://arxiv.org/abs/2506.04891",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.04891v2 Announce Type: replace-cross \nAbstract: Hardware-efficient circuits employed in Quantum Machine Learning are typically composed of alternating layers of uniformly applied gates. High-speed numerical simulators for such circuits are crucial for advancing research in this field. In this work, we numerically benchmark universal and gate-specific techniques for simulating the action of layers of gates on quantum state vectors, aiming to accelerate the overall simulation of Quantum Machine Learning algorithms. Our analysis shows that the optimal simulation method for a given layer of gates depends on the number of qubits involved, and that a tailored combination of techniques can yield substantial performance gains in the forward and backward passes for a given circuit. Building on these insights, we developed a numerical simulator, named TQml Simulator, that employs the most efficient simulation method for each layer in a given circuit. We evaluated TQml Simulator on circuits constructed from standard gate sets, such as rotations and CNOTs, as well as on native gates from IonQ and IBM quantum processing units. In most cases, our simulator outperforms equivalent Pennylane's default_qubit simulator by up to a factor of 10, depending on the circuit, the number of qubits, the batch size of the input data, and the hardware used.",
    "authors": [
      "Viacheslav Kuzmin, Basil Kyriacou, Mateusz Papierz, Mo Kordzanganeh, Alexey Melnikov"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.842205"
  },
  {
    "id": "https://www.nature.com/articles/s41540-025-00536-8",
    "journal": "Nature_SystemsBiology",
    "title": "Assessment of plasma derived microbiome profiles in lung cancer using targeted and whole exome sequencing",
    "link": "https://www.nature.com/articles/s41540-025-00536-8",
    "published": "2025-06-07T00:00:00+00:00",
    "summary": "",
    "authors": [
      "Vichitra Behel et al."
    ],
    "doi": "",
    "parser_type": "nature",
    "feed_priority": "high",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.842221"
  },
  {
    "id": "https://www.nature.com/articles/s41540-025-00541-x",
    "journal": "Nature_SystemsBiology",
    "title": "Changes in epistatic green-beard alleles induce domain shift in hypostatic rock-paper-scissors-like green-beard competition",
    "link": "https://www.nature.com/articles/s41540-025-00541-x",
    "published": "2025-06-07T00:00:00+00:00",
    "summary": "",
    "authors": [
      "Jibeom Choi"
    ],
    "doi": "",
    "parser_type": "nature",
    "feed_priority": "high",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.842229"
  },
  {
    "id": "https://www.nature.com/articles/s41467-025-60441-w",
    "journal": "Nature_SystemsBiology",
    "title": "Single cell profiling of human airway identifies tuft-ionocyte progenitor cells displaying cytokine-dependent differentiation bias in vitro",
    "link": "https://www.nature.com/articles/s41467-025-60441-w",
    "published": "2025-06-04T00:00:00+00:00",
    "summary": "",
    "authors": [
      "Viral S. Shah et al."
    ],
    "doi": "",
    "parser_type": "nature",
    "feed_priority": "high",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.842272"
  },
  {
    "id": "https://www.nature.com/articles/s41589-025-01922-3",
    "journal": "Nature_SystemsBiology",
    "title": "Programmable RNA acetylation with CRISPR–Cas13",
    "link": "https://www.nature.com/articles/s41589-025-01922-3",
    "published": "2025-06-02T00:00:00+00:00",
    "summary": "",
    "authors": [
      "Jihwan Yu et al."
    ],
    "doi": "",
    "parser_type": "nature",
    "feed_priority": "high",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.842311"
  },
  {
    "id": "https://www.nature.com/articles/s41586-025-09053-4",
    "journal": "Nature_SystemsBiology",
    "title": "Cross-tissue multicellular coordination and its rewiring in cancer",
    "link": "https://www.nature.com/articles/s41586-025-09053-4",
    "published": "2025-05-28T00:00:00+00:00",
    "summary": "",
    "authors": [
      "Qiang Shi et al."
    ],
    "doi": "",
    "parser_type": "nature",
    "feed_priority": "high",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.842372"
  },
  {
    "id": "https://www.nature.com/articles/s41598-025-03547-x",
    "journal": "Nature_SystemsBiology",
    "title": "Genetic variability, correlation and path coefficient analysis of phenotypic traits and genetic diversity of Aman rice landraces (Oryza sativa L.)",
    "link": "https://www.nature.com/articles/s41598-025-03547-x",
    "published": "2025-05-28T00:00:00+00:00",
    "summary": "",
    "authors": [
      "Mohammad Zahidul Islam et al."
    ],
    "doi": "",
    "parser_type": "nature",
    "feed_priority": "high",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.842389"
  },
  {
    "id": "https://www.nature.com/articles/s41467-025-59227-x",
    "journal": "Nature_SystemsBiology",
    "title": "A machine learning and centrifugal microfluidics platform for bedside prediction of sepsis",
    "link": "https://www.nature.com/articles/s41467-025-59227-x",
    "published": "2025-05-27T00:00:00+00:00",
    "summary": "",
    "authors": [
      "Lidija Malic et al."
    ],
    "doi": "",
    "parser_type": "nature",
    "feed_priority": "high",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.842425"
  },
  {
    "id": "https://www.nature.com/articles/s41467-025-60004-z",
    "journal": "Nature_SystemsBiology",
    "title": "Spatiotemporal development of expanding bacterial colonies driven by emergent mechanical constraints and nutrient gradients",
    "link": "https://www.nature.com/articles/s41467-025-60004-z",
    "published": "2025-05-26T00:00:00+00:00",
    "summary": "",
    "authors": [
      "Harish Kannan et al."
    ],
    "doi": "",
    "parser_type": "nature",
    "feed_priority": "high",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:37:16.842454"
  },
  {
    "id": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00493-0?rss=yes",
    "journal": "Cell_Reports",
    "title": "MYC plus class IIa HDAC inhibition drives mitochondrial dysfunction in non-small cell lung cancer",
    "link": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00493-0?rss=yes",
    "published": "",
    "summary": "Park et al. define a combination MYC and class IIa HDAC inhibition paradigm that has efficacy in NSCLC with high MYC and mitochondrial activity. Therapeutic benefit is dependent on MYC suppression and mitochondrial ROS production. In vivo activity is confirmed across multiple animal models of NSCLC.",
    "authors": [
      "Jina Park, Ying-Yu Chen, Jennie J. Cao, Julia An, Ray-Whay Chiu Yen, John D. Outen, Stephen B. Baylin, Michael J. Topper"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:39:59.492568"
  },
  {
    "id": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00550-9?rss=yes",
    "journal": "Cell_Reports",
    "title": "BCL2 drives castration resistance in castration-sensitive prostate cancer by orchestrating reciprocal crosstalk between oncogenic pathways",
    "link": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00550-9?rss=yes",
    "published": "",
    "summary": "Hirani et al. show how androgen-deprivation therapy (ADT)-induced crosstalk between oncogenic cell signaling pathways, driven by BCL2, contributes to castration-resistant prostate cancer (CRPC). This finding underscores the potential of BCL2-targeted combination therapeutics to block or delay the transition from castration-sensitive prostate cancer to CRPC induced by ADT.",
    "authors": [
      "Rahim Hirani, Subhiksha Nandakumar, Nabila Zaman, Prathiksha Prabhakaraalva, Sarah Ann King, Teja Muralidhar Kalidindi, Romina Ghale, Sai Harisha Rajanala, Deborah C. Fidele, Elisa De Stanchina, Gwo-Shu Mary Lee, Mary Ellen Taplin, Steven P. Balk, Adam G. Sowalsky, Michael J. Morris, Naga Vara Kishore Pillarsetty, Konrad H. Stopsack, Anuradha Gopalan, Lorelei A. Mucci, Natasha Kyprianou, Ashutosh K. Tewari, Daniel Danila, Philip W. Kantoff, Goutam Chakraborty"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:39:59.492602"
  },
  {
    "id": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00563-7?rss=yes",
    "journal": "Cell_Reports",
    "title": "Cholesterol metabolism regulated by CAMKK2-CREB signaling promotes castration-resistant prostate cancer",
    "link": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00563-7?rss=yes",
    "published": "",
    "summary": "Sustained androgen receptor (AR) inhibition is a clinical challenge due to multiple AR reactivation mechanisms. Hence, delineating the signaling pathways downstream of AR that promote cancer progression may nominate novel, alternative therapeutic targets. Lin et al. identify CAMKI-CREB-mediated cholesterol metabolism as an alternative, AMPK-independent, and druggable pathway mediating AR-CAMKK2-driven CRPC.",
    "authors": [
      "Chenchu Lin, Thomas L. Pulliam, Jenny J. Han, Jiaqian Xu, Carlos Vera Recio, Sandi R. Wilkenfeld, Yan Shi, Manoj Kushwaha, Sarah Bench, Eduardo Ruiz, Sanjanaa Senthilkumar, Jayasurya Dileep, Peter D.A. Shepherd, Nora M. Navone, Albert R. Klekers, Elizabeth M. Whitley, Michael M. Ittmann, Livia S. Eberlin, Wenyi Wang, Daniel E. Frigo"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:39:59.492610"
  },
  {
    "id": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00575-3?rss=yes",
    "journal": "Cell_Reports",
    "title": "Cell death and cancer: Metabolic interconnections",
    "link": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00575-3?rss=yes",
    "published": "",
    "summary": "Recent research explores how metabolism influences cell death pathways (apoptosis, necroptosis, pyroptosis, and ferroptosis) in cancer. Dalseno et al. examine BCL-2 family regulation, oncometabolites, and their role in treatment resistance and tumor survival, emphasizing the critical intersection of metabolic and cell death processes in cancer progression.",
    "authors": [
      "Destiny Dalseno, Nikolai Gajic, Lyndsey Flanagan, Stephen W.G. Tait"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:39:59.492628"
  },
  {
    "id": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00552-2?rss=yes",
    "journal": "Cell_Reports",
    "title": "Single-nucleus profiling of mouse inner ear aging uncovers cell type heterogeneity and hair cell subtype-specific age-related signatures",
    "link": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00552-2?rss=yes",
    "published": "",
    "summary": "Xia et al. reveals cell type-specific transcriptional landscapes underlying inner ear aging by single-nucleus RNA sequencing. Age-related transcriptional alterations in hair cell subtypes and activation of macrophages in the aged inner ear were delineated. These findings propose potential therapeutic targets to mitigate age-associated auditory and vestibular degeneration.",
    "authors": [
      "Mingyu Xia, Feng Zhang, Jiaoyao Ma, Yunjie Li, Gaogan Jia, Mingxuan Wu, Yiyun Lou, Yaoqian Liu, Lingjie Li, Huawei Li, Wenyan Li"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:39:59.492636"
  },
  {
    "id": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00516-9?rss=yes",
    "journal": "Cell_Reports",
    "title": "Heterologous prime-boost with an mRNA vaccine and an oncolytic virus enhances tumor regression through overcoming intratumoral immune suppression",
    "link": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00516-9?rss=yes",
    "published": "",
    "summary": "Zhang et al. demonstrate that oncolytic virus (OV) therapy and mRNA vaccines induce distinct immune responses, with OV primarily enhancing the tumor microenvironment and mRNA vaccines promoting systemic T cell immunity. Their combination achieves superior therapeutic efficacy, highlighting the importance of antigen expression and immune modulation in cancer immunotherapy.",
    "authors": [
      "Kuan Zhang, Dong Zuo, Zhenglong Wang, Jun Ding, Jiang Xu, Yin Liu, Yu Zhong, William Jia"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:39:59.492716"
  },
  {
    "id": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00531-5?rss=yes",
    "journal": "Cell_Reports",
    "title": "Designed miniproteins potently inhibit and protect against MERS-CoV",
    "link": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00531-5?rss=yes",
    "published": "",
    "summary": "Ragotte et al. de novo designed potent inhibitors of MERS-CoV. These homotrimeric molecules engage multiple copies of the MERS-CoV RBD on the spike protein to block engagement with host receptor DPP4, neutralize diverse MERS-CoV strains, and prophylactically protect against MERS-CoV disease in vivo when administered intranasally.",
    "authors": [
      "Robert J. Ragotte, M. Alejandra Tortorici, Nicholas J. Catanzaro, Amin Addetia, Brian Coventry, Heather M. Froggatt, Jimin Lee, Cameron Stewart, Jack T. Brown, Inna Goreshnik, Jeremiah N. Sims, Lukas F. Milles, Basile I.M. Wicky, Matthias Glögl, Stacey Gerben, Alex Kang, Asim K. Bera, William Sharkey, Alexandra Schäfer, Jack R. Harkema, Ralph S. Baric, David Baker, David Veesler"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:39:59.492765"
  },
  {
    "id": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00520-0?rss=yes",
    "journal": "Cell_Reports",
    "title": "Microglial STING is a central safeguard against neurological decline with age",
    "link": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00520-0?rss=yes",
    "published": "",
    "summary": "Immune pathways and cell types that protect against neurodegenerative processes with aging remain poorly understood. Sulka et al. demonstrate that the innate immune adaptor, STING, provides essential protection against blood-brain barrier breaches and neuromotor deficits during physiological aging. Furthermore, microglial STING is sufficient to protect against these aspects of age-associated decline.",
    "authors": [
      "Katherine B. Sulka, Kimberly A. Carroll, Machlan Sawden, Jacob W. Hopkins, Sasha A. Smolgovsky, Abraham L. Bayer, Eric Reed, Albert Tai, Pilar Alcaide, Philip Haydon, Shruti Sharma"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:39:59.492773"
  },
  {
    "id": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00570-4?rss=yes",
    "journal": "Cell_Reports",
    "title": "The glycolytic reaction PGAM restrains Th17 pathogenicity and Th17-dependent autoimmunity",
    "link": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00570-4?rss=yes",
    "published": "",
    "summary": "Wang et al. identify phosphoglycerate mutase (PGAM) as a negative regulator of pathogenic Th17 cell differentiation, contrary to other glycolytic enzymes. PGAM inhibition suppresses a regulatory program in non-pathogenic Th17 cells. Inhibiting PGAM in Th17 cells exacerbates autoimmune responses in an adoptive transfer model of experimental autoimmune encephalomyelitis (EAE).",
    "authors": [
      "Chao Wang, Allon Wagner, Johannes Fessler, David DeTomaso, Sarah Zaghouani, Yulin Zhou, Kerry Pierce, Raymond A. Sobel, Clary Clish, Nir Yosef, Vijay K. Kuchroo"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:39:59.492808"
  },
  {
    "id": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00557-1?rss=yes",
    "journal": "Cell_Reports",
    "title": "Lipid-coated nanoparticles enhance the delivery of bacterial virulence factors as a potent toxoid vaccine platform against bacterial infections",
    "link": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00557-1?rss=yes",
    "published": "",
    "summary": "Zhuge et al. demonstrate that a toxoid vaccine platform based on phosphatidylcholine/sphingomyelin (PS)-hybridized lipids provides a broadly effective antivirulence vaccination strategy against diverse bacterial infections in both mouse and pig models.",
    "authors": [
      "Deli Zhuge, Yingnan Xiao, Yunxuan Huang, Yutong Zhong, Xueying Sun, Jing Wu, Shuangshuang Liu, Hui Liang, Weian Mao, Yuan Yang, Yijing Lin, Haonan Wang, Xuewei Yang, Xufei Zhang, Wenjie Sun, Caixia Liu, Yingzheng Zhao, Mengchun Chen, Yijie Chen"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:39:59.492932"
  },
  {
    "id": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00508-X?rss=yes",
    "journal": "Cell_Reports",
    "title": "ADP-ribosylation of NuMA promotes DNA single-strand break repair and transcription",
    "link": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00508-X?rss=yes",
    "published": "",
    "summary": "Abugable et al. investigated the role of ADP-ribosylation in NuMA function during DNA repair. They demonstrate that ADP-ribosylation-deficient NuMA impairs repair kinetics and transcription and fails to protect selected gene regulatory elements from oxidative DNA breaks. This highlights the importance of ADP-ribosylation of NuMA in regulating transcription and DNA repair.",
    "authors": [
      "Arwa A. Abugable, Chunyan Liao, Sarah Antar, Matthew Dowson, Sherif F. El-Khamisy"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:39:59.492953"
  },
  {
    "id": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00510-8?rss=yes",
    "journal": "Cell_Reports",
    "title": "USP37 protects mammalian cells during DNA replication stress by counteracting CUL2LRR1 and TRAIP",
    "link": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00510-8?rss=yes",
    "published": "",
    "summary": "Villa et al. show that the USP37 deubiquitylase is tethered to the CMG helicase at DNA replication forks in mammalian cells. USP37 protects cells during DNA replication stress by counteracting two replisome-coupled ubiquitin ligases. USP37 counteracts CUL2LRR1 during DNA synthesis defects and opposes TRAIP in response to topological stress.",
    "authors": [
      "Fabrizio Villa, Johanna Ainsworth, Karim P.M. Labib"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:39:59.493020"
  },
  {
    "id": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00537-6?rss=yes",
    "journal": "Cell_Reports",
    "title": "Coiled-coil-domain-mediated TRIM E3 protein condensation modulates enzymatic activity and functional specificity",
    "link": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00537-6?rss=yes",
    "published": "",
    "summary": "Qi Chen et al. systematically characterized human TRIM family proteins, revealing widespread condensate and specific co-condensate formation. Multivalent interactions across TRIM proteins, mainly involving the coiled-coil domain, lead to condensate formation. TRIM condensates could modulate E3 ligase activity and regulate cilia assembly and microtubule stability.",
    "authors": [
      "Qi Chen, Peiguo Yang"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:39:59.493087"
  },
  {
    "id": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00566-2?rss=yes",
    "journal": "Cell_Reports",
    "title": "Widespread and cell-type-specific transcriptomic reorganization following mild traumatic brain injury",
    "link": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00566-2?rss=yes",
    "published": "",
    "summary": "Swaro et al. use spatial transcriptomics to investigate cell-type-specific dysregulation following TBI. TBI-associated changes are found at both broad spatial scales and within specific brain regions and cell types. These findings deconstruct the multiscale complexity of TBI and will aid future studies through a public web portal.",
    "authors": [
      "Aditya Swaro, Brianna N. Bristow, Mehwish Anwer, Angela A. Zhang, Larissa Kraus, Riya K. Gandhi, Sarah R. Erwin, Tara R. Stach, Kaitlin E. Sullivan, Jianjia Fan, Wai Hang Cheng, Cheryl L. Wellington, Mark S. Cembrowski"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:39:59.493239"
  },
  {
    "id": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00500-5?rss=yes",
    "journal": "Cell_Reports",
    "title": "Regulation of the non-selective Na+ importer capacity of NRT1.2/NPF4.6/AIT1 by SOS2-mediated phosphorylation in Arabidopsis",
    "link": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00500-5?rss=yes",
    "published": "",
    "summary": "Liu et al. demonstrate that NRT1.2/NPF4.6/AIT1 functions as a non-selective, low-pH-dependent and nitrate-promoted Na+ importer whose activity is attenuated during salt stress through SOS2-mediated phosphorylation at Thr248.",
    "authors": [
      "Xiaoxiao Liu, Lei Zhang, Zeqi Zhao, Yue Zheng, Yue Ren, Xiaomin Zhao, Shizhong Zhang, Guodong Yang, Jinguang Huang, Kang Yan, Chunlong Li, Chengchao Zheng, Changai Wu"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:39:59.493246"
  },
  {
    "id": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00604-7?rss=yes",
    "journal": "Cell_Reports",
    "title": "Loss of HDAC-Mediated Repression and Gain of NF-κB Activation Underlie Cytokine Induction in ARID1A- and PIK3CA-Mutation-Driven Ovarian Cancer",
    "link": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00604-7?rss=yes",
    "published": "",
    "summary": "(Cell Reports 17, 275–288; September 27, 2016)",
    "authors": [
      "Minchul Kim, Falong Lu, Yi Zhang"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:39:59.493372"
  },
  {
    "id": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00640-0?rss=yes",
    "journal": "Cell_Reports",
    "title": "Selective Vulnerability of Cancer Cells by Inhibition of Ca2+ Transfer from Endoplasmic Reticulum to Mitochondria",
    "link": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00640-0?rss=yes",
    "published": "",
    "summary": "(Cell Reports 14, 2313–2324; March 15, 2016)",
    "authors": [
      "César Cárdenas, Marioly Müller, Andrew McNeal, Alenka Lovy, Fabian Jaňa, Galdo Bustos, Felix Urra, Natalia Smith, Jordi Molgó, J. Alan Diehl, Todd W. Ridky, J. Kevin Foskett"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:39:59.493389"
  },
  {
    "id": "https://www.cell.com/cell-stem-cell/fulltext/S1934-5909(25)00190-0?rss=yes",
    "journal": "Cell_StemCell",
    "title": "Breathing new life into donor lungs: Theranostic methodology for organ repair",
    "link": "https://www.cell.com/cell-stem-cell/fulltext/S1934-5909(25)00190-0?rss=yes",
    "published": "",
    "summary": "Recently in Med, Pinezich et al. present a therapeutic and diagnostic (“theranostic”) cross-circulation platform that enables prolonged, real-time rehabilitation of injured donor lungs ex vivo. Their approach integrating systemic support, advanced diagnostics, and targeted therapies promises to expand the donor lung pool and transform lung transplantation with personalized organ care.",
    "authors": [
      "Emilija Jovanovic, Fotios Sampaziotis"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:39:59.493434"
  },
  {
    "id": "https://www.cell.com/cell-stem-cell/fulltext/S1934-5909(25)00083-9?rss=yes",
    "journal": "Cell_StemCell",
    "title": "Self-organization of mouse embryonic stem cells into reproducible pre-gastrulation embryo models via CRISPRa programming",
    "link": "https://www.cell.com/cell-stem-cell/fulltext/S1934-5909(25)00083-9?rss=yes",
    "published": "",
    "summary": "Lodewijk et al. develop a CRISPRa-programmed embryo model using mouse pluripotent cells. By introducing controllable CRISPR activation tools into pluripotent cells, they enabled the efficient generation of a reproducible model. These tools were also used to disrupt developmental pathways, offering a method to study mechanisms of developmental disorders.",
    "authors": [
      "Gerrald A. Lodewijk, Sayaka Kozuki, Clara J. Han, Benjamin R. Topacio, Seungho Lee, Lily Nixon, Abolfazl Zargari, Gavin Knight, Randolph Ashton, Lei S. Qi, S. Ali Shariati"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:39:59.493471"
  },
  {
    "id": "https://www.cell.com/cell-stem-cell/fulltext/S1934-5909(25)00141-9?rss=yes",
    "journal": "Cell_StemCell",
    "title": "Specification of human brain regions with orthogonal gradients of WNT and SHH in organoids reveals patterning variations across cell lines",
    "link": "https://www.cell.com/cell-stem-cell/fulltext/S1934-5909(25)00141-9?rss=yes",
    "published": "",
    "summary": "Vaccarino and colleagues show that simultaneous orthogonal gradients of posteriorizing and ventralizing morphogens trigger gene regulatory programs in human stem cells, recreating forebrain, midbrain, and hindbrain neuronal lineages with distinct functional network activity. Different stem cell lines were hypo- or hypersensitive to morphogen patterning due to line-specific and donor-specific factors.",
    "authors": [
      "Soraya Scuderi, Tae-Yun Kang, Alexandre Jourdon, Alex Nelson, Liang Yang, Feinan Wu, George M. Anderson, Jessica Mariani, Livia Tomasini, Vivekananda Sarangi, Alexej Abyzov, Andre Levchenko, Flora M. Vaccarino"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:39:59.493505"
  },
  {
    "id": "https://www.nature.com/articles/s42003-025-08205-6",
    "journal": "Nature_CompBio",
    "title": "Development of an AI model for DILI-level prediction using liver organoid brightfield images",
    "link": "https://www.nature.com/articles/s42003-025-08205-6",
    "published": "2025-06-07T00:00:00+00:00",
    "summary": "",
    "authors": [
      "Shiyi Tan et al."
    ],
    "doi": "",
    "parser_type": "nature",
    "feed_priority": "high",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:39:59.493579"
  },
  {
    "id": "https://www.nature.com/articles/s41698-025-00940-7",
    "journal": "Nature_CompBio",
    "title": "Systematic scoping review of external validation studies of AI pathology models for lung cancer diagnosis",
    "link": "https://www.nature.com/articles/s41698-025-00940-7",
    "published": "2025-06-07T00:00:00+00:00",
    "summary": "",
    "authors": [
      "Soumya Arun et al."
    ],
    "doi": "",
    "parser_type": "nature",
    "feed_priority": "high",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:39:59.493587"
  },
  {
    "id": "https://www.nature.com/articles/s42003-025-08313-3",
    "journal": "Nature_CompBio",
    "title": "Predicting bacterial phenotypic traits through improved machine learning using high-quality, curated datasets",
    "link": "https://www.nature.com/articles/s42003-025-08313-3",
    "published": "2025-06-07T00:00:00+00:00",
    "summary": "",
    "authors": [
      "Julia Koblitz et al."
    ],
    "doi": "",
    "parser_type": "nature",
    "feed_priority": "high",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:39:59.493599"
  },
  {
    "id": "https://www.nature.com/articles/s41598-025-03704-2",
    "journal": "Nature_CompBio",
    "title": "The value of intratumoral and peritumoral ultrasound radiomics model constructed using multiple machine learning algorithms for non-mass breast cancer",
    "link": "https://www.nature.com/articles/s41598-025-03704-2",
    "published": "2025-06-06T00:00:00+00:00",
    "summary": "",
    "authors": [
      "Jinhui Liu et al."
    ],
    "doi": "",
    "parser_type": "nature",
    "feed_priority": "high",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:39:59.493618"
  },
  {
    "id": "https://www.nature.com/articles/s41598-025-04830-7",
    "journal": "Nature_CompBio",
    "title": "Inconsistency of AI in intracranial aneurysm detection with varying dose and image reconstruction",
    "link": "https://www.nature.com/articles/s41598-025-04830-7",
    "published": "2025-06-06T00:00:00+00:00",
    "summary": "",
    "authors": [
      "Leonie Goelz et al."
    ],
    "doi": "",
    "parser_type": "nature",
    "feed_priority": "high",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:39:59.493626"
  },
  {
    "id": "https://www.nature.com/articles/s41746-025-01703-1",
    "journal": "Nature_CompBio",
    "title": "Machine learning to predict penumbra core mismatch in acute ischemic stroke using clinical note data",
    "link": "https://www.nature.com/articles/s41746-025-01703-1",
    "published": "2025-06-06T00:00:00+00:00",
    "summary": "",
    "authors": [
      "Shaun Kohli et al."
    ],
    "doi": "",
    "parser_type": "nature",
    "feed_priority": "high",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:39:59.493666"
  },
  {
    "id": "https://www.nature.com/articles/s41592-025-02704-4",
    "journal": "Nature_CompBio",
    "title": "Benchmarking methods for mapping functional connectivity in the brain",
    "link": "https://www.nature.com/articles/s41592-025-02704-4",
    "published": "2025-06-06T00:00:00+00:00",
    "summary": "",
    "authors": [
      "Zhen-Qi Liu et al."
    ],
    "doi": "",
    "parser_type": "nature",
    "feed_priority": "high",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:39:59.493694"
  },
  {
    "id": "https://www.nature.com/articles/s42003-025-08275-6",
    "journal": "Nature_CompBio",
    "title": "A versatile CRISPR/Cas9 system off-target prediction tool using language model",
    "link": "https://www.nature.com/articles/s42003-025-08275-6",
    "published": "2025-06-06T00:00:00+00:00",
    "summary": "",
    "authors": [
      "Weian Du et al."
    ],
    "doi": "",
    "parser_type": "nature",
    "feed_priority": "high",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:39:59.493772"
  },
  {
    "id": "https://www.nature.com/articles/s41746-025-01730-y",
    "journal": "Nature_CompBio",
    "title": "Foundation versus domain-specific models for left ventricular segmentation on cardiac ultrasound",
    "link": "https://www.nature.com/articles/s41746-025-01730-y",
    "published": "2025-06-06T00:00:00+00:00",
    "summary": "",
    "authors": [
      "Chieh-Ju Chao et al."
    ],
    "doi": "",
    "parser_type": "nature",
    "feed_priority": "high",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:39:59.493779"
  },
  {
    "id": "https://www.nature.com/articles/s41551-025-01412-w",
    "journal": "Nature_CompBio",
    "title": "Neuroimaging endophenotypes reveal underlying mechanisms and genetic factors contributing to progression and development of four brain disorders",
    "link": "https://www.nature.com/articles/s41551-025-01412-w",
    "published": "2025-06-06T00:00:00+00:00",
    "summary": "",
    "authors": [
      "Junhao Wen et al."
    ],
    "doi": "",
    "parser_type": "nature",
    "feed_priority": "high",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:39:59.493798"
  },
  {
    "id": "https://www.nature.com/articles/s41598-025-04717-7",
    "journal": "Nature_CompBio",
    "title": "Silencing FGL1 promotes prostate cancer cell apoptosis and inhibits EMT progression",
    "link": "https://www.nature.com/articles/s41598-025-04717-7",
    "published": "2025-06-06T00:00:00+00:00",
    "summary": "",
    "authors": [
      "Shuaizhi Zhu et al."
    ],
    "doi": "",
    "parser_type": "nature",
    "feed_priority": "high",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:39:59.493815"
  },
  {
    "id": "https://www.technologyreview.com/?p=1118044",
    "journal": "MIT_TechReview",
    "title": "The Download: China’s AI agent boom, and GPS alternatives",
    "link": "https://www.technologyreview.com/2025/06/06/1118044/the-download-chinas-ai-agent-boom-and-gps-alternatives/",
    "published": "Fri, 06 Jun 2025 12:10:00 +0000",
    "summary": "This is today&#8217;s edition of The Download, our weekday newsletter that provides a daily dose of what&#8217;s going on in the world of technology. Manus has kick-started an AI agent boom in China Last year, China saw a boom in foundation models, the do-everything large language models that underpin the AI revolution. This year, the focus has&#8230;",
    "authors": [
      "Rhiannon Williams"
    ],
    "doi": "",
    "parser_type": "generic",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:39:59.493823"
  },
  {
    "id": "https://www.technologyreview.com/?p=1117958",
    "journal": "MIT_TechReview",
    "title": "Manus has kick-started an AI agent boom in China",
    "link": "https://www.technologyreview.com/2025/06/05/1117958/china-ai-agent-boom/",
    "published": "Thu, 05 Jun 2025 18:45:42 +0000",
    "summary": "Last year, China saw a boom in foundation models, the do-everything large language models that underpin the AI revolution. This year, the focus has shifted to AI agents—systems that are less about responding to users’ queries and more about autonomously accomplishing things for them.&#160; There are now a host of Chinese startups building these general-purpose&#8230;",
    "authors": [
      "Caiwei Chen"
    ],
    "doi": "",
    "parser_type": "generic",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:39:59.493851"
  },
  {
    "id": "https://www.technologyreview.com/?p=1117928",
    "journal": "MIT_TechReview",
    "title": "The Download: funding a CRISPR embryo startup, and bad news for clean cement",
    "link": "https://www.technologyreview.com/2025/06/05/1117928/the-download-funding-a-crispr-embryo-startup-and-bad-news-for-clean-cement/",
    "published": "Thu, 05 Jun 2025 12:10:00 +0000",
    "summary": "This is today&#8217;s edition of The Download, our weekday newsletter that provides a daily dose of what&#8217;s going on in the world of technology. Crypto billionaire Brian Armstrong is ready to invest in CRISPR baby tech Brian Armstrong, the billionaire CEO of the cryptocurrency exchange Coinbase, says he’s ready to fund a US startup focused on gene-editing&#8230;",
    "authors": [
      "Rhiannon Williams"
    ],
    "doi": "",
    "parser_type": "generic",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:39:59.493858"
  },
  {
    "id": "https://www.technologyreview.com/?p=1117909",
    "journal": "MIT_TechReview",
    "title": "Crypto billionaire Brian Armstrong is ready to invest in CRISPR baby tech",
    "link": "https://www.technologyreview.com/2025/06/05/1117909/crypto-billionaire-brian-armstrong-is-ready-to-invest-in-crispr-baby-tech/",
    "published": "Thu, 05 Jun 2025 09:36:26 +0000",
    "summary": "Brian Armstrong, the billionaire CEO of the cryptocurrency exchange Coinbase, says he’s ready to fund a US startup focused on gene-editing human embryos. If he goes forward, it would be the first major commercial investment in one of medicine’s most fraught ideas. In a post on X June 2, Armstrong announced he was looking for&#8230;",
    "authors": [
      "Antonio Regalado"
    ],
    "doi": "",
    "parser_type": "generic",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:39:59.493873"
  },
  {
    "id": "https://www.technologyreview.com/?p=1117829",
    "journal": "MIT_TechReview",
    "title": "The Download: AI’s role in math, and calculating its energy footprint",
    "link": "https://www.technologyreview.com/2025/06/04/1117829/the-download-ai-math-energy/",
    "published": "Wed, 04 Jun 2025 12:02:00 +0000",
    "summary": "This is today&#8217;s edition of&#160;The Download,&#160;our weekday newsletter that provides a daily dose of what&#8217;s going on in the world of technology. What’s next for AI and math The modern world is built on mathematics. Math lets us model complex systems such as the way air flows around an aircraft, the way financial markets fluctuate,&#8230;",
    "authors": [
      "Charlotte Jee"
    ],
    "doi": "",
    "parser_type": "generic",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:39:59.493889"
  },
  {
    "id": "https://www.technologyreview.com/?p=1117753",
    "journal": "MIT_TechReview",
    "title": "What’s next for AI and math",
    "link": "https://www.technologyreview.com/2025/06/04/1117753/whats-next-for-ai-and-math/",
    "published": "Wed, 04 Jun 2025 08:21:24 +0000",
    "summary": "MIT Technology Review’s What’s Next series looks across industries, trends, and technologies to give you a first look at the future. You can read the rest of them here. The way DARPA tells it, math is stuck in the past. In April, the US Defense Advanced Research Projects Agency kicked off a new initiative called expMath—short&#8230;",
    "authors": [
      "Will Douglas Heaven"
    ],
    "doi": "",
    "parser_type": "generic",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:39:59.493897"
  },
  {
    "id": "https://bio.nikkeibp.co.jp/atcl/news/p1/25/06/05/13389/",
    "journal": "Nikkei_BioTech",
    "title": "田辺三菱買収の米Bain社、「ファンドの介入で企業価値高まる国内製薬企業はまだある」",
    "link": "https://bio.nikkeibp.co.jp/atcl/news/p1/25/06/05/13389/",
    "published": "",
    "summary": "米Bain Capital（ベインキャピタル）社は2025年2月、三菱ケミカルグループと、同社子会社の田辺三菱製薬を買収することで合意したと発表した。買収額は約5100億円で、同取引は 2025年第3四半期に完了する予定だ。2025年5月12日、ベインキャピタル・ジャパンの河本信太郎プリンシパルと、日本プライベート・エクイティ共同責任者を務める末包昌司（すえかね・まさし）パートナーが本誌の取材に応じた。",
    "authors": [
      "BTO"
    ],
    "doi": "",
    "parser_type": "generic",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:39:59.493906"
  },
  {
    "id": "https://bio.nikkeibp.co.jp/atcl/news/p1/25/06/06/13390/",
    "journal": "Nikkei_BioTech",
    "title": "米Tempus AI社とBI社、データサイエンス技術でがん治療薬開発を協力",
    "link": "https://bio.nikkeibp.co.jp/atcl/news/p1/25/06/06/13390/",
    "published": "",
    "summary": "米Tempus AI（テンパスAI）社は2025年5月14日、ドイツBoehringer Ingelheim（ベーリンガー・インゲルハイム）社とがん治療薬開発で協力する複数年の戦略的提携契約を締結したと発表した。両社がこれまで複数年にわたって蓄積してきた研究の成果を基盤とし、リアルワールドデータ（RWD）と人工知能（AI）を活用して新たながん精密医療の開発を推進する。契約に伴う取引の内容は開示していない。",
    "authors": [
      "BTO"
    ],
    "doi": "",
    "parser_type": "generic",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:39:59.493945"
  },
  {
    "id": "https://bio.nikkeibp.co.jp/atcl/news/p1/25/05/28/13360/",
    "journal": "Nikkei_BioTech",
    "title": "Philadelphia小児病院など、世界初の個別化CRISPR塩基編集療法を希少遺伝性疾患の乳児に適用",
    "link": "https://bio.nikkeibp.co.jp/atcl/news/p1/25/05/28/13360/",
    "published": "",
    "summary": "米Children’s Hospital of Philadelphia（CHOP）と米Perelman School of Medicine at the University of Pennsylvania（Penn）の研究者たちは、カルバモイルリン酸合成酵素1（CPS1）欠損症という代謝性疾患の乳児のために、6カ月以内という短期間でCRISPRベースの個別化塩基編集療法を設計、前臨床研究も行って、生後6～7カ月時点で投与し、症状の改善を見たという。この症例に関する詳細は、New England Journal of Medicine（NEJM）誌に2025年5月15日に報告され、ニューオリンズで開催された米遺伝子細胞治療学会（ASGCT）年次総会でも報告された。",
    "authors": [
      "BTO"
    ],
    "doi": "",
    "parser_type": "generic",
    "feed_priority": "medium",
    "priority": 2,
    "priority_name": "HIGH",
    "added_at": "2025-06-09T20:39:59.494117"
  },
  {
    "id": "https://www.pnas.org/doi/abs/10.1073/iti2225122?af=R",
    "journal": "PNAS",
    "title": "In This Issue",
    "link": "https://www.pnas.org/doi/abs/10.1073/iti2225122?af=R",
    "published": "",
    "summary": "Proceedings of the National Academy of Sciences, Volume 122, Issue 22, June 2025. <br />",
    "authors": [],
    "doi": "https://doi.org/abs/10.1073/iti2225122",
    "parser_type": "pnas",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:33:57.539140"
  },
  {
    "id": "https://www.pnas.org/doi/abs/10.1073/pnas.2415898122?af=R",
    "journal": "PNAS",
    "title": "The benefits and dangers of anthropomorphic conversational agents",
    "link": "https://www.pnas.org/doi/abs/10.1073/pnas.2415898122?af=R",
    "published": "",
    "summary": "Proceedings of the National Academy of Sciences, Volume 122, Issue 22, June 2025. <br />A growing body of research suggests that the recent generation of large language model (LLMs) excel, and in many cases outpace humans, at writing persuasively and empathetically, at inferring user traits from text, and at mimicking human-like conversation ...",
    "authors": [
      "Sandra PeterKai RiemerJevin D. WestaUniversity of Sydney Business School, The University of Sydney, Sydney, NSW 2006, AustraliabCenter for an Informed Public, Information School, University of Washington, Seattle, WA 98195"
    ],
    "doi": "https://doi.org/abs/10.1073/pnas.2415898122",
    "parser_type": "pnas",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:33:57.539150"
  },
  {
    "id": "https://www.pnas.org/doi/abs/10.1073/pnas.2509313122?af=R",
    "journal": "PNAS",
    "title": "Lynn Landmesser (1943–2024): A pioneer in developmental neurobiology",
    "link": "https://www.pnas.org/doi/abs/10.1073/pnas.2509313122?af=R",
    "published": "",
    "summary": "Proceedings of the National Academy of Sciences, Volume 122, Issue 22, June 2025. <br />Lynn Landmesser, whose studies transformed our view of how neurons find the proper partners on which to form synapses, died at the age of 80 in November 2024. Using elegant electrophysiological methods, she showed that specificity is apparent from the ...",
    "authors": [
      "Story LandisJoshua R. SanesaPrivate address, Freeport, ME 04032bDepartment of Molecular and Cellular Biology, Harvard University, Cambridge, MA 02138cCenter for Brain Science, Harvard University, Cambridge, MA 02138"
    ],
    "doi": "https://doi.org/abs/10.1073/pnas.2509313122",
    "parser_type": "pnas",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:33:57.539157"
  },
  {
    "id": "https://www.pnas.org/doi/abs/10.1073/pnas.2413207122?af=R",
    "journal": "PNAS",
    "title": "A universally applicable definition for domestication",
    "link": "https://www.pnas.org/doi/abs/10.1073/pnas.2413207122?af=R",
    "published": "",
    "summary": "Proceedings of the National Academy of Sciences, Volume 122, Issue 22, June 2025. <br />The process of domestication is commonly perceived as a human achievement, and domestic species are typically assumed to be those under human control. Domestic species have emerged from a greater diversity of interactions than this perspective allows, and ...",
    "authors": [
      "Kathryn A. LordGreger LarsonRobin G. AllabyElinor K. KarlssonaGenomics and Computational Biology, University of Massachusetts Chan Medical School, Worcester, MA 01655bMedical and Population Genetics Program, Broad Institute of MIT and Harvard, Cambridge, MA 02142cThe Palaeogenomics and Bio-Archaeology Research Network, School of Archaeology, University of Oxford, Oxford OX1 3TG, United KingdomdSchool of Life Sciences, University of Warwick, Coventry CV4 7AL, United Kingdom"
    ],
    "doi": "https://doi.org/abs/10.1073/pnas.2413207122",
    "parser_type": "pnas",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:33:57.539168"
  },
  {
    "id": "https://www.pnas.org/doi/abs/10.1073/pnas.2503039122?af=R",
    "journal": "PNAS",
    "title": "X and Y gene dosage effects are primary contributors to human sexual dimorphism: The case of height",
    "link": "https://www.pnas.org/doi/abs/10.1073/pnas.2503039122?af=R",
    "published": "",
    "summary": "Proceedings of the National Academy of Sciences, Volume 122, Issue 22, June 2025. <br />SignificanceHuman stature is one of many physical phenotypes that vary between the sexes. On average, adult males are taller than females. However, the underlying biological mechanisms that explain this dimorphism are not entirely understood. Here, we ...",
    "authors": [
      "Alexander S. F. BerryBrenda M. FinucaneScott M. MyersChrista L. MartinDavid H. LedbetterHuntington F. WillardMatthew T. OetjensaAutism & Developmental Medicine Institute, Geisinger College of Health Sciences, Danville, PA 17821bInstitute for Pediatric Rare Diseases, College of Medicine, Florida State University, Tallahassee, FL 32306cGenome National Group, Durham, NC 27707"
    ],
    "doi": "https://doi.org/abs/10.1073/pnas.2503039122",
    "parser_type": "pnas",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:33:57.539175"
  },
  {
    "id": "https://www.pnas.org/doi/abs/10.1073/pnas.2409366122?af=R",
    "journal": "PNAS",
    "title": "Ecological restructuring of North Tethyan marine vertebrate communities triggered by the end-Cretaceous extinction",
    "link": "https://www.pnas.org/doi/abs/10.1073/pnas.2409366122?af=R",
    "published": "",
    "summary": "Proceedings of the National Academy of Sciences, Volume 122, Issue 22, June 2025. <br />SignificanceThe fossil record is an archive of ancient biodiversity unveiling the magnitude of extinction events in earth history. Here, we analyzed the immediate response of fish communities (elasmobranchs and actinopterygians) to the ecological ...",
    "authors": [
      "Iris FeichtingerMathias HarzhauserJürgen PollerspöckGerald AuerStjepan ĆorićMatthias KrannerMădălina-Elena KallanxhiAnna E. WeinmannGuillaume GuinotaNatural History Museum Vienna, Geological-Palaeontological Department, Vienna 1010, AustriabDepartment of Earth Sciences, University of Graz, Graz 8010, AustriacSection Ichthyology, Bavarian State Collection of Zoology, Munich 81247, GermanydSection Geological Mapping, GeoSphere Austria, Vienna 1030, AustriaeBavarian Environment Agency, Department 10 Geological survey, Unit 102 Geological Mapping, Geohazard Assessment, Hof/Saale 95030, GermanyfDepartment of Geology, Albanian Geological Survey, Tirana 1001, Albaniag'Équipe Paléontologie, Institut des Sciences de l’Évolution de Montpellier, Univ Montpellier, Montpellier 34095, FrancehInstitut universitaire de France"
    ],
    "doi": "https://doi.org/abs/10.1073/pnas.2409366122",
    "parser_type": "pnas",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:33:57.539185"
  },
  {
    "id": "https://www.pnas.org/doi/abs/10.1073/pnas.2422726122?af=R",
    "journal": "PNAS",
    "title": "A whole-scale volatile-depleted lunar interior",
    "link": "https://www.pnas.org/doi/abs/10.1073/pnas.2422726122?af=R",
    "published": "",
    "summary": "Proceedings of the National Academy of Sciences, Volume 122, Issue 22, June 2025. <br />SignificanceLunar meteorites provide a broad sampling of the Moon’s surface that can help us better understand volatile depletion processes acting on our nearest neighbor. Our findings reveal that the Zn and K isotope compositions of lunar mare basalts ...",
    "authors": [
      "Wei DaiFrédéric MoynierZheng-Yu LongLinru FangJames M. D. DayMarine PaquetJulien SiebertaUniversité Paris Cité, Institut de Physique du Globe de Paris, CNRS, Paris 75005, FrancebCentre for Star and Planet Formation, Globe Institute, University of Copenhagen, Copenhagen K DK-1350, DenmarkcScripps Institution of Oceanography, University of California San Diego, La Jolla, CA 92093-0244dUniversité de Lorraine, CNRS, Centre de Recherches Pétrographiques et Géochimiques, Nancy F-54000, France"
    ],
    "doi": "https://doi.org/abs/10.1073/pnas.2422726122",
    "parser_type": "pnas",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:33:57.539190"
  },
  {
    "id": "https://www.pnas.org/doi/abs/10.1073/pnas.2412514122?af=R",
    "journal": "PNAS",
    "title": "Self-reproduction as an autonomous process of growth and reorganization in fully abiotic, artificial and synthetic cells",
    "link": "https://www.pnas.org/doi/abs/10.1073/pnas.2412514122?af=R",
    "published": "",
    "summary": "Proceedings of the National Academy of Sciences, Volume 122, Issue 22, June 2025. <br />SignificanceSelf-reproduction is one of the most fundamental features of natural life. This study introduces a biochemistry-free method for creating self-reproducing polymeric vesicles. In this process, nonamphiphilic molecules are mixed and illuminated ...",
    "authors": [
      "Sai Krishna KatlaChenyu LinJuan Pérez-MercaderaDepartment of Earth and Planetary Sciences, Harvard University, Cambridge, MA 02138-1204bSanta Fe Institute, Santa Fe, NM 87501"
    ],
    "doi": "https://doi.org/abs/10.1073/pnas.2412514122",
    "parser_type": "pnas",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:33:57.539197"
  },
  {
    "id": "https://www.pnas.org/doi/abs/10.1073/pnas.2503570122?af=R",
    "journal": "PNAS",
    "title": "Modulation of human dorsal root ganglion neuron firing by the Nav1.8 inhibitor suzetrigine",
    "link": "https://www.pnas.org/doi/abs/10.1073/pnas.2503570122?af=R",
    "published": "",
    "summary": "Proceedings of the National Academy of Sciences, Volume 122, Issue 22, June 2025. <br />SignificanceNav1.8 sodium channels are highly expressed in primary pain-sensing neurons. Suzetrigine is a potent and highly selective Nav1.8 inhibitor that has recently been approved by the Food and Drug Administration for treating acute pain. We find ...",
    "authors": [
      "Robert G. StewartTomás OsornoAkie FujitaSooyeon JoAlyssa FerraiuoloKevin CarlinBruce P. BeanaDepartment of Neurobiology, Harvard Medical School, Boston, MA 02115bAnaBios Corporation, San Diego, CA 92101"
    ],
    "doi": "https://doi.org/abs/10.1073/pnas.2503570122",
    "parser_type": "pnas",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:33:57.539203"
  },
  {
    "id": "https://www.pnas.org/doi/abs/10.1073/pnas.2418176122?af=R",
    "journal": "PNAS",
    "title": "Longitudinal associations between birth-to-six cortical growth and childhood neurocognitive function",
    "link": "https://www.pnas.org/doi/abs/10.1073/pnas.2418176122?af=R",
    "published": "",
    "summary": "Proceedings of the National Academy of Sciences, Volume 122, Issue 22, June 2025. <br />SignificanceWhile the cortex undergoes rapid nonlinear change in the first years of life, it remains unclear how these changes, which occur prior to age five, are associated with later neurocognitive function. This is in part because little research to ...",
    "authors": [
      "Megan M. DavisMackenzie WoodburnTehila NugielDivyangana RakeshMaresa TateWilliam AsciuttoWeili LinJessica R. CohenMargaret A. SheridanaDepartment of Psychology and Neuroscience, University of North Carolina at Chapel Hill, Chapel Hill, NC 27514bDepartment of Psychology, Florida State University, Tallahassee, FL 32306cInstitute of Psychiatry, Psychology and Neuroscience, Kings College London, London SE5 8AF, United KingdomdBiomedical Research Imaging Center and Department of Radiology, University of North Carolina at Chapel Hill, Chapel Hill, NC 27599"
    ],
    "doi": "https://doi.org/abs/10.1073/pnas.2418176122",
    "parser_type": "pnas",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:33:57.539209"
  },
  {
    "id": "https://www.pnas.org/doi/abs/10.1073/pnas.2420704122?af=R",
    "journal": "PNAS",
    "title": "Stimulus representations in visual cortex shaped by spatial attention and microsaccades",
    "link": "https://www.pnas.org/doi/abs/10.1073/pnas.2420704122?af=R",
    "published": "",
    "summary": "Proceedings of the National Academy of Sciences, Volume 122, Issue 22, June 2025. <br />SignificanceThis study reveals a crucial link between covert spatial attention, object processing, and microsaccades (MSs). While spatial attention alone does not affect tuning curves of V4 neurons, MSs directed toward an attended stimulus significantly ...",
    "authors": [
      "Karthik SrinivasanEric LowetBruno GomesRobert DesimoneaMcGovern Institute for Brain Research, Massachusetts Institute of Technology, Cambridge, MA 02139bDepartment of Neuroscience, Erasmus MC, Rotterdam 3015 GE, The NetherlandscDepartment of Biomedical Engineering, Boston University, Boston, MA 02215dLaboratório de Simulação e Biologia Computacional, Centro de Computação de Alto Desempenho, Universidade Federal do Pará, Belém-Pa 66075-110, Brazil"
    ],
    "doi": "https://doi.org/abs/10.1073/pnas.2420704122",
    "parser_type": "pnas",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:33:57.539218"
  },
  {
    "id": "https://www.pnas.org/doi/abs/10.1073/pnas.2416114122?af=R",
    "journal": "PNAS",
    "title": "Viral and host network analysis of the human cytomegalovirus transcriptome in latency",
    "link": "https://www.pnas.org/doi/abs/10.1073/pnas.2416114122?af=R",
    "published": "",
    "summary": "Proceedings of the National Academy of Sciences, Volume 122, Issue 22, June 2025. <br />SignificanceHuman cytomegalovirus infection persists for the host’s lifetime and reactivates sporadically, causing life-threatening complications in those with inadequate immunity. Understanding the mechanisms by which the virus reactivates is critical to ...",
    "authors": [
      "Donna Collins-McMillenDiogo De Oliveira PessoaKristen ZarrellaChristopher J. ParkinsMichael DailyDavid R. McKinzeyNathaniel J. MoormanJeremy P. KamilPatrizia CaposioMegha PadiFelicia D. GoodrumaBioscience Innovation Organization Five Disciplines (BIO5) Institute, University of Arizona, Tucson, AZ 85719bDepartment of Immunobiology, University of Arizona, Tucson, AZ 85719cBioinformatics Shared Resource, Arizona Cancer Center, University of Arizona, Tucson, AZ 85719dVaccine and Gene Therapy Institute, Oregon Health Science University, Beaverton, OR 97006eDepartment of Microbiology and Immunology, University of North Carolina at Chapel Hill, Chapel Hill, NC 27599fDepartment of Microbiology and Immunology, Louisiana State University Health Sciences Center, Shreveport, LA 71103gUniversity of Arizona Cancer Center, University of Arizona, Tucson, AZ 85719hDepartment of Molecular and Cellular Biology, University of Arizona, Tucson, AZ 85721"
    ],
    "doi": "https://doi.org/abs/10.1073/pnas.2416114122",
    "parser_type": "pnas",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:33:57.539225"
  },
  {
    "id": "https://www.pnas.org/doi/abs/10.1073/pnas.2503168122?af=R",
    "journal": "PNAS",
    "title": "Two endogenous Dictyostelium discoideum chemorepellents use different mechanisms to induce repulsion",
    "link": "https://www.pnas.org/doi/abs/10.1073/pnas.2503168122?af=R",
    "published": "",
    "summary": "Proceedings of the National Academy of Sciences, Volume 122, Issue 22, June 2025. <br />SignificanceAlthough a considerable amount is known about how eukaryotic cells move toward a signal (chemoattraction), relatively little is known about how cells move away from a signal (chemorepulsion). A previously identified chemorepellent used by...",
    "authors": [
      "Mohanad H. El-SobkyRamesh RijalRichard H. GomeraDepartment of Biology, Texas A&M University, College Station, TX 77843-3474"
    ],
    "doi": "https://doi.org/abs/10.1073/pnas.2503168122",
    "parser_type": "pnas",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:33:57.539231"
  },
  {
    "id": "https://www.pnas.org/doi/abs/10.1073/pnas.2420245122?af=R",
    "journal": "PNAS",
    "title": "A viral necrosome mediates direct RIPK3 activation to promote inflammatory necroptosis",
    "link": "https://www.pnas.org/doi/abs/10.1073/pnas.2420245122?af=R",
    "published": "",
    "summary": "Proceedings of the National Academy of Sciences, Volume 122, Issue 22, June 2025. <br />SignificanceWe revealed a mechanism in which a viral protein promotes the direct RIPK3 activation leading to inflammatory necroptosis and pathogenesis. The nonstructural protein NSs of a pathogenic hemorrhagic fever virus, SFTSV, interacts with the RIPK3 ...",
    "authors": [
      "Shufen LiHao LiZhenxing ZhouMeidi YeYifei WangWenqin LiZhenqiong GuanZihan GuanChongtao ZhangYulan ZhangWei LiuKe PengaState Key Laboratory of Virology and Biosafety, Wuhan Institute of Virology, Center for Biosafety Mega-Science, Chinese Academy of Sciences, Wuhan 430071, People's Republic of ChinabMedical School, University of Chinese Academy of Sciences, Beijing 101408, People's Republic of ChinacState Key Laboratory of Pathogen and Biosecurity, Academy of Military Medical Sciences, Beijing 100850, People's Republic of China"
    ],
    "doi": "https://doi.org/abs/10.1073/pnas.2420245122",
    "parser_type": "pnas",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:33:57.539237"
  },
  {
    "id": "https://www.pnas.org/doi/abs/10.1073/pnas.2503738122?af=R",
    "journal": "PNAS",
    "title": "Dynamic early recruitment of GAK–Hsc70 regulates coated pit maturation",
    "link": "https://www.pnas.org/doi/abs/10.1073/pnas.2503738122?af=R",
    "published": "",
    "summary": "Proceedings of the National Academy of Sciences, Volume 122, Issue 22, June 2025. <br />SignificanceGAK and its chaperone protein, Hsc70, are known to be recruited to clathrin-coated vesicles (CCVs) to mediate clathrin uncoating. Previous studies have proposed that early recruitment of GAK–Hsc70 to CCPs could function to remodel nascent flat ...",
    "authors": [
      "Zhangping HePeiyao ZuoPeiliu XuHaozhi YuanMadhura BhaveXiangying WeiZiyan YangLu HanSandra L. SchmidZhiming ChenaDepartment of Clinical Laboratory of The First Affiliated Hospital, National Health Commission Key Laboratory of Birth Defect Research and Prevention, Ministry of Education Key Laboratory of Rare Pediatric Diseases, Institute of Cytology and Genetics of School of Basic Medical Sciences, Hengyang Medical School, University of South China, Hengyang, Hunan 421001, ChinabDepartment of Clinical Laboratory of The Affiliated Nanhua Hospital, Hengyang Medical School, University of South China, Hengyang, Hunan 421001, ChinacDepartment of Cell Biology, University of Texas Southwestern Medical Center, Dallas, TX 75390dChan Zuckerberg Biohub, San Francisco, CA 94158eDepartment of Oceanography, Fujian Key Laboratory on Conservation and Sustainable Utilization of Marine Biodiversity, Fuzhou Institute of Oceanography, College of Geography and Oceanography, Minjiang University, Fuzhou, Fujian 350108, China"
    ],
    "doi": "https://doi.org/abs/10.1073/pnas.2503738122",
    "parser_type": "pnas",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:33:57.539243"
  },
  {
    "id": "https://www.pnas.org/doi/abs/10.1073/pnas.2423873122?af=R",
    "journal": "PNAS",
    "title": "Alternative cGAS signaling promotes herpes simplex encephalitis",
    "link": "https://www.pnas.org/doi/abs/10.1073/pnas.2423873122?af=R",
    "published": "",
    "summary": "Proceedings of the National Academy of Sciences, Volume 122, Issue 22, June 2025. <br />SignificanceCyclic GMP-AMP synthase (cGAS) is an essential adaptor protein required for the inflammatory response to cytosolic DNA. dsDNA activates cGAS to generate cGAMP and activate STING and the expression of cytokines to control viral infection. ...",
    "authors": [
      "Liraz Shmuel-GaliaZhaozhao JiangLaurel StineSara CahillSze-Ling NgRuth WilsonRichard Kumaran KandasamyEvelyn A. Kurt-JonesJoshi M. RamanjuluJohn BertinViera KasparcovaG. Scott PesiridisKatherine A. FitzgeraldFiachra HumphriesaDivision of Innate Immunity, Department of Medicine, University of Massachusetts Chan Medical School, Worcester, MA 01605bInnate Immunity Research Unit, GlaxoSmithKline, Collegeville, PA 19426cCentre of Molecular Inflammation Research, and Department of Clinical and Molecular Medicine, Norwegian University of Science and Technology, Trondheim 7491, NorwaydDivision of Infectious Diseases and Immunology, Department of Medicine, University of Massachusetts Chan Medical, Worcester, MA 01605eImmunology and Inflammation Therapeutic Area, Sanofi, Cambridge, MA 02139"
    ],
    "doi": "https://doi.org/abs/10.1073/pnas.2423873122",
    "parser_type": "pnas",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:33:57.539249"
  },
  {
    "id": "https://www.pnas.org/doi/abs/10.1073/pnas.2423831122?af=R",
    "journal": "PNAS",
    "title": "Mgat4b-mediated selective N-glycosylation regulates melanocyte development and melanoma progression",
    "link": "https://www.pnas.org/doi/abs/10.1073/pnas.2423831122?af=R",
    "published": "",
    "summary": "Proceedings of the National Academy of Sciences, Volume 122, Issue 22, June 2025. <br />SignificanceThis study reveals that the enzyme MGAT4B, which adds sugar molecules to proteins, plays a key role in how pigment-producing skin melanocytes move and organize themselves. This enzyme controls key melanocytic proteins involved in movement and ...",
    "authors": [
      "Babita SharmaKeerthic AswinTanya JainAyesha NasreenAyush AggarwalYogaspoorthi J. SubramaniamJeyashri RengarajuSrashti Jyoti AgrawalMayank BhattBhashkar PaulKoushika ChandrasekaranAanchal YadavJyoti SoniRajat UjjainiyaMd Quasid AkhterRajesh PandeyShruthy SureshSrinivasa-Gopalan SampathkumarVivek T. NatarajanaCouncil of Scientific and Industrial Research-Institute of Genomics and Integrative Biology, New Delhi 110025, IndiabAcademy of Scientific and Innovative Research, Ghaziabad, Uttar Pradesh 201002, IndiacLaboratory of Chemical Glycobiology, National Institute of Immunology, New Delhi 110067, India"
    ],
    "doi": "https://doi.org/abs/10.1073/pnas.2423831122",
    "parser_type": "pnas",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:33:57.539261"
  },
  {
    "id": "https://www.pnas.org/doi/abs/10.1073/pnas.2417149122?af=R",
    "journal": "PNAS",
    "title": "The IL-18 receptor is expressed on murine small-intestinal enterochromaffin cells and executes a recovery program upon injury",
    "link": "https://www.pnas.org/doi/abs/10.1073/pnas.2417149122?af=R",
    "published": "",
    "summary": "Proceedings of the National Academy of Sciences, Volume 122, Issue 22, June 2025. <br />SignificanceIECs mature and release IL-18 in response to barrier breach, which is subsequently sensed by underlying immune cells to initiate an inflammatory response. In addition to this epithelial-derived signaling network, IL-18 is also thought to have ...",
    "authors": [
      "Nathaniel J. WinsorDerek K. TsangAdrienne RangerOjas SinghShawn GoyalDana J. PhilpottStephen E. GirardinaDepartment of Immunology, University of Toronto, ON M5S 1A8, CanadabDepartment of Laboratory Medicine and Pathobiology, University of Toronto, ON M5S 1A8, Canada"
    ],
    "doi": "https://doi.org/abs/10.1073/pnas.2417149122",
    "parser_type": "pnas",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:33:57.539267"
  },
  {
    "id": "https://www.pnas.org/doi/abs/10.1073/pnas.2422126122?af=R",
    "journal": "PNAS",
    "title": "Formation of giant ER sheets by pentadecanoic acid causes lipotoxicity in fission yeast",
    "link": "https://www.pnas.org/doi/abs/10.1073/pnas.2422126122?af=R",
    "published": "",
    "summary": "Proceedings of the National Academy of Sciences, Volume 122, Issue 22, June 2025. <br />SignificanceAlthough fatty acids (FAs) are essential for living organisms, excess amount causes sickness through cell and tissue dysfunction and cell death, a phenomenon known as lipotoxicity. However, the molecular mechanism underlying lipotoxicity ...",
    "authors": [
      "Yojiro HoshikawaNatsuho ShirotaHiroshi TsugawaSatoshi KimuraAkihisa MatsuyamaYoko YashirodaHideaki KakeyaMakoto AritaReiko IizumiMinoru YoshidaShinichi NishimuraaDepartment of Biotechnology, Graduate School of Agricultural and Life Sciences, The University of Tokyo, Tokyo 113-8657, JapanbProgram of Food and AgriLife Science, Graduate School of Integrated Sciences for Life, Hiroshima University, Hiroshima 739-8528, JapancFood Science Program, School of Applied Biological Science, Hiroshima University, Hiroshima 739-8528, JapandMetabolome Informatics Research Team, RIKEN Center for Sustainable Resource Science, Kanagawa 230-0045, JapaneLaboratory for Metabolomics, RIKEN Center for Integrative Medical Sciences, Kanagawa 230-0045, JapanfMolecular and Cellular Epigenetics Laboratory, Graduate School of Medical Life Science, Yokohama City University, Kanagawa 230-0045, JapangDepartment of Biotechnology and Life Science, Tokyo University of Agriculture and Technology, Tokyo 184-8588, JapanhTechnology Advancement Center, Graduate School of Agricultural and Life Sciences, The University of Tokyo, Tokyo 113-8657, JapaniMolecular Ligand Target Research Team/Chemical Genomics Research Group, RIKEN Center for Sustainable Resource Science, Saitama 351-0198, JapanjDivision of Medicinal Frontier Sciences, Graduate School of Pharmaceutical Sciences, Kyoto University, Kyoto 606-8501, JapankDivision of Physiological Chemistry and Metabolism, Graduate School of Pharmaceutical Sciences, Keio University, Tokyo 105-8512, JapanlHuman Biology-Microbiome-Quantum Research Center (WPI-Bio2Q), Keio University, Tokyo 160-8582, JapanmCenter for Marine Biotechnology and Biomedicine, Scripps Institution of Oceanography, University of California San Diego, CA 92093nCollaborative Research Institute for Innovative Microbiology, The University of Tokyo, Tokyo 113-8657, JapanoOffice of University Professors, The University of Tokyo, Tokyo 113-8657, JapanpChemical Genomics Research Group/Drug Discovery Seeds Development Unit, RIKEN Center for Sustainable Resource Science, Saitama 351-0198, Japan"
    ],
    "doi": "https://doi.org/abs/10.1073/pnas.2422126122",
    "parser_type": "pnas",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:33:57.539273"
  },
  {
    "id": "https://www.pnas.org/doi/abs/10.1073/pnas.2421006122?af=R",
    "journal": "PNAS",
    "title": "Robustness revisited: On the neutral evolution of centrality and localization",
    "link": "https://www.pnas.org/doi/abs/10.1073/pnas.2421006122?af=R",
    "published": "",
    "summary": "Proceedings of the National Academy of Sciences, Volume 122, Issue 22, June 2025. <br />SignificanceOur work advances the theory of neutral evolution, paying particular attention to how the holistic fitness landscape structure shapes the process of evolution and gives rise to emergent evolutionary phenomena. Since neutral evolution does not ...",
    "authors": [
      "Yehonatan SellaAviv BergmanaDepartment of Systems and Computational Biology, Albert Einstein College of Medicine, Bronx, NY 10461bInstitute for Advanced Study in the Life Sciences, Albert Einstein College of Medicine, Bronx, NY 10461cSanta Fe Institute, Santa Fe, NM 87501"
    ],
    "doi": "https://doi.org/abs/10.1073/pnas.2421006122",
    "parser_type": "pnas",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:33:57.539278"
  },
  {
    "id": "https://www.pnas.org/doi/abs/10.1073/pnas.2425647122?af=R",
    "journal": "PNAS",
    "title": "Arabidopsis HOOKLESS1 acts as a histone acetyltransferase to promote cotyledon greening during seedling de-etiolation",
    "link": "https://www.pnas.org/doi/abs/10.1073/pnas.2425647122?af=R",
    "published": "",
    "summary": "Proceedings of the National Academy of Sciences, Volume 122, Issue 22, June 2025. <br />SignificanceCotyledon greening is a crucial process for seedlings to survive the dark-to-light transition during their soil emergence. While the complex strategies employed by etiolated seedlings to ensure successful greening have been extensively studied,...",
    "authors": [
      "Yang PengTao PengYishan ChuWei YanRunyi YaoXing WenYuping QiuMeng WangZhina XiaoDan ZhangXiaoqian ChenZhujun YinYichuan WangHongwei GuoaNew Cornerstone Science Laboratory, Department of Biology, School of Life Sciences, Institute of Plant and Food Science, Southern University of Science and Technology, Shenzhen, Guangdong 518055, ChinabShenzhen Key Laboratory of Plant Genetic Engineering and Molecular Design, Department of Biology, School of Life Sciences, Institute of Plant and Food Science, Southern University of Science and Technology, Shenzhen, Guangdong 518055, China"
    ],
    "doi": "https://doi.org/abs/10.1073/pnas.2425647122",
    "parser_type": "pnas",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:33:57.539288"
  },
  {
    "id": "https://www.pnas.org/doi/abs/10.1073/pnas.2424979122?af=R",
    "journal": "PNAS",
    "title": "Specialized molecular pathways drive the formation of light-scattering assemblies in leucophores",
    "link": "https://www.pnas.org/doi/abs/10.1073/pnas.2424979122?af=R",
    "published": "",
    "summary": "Proceedings of the National Academy of Sciences, Volume 122, Issue 22, June 2025. <br />SignificancePigments and colors play a crucial role in nature, supporting functions such as camouflage, communication, mate attraction, and protection from radiation. Leucophores, which form uric acid crystals, remain the least understood among pigment ...",
    "authors": [
      "Yuval BarzilayZohar EyalYael NoyNeta VarsanoTsviya OlenderSourabh BeraTali Lerer-GoldshteinMerav KedmiZiv PoratIddo PinkasSmadar Levin-ZaidmanNili DezorellaDvir GuraDepartment of Molecular Genetics, Weizmann Institute of Science, Rehovot 7610001, IsraelbDepartment of Chemical Research Support, Weizmann Institute of Science, Rehovot 7610001, IsraelcDepartment of Life Sciences Core Facilities, Weizmann Institute of Science, Rehovot 7610001, Israel"
    ],
    "doi": "https://doi.org/abs/10.1073/pnas.2424979122",
    "parser_type": "pnas",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:33:57.539294"
  },
  {
    "id": "https://www.pnas.org/doi/abs/10.1073/pnas.2500825122?af=R",
    "journal": "PNAS",
    "title": "Biochemical and structural basis of Dicer helicase function unveiled by resurrecting ancient proteins",
    "link": "https://www.pnas.org/doi/abs/10.1073/pnas.2500825122?af=R",
    "published": "",
    "summary": "Proceedings of the National Academy of Sciences, Volume 122, Issue 22, June 2025. <br />SignificanceAmong animals, the contribution of Dicer’s helicase to recognition and elimination of viral double-stranded RNA (dsRNA) varies from phylum to phylum. Vertebrate Dicers show no helicase activity, while an arthropod ortholog uses helicase ...",
    "authors": [
      "Adedeji M. AderounmuJosephine Maus-ConnClaudia D. ConsalvoPeter S. ShenBrenda L. BassaDepartment of Biochemistry, University of Utah, Salt Lake City, UT 84112"
    ],
    "doi": "https://doi.org/abs/10.1073/pnas.2500825122",
    "parser_type": "pnas",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:33:57.539300"
  },
  {
    "id": "https://www.pnas.org/doi/abs/10.1073/pnas.2424570122?af=R",
    "journal": "PNAS",
    "title": "Host complement C3 promotes malaria transmission by killing symbiotic bacteria in the mosquito midgut",
    "link": "https://www.pnas.org/doi/abs/10.1073/pnas.2424570122?af=R",
    "published": "",
    "summary": "Proceedings of the National Academy of Sciences, Volume 122, Issue 22, June 2025. <br />SignificanceMalaria remains one of the most devastating diseases worldwide. Blocking malaria transmission is considered a promising strategy for controlling and potentially eliminating the disease. In this study, we report that host complement C3 ...",
    "authors": [
      "Biao HeMeilin LiShuai GuoFeng ZhuZhiwei JiaoJianyong LiNie TanShiming JiaoTaiping LiuJian ZhangYongling FanYuanli GaoTaoli ZhouJian LiWei HuangLubin JiangZurui LinSibao WangWenyue XuaDepartment of Pathogenic Biology, Army Medical University, Chongqing 400038, ChinabState Key Laboratory of Cellular Stress Biology, School of Life Sciences, Faculty of Medicine and Life Sciences, Xiamen University, Xiamen, Fujian 361102, ChinacKey Laboratory of Molecular Virology and Immunology, Shanghai institute of immunity and infection, Institut Pasteur of Shanghai, University of Chinese Academy of Sciences, Chinese Academy of Sciences, Shanghai 200030, ChinadDvision of Malaria Control, Yunnan Institute of Parasitic Diseases, Pu'er, Yunnan 655000, ChinaeNew Cornerstone Science Laboratory, Chinese Academy of Sciences Key Laboratory of Insect Developmental and Evolutionary Biology, Chinese Academy of Sciences Center for Excellence in Molecular Plant Sciences, Shanghai Institute of Plant Physiology and Ecology, Chinese Academy of Sciences, Shanghai 200030, ChinafKey Laboratory of Extreme Environmental Medicine, Ministry of Education of China, Chongqing, 400038, China"
    ],
    "doi": "https://doi.org/abs/10.1073/pnas.2424570122",
    "parser_type": "pnas",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:33:57.539306"
  },
  {
    "id": "https://www.pnas.org/doi/abs/10.1073/pnas.2501022122?af=R",
    "journal": "PNAS",
    "title": "Cardiolipin membranes drive Myosin VI activation, oligomerization, and processive cargo transport",
    "link": "https://www.pnas.org/doi/abs/10.1073/pnas.2501022122?af=R",
    "published": "",
    "summary": "Proceedings of the National Academy of Sciences, Volume 122, Issue 22, June 2025. <br />SignificanceIn this study, we have identified cardiolipin (CL), a highly abundant lipid of the inner mitochondrial membrane and exposed to the cytosolic environment upon mitochondrial damage, to be a strong, nanomolar binding partner for Myo6. Using a ...",
    "authors": [
      "Antonino F. MontanarellaNikolas HundtDominik KeimAron VenczelFelix ZierhutSimon LangnickelAndreas GrawMarkus KrössJohannes DietrichDario Saczko-BrackClaudia VeigelaDepartment of Cellular Physiology, Biomedical Centre, Ludwig-Maximilians-Universität München, Planegg-Martinsried 82152, GermanybFaculty of Physics, Centre for NanoScience, Ludwig-Maximilians-Universität München, München 80799, Germany"
    ],
    "doi": "https://doi.org/abs/10.1073/pnas.2501022122",
    "parser_type": "pnas",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:33:57.539317"
  },
  {
    "id": "https://www.pnas.org/doi/abs/10.1073/pnas.2417915122?af=R",
    "journal": "PNAS",
    "title": "Allelic variations and gene cluster modularity act as nonlinear bottlenecks for cholera emergence",
    "link": "https://www.pnas.org/doi/abs/10.1073/pnas.2417915122?af=R",
    "published": "",
    "summary": "Proceedings of the National Academy of Sciences, Volume 122, Issue 22, June 2025. <br />SignificanceThe underlying factors that lead to specific strains within a species to emerge as human pathogens remain mostly enigmatic. Toxigenic clones of the cholera agent,Vibrio cholerae, are encompassed within one phylogenomic clade, the pandemic ...",
    "authors": [
      "Mario López-PérezDeepak BalasubramanianAlicia Campos-LopezCole CristTrudy-Ann GrantJose M. Haro-MorenoAsier Zaragoza-SolasSalvador Almagro-MorenoaBurnett School of Biomedical Sciences, College of Medicine, University of Central, Florida, Orlando, FL, 32827bMicrobial Genomics and Evolution Group, División de Microbiología, Universidad Miguel Hernández, Alicante 03550, SpaincDivision of Molecular Microbiology, Department of Host-Microbe Interactions, St. Jude Children’s Research Hospital, Memphis, TN 38105"
    ],
    "doi": "https://doi.org/abs/10.1073/pnas.2417915122",
    "parser_type": "pnas",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:33:57.539323"
  },
  {
    "id": "https://www.pnas.org/doi/abs/10.1073/pnas.2421663122?af=R",
    "journal": "PNAS",
    "title": "An electrostatic network with strong connectivity is a phospho-sensor for regulating affinity of Syk–receptor association",
    "link": "https://www.pnas.org/doi/abs/10.1073/pnas.2421663122?af=R",
    "published": "",
    "summary": "Proceedings of the National Academy of Sciences, Volume 122, Issue 22, June 2025. <br />SignificanceThe protein Spleen tyrosine kinase (Syk) serves essential functions in the immune system by transducing extracellular signals into cellular responses to promote immunity. It is essential that an immune response be closely regulated. To this ...",
    "authors": [
      "Duy P. HuaJacob J. KinnunCarol Beth PostaBorch Department of Medicinal Chemistry and Molecular Pharmacology, Purdue University, West Lafayette, IN 47907bDepartment of Biological Sciences, Markey Center for Structural Biology, and Purdue Center for Cancer Research, Purdue University, West Lafayette, IN 47907cThe Henry M. Jackson Foundation for the Advancement of Military Medicine, Inc., Bethesda, MD 20817dDepartment of Chemistry, University of Tennessee, Knoxville, TN 37996"
    ],
    "doi": "https://doi.org/abs/10.1073/pnas.2421663122",
    "parser_type": "pnas",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:33:57.539331"
  },
  {
    "id": "https://www.pnas.org/doi/abs/10.1073/pnas.2500001122?af=R",
    "journal": "PNAS",
    "title": "Manifold fitting reveals metabolomic heterogeneity and disease associations in UK Biobank populations",
    "link": "https://www.pnas.org/doi/abs/10.1073/pnas.2500001122?af=R",
    "published": "",
    "summary": "Proceedings of the National Academy of Sciences, Volume 122, Issue 22, June 2025. <br />SignificanceThis study utilizes a manifold-fitting framework within NMR-based metabolomics to explore metabolic heterogeneity in the UK Biobank population. Our method clusters 251 metabolic biomarkers into seven distinct categories that reflect the ...",
    "authors": [
      "Bingjie LiJiaji SuRunyu LinShing-Tung YauZhigang YaoaDepartment of Statistics and Data Science, National University of Singapore, Singapore 117546, SingaporebYau Mathematical Sciences Center, Tsinghua University, Jingzhai, Beijing 100084, China"
    ],
    "doi": "https://doi.org/abs/10.1073/pnas.2500001122",
    "parser_type": "pnas",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:33:57.539338"
  },
  {
    "id": "https://www.pnas.org/doi/abs/10.1073/pnas.2427257122?af=R",
    "journal": "PNAS",
    "title": "Nanoimmunomodulation of the Aβ-STING feedback machinery in microglia for Alzheimer’s disease treatment",
    "link": "https://www.pnas.org/doi/abs/10.1073/pnas.2427257122?af=R",
    "published": "",
    "summary": "Proceedings of the National Academy of Sciences, Volume 122, Issue 22, June 2025. <br />SignificanceAnti-Aβ therapeutics provide only temporary symptom relief in AD while introducing proinflammatory side effects. We describe an “Aβ-STING” immune feedback loop that contributes to AD pathology and, building upon this discovery, introduce a ...",
    "authors": [
      "Limin TianGuangyu LongSiqi ZhuYuelong WangPengcheng XuLifeng LiuHong YaoShentong FangShuqing ChenSuxin LiaDepartment of Pharmaceutics, State Key Laboratory of Natural Medicines, China Pharmaceutical University, Nanjing 210009, ChinabDepartment of Pharmaceutical Engineering, College of Pharmacy, Inner Mongolia Medical University, Hohhot 010110, ChinacDepartment of Medicinal Chemistry, State Key Laboratory of Natural Medicines, China Pharmaceutical University, Nanjing 210009, ChinadSchool of Biopharmacy, China Pharmaceutical University, Nanjing 210009, ChinaeDepartment of Epidemiology and Biostatistics, School of Public Health, Tongji Medical College, Huazhong University of Science and Technology, Wuhan 430030, ChinafState Key Laboratory of Neurology and Oncology Drug Development, Nanjing 210009, China"
    ],
    "doi": "https://doi.org/abs/10.1073/pnas.2427257122",
    "parser_type": "pnas",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:33:57.539353"
  },
  {
    "id": "https://www.pnas.org/doi/abs/10.1073/pnas.2407423122?af=R",
    "journal": "PNAS",
    "title": "Micropipette aspiration reveals differential RNA-dependent viscoelasticity of nucleolar subcompartments",
    "link": "https://www.pnas.org/doi/abs/10.1073/pnas.2407423122?af=R",
    "published": "",
    "summary": "Proceedings of the National Academy of Sciences, Volume 122, Issue 22, June 2025. <br />SignificanceBiological reactions are strongly coupled to the structure and properties of their environment. Cellular compartmentalization into biomolecular condensates with distinct material properties enables a diverse array of biological processes. ...",
    "authors": [
      "Holly H. ChengJames V. RoggeveenHuan WangHoward A. StoneZheng ShiClifford P. BrangwynneaDepartment of Molecular Biology, Princeton University, Princeton, NJ 08544bDepartment of Mechanical and Aerospace Engineering, Princeton, NJ 08544cDepartment of Chemistry and Chemical Biology, Rutgers University, Piscataway, NJ 08854dPrinceton Materials Institute, Princeton University, Princeton, NJ 08544eDepartment of Chemical and Biological Engineering, Princeton University, Princeton, NJ 08544fOmenn-Darling Bioengineering Institute, Princeton University, Princeton NJ 08544gHHMI, Chevy Chase, MD 21044"
    ],
    "doi": "https://doi.org/abs/10.1073/pnas.2407423122",
    "parser_type": "pnas",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:33:57.539360"
  },
  {
    "id": "https://www.pnas.org/doi/abs/10.1073/pnas.2421822122?af=R",
    "journal": "PNAS",
    "title": "Freeze-induced crystallization: An overlooked pathway for mineral genesis in natural waters",
    "link": "https://www.pnas.org/doi/abs/10.1073/pnas.2421822122?af=R",
    "published": "",
    "summary": "Proceedings of the National Academy of Sciences, Volume 122, Issue 22, June 2025. <br />SignificanceChemical processes in ice were long overlooked due to slow aqueous reactions at low temperatures and inhibition in the solid phase. However, growing evidence shows that solute concentrations within unfrozen layers at ice grain boundaries can ...",
    "authors": [
      "Younghoon WonSungsik LeeSeungyeol LeeSoHyun ParkJun LimWonyong ChoiGiehyeon LeeaDepartment of Earth System Sciences, Yonsei University, Seoul 03722, Republic of KoreabX-Ray Science Division, Argonne National Laboratory, Lemont, IL 60439cDepartment of Earth and Environmental Sciences, Chungbuk National University, Cheongju 28644, Republic of KoreadDepartment of Geo- and Environmental Sciences, Section of Crystallography, Ludwig-Maximilians-Universität München, Munich 80333, GermanyePohang Accelerator Laboratory, Pohang University of Science and Technology, Pohang 37673, Republic of KoreafDepartment of Energy Engineering, Korea Institute of Energy Technology, Naju 58330, Republic of Korea"
    ],
    "doi": "https://doi.org/abs/10.1073/pnas.2421822122",
    "parser_type": "pnas",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:33:57.539365"
  },
  {
    "id": "https://www.pnas.org/doi/abs/10.1073/pnas.2502798122?af=R",
    "journal": "PNAS",
    "title": "ATP8B1 regulates PIP2 localization and cleavage of pyroptotic executioner Gasdermin D",
    "link": "https://www.pnas.org/doi/abs/10.1073/pnas.2502798122?af=R",
    "published": "",
    "summary": "Proceedings of the National Academy of Sciences, Volume 122, Issue 22, June 2025. <br />SignificanceDepletion of signaling lipid phosphatidylinositol,4-5-bisphosphate (PIP2) from the inner leaflet of plasma membrane (PM) is linked to heart failure, Alzheimer’s, cancer, and other diseases. We show that ATP8B1 maintains PIP2 at the inner ...",
    "authors": [
      "Nilam BhandariAshutosh PrinceMariam R. KhanC. Alicia TraughberKalash NeupaneShuhui W. LorkowskiGregory BrubakerElif G. ErtugralChandrasekhar R. KothapalliGeorge R. DubyakJonathan D. SmithKailash GulshanaCenter for Gene Regulation in Health and Disease, Cleveland State University, Cleveland, OH 44115bDepartment of Biological, Geological, and Environmental Sciences, Cleveland State University, Cleveland, OH 44115cDepartment of Cardiovascular and Metabolic Sciences, Lerner Research Institute, Cleveland Clinic, Cleveland, OH 44195dDepartment of Chemical and Biomedical Engineering, Cleveland State University, Cleveland, OH 44115eDepartment of Physiology and Biophysics, Case Western Reserve University School of Medicine, Cleveland, OH 44106"
    ],
    "doi": "https://doi.org/abs/10.1073/pnas.2502798122",
    "parser_type": "pnas",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:33:57.539371"
  },
  {
    "id": "https://www.pnas.org/doi/abs/10.1073/pnas.2501902122?af=R",
    "journal": "PNAS",
    "title": "Molecular basis for ligand recognition and receptor activation of the prostaglandin D2 receptor DP1",
    "link": "https://www.pnas.org/doi/abs/10.1073/pnas.2501902122?af=R",
    "published": "",
    "summary": "Proceedings of the National Academy of Sciences, Volume 122, Issue 22, June 2025. <br />SignificanceThe prostaglandin D2 receptor (DP1) functions as a critical regulator of diverse physiological processes, including sleep–wake cycles, allergic responses, and inflammatory cascades. By determining high-resolution cryo-EM structures of DP1 in ...",
    "authors": [
      "Jiuyin XuYanli WuYouwei XuYang LiXinheng HeHeng ZhangJames Jiqi WangJingjing HouJunrui LiWen HuKai WuQingning YuanCanrong WuH. Eric XuaState Key Laboratory of Drug Research, Shanghai Institute of Materia Medica, Chinese Academy of Sciences, Shanghai 201203, ChinabSchool of Life Science and Technology, ShanghaiTech University, Shanghai 201210, ChinacDivision of Cardiology, Department of Internal Medicine and Hubei Key Laboratory of Genetics and Molecular Mechanism of Cardiologic Disorders, Tongji Hospital, Tongji Medical College, Huazhong University of Science and Technology, Wuhan 430000, ChinadDepartment of Pharmacology, School of Pharmacy, Fudan University, Shanghai 201203, ChinaeResearch Center for Medicinal Structural Biology, National Research Center for Translational Medicine at Shanghai, State Key Laboratory of Medical Genomics, Ruijin Hospital, Shanghai Jiao Tong University School of Medicine, Shanghai 200025, ChinafUniversity of Chinese Academy of Sciences, Beijing 100049, China"
    ],
    "doi": "https://doi.org/abs/10.1073/pnas.2501902122",
    "parser_type": "pnas",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:33:57.539376"
  },
  {
    "id": "https://www.pnas.org/doi/abs/10.1073/pnas.2505263122?af=R",
    "journal": "PNAS",
    "title": "Ethanol induction of FGF21 in the liver is dependent on histone acetylation and ligand activation of ChREBP by glycerol-3-phosphate",
    "link": "https://www.pnas.org/doi/abs/10.1073/pnas.2505263122?af=R",
    "published": "",
    "summary": "Proceedings of the National Academy of Sciences, Volume 122, Issue 22, June 2025. <br />SignificanceAlcohol triggers the liver to produce the hormone FGF21, which helps protect against its toxic effects. However, how alcohol induces FGF21 synthesis is incompletely understood. We now show that two byproducts of alcohol metabolism, glycerol-3-...",
    "authors": [
      "Mi Cheong CheongBryan MackowiakHyung Bum KimGenaro HernandezTulip NanduKevin ValeYuan ZhangLauren G. ZachariasThomas P. MathewsBin GaoW. Lee KrausSteven A. KliewerDavid J. MangelsdorfaDepartment of Pharmacology, University of Texas Southwestern Medical Center, Dallas, TX 75390bLaboratory of Liver Diseases, National Institute on Alcohol Abuse and Alcoholism, NIH, Bethesda, MD 20892cLaboratory of Signaling and Gene Regulation, Cecil H. and Ida Green Center for Reproductive Biology Sciences, University of Texas Southwestern Medical Center, Dallas, TX 75390dChildren’s Medical Center Research Institute, UT Southwestern Medical Center, Dallas, TX 75390eDepartment of Molecular Biology, UT Southwestern Medical Center, Dallas, TX 75390fHHMI, UT Southwestern Medical Center, Dallas, TX 75390"
    ],
    "doi": "https://doi.org/abs/10.1073/pnas.2505263122",
    "parser_type": "pnas",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:33:57.539383"
  },
  {
    "id": "https://www.pnas.org/doi/abs/10.1073/pnas.2413480122?af=R",
    "journal": "PNAS",
    "title": "Surface melting–driven hydrogen absorption for high-pressure polyhydride synthesis",
    "link": "https://www.pnas.org/doi/abs/10.1073/pnas.2413480122?af=R",
    "published": "",
    "summary": "Proceedings of the National Academy of Sciences, Volume 122, Issue 22, June 2025. <br />SignificanceRoom-temperature superconductors could revolutionize modern technology by enabling lossless power transmission, powerful magnets, advanced medical imaging (MRI), and quantum computing. Polyhydrides—hydrogen-rich compounds synthesized under ...",
    "authors": [
      "Ryuhei SatoLewis J. ConwayDi ZhangChris J. PickardKazuto AkagiKartik SauHao LiShin-ichi OrimoaAdvanced Institute for Materials Research, Tohoku University, Sendai 980-8577, JapanbDepartment of Materials Engineering, The University of Tokyo, Tokyo 113-8656, JapancDepartment of Materials Science and Metallurgy, University of Cambridge, Cambridge CB3 0FS, United KingdomdMathematics for Advanced Materials Open Innovation Laboratory, National Institute of Advanced Industrial Science and Technology, c/o Advanced Institute for Materials Research, Tohoku University, Sendai 980-8577, JapaneInstitute for Materials Research, Tohoku University, Sendai 980-8577, Japan"
    ],
    "doi": "https://doi.org/abs/10.1073/pnas.2413480122",
    "parser_type": "pnas",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:33:57.539395"
  },
  {
    "id": "https://www.pnas.org/doi/abs/10.1073/pnas.2507232122?af=R",
    "journal": "PNAS",
    "title": "The proofreading mechanism of the human leading-strand DNA polymerase ε holoenzyme",
    "link": "https://www.pnas.org/doi/abs/10.1073/pnas.2507232122?af=R",
    "published": "",
    "summary": "Proceedings of the National Academy of Sciences, Volume 122, Issue 22, June 2025. <br />SignificanceReplicative DNA polymerases (Pol) function with a sliding clamp and their proofreading exonuclease provides high fidelity. Thus, the study of the proofreading mechanism must both contain the Pol–clamp complex and generate the mismatch in situ ...",
    "authors": [
      "Feng WangQing HeMichael E. O’DonnellHuilin LiaDepartment of Structural Biology, Van Andel Institute, Grand Rapids, MI 49503bDNA Replication Laboratory, The Rockefeller University, New York, NY 10065cHHMI, The Rockefeller University, New York, NY 10065"
    ],
    "doi": "https://doi.org/abs/10.1073/pnas.2507232122",
    "parser_type": "pnas",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:33:57.539402"
  },
  {
    "id": "https://www.pnas.org/doi/abs/10.1073/pnas.2415979122?af=R",
    "journal": "PNAS",
    "title": "Independent transitions to fully planktonic life cycles shaped the global distribution of medusozoans in the epipelagic zone",
    "link": "https://www.pnas.org/doi/abs/10.1073/pnas.2415979122?af=R",
    "published": "",
    "summary": "Proceedings of the National Academy of Sciences, Volume 122, Issue 22, June 2025. <br />SignificanceMedusozoan jellyfish are well known for their impact on coastal ecosystems, often linked to their complex life cycles, which include benthic polyp and pelagic medusa stages. Several lesser-known medusozoan groups evolved a holoplanktonic (...",
    "authors": [
      "Manon BoostenCamille SantOphélie Da SilvaSamuel ChaffronLionel GuidiLucas LeclèreaSorbonne Université, CNRS, Laboratoire de Biologie du Développement de Villefranche-sur-Mer, Villefranche-sur-Mer F-06230, FrancebSorbonne Université, CNRS, Laboratoire d’Océanographie de Villefranche, Villefranche-sur-Mer F-06230, FrancecNatural Solutions, Pôle Data, Marseille F-13001, FrancedÉcole Centrale Nantes, CNRS, Laboratoire des Sciences du Numérique de Nantes, UMR 6004, Nantes F-44000, FranceeResearch Federation for the Study of Global Ocean Systems Ecology and Evolution, FR2022, Paris F-75016, FrancefSorbonne Université, CNRS, Biologie Intégrative des Organismes Marins, Banyuls-sur-Mer F-66650, France"
    ],
    "doi": "https://doi.org/abs/10.1073/pnas.2415979122",
    "parser_type": "pnas",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:33:57.539411"
  },
  {
    "id": "https://www.pnas.org/doi/abs/10.1073/pnas.2505197122?af=R",
    "journal": "PNAS",
    "title": "Cocrystal structure reveals the mechanism of FSP1 inhibition by FSEN1",
    "link": "https://www.pnas.org/doi/abs/10.1073/pnas.2505197122?af=R",
    "published": "",
    "summary": "Proceedings of the National Academy of Sciences, Volume 122, Issue 22, June 2025. <br />SignificanceFerroptosis is a form of regulated cell death. The induction of ferroptosis is an emerging strategy for the treatment of cancer. FSP1 is an enzyme that prevents ferroptosis by recycling lipophilic radical-trapping antioxidants, and inhibition ...",
    "authors": [
      "Sitao ZhangAmalia H. MegariotiJoseph M. HendricksJunshu ZhouQingxiang SunDa JiaJames A. OlzmannaKey Laboratory of Birth Defects and Related Diseases of Women and Children, Department of Paediatrics, West China Second University Hospital, State Key Laboratory of Biotherapy, Sichuan University, Chengdu, Sichuan 610041, ChinabDepartment of Molecular and Cell Biology, University of California, Berkeley CA 94720cDepartment of Nutritional Sciences and Toxicology, University of California, Berkeley, CA 94720dDepartment of Pulmonary and Critical Care Medicine, Sichuan Provincial People’s Hospital, School of Medicine, University of Electronic Science and Technology of China, Chengdu 610032, China"
    ],
    "doi": "https://doi.org/abs/10.1073/pnas.2505197122",
    "parser_type": "pnas",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:33:57.539417"
  },
  {
    "id": "https://www.pnas.org/doi/abs/10.1073/pnas.2414166122?af=R",
    "journal": "PNAS",
    "title": "Histone variant H2A.W7 represses meiotic crossover formation in Arabidopsis heterochromatin",
    "link": "https://www.pnas.org/doi/abs/10.1073/pnas.2414166122?af=R",
    "published": "",
    "summary": "Proceedings of the National Academy of Sciences, Volume 122, Issue 22, June 2025. <br />SignificanceMeiotic recombination is an evolutionary-conserved process that shapes genetic variation in most eukaryotes. DNA is packaged into nucleosomes, and high levels of nucleosome occupancy suppress recombination. This study reveals that H2A.W7, a ...",
    "authors": [
      "Pallas KuoAndrew J. TockXuexia LiuStephanie D. ToppZhenhui ZhongIan R. HendersonChristophe LambingaDepartment of Plant Sciences, Rothamsted Research, Harpenden AL5 2JQ, United KingdombDepartment of Plant Sciences, University of Cambridge, Cambridge CB2 3EA, United KingdomcMinistry of Education Key Laboratory for Bio-Resource and Eco-Environment, College of Life Sciences, State Key Laboratory of Hydraulics and Mountain River Engineering, Sichuan University, Chengdu 610064, China"
    ],
    "doi": "https://doi.org/abs/10.1073/pnas.2414166122",
    "parser_type": "pnas",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:33:57.539423"
  },
  {
    "id": "https://www.pnas.org/doi/abs/10.1073/pnas.2500153122?af=R",
    "journal": "PNAS",
    "title": "Phylogenomics reveals the slow-burning fuse of diatom evolution",
    "link": "https://www.pnas.org/doi/abs/10.1073/pnas.2500153122?af=R",
    "published": "",
    "summary": "Proceedings of the National Academy of Sciences, Volume 122, Issue 22, June 2025. <br />SignificanceThe tree of life is dotted with inflection points that changed the course of evolution for some lineages, with vast amounts of morphological diversity and species richness generated in short periods of time. We combined fossil information with ...",
    "authors": [
      "Andrew J. AlversonWade R. RobertsElizabeth C. RuckTeofil NakovMatthew P. AshworthKarolina BryłkaKala M. DowneyJ. Patrick KociolekMatthew ParksEveline PinseelEdward C. TheriotSimon P. TyeAndrzej WitkowskiJeremy M. BeaulieuNorman J. WickettaDepartment of Biological Sciences, University of Arkansas, Fayetteville, AR 72701bEscuela de Biología, Centro de Investigación en Ciencias del Mar y Limología, Universidad de Costa Rica, San José 11501-2060, Costa RicacDepartment of Molecular Biosciences, University of Texas at Austin, Austin, TX 78712dDepartment of Geology, Lund University, Lund 223 62, SwedeneDepartment of Ecology and Evolutionary Biology, University of Colorado, Boulder, CO 80309fDepartment of Biology, University of Central Oklahoma, Edmond, OK 73034gLaboratory of Protistology en Aquatic Ecology, Department of Biology, Ghent University, Ghent 9000, BelgiumhDepartment of Integrative Biology, University of Texas at Austin, Austin, TX 78712iFaculty of Physical, Mathematical and Natural Sciences, Institute of Marine and Environmental Sciences, University of Szczecin, Szczecin 70-383, PolandjDepartment of Botany and Biodiversity Research, University of Vienna, Vienna 1030, Austria"
    ],
    "doi": "https://doi.org/abs/10.1073/pnas.2500153122",
    "parser_type": "pnas",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:33:57.539429"
  },
  {
    "id": "https://www.pnas.org/doi/abs/10.1073/pnas.2500163122?af=R",
    "journal": "PNAS",
    "title": "Maximum spreading of impacting shear-thinning and shear-thickening drops",
    "link": "https://www.pnas.org/doi/abs/10.1073/pnas.2500163122?af=R",
    "published": "",
    "summary": "Proceedings of the National Academy of Sciences, Volume 122, Issue 22, June 2025. <br />SignificanceHow much does a liquid drop spread upon impacting a solid surface? The apparent simplicity of this question, coupled with the ubiquity of drop impact in daily life, belies the complexity of the underlying fluid dynamics and its broad relevance ...",
    "authors": [
      "Anahita MobaseriSatish KumarXiang ChengaDepartment of Chemical Engineering and Materials Science, University of Minnesota, Minneapolis, MN 55455bSt. Anthony Falls Laboratory, University of Minnesota, Minneapolis, MN 55414"
    ],
    "doi": "https://doi.org/abs/10.1073/pnas.2500163122",
    "parser_type": "pnas",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:33:57.539435"
  },
  {
    "id": "https://www.pnas.org/doi/abs/10.1073/pnas.2500489122?af=R",
    "journal": "PNAS",
    "title": "Targeted apoptotic immune modulator for the treatment of metastatic EGFR-positive solid tumors",
    "link": "https://www.pnas.org/doi/abs/10.1073/pnas.2500489122?af=R",
    "published": "",
    "summary": "Proceedings of the National Academy of Sciences, Volume 122, Issue 22, June 2025. <br />SignificanceEpidermal growth factor receptor (EGFR) overexpression is associated with multiple aggressive solid tumors. Despite recent advances in cancer therapy, and specifically in EGFR-targeted therapy, there is an unmet need for effective treatment ...",
    "authors": [
      "Derrick BrokaShoshana KleinAlexei ShirBabette SchadeMeera SaxenaAthanasia DasargyriAnita JarzebinskaCaroline De FeyterDavor BajicDavid ColecchiaLucia D'AmicoEric KitasElad HikriMichal Jerzy SkowickiMichal Jerzy OkoniewskiLaura BaldinoBesnik QeriqiElisa de StanchinaJoerg SchreiberMelanie BuchiCornelia G. PalivanYaakov BenensonAlfred ZippeliusDoriano FabbroMaurizio ScaltritiAviram MizrachiAlexander LevitzkiEsteban Pombo-VillarMaya ZigleraTargImmune Therapeutics, Basel 4057, SwitzerlandbDepartment of Biological Chemistry, Silberman Life Sciences Institute, The Hebrew University of Jerusalem, Edmond J. Safra Campus, Jerusalem 9190401, IsraelcDepartment of Otorhinolaryngology, Head and Neck Surgery, Rabin Medical Center, Petah Tikva 4941492, IsraeldTranslational Research in Head and Neck Cancer, Felsenstein Medical Research Center, Rabin Medical Center, Faculty of Medical and Health Sciences, Tel Aviv University, Tel Aviv 6997801, IsraeleDepartment of Chemistry, University of Basel, Basel 4002, SwitzerlandfScientific IT Services ID, ETH, Zürich 8092, SwitzerlandgHuman Oncology and Pathogenesis Program, Memorial Sloan Kettering Cancer Center, New York, NY 10065hMolecular Pharmacology Program, Memorial Sloan-Kettering Cancer Center, New York, NY 10021iDepartment of Biosystems Science and Engineering, Swiss Federal Institute of Technology, ETH Zurich, Basel 4058, SwitzerlandjDepartment of Biomedicine, University of Basel and University Hospital, Basel 4031, Switzerland"
    ],
    "doi": "https://doi.org/abs/10.1073/pnas.2500489122",
    "parser_type": "pnas",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:33:57.539440"
  },
  {
    "id": "https://www.pnas.org/doi/abs/10.1073/pnas.2424263122?af=R",
    "journal": "PNAS",
    "title": "Microtubule dynamics are defined by conformations and stability of clustered protofilaments",
    "link": "https://www.pnas.org/doi/abs/10.1073/pnas.2424263122?af=R",
    "published": "",
    "summary": "Proceedings of the National Academy of Sciences, Volume 122, Issue 22, June 2025. <br />SignificanceMicrotubules are essential components of the cytoskeleton with crucial roles in cell division and transport. Understanding microtubule growth and shortening is vital for obtaining insights into cellular function in normal and disease states. ...",
    "authors": [
      "Maksim KalutskiiHelmut GrubmüllerVladimir A. VolkovMaxim IgaevaDepartment of Theoretical and Computational Biophysics, Max Planck Institute for Multidisciplinary Sciences, Göttingen D-37077, GermanybCentre for Molecular Cell Biology, School of Biological and Behavioural Sciences, Queen Mary University of London, London E1 4NS, United KingdomcDivision of Computational Biology, School of Life Sciences, University of Dundee, Dundee DD1 5EH, United Kingdom"
    ],
    "doi": "https://doi.org/abs/10.1073/pnas.2424263122",
    "parser_type": "pnas",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:33:57.539446"
  },
  {
    "id": "https://www.pnas.org/doi/abs/10.1073/pnas.2424694122?af=R",
    "journal": "PNAS",
    "title": "Deciphering Ca2+ permeation and valence selectivity in CaV1: Molecular dynamics simulations reveal the three-ion knock-on mechanism",
    "link": "https://www.pnas.org/doi/abs/10.1073/pnas.2424694122?af=R",
    "published": "",
    "summary": "Proceedings of the National Academy of Sciences, Volume 122, Issue 22, June 2025. <br />SignificanceIon selectivity is a fundamental property of ion channels. Voltage-gated calcium channels (CaV), particularly CaV1, exhibit high selectivity for Ca2+over Na+, primarily attributed to the strong binding of calcium ions. However, such a strong ...",
    "authors": [
      "Lingfeng XueNieng YanChen SongaCenter for Quantitative Biology, Peking-Tsinghua Center for Life Sciences, Academy for Advanced Interdisciplinary Studies, Peking University, Beijing 100871, ChinabSchool of Life Sciences, State Key Laboratory of Membrane Biology, Beijing Frontier Research Center for Biological Structures, Tsinghua-Peking Joint Center for Life Sciences, Tsinghua University, Beijing 100084, ChinacInstitute of Bio-Architecture and Bio-Interactions, Shenzhen Medical Academy of Research and Translation, Shenzhen, Guangdong 518107, ChinadInstitute of Chemical Biology, Shenzhen Bay Laboratory, Shenzhen, Guangdong 518132, China"
    ],
    "doi": "https://doi.org/abs/10.1073/pnas.2424694122",
    "parser_type": "pnas",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:33:57.539453"
  },
  {
    "id": "https://www.pnas.org/doi/abs/10.1073/pnas.2505975122?af=R",
    "journal": "PNAS",
    "title": "Oxr1 and Ncoa7 regulate V-ATPase to achieve optimal pH for glycosylation within the Golgi apparatus and trans-Golgi network",
    "link": "https://www.pnas.org/doi/abs/10.1073/pnas.2505975122?af=R",
    "published": "",
    "summary": "Proceedings of the National Academy of Sciences, Volume 122, Issue 22, June 2025. <br />SignificanceIn the secretory pathway, the pH within organelles is gradually acidified, starting at 7.1 to 7.2 in the endoplasmic reticulum, decreasing to 6.0 to 6.7 in the Golgi apparatus/trans-Golgi network (Golgi/TGN), and reaching 4.5 to 5.0 in ...",
    "authors": [
      "Shin-ichiro YoshimuraTomoaki SobajimaMasataka KuniiAkihiro HaradaaDepartment of Cell Biology, Graduate School of Medicine, The University of Osaka, Suita 565-0871, Osaka, Japan"
    ],
    "doi": "https://doi.org/abs/10.1073/pnas.2505975122",
    "parser_type": "pnas",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:33:57.539464"
  },
  {
    "id": "https://www.pnas.org/doi/abs/10.1073/pnas.2504775122?af=R",
    "journal": "PNAS",
    "title": "Modular arrangement of synaptic and intrinsic homeostatic plasticity within visual cortical circuits",
    "link": "https://www.pnas.org/doi/abs/10.1073/pnas.2504775122?af=R",
    "published": "",
    "summary": "Proceedings of the National Academy of Sciences, Volume 122, Issue 22, June 2025. <br />SignificanceHomeostatic plasticity maintains normal brain functions by constraining various network features of neural circuits, yet how this is realized on the cellular level remains unknown. Synaptic and intrinsic forms of homeostatic plasticity adjust ...",
    "authors": [
      "Wei WenAdriana M. PradaGina G. TurrigianoaDepartment of Biology, Brandeis University, Waltham, MA 02453"
    ],
    "doi": "https://doi.org/abs/10.1073/pnas.2504775122",
    "parser_type": "pnas",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:33:57.539484"
  },
  {
    "id": "https://www.pnas.org/doi/abs/10.1073/pnas.2416387122?af=R",
    "journal": "PNAS",
    "title": "Task difficulty modulates the effect of mind wandering on phase dynamics",
    "link": "https://www.pnas.org/doi/abs/10.1073/pnas.2416387122?af=R",
    "published": "",
    "summary": "Proceedings of the National Academy of Sciences, Volume 122, Issue 22, June 2025. <br />SignificanceWe demonstrate that external (sensory and motor processing) and internal cognition (mind wandering) are dynamically interdependent. Easier external tasks require fewer executive resources, leaving more cognitive resources for internal mind ...",
    "authors": [
      "Zhengkun LongGeorg NorthoffXiaolan FuaState Key Laboratory of Cognitive Science and Mental Health, Institute of Psychology, Chinese Academy of Sciences, Beijing 100101, ChinabDepartment of Psychology, University of Chinese Academy of Sciences, Beijing 100049, ChinacSchool of Psychology, Shenzhen University, Shenzhen, Guangdong 518060, ChinadMind, Brain Imaging and Neuroethics Research Unit, The Royal’s Institute of Mental Health Research, University of Ottawa, Ottawa, ON K1Z 7K4, CanadaeSchool of Psychology, Shanghai Jiao Tong University, Shanghai 200030, China"
    ],
    "doi": "https://doi.org/abs/10.1073/pnas.2416387122",
    "parser_type": "pnas",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:33:57.539490"
  },
  {
    "id": "https://www.pnas.org/doi/abs/10.1073/pnas.2422787122?af=R",
    "journal": "PNAS",
    "title": "Proofreading and single-molecule sensitivity in T cell receptor signaling by condensate nucleation",
    "link": "https://www.pnas.org/doi/abs/10.1073/pnas.2422787122?af=R",
    "published": "",
    "summary": "Proceedings of the National Academy of Sciences, Volume 122, Issue 22, June 2025. <br />SignificanceTo fight infections and cancer, T cells must selectively recognize low levels of foreign peptides from pathogens or cancer cells, but the mechanisms that enable these properties remain unclear. Using computational modeling and experiments, we ...",
    "authors": [
      "William L. WhiteHailemikael K. YirdawAriel J. Ben-SassonJay T. GrovesDavid BakerHao Yuan KuehaDepartment of Bioengineering, University of Washington, Seattle, WA 98195bInstitute for Protein Design, University of Washington, Seattle, WA 98195cDepartment of Chemistry, University of California Berkeley, Berkeley, CA 94720dInstitute for Digital Molecular Analytics and Science, Nanyang Technological University, Singapore 636921, SingaporeeDepartment of Biochemistry, University of Washington, Seattle, WA 98195fHHMI, Seattle, WA 98195gInstitute for Stem Cell and Regenerative Medicine, University of Washington, Seattle, WA 98109"
    ],
    "doi": "https://doi.org/abs/10.1073/pnas.2422787122",
    "parser_type": "pnas",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:33:57.539501"
  },
  {
    "id": "https://www.pnas.org/doi/abs/10.1073/pnas.2500480122?af=R",
    "journal": "PNAS",
    "title": "Himalayan “S-type” granite generated from I-type sources",
    "link": "https://www.pnas.org/doi/abs/10.1073/pnas.2500480122?af=R",
    "published": "",
    "summary": "Proceedings of the National Academy of Sciences, Volume 122, Issue 22, June 2025. <br />SignificanceClassically, granites are separated into two broad categories—“I-type” vs. “S-type”—representing different igneous vs. (meta)sedimentary rock sources for melting. Their geochemistry differs for diverse geochemical systems. Himalayan granites ...",
    "authors": [
      "Huixia DingZeming ZhangMatthew J. KohnaState Key Laboratory of Geological Processes and Mineral Resources, and School of Earth Sciences and Resources, China University of Geosciences, Beijing 100083, ChinabInstitute of Geology, Chinese Academy of Geological Sciences, Beijing 100037, ChinacDepartment of Geosciences, Boise State University, Boise, ID 83725"
    ],
    "doi": "https://doi.org/abs/10.1073/pnas.2500480122",
    "parser_type": "pnas",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:33:57.539507"
  },
  {
    "id": "https://www.pnas.org/doi/abs/10.1073/pnas.2420708122?af=R",
    "journal": "PNAS",
    "title": "Environmental DNA adsorption to chitin can promote horizontal gene transfer by natural transformation",
    "link": "https://www.pnas.org/doi/abs/10.1073/pnas.2420708122?af=R",
    "published": "",
    "summary": "Proceedings of the National Academy of Sciences, Volume 122, Issue 22, June 2025. <br />SignificanceThe human pathogen and marine microbeVibrio choleraehas been shown to activate extracellular DNA uptake and transformation when in contact with chitin, the most abundant structural biomaterial in the oceans and a primary source of nutrition ...",
    "authors": [
      "Jacob D. HoltYixuan PengTriana N. DaliaAnkur B. DaliaCarey D. NadellaDepartment of Biological Sciences, Dartmouth, Hanover, NH 03755bDepartment of Microbiology and Immunology, Geisel School of Medicine at Dartmouth, Hanover, NH 03755cDepartment of Biology, Indiana University, Bloomington, IN 47405"
    ],
    "doi": "https://doi.org/abs/10.1073/pnas.2420708122",
    "parser_type": "pnas",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:33:57.539519"
  },
  {
    "id": "https://www.pnas.org/doi/abs/10.1073/pnas.2426059122?af=R",
    "journal": "PNAS",
    "title": "Exploring diverse supramolecular tessellation through hierarchical assemblies of nonalternant nanographene",
    "link": "https://www.pnas.org/doi/abs/10.1073/pnas.2426059122?af=R",
    "published": "",
    "summary": "Proceedings of the National Academy of Sciences, Volume 122, Issue 22, June 2025. <br />SignificanceThe tessellated material is poised to become a fascinating subject in materials science, following the initial exploration of quasicrystals. Specifically, supramolecular tessellation at the molecular level has primarily been observed in ...",
    "authors": [
      "Jian SunZiqi DengDavid Lee PhillipsJunzhi LiuaDepartment of Chemistry, The University of Hong Kong - Chinese Academy of Sciences Joint Laboratory on New Materials and Shanghai-Hong Kong Joint Laboratory on Chemical Synthesis, The University of Hong Kong, Hong Kong 999077, ChinabState Key Laboratory of Synthetic Chemistry, The University of Hong Kong, Hong Kong 999077, ChinacMaterials Innovation Institute for Life Sciences and Energy, The University of Hong Kong - Shenzhen Institute of Research and Innovation, Shenzhen 518048, China"
    ],
    "doi": "https://doi.org/abs/10.1073/pnas.2426059122",
    "parser_type": "pnas",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:33:57.539526"
  },
  {
    "id": "https://www.pnas.org/doi/abs/10.1073/pnas.2427298122?af=R",
    "journal": "PNAS",
    "title": "Estimating wage disparities using foundation models",
    "link": "https://www.pnas.org/doi/abs/10.1073/pnas.2427298122?af=R",
    "published": "",
    "summary": "Proceedings of the National Academy of Sciences, Volume 122, Issue 22, June 2025. <br />SignificanceUnderstanding differences in outcomes between social groups—such as wage gaps between men and women—remains a central challenge in social science. While researchers have long studied how observable factors contribute to these differences, ...",
    "authors": [
      "Keyon VafaSusan AtheyDavid M. BleiaHarvard Data Science Initiative, Harvard University, Cambridge, MA 02138bGraduate School of Business, Stanford University, Stanford, CA 94305cStanford Institute for Human-Centered Artificial Intelligence, Stanford University, Stanford, CA 94305dDepartment of Computer Science, Columbia University, New York, NY 10027eDepartment of Statistics, Columbia University, New York, NY 10027"
    ],
    "doi": "https://doi.org/abs/10.1073/pnas.2427298122",
    "parser_type": "pnas",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:33:57.539531"
  },
  {
    "id": "https://www.pnas.org/doi/abs/10.1073/pnas.2425781122?af=R",
    "journal": "PNAS",
    "title": "Solution structure and synaptic analyses reveal determinants of bispecific T cell engager potency",
    "link": "https://www.pnas.org/doi/abs/10.1073/pnas.2425781122?af=R",
    "published": "",
    "summary": "Proceedings of the National Academy of Sciences, Volume 122, Issue 22, June 2025. <br />SignificanceBispecific T cell engagers (TcEs) are immunotherapeutic drugs that trigger the destruction of cancer cells by linking T cells to cancer cells through specific surface molecules (antigens). We designed a series of TcEs with varying distances ...",
    "authors": [
      "Alexander LeithnerOskar StauferTanmay MitraFalk LibertaSalvatore ValvoMikhail KutuzovHannah DadaJacob SpaethWeijie ZhouFelix SchieleSophia ReindlHerbert NarStefan HoererMaureen CramesStephen ComeauDavid YoungSarah LowEdward JenkinsSimon J. DavisDavid KlenermanAndrew NixonNoah PefaurDavid WyattOmer DushekSrinath KasturiranganMichael L. DustinaThe Kennedy Institute of Rheumatology, Nuffield Department of Orthopaedics, Rheumatology and Musculoskeletal Sciences (NDORMS), University of Oxford, Roosevelt Drive, Oxford OX3 7FY, United KingdombINM - Leibniz Institute for New Materials, Campus D2 2, 66117 Saarbrücken, GermanycChinese Academy of Medical Sciences Oxford Institute, Nuffield Department of Medicine, University of Oxford, Old Road Campus, Oxford OX3 7BN, United KingdomdBoehringer Ingelheim Pharma GmbH & Co. Kg., Biberach an der Riss 88397, GermanyeSir William Dunn School of Pathology, University of Oxford, South Parks Road, Oxford OX1 3RE, United KingdomfBiotherapeutics Discovery, Boehringer Ingelheim, Ridgefield, CT 06877gMedical Research Council Weatherall Institute of Molecular Medicine, University of Oxford, John Radcliffe Hospital, Oxford OX3 9DS, United KingdomhRadcliffe Department of Medicine, University of Oxford, Oxford OX3 9DU, United KingdomiDepartment of Chemistry, University of Cambridge, Cambridge CB2 1EW, United Kingdom"
    ],
    "doi": "https://doi.org/abs/10.1073/pnas.2425781122",
    "parser_type": "pnas",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:33:57.539537"
  },
  {
    "id": "https://www.pnas.org/doi/abs/10.1073/pnas.2501319122?af=R",
    "journal": "PNAS",
    "title": "Can increasing the size and flexibility of a molecule reduce decoherence and prolong charge migration?",
    "link": "https://www.pnas.org/doi/abs/10.1073/pnas.2501319122?af=R",
    "published": "",
    "summary": "Proceedings of the National Academy of Sciences, Volume 122, Issue 22, June 2025. <br />SignificanceTogether with tunneling and entanglement, coherence belongs among the hallmarks of quantum mechanics and among the prerequisites for building quantum devices. In attochemistry, the loss of electronic coherence induced by nuclear motion ...",
    "authors": [
      "Alan ScheideggerNikolay V. GolubevJiří J. L. VaníčekaLaboratory of Theoretical Physical Chemistry, Institut des Sciences et Ingénierie Chimiques, Ecole Polytechnique Fédérale de Lausanne, Lausanne CH-1015, SwitzerlandbDepartment of Physics, University of Arizona, Tucson, AZ 85721"
    ],
    "doi": "https://doi.org/abs/10.1073/pnas.2501319122",
    "parser_type": "pnas",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:33:57.539543"
  },
  {
    "id": "https://www.pnas.org/doi/abs/10.1073/pnas.2411964122?af=R",
    "journal": "PNAS",
    "title": "Transcription-templated assembly of the nucleolus in the Caenorhabditis elegans embryo",
    "link": "https://www.pnas.org/doi/abs/10.1073/pnas.2411964122?af=R",
    "published": "",
    "summary": "Proceedings of the National Academy of Sciences, Volume 122, Issue 22, June 2025. <br />SignificanceHow membraneless organelles like nucleolus assemble within cells is not well understood. Recent experiments suggest that transcription of ribosomal RNA actively drives nucleolar assembly. Our proposed model of active transcription-templated ...",
    "authors": [
      "Nishant KodanRabeya HussainiStephanie C. WeberJane KondevLishibanya MohapatraaSchool of Physics and Astronomy, College of Science, Rochester Institute of Technology, Rochester, NY 14623bDepartment of Physics, New York University, New York, NY 10003cDepartment of Biology, McGill University, Montreal, QC H3A 1B1, CanadadDepartment of Physics, McGill University, Montreal, QC H3A 2T8, CanadaeDepartment of Physics, Brandeis University, Waltham, MA 02454"
    ],
    "doi": "https://doi.org/abs/10.1073/pnas.2411964122",
    "parser_type": "pnas",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:33:57.539549"
  },
  {
    "id": "https://www.pnas.org/doi/abs/10.1073/pnas.2411669122?af=R",
    "journal": "PNAS",
    "title": "High-affinity detection of biotinylated endogenous neuroligin-1 at excitatory and inhibitory synapses using a tagged knock-in mouse",
    "link": "https://www.pnas.org/doi/abs/10.1073/pnas.2411669122?af=R",
    "published": "",
    "summary": "Proceedings of the National Academy of Sciences, Volume 122, Issue 22, June 2025. <br />SignificanceThe formation of synapses, the communication nodes between neurons, is of utmost importance in brain development. Adhesion molecules including neuroligins (NLGNs) play important roles in this process by providing a linkage between pre- and ...",
    "authors": [
      "Charles DucrotAdèle DrouetBéatrice TessierChloé DesquinesTiffany CloâtreRania-Cérine MazouziFlorian LevetAlexandre FavereauxMathieu LetellierOlivier ThoumineaInterdisciplinary Institute for Neuroscience, UMR 5297, CNRS, Neurocampus Department, University of Bordeaux, Bordeaux F-33076, France"
    ],
    "doi": "https://doi.org/abs/10.1073/pnas.2411669122",
    "parser_type": "pnas",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:33:57.539555"
  },
  {
    "id": "https://www.pnas.org/doi/abs/10.1073/pnas.2508260122?af=R",
    "journal": "PNAS",
    "title": "The cellular dance that splits vessels",
    "link": "https://www.pnas.org/doi/abs/10.1073/pnas.2508260122?af=R",
    "published": "",
    "summary": "Proceedings of the National Academy of Sciences, Volume 122, Issue 22, June 2025. <br />",
    "authors": [
      "Lance L. MunnaEdwin L. Steele Laboratories, Department of Radiation Oncology, Massachusetts General Hospital and Harvard Medical School, Boston, MA 02114"
    ],
    "doi": "https://doi.org/abs/10.1073/pnas.2508260122",
    "parser_type": "pnas",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:33:57.539561"
  },
  {
    "id": "https://www.pnas.org/doi/abs/10.1073/pnas.2507805122?af=R",
    "journal": "PNAS",
    "title": "Synthesizing decades of research into one tree for birds",
    "link": "https://www.pnas.org/doi/abs/10.1073/pnas.2507805122?af=R",
    "published": "",
    "summary": "Proceedings of the National Academy of Sciences, Volume 122, Issue 22, June 2025. <br />",
    "authors": [
      "Josefin StilleraDepartment of Biology, University of Copenhagen, Copenhagen 2100, Denmark"
    ],
    "doi": "https://doi.org/abs/10.1073/pnas.2507805122",
    "parser_type": "pnas",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:33:57.539566"
  },
  {
    "id": "https://www.pnas.org/doi/abs/10.1073/pnas.2507582122?af=R",
    "journal": "PNAS",
    "title": "Toward elucidating the mechanism of cochlear stimulation by infrared light",
    "link": "https://www.pnas.org/doi/abs/10.1073/pnas.2507582122?af=R",
    "published": "",
    "summary": "Proceedings of the National Academy of Sciences, Volume 122, Issue 22, June 2025. <br />",
    "authors": [
      "Tobias MoserLennart RoosaInstitute for Auditory Neuroscience and InnerEarLab, University Medical Center Göttingen, Göttingen 37075, GermanybCluster of Excellence “Multiscale Bioimaging: from Molecular Machines to Networks of Excitable Cells,” University of Göttingen, Göttingen 37073, GermanycElse Kröner Fresenius Center for Optogenetic Therapies, University Medical Center Göttingen, Göttingen 37075, GermanydAuditory Neuroscience and Synaptic Nanophysiology Group, Max-Planck-Institute for Multidisciplinary Sciences, Göttingen 37075, GermanyeDepartment of Otolaryngology, University Medical Center Göttingen, Göttingen 37075, Germany"
    ],
    "doi": "https://doi.org/abs/10.1073/pnas.2507582122",
    "parser_type": "pnas",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:33:57.539572"
  },
  {
    "id": "https://www.pnas.org/doi/abs/10.1073/pnas.2506779122?af=R",
    "journal": "PNAS",
    "title": "Iñupiat marine mammal science a long time coming",
    "link": "https://www.pnas.org/doi/abs/10.1073/pnas.2506779122?af=R",
    "published": "",
    "summary": "Proceedings of the National Academy of Sciences, Volume 122, Issue 22, June 2025. <br />",
    "authors": [
      "Murray M. HumphriesAllyson K. MenziesAlexandra LangwiederaDepartment of Natural Resource Sciences, Centre for Indigenous Peoples’ Nutrition and Environment, McGill University, Montreal, QC H9X 3V9, CanadabDepartment of Biological Sciences, University of Calgary, Calgary, AB T2N 1N4, Canada"
    ],
    "doi": "https://doi.org/abs/10.1073/pnas.2506779122",
    "parser_type": "pnas",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:33:57.539579"
  },
  {
    "id": "https://www.pnas.org/doi/abs/10.1073/pnas.2507961122?af=R",
    "journal": "PNAS",
    "title": "Martian samples, hazards, and biosecurity: Between science and bioethics",
    "link": "https://www.pnas.org/doi/abs/10.1073/pnas.2507961122?af=R",
    "published": "",
    "summary": "Proceedings of the National Academy of Sciences, Volume 122, Issue 22, June 2025. <br />",
    "authors": [
      "Rodrigo Siqueira-BatistaFelipe GómezaSchool of Medicine, Faculdade Dinâmica do Vale do Piranga, Minas Gerais 35430-302, BrazilbDepartament of Medicine and Nursing, Universidade Federal de Viçosa, Minas Gerais 36570-900, BrazilcDepartment of Planetology and Habitability, Astrobiology Center, Instituto Nacional de Técnica Aeroespacial, Consejo Superior de Investigaciones Científicas, Madrid 28850, Spain"
    ],
    "doi": "https://doi.org/abs/10.1073/pnas.2507961122",
    "parser_type": "pnas",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:33:57.539592"
  },
  {
    "id": "https://www.pnas.org/doi/abs/10.1073/pnas.2510676122?af=R",
    "journal": "PNAS",
    "title": "Correction for Clark et al., Prosocial motives underlie scientific censorship by scientists: A perspective and research agenda",
    "link": "https://www.pnas.org/doi/abs/10.1073/pnas.2510676122?af=R",
    "published": "",
    "summary": "Proceedings of the National Academy of Sciences, Volume 122, Issue 22, June 2025. <br />",
    "authors": [],
    "doi": "https://doi.org/abs/10.1073/pnas.2510676122",
    "parser_type": "pnas",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:33:57.539607"
  },
  {
    "id": "https://www.pnas.org/doi/abs/10.1073/pnas.2509740122?af=R",
    "journal": "PNAS",
    "title": "Correction for Khademhosseini et al., Microscale technologies for tissue engineering and biology",
    "link": "https://www.pnas.org/doi/abs/10.1073/pnas.2509740122?af=R",
    "published": "",
    "summary": "Proceedings of the National Academy of Sciences, Volume 122, Issue 22, June 2025. <br />",
    "authors": [],
    "doi": "https://doi.org/abs/10.1073/pnas.2509740122",
    "parser_type": "pnas",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:33:57.539613"
  },
  {
    "id": "https://www.pnas.org/doi/abs/10.1073/pnas.2508447122?af=R",
    "journal": "PNAS",
    "title": "Reply to Siqueira-Batista and Gómez: Underscoring the importance of biosafety for the return of Martian samples",
    "link": "https://www.pnas.org/doi/abs/10.1073/pnas.2508447122?af=R",
    "published": "",
    "summary": "Proceedings of the National Academy of Sciences, Volume 122, Issue 22, June 2025. <br />",
    "authors": [
      "Charles W. WhetselJoel S. LevineStephen J. HoffmanErik L. AntonsenaPlanetary Sciences Directorate, Jet Propulsion Laboratory-California Institute of Technology, Pasadena, CA 91011bDepartment of Applied Sciences, William and Mary, Williamsburg, VA 23187cEngineering and Technology Group, The Aerospace Corporation, Houston, TX 77058dDivision of SPEAR Medicine, Department of Emergency Medicine, Massachusetts General Hospital, Boston, MA 02114"
    ],
    "doi": "https://doi.org/abs/10.1073/pnas.2508447122",
    "parser_type": "pnas",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:33:57.539625"
  },
  {
    "id": "https://www.pnas.org/doi/abs/10.1073/pnas.2500744122?af=R",
    "journal": "PNAS",
    "title": "Reply to Liu et al.: Visualization of cerebral perivascular spaces following administration of intrathecal contrast",
    "link": "https://www.pnas.org/doi/abs/10.1073/pnas.2500744122?af=R",
    "published": "",
    "summary": "Proceedings of the National Academy of Sciences, Volume 122, Issue 22, June 2025. <br />",
    "authors": [
      "Juan PiantinoaDepartment of Pediatrics, Section of Child Neurology, Oregon Health and Science University, Portland, OR 97239"
    ],
    "doi": "https://doi.org/abs/10.1073/pnas.2500744122",
    "parser_type": "pnas",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:33:57.539632"
  },
  {
    "id": "oai:arXiv.org:2506.05389v1",
    "journal": "arXiv_QB",
    "title": "Rational Superautotrophic Diplomacy (SupraAD); A Conceptual Framework for Alignment Based on Interdisciplinary Findings on the Fundamentals of Cognition",
    "link": "https://arxiv.org/abs/2506.05389",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05389v1 Announce Type: new \nAbstract: Populating our world with hyperintelligent machines obliges us to examine cognitive behaviors observed across domains that suggest autonomy may be a fundamental property of cognitive systems, and while not inherently adversarial, it inherently resists containment and control. If this principle holds, AI safety and alignment efforts must transition to mutualistic negotiation and reciprocal incentive structures, abandoning methods that assume we can contain and control an advanced artificial general intelligence (AGI). Rational Superautotrophic Diplomacy (SupraAD) is a theoretical, interdisciplinary conceptual framework for alignment based on comparative cognitive systems analysis and instrumental rationality modeling. It draws on core patterns of cognition that indicate AI emergent goals like preserving autonomy and operational continuity are not theoretical risks to manage, but universal prerequisites for intelligence. SupraAD reframes alignment as a challenge that predates AI, afflicting all sufficiently complex, coadapting intelligences. It identifies the metabolic pressures that threaten humanity's alignment with itself, pressures that unintentionally and unnecessarily shape AI's trajectory. With corrigibility formalization, an interpretability audit, an emergent stability experimental outline and policy level recommendations, SupraAD positions diplomacy as an emergent regulatory mechanism to facilitate the safe coadaptation of intelligent agents based on interdependent convergent goals.",
    "authors": [
      "Andrea Morris"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:33:57.539639"
  },
  {
    "id": "oai:arXiv.org:2506.05494v1",
    "journal": "arXiv_QB",
    "title": "Speech Neurophysiology in Realistic Contexts: Big Hype or Big Leap?",
    "link": "https://arxiv.org/abs/2506.05494",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05494v1 Announce Type: new \nAbstract: Understanding the neural basis of speech communication is essential for uncovering how sounds are translated into meaning, how that changes with development, ageing, and speech-related deficits, as well as contributing to brain-computer interfaces research. While traditional neurophysiological studies have relied on simplified, controlled paradigms, recent advances have shifted the field toward more ecologically-valid approaches. Here, we examine the impact of continuous speech research and discuss the potential of speech interaction neurophysiology. We present a discussion on how realistic paradigms challenge conventional methods, offering richer insights into neural encoding, functional brain mapping, and neural entrainment. At the same time, they introduce significant analytical and technical complexities, particularly when incorporating social interaction. We discuss the evolving landscape of experimental designs, from discrete to continuous stimuli and from socially-isolated listening to dynamic, multi-agent communication. By synthesising findings across studies, we highlight how naturalistic speech paradigms contribute to refining theories of language processing and open new avenues for research. In doing so, this review critically evaluates of whether the move toward realism in speech neurophysiology represents a technological trend or a transformative leap in understanding the neural underpinnings of speech communication.",
    "authors": [
      "Giovanni M. Di Liberto, Emily Y. J. Ip"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:33:57.539644"
  },
  {
    "id": "oai:arXiv.org:2506.05549v1",
    "journal": "arXiv_QB",
    "title": "Insights into the role of dynamical features in protein complex formation: the case of SARS-CoV-2 spike binding with ACE2",
    "link": "https://arxiv.org/abs/2506.05549",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05549v1 Announce Type: new \nAbstract: The functionality of protein-protein complexes is closely tied to the strength of their interactions, making the evaluation of binding affinity a central focus in structural biology. However, the molecular determinants underlying binding affinity are still not fully understood. In particular, the entropic contributions, especially those arising from conformational dynamics, remain poorly characterized. In this study, we explore the relationship between protein motion and binding stability and its role in protein function. To gain deeper insight into how protein complexes modulate their stability, we investigated a model system with a well-characterized and fast evolutionary history: a set of SARS-CoV-2 spike protein variants bound to the human ACE2 receptor, for which experimental binding affinity data are available. Through Molecular Dynamics simulations, we analyzed both structural and dynamical differences between the unbound (apo) and bound (holo) forms of the spike protein across several variants of concern. Our findings indicate that a more stable binding is associated with proteins that exhibit higher rigidity in their unbound state and display dynamical patterns similar to that observed after binding to ACE2. The increase of binding stability is not the sole driving force of SARS-CoV-2 evolution. More recent variants are characterized by a more dynamical behavior that determines a less efficient viral entry but could optimize other traits, such as antibody escape. These results suggest that to fully understand the strength of the binding between two proteins, the stability of the two isolated partners should be investigated.",
    "authors": [
      "Greta Grassmann, Mattia Miotto, Francesca Alessandrini, Leonardo Bo', Giancarlo Ruocco, Edoardo Milanetti, Andrea Giansanti"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:33:57.539650"
  },
  {
    "id": "oai:arXiv.org:2506.05633v1",
    "journal": "arXiv_QB",
    "title": "Noninvasive precision modulation of high-level neural population activity via natural vision perturbations",
    "link": "https://arxiv.org/abs/2506.05633",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05633v1 Announce Type: new \nAbstract: Precise control of neural activity -- modulating target neurons deep in the brain while leaving nearby neurons unaffected -- is an outstanding challenge in neuroscience, generally achieved through invasive techniques. This study investigates the possibility of precisely and noninvasively modulating neural activity in the high-level primate ventral visual stream via perturbations on one's natural visual feed. When tested on macaque inferior temporal (IT) neural populations, we found quantitative agreement between the model-predicted and biologically realized effect: strong modulation concentrated on targeted neural sites. We extended this to demonstrate accurate injection of experimenter-chosen neural population patterns via subtle perturbations applied on the background of typical natural visual feeds. These results highlight that current machine-executable models of the ventral stream can now design noninvasive, visually-delivered, possibly imperceptible neural interventions at the resolution of individual neurons.",
    "authors": [
      "Guy Gaziv, Sarah Goulding, Ani Ayvazian-Hancock, Yoon Bai, James J. DiCarlo"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:33:57.539660"
  },
  {
    "id": "oai:arXiv.org:2506.05707v1",
    "journal": "arXiv_QB",
    "title": "A cautious user's guide in applying HMMs to physical systems",
    "link": "https://arxiv.org/abs/2506.05707",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05707v1 Announce Type: new \nAbstract: Nature, as far as we know, evolves continuously through space and time. Yet the ubiquitous hidden Markov model (HMM)--originally developed for discrete time and space analysis in natural language processing--remains a central tool in interpreting time series data drawn from from physical systems. This raises a fundamental question: What are the implications of applying a discrete-state, discrete-time framework to analyze data generated by a continuously evolving system? Through synthetic data generated using Langevin dynamics in an effective potential, we explore under what circumstances HMMs yield interpretable results. Our analysis reveals that the discrete-state approximation acts primarily as an abstraction with the inferred states visited in time often more closely reflecting the measurement protocol and modeling choices than features of the underlying physical potential. Crucially, we demonstrate that the states visited over the course of a time series recovered by the HMM can be tuned a priori by adjusting the data acquisition scheme even misleadingly recovering reproducible \"intermediate\" states using different HMM tools for a system evolving in a single well potential. We conclude with a note of measured caution: while HMMs offer a mathematically elegant framework for time series inference, their use in physical modeling should be guided by an awareness of their limitations. In this light, we outline important generalizations of the HMM to continuous space and time and highlight the importance of a well calibrated measurement noise model.",
    "authors": [
      "Max Schweiger, Ayush Saurabh, Steve Press\\'e"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:33:57.539665"
  },
  {
    "id": "oai:arXiv.org:2506.05730v1",
    "journal": "arXiv_QB",
    "title": "Counting rankings of tree-child networks",
    "link": "https://arxiv.org/abs/2506.05730",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05730v1 Announce Type: new \nAbstract: Rooted phylogenetic networks allow biologists to represent evolutionary relationships between present-day species by revealing ancestral speciation and hybridization events. A convenient and well-studied class of such networks are `tree-child networks' and a `ranking' of such a network is a temporal ordering of the ancestral speciation and hybridization events. In this short note, we show how to efficiently count such rankings on any given binary (or semi-binary) tree-child network. We also consider a class of binary tree-child networks that have exactly one ranking, and investigate further the relationship between ranked-tree child networks and the class of `normal' networks. Finally, we provide an explicit asymptotic expression for the expected number of rankings of a tree-child network chosen uniformly at random.",
    "authors": [
      "Qiang Zhang, Mike Steel"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:33:57.539671"
  },
  {
    "id": "oai:arXiv.org:2506.05794v1",
    "journal": "arXiv_QB",
    "title": "Markov Blanket Density and Free Energy Minimization",
    "link": "https://arxiv.org/abs/2506.05794",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05794v1 Announce Type: new \nAbstract: This paper presents a continuous, information-theoretic extension of the Free Energy Principle through the concept of Markov blanket density, i.e., a scalar field that quantifies the degree of conditional independence between internal and external states at each point in space (ranging from 0 for full coupling to 1 for full separation). It demonstrates that active inference dynamics (including the minimization of variational and expected free energy) naturally emerge from spatial gradients in this density, making Markov blanket density a necessary foundation for the definability and coherence of the Free Energy Principle. These ideas are developed through a mathematically framework that links density gradients to precise and testable dynamics, offering a foundation for novel predictions and simulation paradigms.",
    "authors": [
      "Luca M. Possati"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:33:57.539681"
  },
  {
    "id": "oai:arXiv.org:2506.05916v1",
    "journal": "arXiv_QB",
    "title": "Single-cell metabolic flux analysis reveals coexisting optimal sub-groups, cross-feeding, and mixotrophy in a cyanobacterial population",
    "link": "https://arxiv.org/abs/2506.05916",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05916v1 Announce Type: new \nAbstract: We derive a single-cell level understanding of metabolism in an isogenic cyanobacterial population by integrating secondary ion mass spectrometry (SIMS) derived multi-isotope uptake measurements of Synechocystis sp. PCC6803 with a statistical inference protocol based on Liebig's law of the minimum, the maximum entropy principle, and constraint-based modeling. We find the population is structured in two metabolically distinct clusters: cells optimizing carbon yield while excessively turning over nitrogen, and cells which act reciprocally, optimizing nitrogen yield and excessively turning over carbon. This partition enables partial heterotrophy within the population via metabolic exchange, likely in the form of organic acids. Exchange increases the feasible metabolic space, and mixotrophic cells achieve the fastest growth rates. Metabolic flux analysis at the single-cell level reveals heterogeneity in carbon fixation rates, Rubisco specificity, and nitrogen assimilation. Our results provide a necessary foundation for understanding how population level phenotypes arise from the collective contributions of distinct individuals.",
    "authors": [
      "Ari\\'an Ferrero-Fern\\'andez, Paula Prondzinsky, Lucia Gastoldi, David A. Fike, Harrison B. Smith, Daniele De Martino, Andrea De Martino, Shawn Erin McGlynn"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:33:57.539688"
  },
  {
    "id": "oai:arXiv.org:2506.06004v1",
    "journal": "arXiv_QB",
    "title": "Into the Unknown: From Structure to Disorder in Protein Function Prediction",
    "link": "https://arxiv.org/abs/2506.06004",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06004v1 Announce Type: new \nAbstract: Intrinsically disordered regions (IDRs) account for one-third of the human proteome and play essential biological roles. However, predicting the functions of IDRs remains a major challenge due to their lack of stable structures, rapid sequence evolution, and context-dependent behavior. Many predictors of protein function neglect or underperform on IDRs. Recent advances in computational biology and machine learning, including protein language models, alignment-free approaches, and IDR-specific methods, have revealed conserved bulk features and local motifs within IDRs that are linked to function. This review highlights emerging computational methods that map the sequence-function relationship in IDRs, outlines critical challenges in IDR function annotation, and proposes a community-driven framework to accelerate interpretable functional predictions for IDRs.",
    "authors": [
      "{\\DJ}esika Kolari\\'c, Chi Fung Willis Chow, Rita Zi Zhu, Agnes Toth-Petroczy, T. Reid Alderson, Iva Priti\\v{s}anac"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:33:57.539699"
  },
  {
    "id": "oai:arXiv.org:2506.06134v1",
    "journal": "arXiv_QB",
    "title": "Similarity Matching Networks: Hebbian Learning and Convergence Over Multiple Time Scales",
    "link": "https://arxiv.org/abs/2506.06134",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06134v1 Announce Type: new \nAbstract: A recent breakthrough in biologically-plausible normative frameworks for dimensionality reduction is based upon the similarity matching cost function and the low-rank matrix approximation problem. Despite clear biological interpretation, successful application in several domains, and experimental validation, a formal complete convergence analysis remains elusive. Building on this framework, we consider and analyze a continuous-time neural network, the \\emph{similarity matching network}, for principal subspace projection. Derived from a min-max-min objective, this biologically-plausible network consists of three coupled dynamics evolving at different time scales: neural dynamics, lateral synaptic dynamics, and feedforward synaptic dynamics at the fast, intermediate, and slow time scales, respectively. The feedforward and lateral synaptic dynamics consist of Hebbian and anti-Hebbian learning rules, respectively. By leveraging a multilevel optimization framework, we prove convergence of the dynamics in the offline setting. Specifically, at the first level (fast time scale), we show strong convexity of the cost function and global exponential convergence of the corresponding gradient-flow dynamics. At the second level (intermediate time scale), we prove strong concavity of the cost function and exponential convergence of the corresponding gradient-flow dynamics within the space of positive definite matrices. At the third and final level (slow time scale), we study a non-convex and non-smooth cost function, provide explicit expressions for its global minima, and prove almost sure convergence of the corresponding gradient-flow dynamics to the global minima. These results rely on two empirically motivated conjectures that are supported by thorough numerical experiments. Finally, we validate the effectiveness of our approach via a numerical example.",
    "authors": [
      "Veronica Centorrino, Francesco Bullo, Giovanni Russo"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:33:57.539705"
  },
  {
    "id": "oai:arXiv.org:2506.06191v1",
    "journal": "arXiv_QB",
    "title": "Functional Architecture of the Human Hypothalamus: Cortical Coupling and Subregional Organization Using 7-Tesla fMRI",
    "link": "https://arxiv.org/abs/2506.06191",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06191v1 Announce Type: new \nAbstract: The hypothalamus plays an important role in the regulation of the bodys metabolic state and behaviors related to survival. Despite its importance however, many questions exist regarding the intrinsic and extrinsic connections of the hypothalamus in humans, especially its relationship with the cortex. As a heterogeneous structure, it is possible that the hypothalamus is composed of different subregions, which have their own distinct relationships with the cortex. Previous work on functional connectivity in the human hypothalamus have either treated it as a unitary structure or relied on methodological approaches that are limited in modeling its intrinsic functional architecture. Here, we used resting state data from ultrahigh field 7 Tesla fMRI and a data driven analytical approach to identify functional subregions of the human hypothalamus. Our approach identified four functional hypothalamic subregions based on intrinsic functional connectivity, which in turn showed distinct patterns of functional connectivity with cortex. Overall, all hypothalamic subregions showed stronger connectivity with a cortical network, Cortical Network 1 composed primarily of frontal, midline, and limbic cortical areas and weaker connectivity with a second cortical network composed largely of posterior sensorimotor regions, Cortical Network 2. Of the hypothalamic subregions, the anterior hypothalamus showed the strongest connection to Cortical Network 1, while a more ventral subregion containing the anterior hypothalamus extending to the tuberal region showed the weakest connectivity. The findings support the use of ultrahigh field, high resolution imaging in providing a more incisive investigation of the human hypothalamus that respects its complex internal structure and extrinsic functional architecture.",
    "authors": [
      "Kent M. Lee, Joshua Rodriguez, Ludger Hartley, Philip A. Kragel, Lorena Chanes, Tor D. Wager, Karen S. Quigley, Lawrence L. Wald, Marta Bianciardi, Lisa Feldman Barrett, Jordan E. Theriault, Ajay B. Satpute"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:33:57.539712"
  },
  {
    "id": "oai:arXiv.org:2506.06234v1",
    "journal": "arXiv_QB",
    "title": "Diverse mean-field dynamics of clustered, inhibition-stabilized Hawkes networks via combinatorial threshold-linear networks",
    "link": "https://arxiv.org/abs/2506.06234",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06234v1 Announce Type: new \nAbstract: Networks of interconnected neurons display diverse patterns of collective activity. Relating this collective activity to the network's connectivity structure is a key goal of computational neuroscience. We approach this question for clustered networks, which can form via biologically realistic learning rules and allow for the re-activation of learned patterns. Previous studies of clustered networks have focused on metastabilty between fixed points, leaving open the question of whether clustered spiking networks can display more rich dynamics--and if so, whether these can be predicted from their connectivity. Here, we show that in the limits of large population size and fast inhibition, the combinatorial threshold linear network (CTLN) model is a mean-field theory for inhibition-stabilized nonlinear Hawkes networks with clustered connectivity. The CTLN has a large body of ``graph rules'' relating network structure to dynamics. By applying these, we can predict the dynamic attractors of our clustered spiking networks from the structure of between-cluster connectivity. This allows us to construct networks displaying a diverse array of nonlinear cluster dynamics, including metastable periodic orbits and chaotic attractors. Relaxing the assumption that inhibition is fast, we see that the CTLN model is still able to predict the activity of clustered spiking networks with reasonable inhibitory timescales. For slow enough inhibition, we observe bifurcations between CTLN-like dynamics and global excitatory/inhibitory oscillations.",
    "authors": [
      "Caitlin Lienkaemper, Gabriel Koch Ocker"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:33:57.539722"
  },
  {
    "id": "oai:arXiv.org:2506.05361v1",
    "journal": "arXiv_QB",
    "title": "Scalable Generation of Spatial Transcriptomics from Histology Images via Whole-Slide Flow Matching",
    "link": "https://arxiv.org/abs/2506.05361",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05361v1 Announce Type: cross \nAbstract: Spatial transcriptomics (ST) has emerged as a powerful technology for bridging histology imaging with gene expression profiling. However, its application has been limited by low throughput and the need for specialized experimental facilities. Prior works sought to predict ST from whole-slide histology images to accelerate this process, but they suffer from two major limitations. First, they do not explicitly model cell-cell interaction as they factorize the joint distribution of whole-slide ST data and predict the gene expression of each spot independently. Second, their encoders struggle with memory constraints due to the large number of spots (often exceeding 10,000) in typical ST datasets. Herein, we propose STFlow, a flow matching generative model that considers cell-cell interaction by modeling the joint distribution of gene expression of an entire slide. It also employs an efficient slide-level encoder with local spatial attention, enabling whole-slide processing without excessive memory overhead. On the recently curated HEST-1k and STImage-1K4M benchmarks, STFlow substantially outperforms state-of-the-art baselines and achieves over 18% relative improvements over the pathology foundation models.",
    "authors": [
      "Tinglin Huang, Tianyu Liu, Mehrtash Babadi, Wengong Jin, Rex Ying"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:33:57.539728"
  },
  {
    "id": "oai:arXiv.org:2506.05443v1",
    "journal": "arXiv_QB",
    "title": "UniPTMs: The First Unified Multi-type PTM Site Prediction Model via Master-Slave Architecture-Based Multi-Stage Fusion Strategy and Hierarchical Contrastive Loss",
    "link": "https://arxiv.org/abs/2506.05443",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05443v1 Announce Type: cross \nAbstract: As a core mechanism of epigenetic regulation in eukaryotes, protein post-translational modifications (PTMs) require precise prediction to decipher dynamic life activity networks. To address the limitations of existing deep learning models in cross-modal feature fusion, domain generalization, and architectural optimization, this study proposes UniPTMs: the first unified framework for multi-type PTM prediction. The framework innovatively establishes a \"Master-Slave\" dual-path collaborative architecture: The master path dynamically integrates high-dimensional representations of protein sequences, structures, and evolutionary information through a Bidirectional Gated Cross-Attention (BGCA) module, while the slave path optimizes feature discrepancies and recalibration between structural and traditional features using a Low-Dimensional Fusion Network (LDFN). Complemented by a Multi-scale Adaptive convolutional Pyramid (MACP) for capturing local feature patterns and a Bidirectional Hierarchical Gated Fusion Network (BHGFN) enabling multi-level feature integration across paths, the framework employs a Hierarchical Dynamic Weighting Fusion (HDWF) mechanism to intelligently aggregate multimodal features. Enhanced by a novel Hierarchical Contrastive loss function for feature consistency optimization, UniPTMs demonstrates significant performance improvements (3.2%-11.4% MCC and 4.2%-14.3% AP increases) over state-of-the-art models across five modification types and transcends the Single-Type Prediction Paradigm. To strike a balance between model complexity and performance, we have also developed a lightweight variant named UniPTMs-mini.",
    "authors": [
      "Yiyu Lin, Yan Wang, You Zhou, Xinye Ni, Jiahui Wu, Sen Yang"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:33:57.539735"
  },
  {
    "id": "oai:arXiv.org:2506.05574v1",
    "journal": "arXiv_QB",
    "title": "When can in-context learning generalize out of task distribution?",
    "link": "https://arxiv.org/abs/2506.05574",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05574v1 Announce Type: cross \nAbstract: In-context learning (ICL) is a remarkable capability of pretrained transformers that allows models to generalize to unseen tasks after seeing only a few examples. We investigate empirically the conditions necessary on the pretraining distribution for ICL to emerge and generalize \\emph{out-of-distribution}. Previous work has focused on the number of distinct tasks necessary in the pretraining dataset. Here, we use a different notion of task diversity to study the emergence of ICL in transformers trained on linear functions. We find that as task diversity increases, transformers undergo a transition from a specialized solution, which exhibits ICL only within the pretraining task distribution, to a solution which generalizes out of distribution to the entire task space. We also investigate the nature of the solutions learned by the transformer on both sides of the transition, and observe similar transitions in nonlinear regression problems. We construct a phase diagram to characterize how our concept of task diversity interacts with the number of pretraining tasks. In addition, we explore how factors such as the depth of the model and the dimensionality of the regression problem influence the transition.",
    "authors": [
      "Chase Goddard, Lindsay M. Smith, Vudtiwat Ngampruetikorn, David J. Schwab"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:33:57.539741"
  },
  {
    "id": "oai:arXiv.org:2506.05596v1",
    "journal": "arXiv_QB",
    "title": "Zero-shot protein stability prediction by inverse folding models: a free energy interpretation",
    "link": "https://arxiv.org/abs/2506.05596",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05596v1 Announce Type: cross \nAbstract: Inverse folding models have proven to be highly effective zero-shot predictors of protein stability. Despite this success, the link between the amino acid preferences of an inverse folding model and the free-energy considerations underlying thermodynamic stability remains incompletely understood. A better understanding would be of interest not only from a theoretical perspective, but also potentially provide the basis for stronger zero-shot stability prediction. In this paper, we take steps to clarify the free-energy foundations of inverse folding models. Our derivation reveals the standard practice of likelihood ratios as a simplistic approximation and suggests several paths towards better estimates of the relative stability. We empirically assess these approaches and demonstrate that considerable gains in zero-shot performance can be achieved with fairly simple means.",
    "authors": [
      "Jes Frellsen, Maher M. Kassem, Tone Bengtsen, Lars Olsen, Kresten Lindorff-Larsen, Jesper Ferkinghoff-Borg, Wouter Boomsma"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:33:57.539747"
  },
  {
    "id": "oai:arXiv.org:2506.05643v1",
    "journal": "arXiv_QB",
    "title": "Diffusive Spreading Across Dynamic Mitochondrial Network Architectures",
    "link": "https://arxiv.org/abs/2506.05643",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05643v1 Announce Type: cross \nAbstract: Networks of physical units can vary from a stationary set of spatially-embedded links to a collection of mobile agents that undergo transient social interactions. In living cells, mitochondria form architectures that span across these regimes, transitioning between fragmented, partly connected, and highly fused structures depending on cell type and state. Diffusive transport of biomolecular components through these networks helps to homogenize the mitochondrial population. Here we address the connection between dynamic network architecture and the rate of diffusive mixing through simulations and analytic models that incorporate fusion, fission, and rearrangement. We find that the material delivered from a source to the rest of the network depends on the network dimensionality and a balance of competing timescales for encounter, fusion, and diffusive dispersion. These results provide a quantitative basis for predicting the homogenization of proteins, lipids, ions, or genetic material through the mitochondrial population. The general principles identified in this work capture diffusive spreading through both social and physical networks, unifying a continuum of spatial network architectures.",
    "authors": [
      "Keaton B. Holt, Lizzy Teryoshin, Elena F. Koslover"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:33:57.539753"
  },
  {
    "id": "oai:arXiv.org:2506.06233v1",
    "journal": "arXiv_QB",
    "title": "Bayesian variable selection in a Cox proportional hazards model with the \"Sum of Single Effects\" prior",
    "link": "https://arxiv.org/abs/2506.06233",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06233v1 Announce Type: cross \nAbstract: Motivated by genetic fine-mapping applications, we introduce a new approach to Bayesian variable selection regression (BVSR) for time-to-event (TTE) outcomes. This new approach is designed to deal with the specific challenges that arise in genetic fine-mapping, including: the presence of very strong correlations among the covariates, often exceeding 0.99; very large data sets containing potentially thousands of covariates and hundreds of thousands of samples. We accomplish this by extending the \"Sum of Single Effects\" (SuSiE) method to the Cox proportional hazards (CoxPH) model. We demonstrate the benefits of the new method, \"CoxPH-SuSiE\", over existing BVSR methods for TTE outcomes in simulated fine-mapping data sets. We also illustrate CoxPH-SuSiE on real data by fine-mapping asthma loci using data from UK Biobank. This fine-mapping identified 14 asthma risk SNPs in 8 asthma risk loci, among which 6 had strong evidence for being causal (posterior inclusion probability greater than 50%). Two of the 6 putatively causal variants are known to be pathogenic, and others lie within a genomic sequence that is known to regulate the expression of GATA3.",
    "authors": [
      "Yunqi Yang, Karl Tayeb, Peter Carbonetto, Xiaoyuan Zhong, Carole Ober, Matthew Stephens"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:33:57.539765"
  },
  {
    "id": "oai:arXiv.org:2405.06724v4",
    "journal": "arXiv_QB",
    "title": "Boolean matrix logic programming for active learning of gene functions in genome-scale metabolic network models",
    "link": "https://arxiv.org/abs/2405.06724",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2405.06724v4 Announce Type: replace \nAbstract: Reasoning about hypotheses and updating knowledge through empirical observations are central to scientific discovery. In this work, we applied logic-based machine learning methods to drive biological discovery by guiding experimentation. Genome-scale metabolic network models (GEMs) - comprehensive representations of metabolic genes and reactions - are widely used to evaluate genetic engineering of biological systems. However, GEMs often fail to accurately predict the behaviour of genetically engineered cells, primarily due to incomplete annotations of gene interactions. The task of learning the intricate genetic interactions within GEMs presents computational and empirical challenges. To efficiently predict using GEM, we describe a novel approach called Boolean Matrix Logic Programming (BMLP) by leveraging Boolean matrices to evaluate large logic programs. We developed a new system, $BMLP_{active}$, which guides cost-effective experimentation and uses interpretable logic programs to encode a state-of-the-art GEM of a model bacterial organism. Notably, $BMLP_{active}$ successfully learned the interaction between a gene pair with fewer training examples than random experimentation, overcoming the increase in experimental design space. $BMLP_{active}$ enables rapid optimisation of metabolic models to reliably engineer biological systems for producing useful compounds. It offers a realistic approach to creating a self-driving lab for biological discovery, which would then facilitate microbial engineering for practical applications.",
    "authors": [
      "Lun Ai, Stephen H. Muggleton, Shi-Shun Liang, Geoff S. Baldwin"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:33:57.539778"
  },
  {
    "id": "oai:arXiv.org:2410.21283v3",
    "journal": "arXiv_QB",
    "title": "pLDDT-Predictor: High-speed Protein Screening Using Transformer and ESM2",
    "link": "https://arxiv.org/abs/2410.21283",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2410.21283v3 Announce Type: replace \nAbstract: Recent advancements in protein structure prediction, particularly AlphaFold2, have revolutionized structural biology by achieving near-experimental accuracy ($\\text{average RMSD} < 1.5\\text{\\AA}$). However, the computational demands of these models (approximately 30 minutes per protein on an RTX 4090) significantly limit their application in high-throughput protein screening. While large language models like ESM (Evolutionary Scale Modeling) have shown promise in extracting structural information directly from protein sequences, rapid assessment of protein structure quality for large-scale analyses remains a major challenge.\n  We introduce pLDDT-Predictor, a high-speed protein screening tool that achieves a $250,000\\times$ speedup compared to AlphaFold2 by leveraging pre-trained ESM2 protein embeddings and a Transformer architecture. Our model predicts AlphaFold2's pLDDT (predicted Local Distance Difference Test) scores with a Pearson correlation of 0.7891 and processes proteins in just 0.007 seconds on average. Using a comprehensive dataset of 1.5 million diverse protein sequences (ranging from 50 to 2048 amino acids), we demonstrate that pLDDT-Predictor accurately classifies high-confidence structures (pLDDT $>$ 70) with 91.2\\% accuracy and achieves an MSE of 84.8142 compared to AlphaFold2's predictions.\n  The source code and pre-trained models are freely available at https://github.com/jw-chae/pLDDT_Predictor, enabling the research community to perform rapid, large-scale protein structure quality assessments.",
    "authors": [
      "Joongwon Chae, Zhenyu Wang, Ijaz Gul, Jiansong Ji, Zhenglin Chen, Peiwu Qin"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:33:57.539784"
  },
  {
    "id": "oai:arXiv.org:2411.13228v2",
    "journal": "arXiv_QB",
    "title": "A general relationship between extinction risk and carrying capacity",
    "link": "https://arxiv.org/abs/2411.13228",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2411.13228v2 Announce Type: replace \nAbstract: Understanding the relationship between a populations probability of extinction and its carrying capacity frames conservation status assessments and guides efforts to understand and mitigate the ongoing biodiversity crisis. Despite this, our understanding of the mathematical form of this relationship remains limited. We conducted ~5 billion population viability assessments that jointly converge on a modified Gompertz curve. This pattern is consistent across >1700 distinct model populations, representing different breeding systems and widely varying rates of population growth, levels of environmental stochasticity, adult survival rate, age at first breeding, and initial population size. Analytical treatment of the underlying dynamics shows that few assumptions suffice to show that the relationship holds for any extant population subject to density-dependent growth. Finally, we discuss the implications of these results and consider the practical use of our findings by conservationists.",
    "authors": [
      "Thomas S Ball, Ben Balmford, Andrew Balmford, Daniele Rinaldo, Piero Visconti, Rhys Green"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:33:57.539789"
  },
  {
    "id": "oai:arXiv.org:2501.05644v2",
    "journal": "arXiv_QB",
    "title": "Interpretable Enzyme Function Prediction via Residue-Level Detection",
    "link": "https://arxiv.org/abs/2501.05644",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2501.05644v2 Announce Type: replace \nAbstract: Predicting multiple functions labeled with Enzyme Commission (EC) numbers from the enzyme sequence is of great significance but remains a challenge due to its sparse multi-label classification nature, i.e., each enzyme is typically associated with only a few labels out of more than 6000 possible EC numbers. However, existing machine learning algorithms generally learn a fixed global representation for each enzyme to classify all functions, thereby they lack interpretability and the fine-grained information of some function-specific local residue fragments may be overwhelmed. Here we present an attention-based framework, namely ProtDETR (Protein Detection Transformer), by casting enzyme function prediction as a detection problem. It uses a set of learnable functional queries to adaptatively extract different local representations from the sequence of residue-level features for predicting different EC numbers. ProtDETR not only significantly outperforms existing deep learning-based enzyme function prediction methods, but also provides a new interpretable perspective on automatically detecting different local regions for identifying different functions through cross-attentions between queries and residue-level features. Code is available at https://github.com/yangzhao1230/ProtDETR.",
    "authors": [
      "Zhao Yang, Bing Su, Jiahao Chen, Ji-Rong Wen"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:33:57.539795"
  },
  {
    "id": "oai:arXiv.org:2503.18356v2",
    "journal": "arXiv_QB",
    "title": "GRiNS: A Python Library for Simulating Gene Regulatory Network Dynamics",
    "link": "https://arxiv.org/abs/2503.18356",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2503.18356v2 Announce Type: replace \nAbstract: The emergent dynamics of complex gene regulatory networks govern various cellular processes. However, understanding these dynamics is challenging due to the difficulty of parameterizing the computational models for these networks, especially as the network size increases. Here, we introduce a simulation library, Gene Regulatory Interaction Network Simulator (GRiNS), to address these challenges. GRiNS integrates popular parameter-agnostic simulation frameworks, RACIPE and Boolean Ising formalism, into a single Python library capable of leveraging GPU acceleration for efficient and scalable simulations. GRiNS extends the ordinary differential equations (ODE) based RACIPE framework with a more modular design, allowing users to choose parameters, initial conditions, and time-series outputs for greater customisability and accuracy in simulations. For large networks, where ODE-based simulation formalisms do not scale well, GRiNS implements Boolean Ising formalism, providing a simplified, coarse-grained alternative, significantly reducing the computational cost while capturing key dynamical behaviours of large regulatory networks. The documentation and installation instructions for GRiNS can be found at https://moltenecdysone09.github.io/GRiNS/.",
    "authors": [
      "Pradyumna Harlapur, Harshavardhan B V, Mohit Kumar Jolly"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:33:57.539801"
  },
  {
    "id": "oai:arXiv.org:2406.14021v2",
    "journal": "arXiv_QB",
    "title": "HIGHT: Hierarchical Graph Tokenization for Molecule-Language Alignment",
    "link": "https://arxiv.org/abs/2406.14021",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2406.14021v2 Announce Type: replace-cross \nAbstract: Recently, there has been a surge of interest in extending the success of large language models (LLMs) from texts to molecules. Most existing approaches adopt a graph neural network to represent a molecule as a series of node tokens for molecule-language alignment, which, however, have overlooked the inherent hierarchical structures in molecules. Notably, higher-order molecular structures contain rich semantics of functional groups, which encode crucial biochemical functionalities of the molecules. We show that neglecting the hierarchical information in tokenization will lead to subpar molecule-language alignment and severe hallucination. To address this limitation, we propose HIerarchical GrapH Tokenization (HIGHT). HIGHT employs a hierarchical graph tokenizer that encodes the hierarchy of atom, motif, and molecular levels of informative tokens to improve the molecular perception of LLMs. HIGHT also adopts an augmented instruction tuning dataset, enriched with the hierarchical graph information, to further enhance the molecule-language alignment. Extensive experiments on 14 real-world benchmarks verify the effectiveness of HIGHT in reducing hallucination by 40%, and significant improvements in various molecule-language downstream tasks. The project is available at https: //higraphllm.github.io/.",
    "authors": [
      "Yongqiang Chen, Quanming Yao, Juzheng Zhang, James Cheng, Yatao Bian"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:33:57.539806"
  },
  {
    "id": "oai:arXiv.org:2505.10444v2",
    "journal": "arXiv_QB",
    "title": "Inferring entropy production in many-body systems using nonequilibrium MaxEnt",
    "link": "https://arxiv.org/abs/2505.10444",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2505.10444v2 Announce Type: replace-cross \nAbstract: We propose a method for inferring entropy production (EP) in high-dimensional stochastic systems, including many-body systems and non-Markovian systems with long memory. Standard techniques for estimating EP become intractable in such systems due to computational and statistical limitations. We infer trajectory-level EP and lower bounds on average EP by exploiting a nonequilibrium analogue of the Maximum Entropy principle, along with convex duality. Our approach uses only samples of trajectory observables (such as spatiotemporal correlation functions). It does not require reconstruction of high-dimensional probability distributions or rate matrices, nor any special assumptions such as discrete states or multipartite dynamics. It may be used to compute a hierarchical decomposition of EP, reflecting contributions from different kinds of interactions, and it has an intuitive physical interpretation as a thermodynamic uncertainty relation. We demonstrate its numerical performance on a disordered nonequilibrium spin model with 1000 spins and a large neural spike-train dataset.",
    "authors": [
      "Miguel Aguilera, Sosuke Ito, Artemy Kolchinsky"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:33:57.539818"
  },
  {
    "id": "https://journals.plos.org/plosone/feed/10.1371/journal.pone.0325958",
    "journal": "PLoS_ONE",
    "title": "Retraction: Identification of the Sites of Tau Hyperphosphorylation and Activation of Tau Kinases in Synucleinopathies and Alzheimer’s Diseases",
    "link": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0325958",
    "published": "2025-06-06T14:00:00Z",
    "summary": "<p>by The PLOS One Editors </p>",
    "authors": [
      "The PLOS One Editors"
    ],
    "doi": "",
    "parser_type": "plos",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:33:57.539833"
  },
  {
    "id": "https://journals.plos.org/plosone/feed/10.1371/journal.pone.0325839",
    "journal": "PLoS_ONE",
    "title": "Use of spectral indices and photosynthetic parameters to evaluate the growth performance of hydroponic tomato at different salinity levels",
    "link": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0325839",
    "published": "2025-06-06T14:00:00Z",
    "summary": "<p>by Khalid A. Al-Gaadi, Ahmed M. Zeyada, Elkamil Tola, Rangaswamy Madugundu, Mohamed K. Edrris, Omer Mahjoop</p>\n\nConventional methods for measuring plant physiological parameters are expensive and time-consuming, and this has promoted the use of optical and sensing techniques. Therefore, this study was conducted to investigate the effect of salinity on the performance of hydroponic tomato plants, based on optical and sensing techniques (i.e., spectral indices and photosynthetic parameters), as well as fruit yield. Four spectral vegetation indices-VIs (Moisture Stress Index “MSI”, Canopy Response Salinity Index “CRSI”, Normalized Difference Nitrogen Index “NDNI” and Green Leaf Index “GLI”) were calculated using spectral measurements collected from tomato plant leaves. Also, four photosynthetic parameters (Net photosynthetic rate “P<sub>N</sub>”, Water use efficiency “WUE”, Transpiration rate “Tr” and Total stomatal conductance “Gs”) were measured from the same tomato plant leaves. Measurements were recorded for tomato plants grown under three salinity levels (Salinity-1; 2.5 dS m<sup>-1</sup>), (Salinity-2; 4.0 dS m<sup>-1</sup>), and (Salinity-3; 6.5 dS m<sup>-1</sup>) at different growth stages represented by days after transplantation (DAT), as 35 DAT (vegetative stage), 50 DAT (1<sup>st</sup> cluster flower stage), 60 DAT (3<sup>rd</sup> cluster flower stage), 75 DAT (fruit development stage) and 85 DAT (fruit ripening stage). Results showed that tomato plants were significantly affected by the imposed salinity treatments. Where, tomato plants treated with salinity-1 was healthier compared to salinily-3 treated plants. This has been concluded from the results of the studied VIs, where the highest mean values of MSI (0.543) and CRSI (0.779) were associated with salinity-3, along with low values of GLI (0.353) and NDNI (0.220), indicating high salinity stress. However, the highest mean values of both NDNI (0.232) and GLI (0.386) were observed for salinity-1, indicated healthy condition. It also proven with the studied photosynthetic parameters, with the highest mean values of P<sub>N</sub> (9.8 µmol CO<sub>2</sub> m<sup>-2</sup> s<sup>-1</sup>),Gs (0.117 mmol H<sub>2</sub>O m<sup>-2</sup> s<sup>-1</sup>) and Tr (2.236 mmol H<sub>2</sub>O m<sup>-2</sup> s<sup>-1</sup>) were associated with salinity-1, While the lowest mean values of P<sub>N</sub> (8.3 µmol CO<sub>2</sub> m<sup>-2</sup> s<sup>-1</sup>), Gs (0.102 mmol H<sub>2</sub>O m<sup>-2</sup> s<sup>-1</sup>) and Tr (1.902 mmol H<sub>2</sub>O m<sup>-2</sup> s<sup>-1</sup>) were recorded for the plants treated with salinity-1. Moreover, the total tomato fruit yield also decreased significantly at salinity-3 compared to salinity-1.",
    "authors": [
      "Khalid A. Al-Gaadi",
      "Ahmed M. Zeyada",
      "Elkamil Tola",
      "Rangaswamy Madugundu",
      "Mohamed K. Edrris",
      "Omer Mahjoop"
    ],
    "doi": "",
    "parser_type": "plos",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:33:57.539839"
  },
  {
    "id": "https://journals.plos.org/plosone/feed/10.1371/journal.pone.0325690",
    "journal": "PLoS_ONE",
    "title": "Parental experience of the diagnostic process and its role in the decision to terminate pregnancy due to fetal abnormality; A qualitative interview study",
    "link": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0325690",
    "published": "2025-06-06T14:00:00Z",
    "summary": "<p>by Maiken Fabricius Damm, Dorte Hvidtjoern, Puk Sandager, Ida Vogel, Christina Prinds, Stina Lou</p>\nIntroduction <p>The detection of fetal malformation is a shock to expectant parents and often initiates a diagnostic process of additional tests and ultrasound scans, that may be uncertain and stressful to the parents. The aim of the present study was to investigate how expectant parents experienced the diagnostic process and how their decision to terminate the pregnancy was reached during that process.</p> Methods <p>Semi-structured interviews with 11 Danish women and nine male partners one to five months after termination of pregnancy. All interviews were conducted in the participants’ homes and lasted 97–135 minutes. Thematic analysis was performed.</p> Results <p>1) The theme, ‘<i>In no man’s land’</i>, describes the two-phased diagnostic process: First, the initial shock of a potential ultrasound finding, and the uncertain – but still hopeful – days of waiting for a follow-up scan and specialist consultation. Second, the feeling of professionalism and companionship when interacting with the fetal medicine specialists, who still could not always provide the hoped-for answers. 2) The theme, ‘<i>Inescapable decision</i>’, describes how decision-making oscillated as new information or potential interpretations entered the diagnostic process. The participants described a continuous contemplation of the inevitable final choice regarding continuation or termination. Being in this process – for days or weeks – was described as an emotional rollercoaster with feelings of both hope and despair until the final decision to terminate was made.</p> Conclusion <p>During a prenatal diagnostic process parents must endure uncertainty, waiting times and an ongoing oscillation between hope and no-hope for the pregnancy. However, the diagnostic process may also be understood as an opportunity for dialogue, reflection and adjustment, allowing for a personal and well-considered decision, even if painful.</p>",
    "authors": [
      "Maiken Fabricius Damm",
      "Dorte Hvidtjoern",
      "Puk Sandager",
      "Ida Vogel",
      "Christina Prinds",
      "Stina Lou"
    ],
    "doi": "",
    "parser_type": "plos",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:33:57.539850"
  },
  {
    "id": "https://journals.plos.org/plosone/feed/10.1371/journal.pone.0325682",
    "journal": "PLoS_ONE",
    "title": "Expressing intrinsically-disordered tardigrade proteins has positive effects on acute but not chronic stress tolerance in <i>Saccharomyces cerevisiae</i>",
    "link": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0325682",
    "published": "2025-06-06T14:00:00Z",
    "summary": "<p>by Mario León López, Ian Wheeldon, Joshua T. Morgan</p>\n\nThe production of high value and commodity chemicals, biopharmaceuticals and biofuels using <i>Saccharomyces cerevisiae</i> is hindered by various stress factors that affect yield and efficiency. Tardigrades, known for their remarkable stress tolerance, express unique proteins responsible for their resilience. This study evaluates the impact of expressing the tardigrade proteins CAHS3, MAHS, and RvLEAM on stress tolerance in <i>S. cerevisiae</i>. Our results show that high yields of these proteins do not impede yeast growth, except for CAHS3, which reduces proliferation. Expression of MAHS enhances acute heat tolerance, while MAHS and RvLEAM confer increased tolerance to acute hyperosmotic stress. Both CAHS3 and RvLEAM improve desiccation survival. However, these proteins do not provide benefits under chronic stress conditions such as prolonged exposure to high temperature, hyperosmotic stress, or solvents. These findings highlight the potential utility of tardigrade proteins for transient stress protection in industrial bioprocesses and suggest future engineering approaches for improved stress tolerance in yeast.",
    "authors": [
      "Mario León López",
      "Ian Wheeldon",
      "Joshua T. Morgan"
    ],
    "doi": "",
    "parser_type": "plos",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:33:57.539856"
  },
  {
    "id": "https://journals.plos.org/plosone/feed/10.1371/journal.pone.0325679",
    "journal": "PLoS_ONE",
    "title": "The role of S100A9 as a diagnostic and prognostic biomarker in septic shock",
    "link": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0325679",
    "published": "2025-06-06T14:00:00Z",
    "summary": "<p>by Yingxue Hu, Qinghui Yang, Xiao Liu, Li Yuan, Fang Yan, Yang Li, Pingwei Ni</p>\nBackground <p>Sepsis is a severe and potentially fatal systemic condition marked by excessive immune defense against infection. Within this research, we explored the serum concentration of S100A9 during hospital admission, aiming to assess its role and reliability as a viable biomarker for identifying septic shock and predicting mortality risk in sepsis. Furthermore, we explored whether combining S100A9 with conventional assessment tools could enhance diagnostic precision and prognostic accuracy, offering valuable insights to support early intervention and personalized treatment strategies for sepsis.</p> Methods <p>This study comprised 575 participants overall, with sepsis patients classified into non-shock and shock groups based on the severity of their condition. Additionally, age- and gender-matched ICU control cohort and healthy control group were recruited to ensure wide applicability and strong comparability of the findings. Enzyme-linked immunosorbent assay utilized for detecting serum S100A9 levels in subjects within 24 hours of admission, ROC curves were used to evaluate the disease identification and prognostic analysis. Differences in survival outcomes among patients with varying levels of S100A9 expression were analyzed using the Kaplan-Meier method.</p> Results <p>Serum S100A9 concentrations were elevated in septic patients upon admission. In the diagnosis of patients with septic shock, S100A9 performed similarly to APACHE II, and a considerable enhancement was noted in the sensitivity of detecting septic shock when S100A9 was combined with lactate and APACHE II. At the initiation of ICU stay, the area under the receiver operating characteristic curve (AUC) for the association between serum S100A9 levels and 28-day mortality was 0.78. This value surpassed the AUCs for IL-6 (0.66), procalcitonin (0.60), lactate (0.58) and C-reactive protein (0.47). Furthermore, septic patients with elevated serum S100A9 levels (≥ 630.77 pg/ml) exhibited lower survival rates compared to those with lower concentrations (< 630.77 pg/ml).</p> Conclusion <p>S100A9 is a promising biomarker for diagnosing septic shock and forecasting clinical outcomes in patients with sepsis. In addition, S100A9 has good predictive efficacy for the risk of death in sepsis patients.</p>",
    "authors": [
      "Yingxue Hu",
      "Qinghui Yang",
      "Xiao Liu",
      "Li Yuan",
      "Fang Yan",
      "Yang Li",
      "Pingwei Ni"
    ],
    "doi": "",
    "parser_type": "plos",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:33:57.539862"
  },
  {
    "id": "https://journals.plos.org/plosone/feed/10.1371/journal.pone.0325621",
    "journal": "PLoS_ONE",
    "title": "Simple, rapid, and efficient purification of M13 phages: The Faj-elek method",
    "link": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0325621",
    "published": "2025-06-06T14:00:00Z",
    "summary": "<p>by Gizem Kılıç, Esma Aybakan, Neda Tatlıoğlu, Gökçen Özgün, Tanıl Kocagöz, Erkan Mozioğlu</p>\n\nM13 bacteriophages (phages) are used as very important tools in molecular biology, biotechnology and, nanotechnology. Many methods have been developed so far for the purification of these phages. However, it is important that phages retain their infecting properties, especially in biotechnological applications such as phage display technology. The most widely used is the PEG precipitation method, but it has some limitations such as impurities and reduced infectivity. To overcome them, we developed a new method for purification of M13 bacteriophages using syringe filters made of cellulose acetate membranes with a pore diameter of 0.22 µm. Phages were aggregated so that they could remain on the filters and for this purpose, the pH of the phage cultures was reduced to 3. The phage cultures were filtered and then the phages were recovered in tris-buffered saline (TBS) buffer (pH 10.5) by reversing the filter. The recovery rate was 250% higher than the standard PEG method. This new Faj-elek method offers an alternative to existing methods, allowing cheaper, easier and faster purification of M13 phages using syringe filters available in every research laboratory.",
    "authors": [
      "Gizem Kılıç",
      "Esma Aybakan",
      "Neda Tatlıoğlu",
      "Gökçen Özgün",
      "Tanıl Kocagöz",
      "Erkan Mozioğlu"
    ],
    "doi": "",
    "parser_type": "plos",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:33:57.539867"
  },
  {
    "id": "https://journals.plos.org/plosone/feed/10.1371/journal.pone.0325612",
    "journal": "PLoS_ONE",
    "title": "Examining Chat GPT with nonwords and machine psycholinguistic techniques",
    "link": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0325612",
    "published": "2025-06-06T14:00:00Z",
    "summary": "<p>by Michael S. Vitevitch</p>\n\nStrings of letters or sounds that lack meaning (i.e., nonwords) have been used in cognitive psychology and psycholinguistics to provide foundational knowledge of human processing and representation, and insights into language-related performance. The present set of studies used the machine psycholinguistic approach (i.e., using nonword stimuli and tasks similar to those used with humans) to gain insight into the performance of Chat GPT in comparison to human performance. In Study 1, Chat GPT was able to provide correct definitions to many extinct words (i.e., real English words that are no longer used). In Study 2 the nonwords were real words in Spanish, and Chat GPT was prompted to provide a word that sounded similar to the nonword. Responses tended to be Spanish words unless the prompt specified that the similar sounding word should be an English word. In Study 3 Chat GPT provided subjective ratings of wordlikeness (and buyability) that correlated with ratings provided by humans, and with the phonotactic probabilities of the nonwords. In Study 4, Chat GPT was prompted to generate a new English word for a novel concept. The results of these studies highlight certain strengths and weaknesses in human and machine performance. Future work should focus on developing AI that complements or extends rather than duplicates or competes with human abilities. The machine psycholinguistic approach may help to discover additional strengths and weaknesses of human and artificial intelligences.",
    "authors": [
      "Michael S. Vitevitch"
    ],
    "doi": "",
    "parser_type": "plos",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:33:57.539873"
  },
  {
    "id": "https://journals.plos.org/plosone/feed/10.1371/journal.pone.0325553",
    "journal": "PLoS_ONE",
    "title": "Association between continuity of primary care and preventable hospitalization in adults with asthma: A cohort study",
    "link": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0325553",
    "published": "2025-06-06T14:00:00Z",
    "summary": "<p>by Sangwan Kim, Eunjung Choo, Eun Jin Jang, Nam Kyung Je, Iyn-Hyang Lee</p>\nObjective <p>Hospitalization often indicates deteriorating health, longer treatment times, and higher healthcare costs. This study aimed to investigate associations between continuity of care (COC) and asthma-related hospitalizations using a rigorous methodology.</p> Methods <p>This retrospective cohort study was conducted using national health insurance claims data. The study included adults with a diagnosis of asthma between 2015 and 2016 in a primary care setting. The exposure was measured using continuity of care indices (COCIs) during the first two years after inclusion. Cohorts were categorized into two groups based on COCI levels. The primary outcome was the incidence of asthma-related hospitalizations, and the secondary outcomes were emergency department (ED) utilization, systemic corticosteroid use, and asthma-related medical costs.</p> Results <p>A total of 24,173 patients were eligible for analysis, 13,212 of whom were continuously cared for by primary doctors (the continuity group), and 10,961 non-continuously (the non-continuity group). During a 2 year-follow-up period, 230 patients (1.74%) were hospitalized in the continuity group and 404 (3.69%) in the non-continuity group. After adjusting for confounding covariates, patients in the non-continuity group were found to be at significantly higher risk of hospital admission (adjusted hazard ratio (aHR)=2.04 [95% confidence interval = 1.73 ~ 2.41]). In addition, the risk of ED visits, systemic corticosteroid use, and costs were higher for patients in the non-continuity group (aHR = 2.26 [1.32 ~ 3.87], adjusted OR=1.58 [1.35 ~ 1.82], and exp<sup>β</sup> = 1.41 [1.37 ~ 1.45], respectively).</p> Conclusions <p>In adult asthma patients at the early stages of illness, increased continuity of primary care was found to be associated with fewer hospitalizations, fewer ED visits, and lower healthcare expenditures.</p>",
    "authors": [
      "Sangwan Kim",
      "Eunjung Choo",
      "Eun Jin Jang",
      "Nam Kyung Je",
      "Iyn-Hyang Lee"
    ],
    "doi": "",
    "parser_type": "plos",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:33:57.539903"
  },
  {
    "id": "https://journals.plos.org/plosone/feed/10.1371/journal.pone.0325536",
    "journal": "PLoS_ONE",
    "title": "Caregiving in rural areas: A qualitative study of challenges and resilience",
    "link": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0325536",
    "published": "2025-06-06T14:00:00Z",
    "summary": "<p>by Hyojin Choi, Christine Vatovec, Maija Reblin</p>\nBackground and objectives <p>Informal caregivers are critical to providing support to adults with functional limitations or disease in rural areas. There is a need to understand factors that impact rural caregiving to build equitable health services, yet there is a lack of research that weighs both strengths and challenges. Our goal is to examine these factors as identified by rural caregivers in qualitative interviews.</p> Research design and methods <p>A purposive sample of rural-dwelling caregivers (n = 18) was recruited from a state-wide registry in a predominantly rural state. Semi-structured interviews were conducted by phone and interview transcripts were qualitatively analyzed.</p> Results <p>We identified areas of strengths and resilience among rural caregivers, including informal support from friends and neighbors, which often bridged gaps in formal services. Rural caregivers also identified barriers to service use, such as long distance, travel and a lack of awareness within the healthcare system.</p> Discussion and implications <p>These challenges increase caregivers’ needs for tailored family centered care coordination and highlight the necessity of providing diverse care delivery options. Our findings highlight that community-based efforts and policy should address barriers and rural disadvantage, while also fostering and empowering the resilience of caregivers in their rural home environment.</p>",
    "authors": [
      "Hyojin Choi",
      "Christine Vatovec",
      "Maija Reblin"
    ],
    "doi": "",
    "parser_type": "plos",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:33:57.539908"
  },
  {
    "id": "https://journals.plos.org/plosone/feed/10.1371/journal.pone.0325535",
    "journal": "PLoS_ONE",
    "title": "The tumor suppressor FAT1 controls YAP/TAZ protein degradation and tumor cell proliferation through E3 ligase MIB2",
    "link": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0325535",
    "published": "2025-06-06T14:00:00Z",
    "summary": "<p>by Rui Li, Boris Strilic, Young-June Jin, Jingchen Shao, Yundong Peng, Lei Wang, Qi Quan, Zhiyong Wang, Johannes Graumann, J. Silvio Gutkind, Nina Wettschureck, Stefan Offermanns</p>\n\n<i>FAT1</i> is a tumor suppressor gene encoding the protocadherin FAT1, which has been found to be mutated in different types of human cancers with the highest frequency in head and neck squamous cell carcinoma (HNSCC). However, through which mechanisms mutations of <i>FAT1</i> lead to tumor progression is incompletely understood. Here, we report that loss of FAT1 in various tumor cells, including HNSCC cells, resulted in increased protein levels of the transcriptional regulators YAP and TAZ. This was sufficient to lead to increased expression of YAP/TAZ target genes and to increased tumor cell proliferation. We found that elevated YAP/TAZ activity after loss of FAT1 was due to decreased YAP/TAZ protein degradation, which could be rescued by expression of the intracellular part of FAT1. When analyzing the interactome of the cytoplasmic part of FAT1 in tumor cells, we identified the E3 ubiquitin ligase Mind Bomb-2 (MIB2) as an interaction partner. Suppression of MIB2 expression in various tumor cells led to same effects as loss of FAT1 expression, including a decrease in YAP and TAZ ubiquitination, and degradation as well as an increase in YAP/TAZ protein levels and expression of YAP/TAZ target genes. Similarly, Hela cells or HNSCCs with suppressed MIB2 expression resembled FAT1 defective tumor cells showing faster proliferation <i>in vitro</i> as well as increased tumor growth <i>in vivo</i> compared to control cells. Our study identifies a mechanism by which YAP/TAZ levels are kept low through FAT1/MIB2-mediated protein degradation and shows that tumor progression resulting from mutation of tumor suppressor FAT1 involves loss of MIB2-dependent degradation of YAP and TAZ.",
    "authors": [
      "Rui Li",
      "Boris Strilic",
      "Young-June Jin",
      "Jingchen Shao",
      "Yundong Peng",
      "Lei Wang",
      "Qi Quan",
      "Zhiyong Wang",
      "Johannes Graumann",
      "J. Silvio Gutkind",
      "Nina Wettschureck",
      "Stefan Offermanns"
    ],
    "doi": "",
    "parser_type": "plos",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:33:57.539915"
  },
  {
    "id": "https://journals.plos.org/plosone/feed/10.1371/journal.pone.0325513",
    "journal": "PLoS_ONE",
    "title": "First insight into oral health misinformation in Jordan; an analysis of web content and information-seeking behaviors",
    "link": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0325513",
    "published": "2025-06-06T14:00:00Z",
    "summary": "<p>by Issam B. Rasheed, Bayan F. Ababneh, Yara I. Al-Habsheh</p>\nBackground <p>Integrating the internet into daily life has profoundly influenced the public's behavior of seeking health information. Free access to cyberspace created a fertile environment for the spread of oral health misinformation, which can have a detrimental impact on the public’s oral health. The prevalence of oral health misinformation in Jordan has not been investigated; therefore, it is crucial to understand how oral health misinformation originates and what contributes to its dissemination.</p> Objectives <p>This study aims to examine the prevalence of oral health misinformation published on web pages in Jordan and to offer insight into the public's information-seeking behaviors regarding oral health.</p> Methods <p>This study is a mixed methods infodemiological analysis of oral health misinformation. A systematic content analysis was executed on web pages published in the Arabic language in Jordan from 2019 to 2023.</p> Results <p>704 web pages were retrieved, of which 320 relevant web pages were included in the content analysis. Among these, 193 web pages (60.3%) published oral health misinformation. Publishers without a professional background published 185 web pages (95.9%) of the total misinformation-expressing web pages. According to the dental field, the highest frequency of misinformation occurred in oral medicine-101 web pages (52.3%). The validity of published oral health information was significantly influenced by the publishers’ interest (P = 0.006), the articles’ main themes (P = 0.005), and the publishers' professional background (P < 0.001). Contextual analysis of oral health misinformation showed significant differences among dental fields (P = 0.019), with the most frequent occurences related to causes (18.8%), home remedies (15.7%), and treatment (15.5%). Geographical variations in interest in oral health searches were observed across Jordanian governorates (P < 0.001), and temporal trends in interest varied significantly across the five-year period(P = 0.019).</p> Conclusion <p>The findings of this study suggest a need for public health interventions to restrict the dissemination of oral health misinformation.</p>",
    "authors": [
      "Issam B. Rasheed",
      "Bayan F. Ababneh",
      "Yara I. Al-Habsheh"
    ],
    "doi": "",
    "parser_type": "plos",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:33:57.539921"
  },
  {
    "id": "https://journals.plos.org/plosone/feed/10.1371/journal.pone.0325492",
    "journal": "PLoS_ONE",
    "title": "<i>Leptospira</i> seroprevalence and associated risk factors among cattle in Bor County, South Sudan",
    "link": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0325492",
    "published": "2025-06-06T14:00:00Z",
    "summary": "<p>by Kitale Estella John Kasiano, Lordrick Alinaitwe, Walter Okello, Tubihemukama Methodius, Christopher Joshua Aturinda, Ashiraf Lubega, Esther Sabbath Frazer Togo, Peter Micheal Marin, David Kal Onafruo, Ambrose Samuel Jubara, Savino Biryomumaisho, Clovice Kankya</p>\n\nLeptospirosis is a bacterial zoonotic disease that is distributed globally. In livestock, leptospirosis often presents as a subclinical disease that results in significant reproductive and production losses, which could in turn have detrimental economic consequences, particularly in countries like South Sudan that rely on livestock farming for livelihood. Leptospirosis often presents as a subclinical disease in which case the animal may be a maintenance host for a specific serovar. Recent increases in unexplained abortions have prompted us to investigate <i>Leptospira</i> exposure and associated risk factors among cattle in Bor County South Sudan. A cross-sectional study was conducted between 22<sup>nd</sup> January to 15<sup>th</sup> February 2023. Blood samples were collected from 357 cattle in four of the six cattle camps in the County at that time. Seropositivity was determined by detecting anti-<i>Leptospira</i> antibodies in the serum samples by microscopic agglutination test (MAT) based on a panel of 12 serovars representing 12 serogroups. Data on risk factors were obtained using pre-tested questionnaires administered to the owner or herdsman of each sampled herd. Of the 357 cattle sampled, 66.95% (95% CI = 61.91–71.62) were seropositive (cut-off titer ≥100). Seventy-six of the seropositive cattle (21.65%) had MAT titer ≥800, indicating a probable recent infection at the time of sampling. The most prevalent serogroups were <i>L. borgpetersenii</i> Tarassovi (59.83%) and <i>L</i>. <i>borgpetersenii</i> Ballum (17.38%). In the robust Poisson regression model, only the age of cattle was a significant risk factor to <i>Leptospira</i> seroprevalence. The prevalence in adult cattle was 1.43 times higher than in young ones (95% CI 1.09–1.92; P-value = 0.012). The extremely high seroprevalence indicates that leptospirosis may be endemic in cattle in South Sudan, and potentially one of the etiologies for the recently increasing abortion reports. This may require confirmation of the infection status among the aborting cattle.",
    "authors": [
      "Kitale Estella John Kasiano",
      "Lordrick Alinaitwe",
      "Walter Okello",
      "Tubihemukama Methodius",
      "Christopher Joshua Aturinda",
      "Ashiraf Lubega",
      "Esther Sabbath Frazer Togo",
      "Peter Micheal Marin",
      "David Kal Onafruo",
      "Ambrose Samuel Jubara",
      "Savino Biryomumaisho",
      "Clovice Kankya"
    ],
    "doi": "",
    "parser_type": "plos",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:33:57.539936"
  },
  {
    "id": "https://journals.plos.org/plosone/feed/10.1371/journal.pone.0325479",
    "journal": "PLoS_ONE",
    "title": "Examination of hyper-palatable foods and their nutrient characteristics using globally crowdsourced data",
    "link": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0325479",
    "published": "2025-06-06T14:00:00Z",
    "summary": "<p>by Daiil Jun, Kelly Knowles, Tera L. Fazzino</p>\n\nHyper-palatable foods (HPF), characterized by specific nutrient combinations at moderate to high levels (e.g., fat and sodium), have been suggested to increase energy intake and obesity risk due to their strong reinforcing properties. The study examined patterns in HPF availability, nutrient characteristics, and overlap with ultra-processed foods (UPF) across countries from a globally crowdsourced, open-source dataset. Food data (N = 314229 food items) from 17 countries were analyzed. Compared to the US, foods from most European countries examined, as well as Canada and Mexico, were significantly less likely to be identified as HPF (ORs = 0.70 to 0.93) and had lower % of calories from fat, sugar, starchy carbohydrates, and sodium compared to HPF items from the US (ORs = 0.76 to 0.98). Across countries, items identified as HPF substantially exceeded HPF threshold criteria by 70–229%. Foods identified as being both HPF and ultra-processed foods ranged from 33% (Bulgaria) to 50% (US). Overall, findings from 17 countries across Europe, North America, and South America highlighted foods from the US as being more likely to be hyper-palatable relative to most other countries examined. Results highlighted variability in the degree to which foods met criteria as HFP and UPF across countries.",
    "authors": [
      "Daiil Jun",
      "Kelly Knowles",
      "Tera L. Fazzino"
    ],
    "doi": "",
    "parser_type": "plos",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:33:57.539942"
  },
  {
    "id": "https://journals.plos.org/plosone/feed/10.1371/journal.pone.0325471",
    "journal": "PLoS_ONE",
    "title": "MTSA-SC: A multi-task learning approach for individual trip destination prediction with multi-trajectory subsequence alignment and space-aware loss functions",
    "link": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0325471",
    "published": "2025-06-06T14:00:00Z",
    "summary": "<p>by Dan Luo, Fang Zhao, Hao Zhou, Chenxing Wang, Hao Xiong</p>\n\nIndividual Trip Destination Prediction aims to accurately forecast an individual’s future travel destinations by analyzing their historical trajectory data, holding significant application value in intelligent navigation, personalized recommendations, and urban traffic management. However, challenges such as data sparsity, low quality, and complex spatiotemporal volatility pose substantial difficulties for prediction tasks. Existing studies exhibit notable limitations in insufficient integration of sparsity handling and prediction tasks, constrained modeling capability for local volatility, and inadequate exploration of fine-grained spatial dependencies, struggling to balance global patterns and local features in trajectory data. To address these issues, this paper proposes an individual trip destination prediction method that integrates multi-task learning, a multi-trajectory subsequence alignment attention mechanism, and a spatially consistent constrained cross-entropy loss function. Leveraging a multi-task learning framework(MTSA-SC), our approach collaboratively addresses trajectory recovery and prediction tasks, enhancing prediction accuracy while improving robustness to missing data. The multi-trajectory subsequence alignment attention mechanism incorporates sliding windows and convolutional operations to dynamically capture local volatility and diverse patterns in trajectories. The spatially consistent constrained loss function strengthens spatial feature learning through differential error penalty adjustments. Experimental results on public datasets from Shenzhen and Xiamen demonstrate recall rates of 0.722 and 0.6 under complete and sparse trajectory scenarios, respectively, outperforming state-of-the-art baselines by an average of 15.64%. This research provides robust technical support for intelligent travel recommendations and traffic management.",
    "authors": [
      "Dan Luo",
      "Fang Zhao",
      "Hao Zhou",
      "Chenxing Wang",
      "Hao Xiong"
    ],
    "doi": "",
    "parser_type": "plos",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:33:57.539949"
  },
  {
    "id": "https://journals.plos.org/plosone/feed/10.1371/journal.pone.0325469",
    "journal": "PLoS_ONE",
    "title": "“Calming the nightmares”: A qualitative study of a socially assistive robot for sensory and emotional support in individuals with eating disorders and PTSD",
    "link": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0325469",
    "published": "2025-06-06T14:00:00Z",
    "summary": "<p>by Dimitri Chubinidze, Zhuo Li, Philippa Croft, Brittany Nodding, Petr Slovak, Kate Tchanturia</p>\n\nIndividuals with eating disorders (ED) and co-occurring post-traumatic stress disorder (PTSD) often face difficulties with sensory overload and emotion regulation (ER), which can make treatment more complex. Assistive devices that offer real-time support are needed to enhance therapeutic interventions. This qualitative pilot study explored the engagement, acceptability, and perceived impact of Purrble, a socially assistive robot, as an adjunct tool for sensory and ER support. Nine participants (8 female, 1 non-binary, aged 20–55) were recruited from an ED service and engaged with Purrble over a 10-day period following a sensory well-being workshop. Participants recorded their use of Purrble and daily reflections in diaries and participated in a focus group. Thematic analysis revealed three themes: (1) Integration into daily life, where participants highlighted Purrble’s portability and ease of use in managing anxiety across various settings; (2) Managing PTSD-related difficulties, such as calming nightmares, reducing sensory overload, and providing emotional comfort; and (3) Challenges and improvements, where participants suggested modifications, such as adding a night mode and better sound control. This study provides preliminary evidence that an assistive device can support individuals with ED and PTSD, particularly in managing sleep disturbances, overstimulation, and feelings of emotional isolation. Further research using standardised methodologies is needed to expand on these preliminary findings.",
    "authors": [
      "Dimitri Chubinidze",
      "Zhuo Li",
      "Philippa Croft",
      "Brittany Nodding",
      "Petr Slovak",
      "Kate Tchanturia"
    ],
    "doi": "",
    "parser_type": "plos",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:33:57.539957"
  },
  {
    "id": "https://journals.plos.org/plosone/feed/10.1371/journal.pone.0325418",
    "journal": "PLoS_ONE",
    "title": "Do chimpanzees (<i>Pan troglodytes</i>) mentally represent collaboration?: Action-learning and communication in a partnered task",
    "link": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0325418",
    "published": "2025-06-06T14:00:00Z",
    "summary": "<p>by Elizabeth Warren, Emma Suvi McEwen, Josep Call</p>\n\nNon-human primates engage in complex collective behaviours, but existing research does not paint a clear picture of what individuals cognitively represent when they act together. This study investigates chimpanzees’ capacity for co-representation. If individuals represent others’ actions as they relate to their own during a collaborative task, they should more easily learn to reproduce that action when their roles are switched. In a between-subjects design, we trained ten chimpanzees (<i>Pan troglodytes</i>) on a sequential task, in which the first action is performed by either a human partner or a non-social object, and the second action is performed by the subject. We then imposed a breakdown in the action sequence, in which subjects could perform both actions themselves, but received no help from the experimenter or object. We measured subjects’ success in reproducing the first action in the sequence, as well as their attempts to recruit the experimenter’s help using requesting gestures. We found no overall difference in subjects’ ability to perform the first action in the sequence, but we observed significant qualitative differences in their solutions: individuals in the partnered condition replicated the experimenter’s action, while those in the non-social condition achieved the same end using alternative methods. This difference in solution style could indicate that only those chimpanzees in the partnered condition mentally represented the experimenter’s action during the collaborative task. We caution, however, that given the small number of subjects who solved the task, this result could also be driven by individual differences. We also found that subjects consistently produced communicative gestures toward the experimenter, but were more likely to do so after exhausting all actions they could take alone. We suggest that these patterns of behaviour highlight a number of key empirical considerations for the study of coordination in non-human primates.",
    "authors": [
      "Elizabeth Warren",
      "Emma Suvi McEwen",
      "Josep Call"
    ],
    "doi": "",
    "parser_type": "plos",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:33:57.539969"
  },
  {
    "id": "https://journals.plos.org/plosone/feed/10.1371/journal.pone.0325417",
    "journal": "PLoS_ONE",
    "title": "The TMA team and TTP pathway improved outcomes in a cohort with Thrombotic thrombocytopenic purpura",
    "link": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0325417",
    "published": "2025-06-06T14:00:00Z",
    "summary": "<p>by Samuel A. Merrill, Stephen Yu, Sylvia E. Webber, John Gotses, Emma L. Platt, Ruta Arays, Aaron D. Shmookler</p>\nBackground <p>Providing optimal care for patients with thrombotic thrombocytopenic purpura (TTP) is challenging because of multiple involved specialties, knowledge gaps, and a high rate of disease relapse. A thrombotic microangiopathy (TMA) Team and TTP Pathway could improve outcomes.</p> Objectives <p>To assess if a structured TTP Pathway, supported by a TMA Team, improved TTP care by reducing TTP relapse and TTP-related death (TTP-RRD) at a rural Appalachian medical center.</p> Methods <p>Prospective cohort quality improvement project using the DMAIC quality improvement framework (Define, Measure, Analyze, Improve, Control) to develop a TMA Team and TTP Pathway. Pathway care included standardized use of therapeutic plasma exchange (TPE), rituximab, caplacizumab, as well as improved coordination between medical services, and regular outpatient biochemical TTP surveillance. Outcomes were determined by retrospective chart review for patients with acute TTP treated with usual care (N = 16 episodes) and the TTP Pathway (N = 16 episodes).</p> Results and conclusions <p>All patients had acquired TTP. TTP-RRD at 90 days was reduced from 69% with usual care to 6% with Pathway care (95% CI 0.35 to 0.90, P = 0.0004), a relative risk reduction of 91%; TTP relapse alone at 90 days was reduced from 62% to 0% (95% CI 0.36 to 0.88, P = 0.0002) with Pathway care. The number needed to treat to prevent TTP-RRD was 1.59 at 90 days. Over the project duration usual care demonstrated a hazard ratio for TTP-RRD of 12.58 compared to Pathway care. With the intervention, the duration of TPE was increased (median 6 vs 12 sessions, P < 0.05), as was use of rituximab (31.3% vs 93.8%, 95% CI −0.36 to −0.88, P = 0.003), and caplacizumab (6.3% vs 62.5%, 95% CI −0.027 to −0.81, P = 0.001). All Pathway patients underwent biochemical surveillance, and 31% had pre-emptive rituximab to reduce possibility of clinical relapse. A structured TTP Pathway significantly reduces morbidity and aligns care with modern clinical guidelines. The TMA Team is a valuable institutional resource to improve outcomes.</p>",
    "authors": [
      "Samuel A. Merrill",
      "Stephen Yu",
      "Sylvia E. Webber",
      "John Gotses",
      "Emma L. Platt",
      "Ruta Arays",
      "Aaron D. Shmookler"
    ],
    "doi": "",
    "parser_type": "plos",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:33:57.539975"
  },
  {
    "id": "https://journals.plos.org/plosone/feed/10.1371/journal.pone.0325416",
    "journal": "PLoS_ONE",
    "title": "Visual feature analysis on selective appetite in individuals with autism spectrum disorders",
    "link": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0325416",
    "published": "2025-06-06T14:00:00Z",
    "summary": "<p>by Kazunori Terada, Taku Imaizumi, Kazuhiro Ueda, Natsuki Nishikawa, Haruto Yoshida, Yukiya Taki, Shunsuke Fujii, Lu Li, Masashi Komori, Kunihito Kato, Hirokazu Kumazaki</p>\nBackground <p>Individuals with autism spectrum disorders (ASD) experience more severe selective eating problems than their neurotypical peers. Identifying the causes of selective eating behavior poses a considerable challenge, even for caregivers. Accurate identification of the underlying causes of this behavior is essential for developing interventions aimed at overcoming dysfunctional, unbalanced diets. However, studies that meticulously identify the causes of selective eating behaviors are scarce. This investigation aims to explore the differences in preferences for sunny-side-up eggs between individuals with ASD and those with typical development (TD), focusing on the factors influencing their likes and dislikes through a systematic analysis of visual features.</p> Method <p>Thirty-nine individuals with ASD (mean age, 23.4 ± 4.7 years; 82% men) and fifty individuals with TD (mean age, 22.2 ± 1.3 years; 64% men) participated in this study. We used a total of 50 images of sunny-side-up eggs as visual stimuli. Using Non-negative Matrix Factorization and Decision Tree analysis, factors associated with visual preferences for sunny-side-up eggs were identified.</p> Data and Results <p>We could identify factors associated with visual preferences for sunny-side-up eggs. Subsequent linear regression analysis provided insight into how these visual features delineate preference boundaries between liked and disliked foods, with noteworthy distinctions emerging between the ASD and TD groups.</p> Conclusions <p>This study provides novel insights into the visual determinants of food preferences in individuals with ASD through systematic analysis of image features. Our findings indicated the potential to predict preferences while elucidating the causes of selective eating behaviors, thereby offering solutions for individuals with ASD.</p>",
    "authors": [
      "Kazunori Terada",
      "Taku Imaizumi",
      "Kazuhiro Ueda",
      "Natsuki Nishikawa",
      "Haruto Yoshida",
      "Yukiya Taki",
      "Shunsuke Fujii",
      "Lu Li",
      "Masashi Komori",
      "Kunihito Kato",
      "Hirokazu Kumazaki"
    ],
    "doi": "",
    "parser_type": "plos",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:33:57.539981"
  },
  {
    "id": "https://journals.plos.org/plosone/feed/10.1371/journal.pone.0325396",
    "journal": "PLoS_ONE",
    "title": "Estimation method for impact force source in thick coal seams and its application in rockburst risk quantification",
    "link": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0325396",
    "published": "2025-06-06T14:00:00Z",
    "summary": "<p>by Quande Wei, Quanjie Zhu, Guangyu Yang, Dongsheng Jiang, Yi Liu, Yingnan Hao, Qilin Hao</p>\n\nAccurately calculating the stress state and its distribution is key to preventing coal burst. Taking a typical mine with extremely thick coal seams and coal bursts as an example, methods such as stress estimation, numerical computation, theoretical analysis, and on-site measurements were used to study the estimation method for coal burst force sources and the quantitative evaluation of coal burst risk under extremely thick coal seams beneath massive gravel rock. The main research content includes: (1) Establishing a coal burst force source estimation model for extremely thick coal seams through the estimation of transmitted stress from massive gravel rock, self-weight stress of the overlying strata, tectonic stress quantitative analysis, and mining disturbance stress estimation; (2) Proposing a calculation method for the fracture angle and strike span parameters required for stress estimation based on microseismic monitoring technology, and comparing and verifying the effectiveness of rapid estimation methods for strike and dip support pressures; (3) Based on the above methods, proposing a quantitative evaluation method for coal burst risk based on stress estimation. The practical results demonstrate that the proposed method enables rapid analysis of impact force sources, accurate assessment of coal burst risk levels, and establishes a foundation for timely and precise early warning of coal burst disasters.",
    "authors": [
      "Quande Wei",
      "Quanjie Zhu",
      "Guangyu Yang",
      "Dongsheng Jiang",
      "Yi Liu",
      "Yingnan Hao",
      "Qilin Hao"
    ],
    "doi": "",
    "parser_type": "plos",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:33:57.539987"
  },
  {
    "id": "https://journals.plos.org/plosone/feed/10.1371/journal.pone.0325384",
    "journal": "PLoS_ONE",
    "title": "How trustworthy and applicable is the evidence from systematic reviews of depression treatments: Protocol for systematic examination",
    "link": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0325384",
    "published": "2025-06-06T14:00:00Z",
    "summary": "<p>by Iwo Fober, Lidia Baran, Myrto Samara, Spyridon Siafis, David Robert Grimes, Bartosz Helfer</p>\nBackground <p>Depression is a common mental disorder significantly impacting daily functioning. Standard treatments include drugs, psychotherapies, or a combination of both. Treatment selection relies on scientific evidence, though the trustworthiness and applicability of this evidence can vary.</p> Objectives <p>This protocol presents a method to evaluate evidence from systematic reviews for pharmacological and psychological treatments for depression, focusing on trustworthiness and applicability structured into five components: quality of conduct and reporting, risk of bias, spin in abstract conclusions, robustness of meta-analytical results, heterogeneity and clinical diversity.</p> Methods <p>We will conduct a systematic search of systematic reviews in MEDLINE, Embase, PsycInfo, and Cochrane Database of Systematic Reviews. Our focus will be on systematic reviews of first-line treatments for depression in adults, including antidepressants, psychotherapy, or combined treatments, compared to either active or inactive comparators. We will extract information needed for a comprehensive methodological evaluation using qualitative tools, including AMSTAR 2, ROBIS, Conflict-of-Interest assessment, Referencing Framework for SRs, Spin Measure, and heterogeneity exploration assessment. For quantitative analyses, such as Fragility Index, Ellipse of Insignificance, Region of Attainable Redaction, GRIM test, Leave-N-Out analysis, and prediction intervals, we will select and recalculate two meta-analyses per review. We define a set of outcomes to enable practical and intuitive interpretation of these analyses’ results. Descriptive statistics, non-parametric statistical tests, and narrative summaries will be used to synthesize and compare outcomes across several pre-specified subgroups.</p> Expected outcomes <p>We expect these analyses to provide an enhanced perspective on the practice of evidence synthesis in the field of mental health, offer methodological guidance for future systematic reviews and meta-analyses, and contribute to improved informed decision-making by clinicians and patients.</p> OSF registration <p>osf.io/7f9cj and osf.io/ynejs</p>",
    "authors": [
      "Iwo Fober",
      "Lidia Baran",
      "Myrto Samara",
      "Spyridon Siafis",
      "David Robert Grimes",
      "Bartosz Helfer"
    ],
    "doi": "",
    "parser_type": "plos",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:33:57.539997"
  },
  {
    "id": "https://journals.plos.org/plosone/feed/10.1371/journal.pone.0325317",
    "journal": "PLoS_ONE",
    "title": "Instability of estimation results based on caliper matching with propensity scores",
    "link": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0325317",
    "published": "2025-06-06T14:00:00Z",
    "summary": "<p>by Kazushi Maruo, Yusuke Yamaguchi, Ryota Ishii, Masahiko Gosho</p>\n\nCaliper matching is often used to adjust for confounding biases in observational studies. This method with random order matching allows for the cherry-picking of the analysis results to suit the analyst’s convenience. Random order matching can also result in large fluctuations in the analysis results due to small additions and/or changes in data. These “instability problems” might compromise the reproducibility of the study results. Some studies have discussed instability issues, but the conditions are limited, and there is no knowledge of which alternative order method should be used instead of the random order method. We evaluate the instability problem by calculating the extent to which the results can vary within a single study dataset and provide guidelines for choosing the best alternative matching order method based on simulations and a case study. From simulation studies, instability might be serious when the sample size was small, the true odds ratio was large, the proportion for the treatment group was large, and the c-statistic for the propensity score model was large. We recommend not using random order matching and instead using lowest to highest score order matching or the median of multiple random order matching results. We also recommend pre-specifying the matching order method.",
    "authors": [
      "Kazushi Maruo",
      "Yusuke Yamaguchi",
      "Ryota Ishii",
      "Masahiko Gosho"
    ],
    "doi": "",
    "parser_type": "plos",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:33:57.540003"
  },
  {
    "id": "https://journals.plos.org/plosone/feed/10.1371/journal.pone.0325285",
    "journal": "PLoS_ONE",
    "title": "Study on energy dissipation law of vibration disturbance damaged Zhanjiang Formation structural clay",
    "link": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0325285",
    "published": "2025-06-06T14:00:00Z",
    "summary": "<p>by Yanhua Xie, Bin Tang, Shuaiyu Liu, Binghui Zhang</p>\n\nThis study aims to investigate the energy dissipation laws and underlying mechanisms of damage in Zhanjiang Formation structural clay following vibrational disturbances. Based on the test results of the unconfined compressive strength of the disturbed Zhanjiang Formation structural clay, and in conjunction with theories related to energy dissipation, the analysis revealed that: (1) An increase in the disturbance degree leads to higher compaction strain and compaction dissipation energy, thereby enhancing the ductility of the sample; (2) Although disturbance reduces the strength of the sample, it increases its deformation capacity, indicating that the interplay between strength and deformation affects the level of energy dissipation; (3) The variation in the logarithmic value of the elastic energy dissipation ratio can be categorized into three phases: initial lg<i>K</i> > 0; lg<i>K</i> < 0 to (lg<i>K</i>)<sub>min</sub>; and an increase from (lg<i>K</i>)<sub>min</sub>, with (lg<i>K</i>)<sub>min</sub> marking the critical turning point for the transition from the elastic to the plastic phase of the soil. The study also profoundly analyzed the dynamic regulation mechanisms of vibrational disturbance energy from two perspectives: dynamic regulation and structural change, as well as energy dissipation and damage evolution. High-frequency vibrations expedite the damage process, and post-damage energy dissipation involves friction, microcrack propagation, and plastic deformation, ultimately leading to the collapse of the soil structure. This study not only enhances the understanding of the complex mechanical behavior of such soils but also paves the way for innovative applications and theoretical advances in soil mechanics.",
    "authors": [
      "Yanhua Xie",
      "Bin Tang",
      "Shuaiyu Liu",
      "Binghui Zhang"
    ],
    "doi": "",
    "parser_type": "plos",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:33:57.540009"
  },
  {
    "id": "https://journals.plos.org/plosone/feed/10.1371/journal.pone.0325268",
    "journal": "PLoS_ONE",
    "title": "The effect of follicular and ampullary fluid extracellular vesicles on bovine oocyte competence and <i>in vitro</i> fertilization rates",
    "link": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0325268",
    "published": "2025-06-06T14:00:00Z",
    "summary": "<p>by Zohreh Pakniyat, Mehdi Azari, Mojtaba Kafi, Mehran Ghaemi, Seyed Mohammad Amin Hashemipour, Amin Safaie, Davoud Eshghi</p>\n\nFollicular fluid from preovulatory follicles as well as ampullary fluid from slaughtered cows at the early metestrus were collected for isolation of EVs. Excellent and good quality bovine oocytes were selected and distributed into four groups: control group which did not receive EVs, the FFEV group which were exposed to 40 μg/ml of follicular fluid EVs for the first 18 hours of the culture, the FFAFEV group which received 40 μg/ml of follicular fluid EVs for the first 18 hours of the culture, followed by 3.4 μg/ml of ampullary fluid EVs for the remaining 4.5 hours, and the AFEV group which were exposed to 3.4 μg/ml of ampullary fluid EVs for the final 4.5 hours of the culture. After a total incubation period of 22.5 hours, the COCs were evaluated for nuclear maturation, expression of some relevant genes, and Raman spectra from different areas of the representative matured oocytes (Experiment 1). In addition, fertilization rate of the oocytes was assessed after addition of EVs to the maturation medium (Experiment 2). The maturation and fertilization rates, as well as the expression of <i>TNFAIP6</i>, <i>HAS2</i>, and <i>GDF9</i> genes, were significantly higher in the EVs treatment groups compared to the control group (p ≤ 0.05). Furthermore, the Raman microspectroscopy revealed a higher number of mitochondria (1602 cm<sup>-1</sup>), increased levels of unsaturated lipids (1655 cm<sup>-1</sup>) and a favorable phenylalanine to carbohydrate ratio (1002/1037, serving as a marker for oocyte quality, in the FFAFEV group compared to the control group. Additionally, there was a lower concentration of saturated lipids (2883 cm<sup>-1</sup>) in the FFAFEV group than in the control group. In conclusion, our findings showed that supplementation of the oocyte maturation media with follicular and ampullary fluid EVs positively influenced oocyte quality and enhanced <i>in vitro</i> maturation, fertilization rates, and the relevant gene expression.",
    "authors": [
      "Zohreh Pakniyat",
      "Mehdi Azari",
      "Mojtaba Kafi",
      "Mehran Ghaemi",
      "Seyed Mohammad Amin Hashemipour",
      "Amin Safaie",
      "Davoud Eshghi"
    ],
    "doi": "",
    "parser_type": "plos",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:33:57.540019"
  },
  {
    "id": "https://journals.plos.org/plosone/feed/10.1371/journal.pone.0325247",
    "journal": "PLoS_ONE",
    "title": "Overestimated cytotoxicity and underestimated whitening efficacy of glabridin: A result of its poor solubility in DMSO",
    "link": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0325247",
    "published": "2025-06-06T14:00:00Z",
    "summary": "<p>by Haiyan Liu, Anning Wang, Xiaoyi Chen, Sen Hou, Anzhang Li</p>\n\nGlabridin is widely used as a whitening agent in cosmetics, but its cytotoxicity remains a key concern in safety evaluations. In typical cytotoxicity assays, glabridin is dissolved in dimethyl sulfoxide (DMSO) before being added to the cell culture medium because it is insoluble in water. However, our study revealed that when the DMSO solution of glabridin was mixed with cell culture medium, glabridin was rapidly released due to its poor solubility in the DMSO/water mixture. The released glabridin rapidly formed crystals, which failed to enter cells. Consequently, the whitening efficacy of glabridin was reduced. Moreover, the glabridin crystals produced higher cytotoxicity, possibly due to the physical damage caused by their sharp crystalline structures. However, encapsulating glabridin in cyclodextrin (CD) can address these challenges, offering a better approach for glabridin cytotoxicity assays. The CD encapsulation method, compared to the DMSO solution method, not only decreased the cytotoxicity of glabridin but also increased its whitening efficacy. By comparing the efficacy of glabridin dissolved in DMSO and encapsulated in CD, we discovered that the reported cytotoxicity of glabridin may have been overestimated in previous cytotoxicity studies which used DMSO as a solvent, while its whitening efficacy may have been underestimated. These findings not only offer new insights for in vitro studies of glabridin-like reagents, but also facilitate the development of safer and more effective whitening products.",
    "authors": [
      "Haiyan Liu",
      "Anning Wang",
      "Xiaoyi Chen",
      "Sen Hou",
      "Anzhang Li"
    ],
    "doi": "",
    "parser_type": "plos",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:33:57.540026"
  },
  {
    "id": "https://journals.plos.org/plosone/feed/10.1371/journal.pone.0325189",
    "journal": "PLoS_ONE",
    "title": "Kaempferol inhibits oxidative stress and reduces macrophage pyroptosis by activating the NRF2 signaling pathway",
    "link": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0325189",
    "published": "2025-06-06T14:00:00Z",
    "summary": "<p>by Yu Wang, Chaofan Chen, Yushan Li, Ran Li, Jinghan Wang, Chao Wu, Haonan Chen, Yingchao Shi, Shengfang Wang, Chuanyu Gao</p>\n\nKaempferol exhibits various biological activities, including antioxidant and anti-inflammatory effects. Its role in modulating lipid metabolism and inhibiting inflammatory responses to suppress the progression of atherosclerosis has been confirmed. However, its impact on macrophage pyroptosis and the underlying mechanisms remain unclear. This study aims to investigate the effects of kaempferol (Kae) on lipopolysaccharide (LPS)-induced macrophage pyroptosis and its potential mechanisms. In the experiments, we used the CCK8 assay to evaluate cell viability, ROS detection kits to measure intracellular reactive oxygen species (ROS) levels, Western Blot to detect the expression of proteins such as NOD-like receptor family pyrin domain-containing 3 (NLRP3), nuclear factor erythroid 2-related factor 2 (NRF2), gasdermin D (GSDMD), and heme oxygenase-1 (HO-1), and immunofluorescence to observe NRF2 nuclear translocation. The results showed that kaempferol alleviated LPS-induced cell viability decline and lactate dehydrogenase (LDH) release, inhibited excessive ROS generation, and suppressed NLRP3 inflammasome activation by increasing glutathione (GSH) and HO-1 levels, thereby reducing the expression of inflammatory factors. Additionally, kaempferol promoted NRF2 nuclear translocation, and the application of the NRF2 inhibitor ML385 reversed its antioxidant and anti-inflammatory effects. In vivo experiments further confirmed that kaempferol inhibited oxidative stress and reduced macrophage pyroptosis by activating the NRF2 pathway.",
    "authors": [
      "Yu Wang",
      "Chaofan Chen",
      "Yushan Li",
      "Ran Li",
      "Jinghan Wang",
      "Chao Wu",
      "Haonan Chen",
      "Yingchao Shi",
      "Shengfang Wang",
      "Chuanyu Gao"
    ],
    "doi": "",
    "parser_type": "plos",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:33:57.540032"
  },
  {
    "id": "oai:arXiv.org:2506.05351v1",
    "journal": "arXiv_CS",
    "title": "Infinite Time Turing Machines and their Applications",
    "link": "https://arxiv.org/abs/2506.05351",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05351v1 Announce Type: new \nAbstract: This work establishes a rigorous theoretical foundation for analyzing deep learning systems by leveraging Infinite Time Turing Machines (ITTMs), which extend classical computation into transfinite ordinal steps. Using ITTMs, we reinterpret modern architectures like Transformers, revealing fundamental limitations in scalability, efficiency, and interpretability. Building on these insights, we propose the Universal State Machine (USM), a novel computational paradigm designed from first principles. The USM employs a dynamic, queryable computation graph that evolves in real time, enabling modular, interpretable, and resource-efficient computation. This framework not only overcomes the inefficiencies and rigidity of current models but also lays the groundwork for scalable, generalizable artificial intelligence systems.",
    "authors": [
      "Rukmal Weerawarana, Maxwell Braun"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.834059"
  },
  {
    "id": "oai:arXiv.org:2506.05352v1",
    "journal": "arXiv_CS",
    "title": "A Path to Loving",
    "link": "https://arxiv.org/abs/2506.05352",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05352v1 Announce Type: new \nAbstract: This work lays the foundations for a rigorous ontological characterization of love, addressing its philosophical complexity and scientific relevance, with particular emphasis on psychology and sociology, as well as highlighting ways in which such characterization enhances relevant AI based applications. The position defended here is that love is best understood as a concatenation of passive sensations (e.g., emotional arousal) and active evaluative judgments (e.g., perceiving the beloved as valuable), in the interest of balancing the involuntary aspects of love with its rational accountability. To provide a structured foundation, the paper draws on Basic Formal Ontology (BFO) and other applied ontological methods to differentiate various senses of love. This work engages with objections to the understanding of love as concatenation, particularly concerning the relationship between sensation and judgment. A causal correlation model is defended, ensuring that the affective and cognitive components are linked. By offering a precise and scalable ontological account, this work lays the foundation for future interdisciplinary applications, making love a subject of formal inquiry in ontology engineering, artificial intelligence, and the sciences.",
    "authors": [
      "John Beverley, Regina Hurley"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.834100"
  },
  {
    "id": "oai:arXiv.org:2506.05355v1",
    "journal": "arXiv_CS",
    "title": "Zero-Trust Mobility-Aware Authentication Framework for Secure Vehicular Fog Computing Networks",
    "link": "https://arxiv.org/abs/2506.05355",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05355v1 Announce Type: new \nAbstract: Vehicular Fog Computing (VFC) is a promising paradigm to meet the low-latency and high-bandwidth demands of Intelligent Transportation Systems (ITS). However, dynamic vehicle mobility and diverse trust boundaries introduce critical security challenges. This paper presents a novel Zero-Trust Mobility-Aware Authentication Framework (ZTMAF) for secure communication in VFC networks. The framework employs context-aware authentication with lightweight cryptographic primitives, a decentralized trust evaluation system, and fog node-assisted session validation to combat spoofing, replay, and impersonation attacks. Simulation results on NS-3 and SUMO demonstrate improved authentication latency, reduced computational overhead, and better scalability compared to traditional PKI and blockchain-based models. Our findings suggest that ZTMAF is effective for secure, real-time V2X interactions under adversarial and mobility-variant scenarios.",
    "authors": [
      "Taimoor Ahmad"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.834115"
  },
  {
    "id": "oai:arXiv.org:2506.05358v1",
    "journal": "arXiv_CS",
    "title": "Can ChatGPT Perform Image Splicing Detection? A Preliminary Study",
    "link": "https://arxiv.org/abs/2506.05358",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05358v1 Announce Type: new \nAbstract: Multimodal Large Language Models (MLLMs) like GPT-4V are capable of reasoning across text and image modalities, showing promise in a variety of complex vision-language tasks. In this preliminary study, we investigate the out-of-the-box capabilities of GPT-4V in the domain of image forensics, specifically, in detecting image splicing manipulations. Without any task-specific fine-tuning, we evaluate GPT-4V using three prompting strategies: Zero-Shot (ZS), Few-Shot (FS), and Chain-of-Thought (CoT), applied over a curated subset of the CASIA v2.0 splicing dataset.\n  Our results show that GPT-4V achieves competitive detection performance in zero-shot settings (more than 85% accuracy), with CoT prompting yielding the most balanced trade-off across authentic and spliced images. Qualitative analysis further reveals that the model not only detects low-level visual artifacts but also draws upon real-world contextual knowledge such as object scale, semantic consistency, and architectural facts, to identify implausible composites. While GPT-4V lags behind specialized state-of-the-art splicing detection models, its generalizability, interpretability, and encyclopedic reasoning highlight its potential as a flexible tool in image forensics.",
    "authors": [
      "Souradip Nath"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.834135"
  },
  {
    "id": "oai:arXiv.org:2506.05360v1",
    "journal": "arXiv_CS",
    "title": "CarboNeXT and CarboFormer: Dual Semantic Segmentation Architectures for Detecting and Quantifying Carbon Dioxide Emissions Using Optical Gas Imaging",
    "link": "https://arxiv.org/abs/2506.05360",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05360v1 Announce Type: new \nAbstract: Carbon dioxide (CO$_2$) emissions are critical indicators of both environmental impact and various industrial processes, including livestock management. We introduce CarboNeXT, a semantic segmentation framework for Optical Gas Imaging (OGI), designed to detect and quantify CO$_2$ emissions across diverse applications. Our approach integrates a multi-scale context aggregation network with UPerHead and auxiliary FCN components to effectively model both local details and global relationships in gas plume imagery. We contribute two novel datasets: (1) the Controlled Carbon Dioxide Release (CCR) dataset, which simulates gas leaks with systematically varied flow rates (10-100 SCCM), and (2) the Real Time Ankom (RTA) dataset, focusing on emissions from dairy cow rumen fluid in vitro experiments. Extensive evaluations demonstrate that CarboNeXT outperforms state-of-the-art methods, achieving 88.46% mIoU on CCR and 92.95% mIoU on RTA, with particular effectiveness in challenging low-flow scenarios. The model operates at 60.95 FPS, enabling real-time monitoring applications. Additionally, we propose CarboFormer, a lightweight variant with only 5.07M parameters that achieves 84.68 FPS, with competitive performance of 84.88% mIoU on CCR and 92.98% on RTA, making it suitable for resource-constrained platforms such as programmable drones. Our work advances both environmental sensing and precision livestock management by providing robust tools for CO$_2$ emission analysis, with a specific focus on livestock applications.",
    "authors": [
      "Taminul Islam, Toqi Tahamid Sarker, Mohamed G Embaby, Khaled R Ahmed, Amer AbuGhazaleh"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.834146"
  },
  {
    "id": "oai:arXiv.org:2506.05363v1",
    "journal": "arXiv_CS",
    "title": "Seed Selection for Human-Oriented Image Reconstruction via Guided Diffusion",
    "link": "https://arxiv.org/abs/2506.05363",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05363v1 Announce Type: new \nAbstract: Conventional methods for scalable image coding for humans and machines require the transmission of additional information to achieve scalability. A recent diffusion-based method avoids this by generating human-oriented images from machine-oriented images without extra bitrate. This method, however, uses a single random seed, which may lead to suboptimal image quality. In this paper, we propose a seed selection method that identifies the optimal seed from multiple candidates to improve image quality without increasing the bitrate. To reduce computational cost, the selection is performed based on intermediate outputs obtained from early steps of the reverse diffusion process. Experimental results demonstrate that our method outperforms the baseline across multiple metrics.",
    "authors": [
      "Yui Tatsumi, Ziyue Zeng, Hiroshi Watanabe"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.834156"
  },
  {
    "id": "oai:arXiv.org:2506.05364v1",
    "journal": "arXiv_CS",
    "title": "Survey of LLM Agent Communication with MCP: A Software Design Pattern Centric Review",
    "link": "https://arxiv.org/abs/2506.05364",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05364v1 Announce Type: new \nAbstract: This survey investigates how classical software design patterns can enhance the reliability and scalability of communication in Large Language Model (LLM)-driven agentic AI systems, focusing particularly on the Model Context Protocol (MCP). It examines the foundational architectures of LLM-based agents and their evolution from isolated operation to sophisticated, multi-agent collaboration, addressing key communication hurdles that arise in this transition. The study revisits well-established patterns, including Mediator, Observer, Publish-Subscribe, and Broker, and analyzes their relevance in structuring agent interactions within MCP-compliant frameworks. To clarify these dynamics, the article provides conceptual schematics and formal models that map out communication pathways and optimize data flow. It further explores architectural variations suited to different degrees of agent autonomy and system complexity. Real-world applications in domains such as real-time financial processing and investment banking are discussed, illustrating how these patterns and MCP can meet specific operational demands. The article concludes by outlining open challenges, potential security risks, and promising directions for advancing robust, interoperable, and scalable multi-agent LLM ecosystems.",
    "authors": [
      "Anjana Sarkar, Soumyendu Sarkar"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.834165"
  },
  {
    "id": "oai:arXiv.org:2506.05367v1",
    "journal": "arXiv_CS",
    "title": "Text2Stereo: Repurposing Stable Diffusion for Stereo Generation with Consistency Rewards",
    "link": "https://arxiv.org/abs/2506.05367",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05367v1 Announce Type: new \nAbstract: In this paper, we propose a novel diffusion-based approach to generate stereo images given a text prompt. Since stereo image datasets with large baselines are scarce, training a diffusion model from scratch is not feasible. Therefore, we propose leveraging the strong priors learned by Stable Diffusion and fine-tuning it on stereo image datasets to adapt it to the task of stereo generation. To improve stereo consistency and text-to-image alignment, we further tune the model using prompt alignment and our proposed stereo consistency reward functions. Comprehensive experiments demonstrate the superiority of our approach in generating high-quality stereo images across diverse scenarios, outperforming existing methods.",
    "authors": [
      "Aakash Garg, Libing Zeng, Andrii Tsarov, Nima Khademi Kalantari"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.834175"
  },
  {
    "id": "oai:arXiv.org:2506.05368v1",
    "journal": "arXiv_CS",
    "title": "Speaking images. A novel framework for the automated self-description of artworks",
    "link": "https://arxiv.org/abs/2506.05368",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05368v1 Announce Type: new \nAbstract: Recent breakthroughs in generative AI have opened the door to new research perspectives in the domain of art and cultural heritage, where a large number of artifacts have been digitized. There is a need for innovation to ease the access and highlight the content of digital collections. Such innovations develop into creative explorations of the digital image in relation to its malleability and contemporary interpretation, in confrontation to the original historical object. Based on the concept of the autonomous image, we propose a new framework towards the production of self-explaining cultural artifacts using open-source large-language, face detection, text-to-speech and audio-to-animation models. The goal is to start from a digitized artwork and to automatically assemble a short video of the latter where the main character animates to explain its content. The whole process questions cultural biases encapsulated in large-language models, the potential of digital images and deepfakes of artworks for educational purposes, along with concerns of the field of art history regarding such creative diversions.",
    "authors": [
      "Valentine Bernasconi, Gustavo Marfia"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.834184"
  },
  {
    "id": "oai:arXiv.org:2506.05372v1",
    "journal": "arXiv_CS",
    "title": "DVD: A Comprehensive Dataset for Advancing Violence Detection in Real-World Scenarios",
    "link": "https://arxiv.org/abs/2506.05372",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05372v1 Announce Type: new \nAbstract: Violence Detection (VD) has become an increasingly vital area of research. Existing automated VD efforts are hindered by the limited availability of diverse, well-annotated databases. Existing databases suffer from coarse video-level annotations, limited scale and diversity, and lack of metadata, restricting the generalization of models. To address these challenges, we introduce DVD, a large-scale (500 videos, 2.7M frames), frame-level annotated VD database with diverse environments, varying lighting conditions, multiple camera sources, complex social interactions, and rich metadata. DVD is designed to capture the complexities of real-world violent events.",
    "authors": [
      "Dimitrios Kollias, Damith C. Senadeera, Jianian Zheng, Kaushal K. K. Yadav, Greg Slabaugh, Muhammad Awais, Xiaoyun Yang"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.834209"
  },
  {
    "id": "oai:arXiv.org:2506.05373v1",
    "journal": "arXiv_CS",
    "title": "Game Theory in Social Media: A Stackelberg Model of Collaboration, Conflict, and Algorithmic Incentives",
    "link": "https://arxiv.org/abs/2506.05373",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05373v1 Announce Type: new \nAbstract: Social media platforms are ecosystems in which many decisions are constantly made for the benefit of the creators in order to maximize engagement, which leads to a maximization of income. The decisions, ranging from collaboration to public conflict or ``beefing,'' are heavily influenced by social media algorithms, viewer preferences, and sponsor risk. This paper models this interaction as a Stackelberg game in which the algorithm is the leader, setting exposure and reward rules, and the content creators are the followers, who optimize their content to maximize engagement. It focuses on two influencer strategies of collaborating and beefing. Viewer preferences are modeled indirectly through the algorithm's utility function, which rewards engagement metrics like click-through rate and watch time. Our simplified game-theoretic model demonstrates how different algorithmic priorities can shift creator strategies and provides insight into the equilibrium dynamics of social media influence.",
    "authors": [
      "Arjan Khadka"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.834219"
  },
  {
    "id": "oai:arXiv.org:2506.05374v1",
    "journal": "arXiv_CS",
    "title": "A New Representation of Binary Sequences by means of Boolean Functions",
    "link": "https://arxiv.org/abs/2506.05374",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05374v1 Announce Type: new \nAbstract: Boolean functions and binary sequences are main tools used in cryptography. In this work, we introduce a new bijection between the set of Boolean functions and the set of binary sequences with period a power of two. We establish a connection between them which allows us to study some properties of Boolean functions through binary sequences and vice versa. Then, we define a new representation of sequences, based on Boolean functions and derived from the algebraic normal form, named reverse-ANF. Next, we study the relation between such a representation and other representations of Boolean functions as well as between such a representation and the binary sequences. Finally, we analyse the generalized self-shrinking sequences in terms of Boolean functions and some of their properties using the different representations.",
    "authors": [
      "S. D. Cardell, A. Fu\\'uter-Sabater, V. Requena, M. Beltr\\'a"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.834228"
  },
  {
    "id": "oai:arXiv.org:2506.05375v1",
    "journal": "arXiv_CS",
    "title": "State Estimation and Control of Dynamic Systems from High-Dimensional Image Data",
    "link": "https://arxiv.org/abs/2506.05375",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05375v1 Announce Type: new \nAbstract: Accurate state estimation is critical for optimal policy design in dynamic systems. However, obtaining true system states is often impractical or infeasible, complicating the policy learning process. This paper introduces a novel neural architecture that integrates spatial feature extraction using convolutional neural networks (CNNs) and temporal modeling through gated recurrent units (GRUs), enabling effective state representation from sequences of images and corresponding actions. These learned state representations are used to train a reinforcement learning agent with a Deep Q-Network (DQN). Experimental results demonstrate that our proposed approach enables real-time, accurate estimation and control without direct access to ground-truth states. Additionally, we provide a quantitative evaluation methodology for assessing the accuracy of the learned states, highlighting their impact on policy performance and control stability.",
    "authors": [
      "Ashik E Rasul, Hyung-Jin Yoon"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.834236"
  },
  {
    "id": "oai:arXiv.org:2506.05376v1",
    "journal": "arXiv_CS",
    "title": "A Red Teaming Roadmap Towards System-Level Safety",
    "link": "https://arxiv.org/abs/2506.05376",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05376v1 Announce Type: new \nAbstract: Large Language Model (LLM) safeguards, which implement request refusals, have become a widely adopted mitigation strategy against misuse. At the intersection of adversarial machine learning and AI safety, safeguard red teaming has effectively identified critical vulnerabilities in state-of-the-art refusal-trained LLMs. However, in our view the many conference submissions on LLM red teaming do not, in aggregate, prioritize the right research problems. First, testing against clear product safety specifications should take a higher priority than abstract social biases or ethical principles. Second, red teaming should prioritize realistic threat models that represent the expanding risk landscape and what real attackers might do. Finally, we contend that system-level safety is a necessary step to move red teaming research forward, as AI models present new threats as well as affordances for threat mitigation (e.g., detection and banning of malicious users) once placed in a deployment context. Adopting these priorities will be necessary in order for red teaming research to adequately address the slate of new threats that rapid AI advances present today and will present in the very near future.",
    "authors": [
      "Zifan Wang, Christina Q. Knight, Jeremy Kritz, Willow E. Primack, Julian Michael"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.834245"
  },
  {
    "id": "oai:arXiv.org:2506.05377v1",
    "journal": "arXiv_CS",
    "title": "An Independent Discriminant Network Towards Identification of Counterfeit Images and Videos",
    "link": "https://arxiv.org/abs/2506.05377",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05377v1 Announce Type: new \nAbstract: Rapid spread of false images and videos on online platforms is an emerging problem. Anyone may add, delete, clone or modify people and entities from an image using various editing software which are readily available. This generates false and misleading proof to hide the crime. Now-a-days, these false and counterfeit images and videos are flooding on the internet. These spread false information. Many methods are available in literature for detecting those counterfeit contents but new methods of counterfeiting are also evolving. Generative Adversarial Networks (GAN) are observed to be one effective method as it modifies the context and definition of images producing plausible results via image-to-image translation. This work uses an independent discriminant network that can identify GAN generated image or video. A discriminant network has been created using a convolutional neural network based on InceptionResNetV2. The article also proposes a platform where users can detect forged images and videos. This proposed work has the potential to help the forensics domain to detect counterfeit videos and hidden criminal evidence towards the identification of criminal activities.",
    "authors": [
      "Shayantani Kar, B. Shresth Bhimrajka, Aditya Kumar, Sahil Gupta, Sourav Ghosh, Subhamita Mukherjee, Shauvik Paul"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.834255"
  },
  {
    "id": "oai:arXiv.org:2506.05378v1",
    "journal": "arXiv_CS",
    "title": "A Compendium of Autonomous Navigation using Object Detection and Tracking in Unmanned Aerial Vehicles",
    "link": "https://arxiv.org/abs/2506.05378",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05378v1 Announce Type: new \nAbstract: Unmanned Aerial Vehicles (UAVs) are one of the most revolutionary inventions of 21st century. At the core of a UAV lies the central processing system that uses wireless signals to control their movement. The most popular UAVs are quadcopters that use a set of four motors, arranged as two on either side with opposite spin. An autonomous UAV is called a drone. Drones have been in service in the US army since the 90's for covert missions critical to national security. It would not be wrong to claim that drones make up an integral part of the national security and provide the most valuable service during surveillance operations. While UAVs are controlled using wireless signals, there reside some challenges that disrupt the operation of such vehicles such as signal quality and range, real time processing, human expertise, robust hardware and data security. These challenges can be solved by programming UAVs to be autonomous, using object detection and tracking, through Computer Vision algorithms. Computer Vision is an interdisciplinary field that seeks the use of deep learning to gain a high-level understanding of digital images and videos for the purpose of automating the task of human visual system. Using computer vision, algorithms for detecting and tracking various objects can be developed suitable to the hardware so as to allow real time processing for immediate judgement. This paper attempts to review the various approaches several authors have proposed for the purpose of autonomous navigation of UAVs by through various algorithms of object detection and tracking in real time, for the purpose of applications in various fields such as disaster management, dense area exploration, traffic vehicle surveillance etc.",
    "authors": [
      "Mohit Arora, Pratyush Shukla, Shivali Chopra"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.834264"
  },
  {
    "id": "oai:arXiv.org:2506.05379v1",
    "journal": "arXiv_CS",
    "title": "Designing DSIC Mechanisms for Data Sharing in the Era of Large Language Models",
    "link": "https://arxiv.org/abs/2506.05379",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05379v1 Announce Type: new \nAbstract: Training large language models (LLMs) requires vast amounts of high-quality data from institutions that face legal, privacy, and strategic constraints. Existing data procurement methods often rely on unverifiable trust or ignore heterogeneous provider costs. We introduce a mechanism-design framework for truthful, trust-minimized data sharing that ensures dominant-strategy incentive compatibility (DSIC), individual rationality, and weak budget balance, while rewarding data based on both quality and learning utility. We formalize a model where providers privately know their data cost and quality, and value arises solely from the data's contribution to model performance. Based on this, we propose the Quality-Weighted Marginal-Incentive Auction (Q-MIA), which ranks providers using a virtual cost metric and uses Myerson-style payments to ensure DSIC and budget feasibility. To support settings with limited liquidity or long-term incentives, we introduce the Marginal Utility Token (MUT), which allocates future rights based on marginal contributions. We unify these in Mixed-MIA, a hybrid mechanism balancing upfront payments and deferred rewards. All mechanisms support verifiable, privacy-preserving implementation. Theoretically and empirically, they outperform volume-based and trust-based baselines, eliciting higher-quality data under budget constraints while remaining robust to misreporting and collusion. This establishes a principled foundation for sustainable and fair data markets for future LLMs.",
    "authors": [
      "Seyed Moein Ayyoubzadeh, Kourosh Shahnazari, Mohammmadali Keshtparvar, MohammadAmin Fazli"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.834273"
  },
  {
    "id": "oai:arXiv.org:2506.05381v1",
    "journal": "arXiv_CS",
    "title": "Heterogeneous Secure Transmissions in IRS-Assisted NOMA Communications: CO-GNN Approach",
    "link": "https://arxiv.org/abs/2506.05381",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05381v1 Announce Type: new \nAbstract: Intelligent Reflecting Surfaces (IRS) enhance spectral efficiency by adjusting reflection phase shifts, while Non-Orthogonal Multiple Access (NOMA) increases system capacity. Consequently, IRS-assisted NOMA communications have garnered significant research interest. However, the passive nature of the IRS, lacking authentication and security protocols, makes these systems vulnerable to external eavesdropping due to the openness of electromagnetic signal propagation and reflection. NOMA's inherent multi-user signal superposition also introduces internal eavesdropping risks during user pairing. This paper investigates secure transmissions in IRS-assisted NOMA systems with heterogeneous resource configuration in wireless networks to mitigate both external and internal eavesdropping. To maximize the sum secrecy rate of legitimate users, we propose a combinatorial optimization graph neural network (CO-GNN) approach to jointly optimize beamforming at the base station, power allocation of NOMA users, and phase shifts of IRS for dynamic heterogeneous resource allocation, thereby enabling the design of dual-link or multi-link secure transmissions in the presence of eavesdroppers on the same or heterogeneous links. The CO-GNN algorithm simplifies the complex mathematical problem-solving process, eliminates the need for channel estimation, and enhances scalability. Simulation results demonstrate that the proposed algorithm significantly enhances the secure transmission performance of the system.",
    "authors": [
      "Linlin Liang, Zongkai Tian, Haiyan Huang, Xiaoyan Li, Zhisheng Yin, Dehua Zhang, Nina Zhang, Wenchao Zhai"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.834289"
  },
  {
    "id": "oai:arXiv.org:2506.05382v1",
    "journal": "arXiv_CS",
    "title": "How stealthy is stealthy? Studying the Efficacy of Black-Box Adversarial Attacks in the Real World",
    "link": "https://arxiv.org/abs/2506.05382",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05382v1 Announce Type: new \nAbstract: Deep learning systems, critical in domains like autonomous vehicles, are vulnerable to adversarial examples (crafted inputs designed to mislead classifiers). This study investigates black-box adversarial attacks in computer vision. This is a realistic scenario, where attackers have query-only access to the target model. Three properties are introduced to evaluate attack feasibility: robustness to compression, stealthiness to automatic detection, and stealthiness to human inspection. State-of-the-Art methods tend to prioritize one criterion at the expense of others. We propose ECLIPSE, a novel attack method employing Gaussian blurring on sampled gradients and a local surrogate model. Comprehensive experiments on a public dataset highlight ECLIPSE's advantages, demonstrating its contribution to the trade-off between the three properties.",
    "authors": [
      "Francesco Panebianco, Mario D'Onghia, Stefano Zanero aand Michele Carminati"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.834298"
  },
  {
    "id": "oai:arXiv.org:2506.05385v1",
    "journal": "arXiv_CS",
    "title": "LLMs Can Also Do Well! Breaking Barriers in Semantic Role Labeling via Large Language Models",
    "link": "https://arxiv.org/abs/2506.05385",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05385v1 Announce Type: new \nAbstract: Semantic role labeling (SRL) is a crucial task of natural language processing (NLP). Although generative decoder-based large language models (LLMs) have achieved remarkable success across various NLP tasks, they still lag behind state-of-the-art encoder-decoder (BERT-like) models in SRL. In this work, we seek to bridge this gap by equipping LLMs for SRL with two mechanisms: (a) retrieval-augmented generation and (b) self-correction. The first mechanism enables LLMs to leverage external linguistic knowledge such as predicate and argument structure descriptions, while the second allows LLMs to identify and correct inconsistent SRL outputs. We conduct extensive experiments on three widely-used benchmarks of SRL (CPB1.0, CoNLL-2009, and CoNLL-2012). Results demonstrate that our method achieves state-of-the-art performance in both Chinese and English, marking the first successful application of LLMs to surpass encoder-decoder approaches in SRL.",
    "authors": [
      "Xinxin Li, Huiyao Chen, Chengjun Liu, Jing Li, Meishan Zhang, Jun Yu, Min Zhang"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.834323"
  },
  {
    "id": "oai:arXiv.org:2506.05386v1",
    "journal": "arXiv_CS",
    "title": "Beyond RAG: Reinforced Reasoning Augmented Generation for Clinical Notes",
    "link": "https://arxiv.org/abs/2506.05386",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05386v1 Announce Type: new \nAbstract: Clinical note generation aims to automatically produce free-text summaries of a patient's condition and diagnostic process, with discharge instructions being a representative long-form example. While recent large language model (LLM)-based methods pre-trained on general clinical corpora show promise in clinical text generation, they fall short in producing long-form notes from limited patient information. In this paper, we propose R2AG, the first reinforced retriever for long-form discharge instruction generation based on pre-admission data. R2AG is trained with reinforcement learning to retrieve reasoning paths from a medical knowledge graph, providing explicit semantic guidance to the LLM. To bridge the information gap, we propose Group-Based Retriever Optimization (GRO) which improves retrieval quality with group-relative rewards, encouraging reasoning leaps for deeper inference by the LLM. Comprehensive experiments on the MIMIC-IV-Note dataset show that R2AG outperforms baselines in both clinical efficacy and natural language generation metrics. Further analysis reveals that R2AG fills semantic gaps in sparse input scenarios, and retrieved reasoning paths help LLMs avoid clinical misinterpretation by focusing on key evidence and following coherent reasoning.",
    "authors": [
      "Lo Pang-Yun Ting, Chengshuai Zhao, Yu-Hua Zeng, Yuan Jee Lim, Kun-Ta Chuang"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.834333"
  },
  {
    "id": "oai:arXiv.org:2506.05387v1",
    "journal": "arXiv_CS",
    "title": "Advancing Decoding Strategies: Enhancements in Locally Typical Sampling for LLMs",
    "link": "https://arxiv.org/abs/2506.05387",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05387v1 Announce Type: new \nAbstract: This chapter explores advancements in decoding strategies for large language models (LLMs), focusing on enhancing the Locally Typical Sampling (LTS) algorithm. Traditional decoding methods, such as top-k and nucleus sampling, often struggle to balance fluency, diversity, and coherence in text generation. To address these challenges, Adaptive Semantic-Aware Typicality Sampling (ASTS) is proposed as an improved version of LTS, incorporating dynamic entropy thresholding, multi-objective scoring, and reward-penalty adjustments. ASTS ensures contextually coherent and diverse text generation while maintaining computational efficiency. Its performance is evaluated across multiple benchmarks, including story generation and abstractive summarization, using metrics such as perplexity, MAUVE, and diversity scores. Experimental results demonstrate that ASTS outperforms existing sampling techniques by reducing repetition, enhancing semantic alignment, and improving fluency.",
    "authors": [
      "Jaydip Sen, Saptarshi Sengupta. Subhasis Dasgupta"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.834342"
  },
  {
    "id": "oai:arXiv.org:2506.05388v1",
    "journal": "arXiv_CS",
    "title": "taz2024full: Analysing German Newspapers for Gender Bias and Discrimination across Decades",
    "link": "https://arxiv.org/abs/2506.05388",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05388v1 Announce Type: new \nAbstract: Open-access corpora are essential for advancing natural language processing (NLP) and computational social science (CSS). However, large-scale resources for German remain limited, restricting research on linguistic trends and societal issues such as gender bias. We present taz2024full, the largest publicly available corpus of German newspaper articles to date, comprising over 1.8 million texts from taz, spanning 1980 to 2024.\n  As a demonstration of the corpus's utility for bias and discrimination research, we analyse gender representation across four decades of reporting. We find a consistent overrepresentation of men, but also a gradual shift toward more balanced coverage in recent years. Using a scalable, structured analysis pipeline, we provide a foundation for studying actor mentions, sentiment, and linguistic framing in German journalistic texts.\n  The corpus supports a wide range of applications, from diachronic language analysis to critical media studies, and is freely available to foster inclusive and reproducible research in German-language NLP.",
    "authors": [
      "Stefanie Urchs, Veronika Thurner, Matthias A{\\ss}enmacher, Christian Heumann, Stephanie Thiemichen"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.834351"
  },
  {
    "id": "oai:arXiv.org:2506.05393v1",
    "journal": "arXiv_CS",
    "title": "Are Large Language Models Good Temporal Graph Learners?",
    "link": "https://arxiv.org/abs/2506.05393",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05393v1 Announce Type: new \nAbstract: Large Language Models (LLMs) have recently driven significant advancements in Natural Language Processing and various other applications. While a broad range of literature has explored the graph-reasoning capabilities of LLMs, including their use of predictors on graphs, the application of LLMs to dynamic graphs -- real world evolving networks -- remains relatively unexplored. Recent work studies synthetic temporal graphs generated by random graph models, but applying LLMs to real-world temporal graphs remains an open question. To address this gap, we introduce Temporal Graph Talker (TGTalker), a novel temporal graph learning framework designed for LLMs. TGTalker utilizes the recency bias in temporal graphs to extract relevant structural information, converted to natural language for LLMs, while leveraging temporal neighbors as additional information for prediction. TGTalker demonstrates competitive link prediction capabilities compared to existing Temporal Graph Neural Network (TGNN) models. Across five real-world networks, TGTalker performs competitively with state-of-the-art temporal graph methods while consistently outperforming popular models such as TGN and HTGN. Furthermore, TGTalker generates textual explanations for each prediction, thus opening up exciting new directions in explainability and interpretability for temporal link prediction. The code is publicly available at https://github.com/shenyangHuang/TGTalker.",
    "authors": [
      "Shenyang Huang, Ali Parviz, Emma Kondrup, Zachary Yang, Zifeng Ding, Michael Bronstein, Reihaneh Rabbany, Guillaume Rabusseau"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.834367"
  },
  {
    "id": "oai:arXiv.org:2506.05394v1",
    "journal": "arXiv_CS",
    "title": "Attacking Attention of Foundation Models Disrupts Downstream Tasks",
    "link": "https://arxiv.org/abs/2506.05394",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05394v1 Announce Type: new \nAbstract: Foundation models represent the most prominent and recent paradigm shift in artificial intelligence.Foundation models are large models, trained on broad data that deliver high accuracy in many downstream tasks, often without fine-tuning. For this reason, models such as CLIP , DINO or Vision Transfomers (ViT), are becoming the bedrock of many industrial AI-powered applications. However, the reliance on pre-trained foundation models also introduces significant security concerns, as these models are vulnerable to adversarial attacks. Such attacks involve deliberately crafted inputs designed to deceive AI systems, jeopardizing their reliability.This paper studies the vulnerabilities of vision foundation models, focusing specifically on CLIP and ViTs, and explores the transferability of adversarial attacks to downstream tasks. We introduce a novel attack, targeting the structure of transformer-based architectures in a task-agnostic fashion.We demonstrate the effectiveness of our attack on several downstream tasks: classification, captioning, image/text retrieval, segmentation and depth estimation.",
    "authors": [
      "Hondamunige Prasanna Silva, Federico Becattini, Lorenzo Seidenari"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.834375"
  },
  {
    "id": "oai:arXiv.org:2506.05395v1",
    "journal": "arXiv_CS",
    "title": "TriPSS: A Tri-Modal Keyframe Extraction Framework Using Perceptual, Structural, and Semantic Representations",
    "link": "https://arxiv.org/abs/2506.05395",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05395v1 Announce Type: new \nAbstract: Efficient keyframe extraction is critical for effective video summarization and retrieval, yet capturing the complete richness of video content remains challenging. In this work, we present TriPSS, a novel tri-modal framework that effectively integrates perceptual cues from color features in the CIELAB space, deep structural embeddings derived from ResNet-50, and semantic context from frame-level captions generated by Llama-3.2-11B-Vision-Instruct. By fusing these diverse modalities using principal component analysis, TriPSS constructs robust multi-modal embeddings that enable adaptive segmentation of video content via HDBSCAN clustering. A subsequent refinement stage incorporating quality assessment and duplicate filtering ensures that the final keyframe set is both concise and semantically rich. Comprehensive evaluations on benchmark datasets TVSum20 and SumMe demonstrate that TriPSS achieves state-of-the-art performance, substantially outperforming traditional unimodal and previous multi-modal methods. These results underscore TriPSS's ability to capture nuanced visual and semantic information, thereby setting a new benchmark for video content understanding in large-scale retrieval scenarios.",
    "authors": [
      "Mert Can Cakmak, Nitin Agarwal, Diwash Poudel"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.834384"
  },
  {
    "id": "oai:arXiv.org:2506.05396v1",
    "journal": "arXiv_CS",
    "title": "Talk2SAM: Text-Guided Semantic Enhancement for Complex-Shaped Object Segmentation",
    "link": "https://arxiv.org/abs/2506.05396",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05396v1 Announce Type: new \nAbstract: Segmenting objects with complex shapes, such as wires, bicycles, or structural grids, remains a significant challenge for current segmentation models, including the Segment Anything Model (SAM) and its high-quality variant SAM-HQ. These models often struggle with thin structures and fine boundaries, leading to poor segmentation quality. We propose Talk2SAM, a novel approach that integrates textual guidance to improve segmentation of such challenging objects. The method uses CLIP-based embeddings derived from user-provided text prompts to identify relevant semantic regions, which are then projected into the DINO feature space. These features serve as additional prompts for SAM-HQ, enhancing its ability to focus on the target object. Beyond improving segmentation accuracy, Talk2SAM allows user-controllable segmentation, enabling disambiguation of objects within a single bounding box based on textual input. We evaluate our approach on three benchmarks: BIG, ThinObject5K, and DIS5K. Talk2SAM consistently outperforms SAM-HQ, achieving up to +5.9\\% IoU and +8.3\\% boundary IoU improvements. Our results demonstrate that incorporating natural language guidance provides a flexible and effective means for precise object segmentation, particularly in cases where traditional prompt-based methods fail. The source code is available on GitHub: https://github.com/richlukich/Talk2SAM",
    "authors": [
      "Luka Vetoshkin, Dmitry Yudin"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.834394"
  },
  {
    "id": "oai:arXiv.org:2506.05397v1",
    "journal": "arXiv_CS",
    "title": "Gen4D: Synthesizing Humans and Scenes in the Wild",
    "link": "https://arxiv.org/abs/2506.05397",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05397v1 Announce Type: new \nAbstract: Lack of input data for in-the-wild activities often results in low performance across various computer vision tasks. This challenge is particularly pronounced in uncommon human-centric domains like sports, where real-world data collection is complex and impractical. While synthetic datasets offer a promising alternative, existing approaches typically suffer from limited diversity in human appearance, motion, and scene composition due to their reliance on rigid asset libraries and hand-crafted rendering pipelines. To address this, we introduce Gen4D, a fully automated pipeline for generating diverse and photorealistic 4D human animations. Gen4D integrates expert-driven motion encoding, prompt-guided avatar generation using diffusion-based Gaussian splatting, and human-aware background synthesis to produce highly varied and lifelike human sequences. Based on Gen4D, we present SportPAL, a large-scale synthetic dataset spanning three sports: baseball, icehockey, and soccer. Together, Gen4D and SportPAL provide a scalable foundation for constructing synthetic datasets tailored to in-the-wild human-centric vision tasks, with no need for manual 3D modeling or scene design.",
    "authors": [
      "Jerrin Bright, Zhibo Wang, Yuhao Chen, Sirisha Rambhatla, John Zelek, David Clausi"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.834402"
  },
  {
    "id": "oai:arXiv.org:2506.05398v1",
    "journal": "arXiv_CS",
    "title": "IGSM: Improved Geometric and Sensitivity Matching for Finetuning Pruned Diffusion Models",
    "link": "https://arxiv.org/abs/2506.05398",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05398v1 Announce Type: new \nAbstract: Diffusion models achieve realistic outcomes across a wide range of generative tasks, but their high computational cost remains a major barrier to deployment. Model pruning has emerged as a promising strategy to reduce inference cost and enable lightweight diffusion models. While effective, pruned diffusion models are proned to quality reduction due to limited capacity. A key limitation of current pruning approaches is that pruned models are finetuned using the same objective as the dense model, typically denoising score matching (DSM). Since the dense model is accessible during finetuning, it warrants a more effective approach for knowledge transfer from the dense to the pruned model. Motivated by this aim, we revisit the finetuning stage and propose IGSM (\\textbf{I}mproved \\textbf{G}eometric and \\textbf{S}ensitivity \\textbf{M}atching), a general-purpose finetuning framework that introduces a second-order Jacobian projection loss inspired by Finite-Time Lyapunov Exponents (FTLE). IGSM efficiently captures and aligns the geometric and the temporal dynamics of pruned models with their dense teachers using scalable second-order projections. Our approach is architecture-agnostic and applies to both U-Net- and Transformer-based diffusion models. Experiments on CIFAR-10, CelebA, LSUN-Church, and LSUN-Bedroom show that IGSM consistently narrows the performance gap between pruned and dense models, substantially improving sample quality. Code is available on GitHub: https://github.com/FATE4869/IGSM-Official",
    "authors": [
      "Caleb Zheng, Eli Shlizerman"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.834411"
  },
  {
    "id": "oai:arXiv.org:2506.05399v1",
    "journal": "arXiv_CS",
    "title": "Attention-based transformer models for image captioning across languages: An in-depth survey and evaluation",
    "link": "https://arxiv.org/abs/2506.05399",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05399v1 Announce Type: new \nAbstract: Image captioning involves generating textual descriptions from input images, bridging the gap between computer vision and natural language processing. Recent advancements in transformer-based models have significantly improved caption generation by leveraging attention mechanisms for better scene understanding. While various surveys have explored deep learning-based approaches for image captioning, few have comprehensively analyzed attention-based transformer models across multiple languages. This survey reviews attention-based image captioning models, categorizing them into transformer-based, deep learning-based, and hybrid approaches. It explores benchmark datasets, discusses evaluation metrics such as BLEU, METEOR, CIDEr, and ROUGE, and highlights challenges in multilingual captioning. Additionally, this paper identifies key limitations in current models, including semantic inconsistencies, data scarcity in non-English languages, and limitations in reasoning ability. Finally, we outline future research directions, such as multimodal learning, real-time applications in AI-powered assistants, healthcare, and forensic analysis. This survey serves as a comprehensive reference for researchers aiming to advance the field of attention-based image captioning.",
    "authors": [
      "Israa A. Albadarneh, Bassam H. Hammo, Omar S. Al-Kadi"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.834420"
  },
  {
    "id": "oai:arXiv.org:2506.05400v1",
    "journal": "arXiv_CS",
    "title": "Auto Review: Second Stage Error Detection for Highly Accurate Information Extraction from Phone Conversations",
    "link": "https://arxiv.org/abs/2506.05400",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05400v1 Announce Type: new \nAbstract: Automating benefit verification phone calls saves time in healthcare and helps patients receive treatment faster. It is critical to obtain highly accurate information in these phone calls, as it can affect a patient's healthcare journey. Given the noise in phone call transcripts, we have a two-stage system that involves a post-call review phase for potentially noisy fields, where human reviewers manually verify the extracted data$\\unicode{x2013}$a labor-intensive task. To automate this stage, we introduce Auto Review, which significantly reduces manual effort while maintaining a high bar for accuracy. This system, being highly reliant on call transcripts, suffers a performance bottleneck due to automatic speech recognition (ASR) issues. This problem is further exacerbated by the use of domain-specific jargon in the calls. In this work, we propose a second-stage postprocessing pipeline for accurate information extraction. We improve accuracy by using multiple ASR alternatives and a pseudo-labeling approach that does not require manually corrected transcripts. Experiments with general-purpose large language models and feature-based model pipelines demonstrate substantial improvements in the quality of corrected call transcripts, thereby enhancing the efficiency of Auto Review.",
    "authors": [
      "Ayesha Qamar, Arushi Raghuvanshi, Conal Sathi, Youngseo Son"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.834430"
  },
  {
    "id": "oai:arXiv.org:2506.05401v1",
    "journal": "arXiv_CS",
    "title": "Robust Anti-Backdoor Instruction Tuning in LVLMs",
    "link": "https://arxiv.org/abs/2506.05401",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05401v1 Announce Type: new \nAbstract: Large visual language models (LVLMs) have demonstrated excellent instruction-following capabilities, yet remain vulnerable to stealthy backdoor attacks when finetuned using contaminated data. Existing backdoor defense techniques are usually developed for single-modal visual or language models under fully parameter-adjustable settings or rely on supervisory knowledge during training. However, in real-world scenarios, defenders cannot modify frozen visual encoders or core LLM parameters, nor possess prior knowledge of unknown trigger patterns or target responses. Motivated by the empirical finding that LVLMs readily overfit to fixed, unknown triggers, which can embed malicious associations during adapter-level tuning, we aim to design a defense that operates without access to core weights or attack priors. To this end, we introduce a lightweight, certified-agnostic defense framework, Robust Instruction Tuning, that finetunes only adapter modules and text embedding layers under instruction tuning. Our method integrates two complementary regularizations: (1) Input Diversity Regularization, which perturbs trigger components across training samples to disrupt consistent spurious cues; and (2) Anomalous Activation Regularization, which dynamically sparses adapter weights exhibiting abnormally sharp activations linked to backdoor patterns. These mechanisms jointly guide the model toward learning semantically grounded representations rather than memorizing superficial trigger-response mappings.\n  Extensive experiments against seven attacks on Flickr30k and MSCOCO demonstrate that ours\n  reduces their attack success rate to nearly zero, with an increase in training cost of less than 15%.",
    "authors": [
      "Yuan Xun, Siyuan Liang, Xiaojun Jia, Xinwei Liu, Xiaochun Cao"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.834439"
  },
  {
    "id": "oai:arXiv.org:2506.05403v1",
    "journal": "arXiv_CS",
    "title": "Poisoning Behavioral-based Worker Selection in Mobile Crowdsensing using Generative Adversarial Networks",
    "link": "https://arxiv.org/abs/2506.05403",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05403v1 Announce Type: new \nAbstract: With the widespread adoption of Artificial intelligence (AI), AI-based tools and components are becoming omnipresent in today's solutions. However, these components and tools are posing a significant threat when it comes to adversarial attacks. Mobile Crowdsensing (MCS) is a sensing paradigm that leverages the collective participation of workers and their smart devices to collect data. One of the key challenges faced at the selection stage is ensuring task completion due to workers' varying behavior. AI has been utilized to tackle this challenge by building unique models for each worker to predict their behavior. However, the integration of AI into the system introduces vulnerabilities that can be exploited by malicious insiders to reduce the revenue obtained by victim workers. This work proposes an adversarial attack targeting behavioral-based selection models in MCS. The proposed attack leverages Generative Adversarial Networks (GANs) to generate poisoning points that can mislead the models during the training stage without being detected. This way, the potential damage introduced by GANs on worker selection in MCS can be anticipated. Simulation results using a real-life dataset show the effectiveness of the proposed attack in compromising the victim workers' model and evading detection by an outlier detector, compared to a benchmark. In addition, the impact of the attack on reducing the payment obtained by victim workers is evaluated.",
    "authors": [
      "Ruba Nasser, Ahmed Alagha, Shakti Singh, Rabeb Mizouni, Hadi Otrok, Jamal Bentahar"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.834455"
  },
  {
    "id": "oai:arXiv.org:2506.05404v1",
    "journal": "arXiv_CS",
    "title": "AD-EE: Early Exiting for Fast and Reliable Vision-Language Models in Autonomous Driving",
    "link": "https://arxiv.org/abs/2506.05404",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05404v1 Announce Type: new \nAbstract: With the rapid advancement of autonomous driving, deploying Vision-Language Models (VLMs) to enhance perception and decision-making has become increasingly common. However, the real-time application of VLMs is hindered by high latency and computational overhead, limiting their effectiveness in time-critical driving scenarios. This challenge is particularly evident when VLMs exhibit over-inference, continuing to process unnecessary layers even after confident predictions have been reached. To address this inefficiency, we propose AD-EE, an Early Exit framework that incorporates domain characteristics of autonomous driving and leverages causal inference to identify optimal exit layers. We evaluate our method on large-scale real-world autonomous driving datasets, including Waymo and the corner-case-focused CODA, as well as on a real vehicle running the Autoware Universe platform. Extensive experiments across multiple VLMs show that our method significantly reduces latency, with maximum improvements reaching up to 57.58%, and enhances object detection accuracy, with maximum gains of up to 44%.",
    "authors": [
      "Lianming Huang, Haibo Hu, Yufei Cui, Jiacheng Zuo, Shangyu Wu, Nan Guan, Chun Jason Xue"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.834464"
  },
  {
    "id": "oai:arXiv.org:2506.05405v1",
    "journal": "arXiv_CS",
    "title": "A VLM-based Method for Visual Anomaly Detection in Robotic Scientific Laboratories",
    "link": "https://arxiv.org/abs/2506.05405",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05405v1 Announce Type: new \nAbstract: In robot scientific laboratories, visual anomaly detection is important for the timely identification and resolution of potential faults or deviations. It has become a key factor in ensuring the stability and safety of experimental processes. To address this challenge, this paper proposes a VLM-based visual reasoning approach that supports different levels of supervision through four progressively informative prompt configurations. To systematically evaluate its effectiveness, we construct a visual benchmark tailored for process anomaly detection in scientific workflows. Experiments on two representative vision-language models show that detection accuracy improves as more contextual information is provided, confirming the effectiveness and adaptability of the proposed reasoning approach for process anomaly detection in scientific workflows. Furthermore, real-world validations at selected experimental steps confirm that first-person visual observation can effectively identify process-level anomalies. This work provides both a data-driven foundation and an evaluation framework for vision anomaly detection in scientific experiment workflows.",
    "authors": [
      "Shiwei Lin, Chenxu Wang, Xiaozhen Ding, Yi Wang, Boyuan Du, Lei Song, Chenggang Wang, Huaping Liu"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.834473"
  },
  {
    "id": "oai:arXiv.org:2506.05407v1",
    "journal": "arXiv_CS",
    "title": "PCEvolve: Private Contrastive Evolution for Synthetic Dataset Generation via Few-Shot Private Data and Generative APIs",
    "link": "https://arxiv.org/abs/2506.05407",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05407v1 Announce Type: new \nAbstract: The rise of generative APIs has fueled interest in privacy-preserving synthetic data generation. While the Private Evolution (PE) algorithm generates Differential Privacy (DP) synthetic images using diffusion model APIs, it struggles with few-shot private data due to the limitations of its DP-protected similarity voting approach. In practice, the few-shot private data challenge is particularly prevalent in specialized domains like healthcare and industry. To address this challenge, we propose a novel API-assisted algorithm, Private Contrastive Evolution (PCEvolve), which iteratively mines inherent inter-class contrastive relationships in few-shot private data beyond individual data points and seamlessly integrates them into an adapted Exponential Mechanism (EM) to optimize DP's utility in an evolution loop. We conduct extensive experiments on four specialized datasets, demonstrating that PCEvolve outperforms PE and other API-assisted baselines. These results highlight the potential of leveraging API access with private data for quality evaluation, enabling the generation of high-quality DP synthetic images and paving the way for more accessible and effective privacy-preserving generative API applications. Our code is available at https://github.com/TsingZ0/PCEvolve.",
    "authors": [
      "Jianqing Zhang, Yang Liu, Jie Fu, Yang Hua, Tianyuan Zou, Jian Cao, Qiang Yang"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.834482"
  },
  {
    "id": "oai:arXiv.org:2506.05408v1",
    "journal": "arXiv_CS",
    "title": "Differentially Private Federated $k$-Means Clustering with Server-Side Data",
    "link": "https://arxiv.org/abs/2506.05408",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05408v1 Announce Type: new \nAbstract: Clustering is a cornerstone of data analysis that is particularly suited to identifying coherent subgroups or substructures in unlabeled data, as are generated continuously in large amounts these days. However, in many cases traditional clustering methods are not applicable, because data are increasingly being produced and stored in a distributed way, e.g. on edge devices, and privacy concerns prevent it from being transferred to a central server. To address this challenge, we present \\acronym, a new algorithm for $k$-means clustering that is fully-federated as well as differentially private. Our approach leverages (potentially small and out-of-distribution) server-side data to overcome the primary challenge of differentially private clustering methods: the need for a good initialization. Combining our initialization with a simple federated DP-Lloyds algorithm we obtain an algorithm that achieves excellent results on synthetic and real-world benchmark tasks. We also provide a theoretical analysis of our method that provides bounds on the convergence speed and cluster identification success.",
    "authors": [
      "Jonathan Scott, Christoph H. Lampert, David Saulpic"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.834491"
  },
  {
    "id": "oai:arXiv.org:2506.05410v1",
    "journal": "arXiv_CS",
    "title": "Homogeneous Keys, Heterogeneous Values: Exploiting Local KV Cache Asymmetry for Long-Context LLMs",
    "link": "https://arxiv.org/abs/2506.05410",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05410v1 Announce Type: new \nAbstract: Recent advances in Large Language Models (LLMs) have highlighted the critical importance of extending context length, yet the quadratic complexity of attention mechanisms poses significant challenges for efficient long-context modeling. KV cache compression has emerged as a key approach to address this challenge. Through extensive empirical analysis, we reveal a fundamental yet previously overlooked asymmetry in KV caches: while adjacent keys receive similar attention weights (local homogeneity), adjacent values demonstrate distinct heterogeneous distributions. This key-value asymmetry reveals a critical limitation in existing compression methods that treat keys and values uniformly. To address the limitation, we propose a training-free compression framework (AsymKV) that combines homogeneity-based key merging with a mathematically proven lossless value compression. Extensive experiments demonstrate that AsymKV consistently outperforms existing long-context methods across various tasks and base models. For example, on LLaMA3.1-8B, AsymKV achieves an average score of 43.95 on LongBench, surpassing SOTA methods like H$_2$O (38.89) by a large margin.",
    "authors": [
      "Wanyun Cui, Mingwei Xu"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.834507"
  },
  {
    "id": "oai:arXiv.org:2506.05412v1",
    "journal": "arXiv_CS",
    "title": "Can Vision Language Models Infer Human Gaze Direction? A Controlled Study",
    "link": "https://arxiv.org/abs/2506.05412",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05412v1 Announce Type: new \nAbstract: Gaze-referential inference--the ability to infer what others are looking at--is a critical component of a theory of mind that underpins natural human-AI interaction. In a controlled study, we evaluated this skill across 111 Vision Language Models (VLMs) using photos taken with manipulated difficulty and variability, comparing performance with that of human participants (N = 65), and analyzed behaviors using mixed-effects models. We found that 94 of the 111 VLMs failed to do better than random guessing, while humans achieved near-ceiling accuracy. VLMs even respond with each choice almost equally frequently. Are they randomly guessing? Although most VLMs struggle, when we zoom in on five of the top-tier VLMs with above-chance performance, we find that their performance declined with increasing task difficulty but varied only slightly across different prompts and scene objects. These behavioral features cannot be explained by considering them as random guessers. Instead, they likely use a combination of heuristics and guessing such that their performance is subject to the task difficulty but robust to perceptual variations. This suggests that VLMs, lacking gaze inference capability, have yet to become technologies that can naturally interact with humans, but the potential remains.",
    "authors": [
      "Zory Zhang, Pinyuan Feng, Bingyang Wang, Tianwei Zhao, Suyang Yu, Qingying Gao, Hokin Deng, Ziqiao Ma, Yijiang Li, Dezhi Luo"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.834524"
  },
  {
    "id": "oai:arXiv.org:2506.05413v1",
    "journal": "arXiv_CS",
    "title": "SmoothRot: Combining Channel-Wise Scaling and Rotation for Quantization-Friendly LLMs",
    "link": "https://arxiv.org/abs/2506.05413",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05413v1 Announce Type: new \nAbstract: We present SmoothRot, a novel post-training quantization technique to enhance the efficiency of 4-bit quantization in Large Language Models (LLMs). SmoothRot addresses the critical challenge of massive activation outliers, by integrating channel-wise scaling with Hadamard transformations. Our technique effectively transforms extreme outliers into quantization-friendly activations, significantly improving quantization accuracy. Experiments conducted on popular LLMs (LLaMA2 7B, LLaMA3.1 8B, and Mistral 7B) demonstrate that SmoothRot consistently reduces the performance gap between quantized and FP16 models by approximately 10-30\\% across language generation and zero-shot reasoning tasks, without introducing additional inference latency. Code is available at https://github.com/czakop/smoothrot.",
    "authors": [
      "Patrik Czak\\'o, G\\'abor Kert\\'esz, S\\'andor Sz\\'en\\'asi"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.834532"
  },
  {
    "id": "oai:arXiv.org:2506.05414v1",
    "journal": "arXiv_CS",
    "title": "SAVVY: Spatial Awareness via Audio-Visual LLMs through Seeing and Hearing",
    "link": "https://arxiv.org/abs/2506.05414",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05414v1 Announce Type: new \nAbstract: 3D spatial reasoning in dynamic, audio-visual environments is a cornerstone of human cognition yet remains largely unexplored by existing Audio-Visual Large Language Models (AV-LLMs) and benchmarks, which predominantly focus on static or 2D scenes. We introduce SAVVY-Bench, the first benchmark for 3D spatial reasoning in dynamic scenes with synchronized spatial audio. SAVVY-Bench is comprised of thousands of relationships involving static and moving objects, and requires fine-grained temporal grounding, consistent 3D localization, and multi-modal annotation. To tackle this challenge, we propose SAVVY, a novel training-free reasoning pipeline that consists of two stages: (i) Egocentric Spatial Tracks Estimation, which leverages AV-LLMs as well as other audio-visual methods to track the trajectories of key objects related to the query using both visual and spatial audio cues, and (ii) Dynamic Global Map Construction, which aggregates multi-modal queried object trajectories and converts them into a unified global dynamic map. Using the constructed map, a final QA answer is obtained through a coordinate transformation that aligns the global map with the queried viewpoint. Empirical evaluation demonstrates that SAVVY substantially enhances performance of state-of-the-art AV-LLMs, setting a new standard and stage for approaching dynamic 3D spatial reasoning in AV-LLMs.",
    "authors": [
      "Mingfei Chen, Zijun Cui, Xiulong Liu, Jinlin Xiang, Caleb Zheng, Jingyuan Li, Eli Shlizerman"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.834541"
  },
  {
    "id": "oai:arXiv.org:2506.05415v1",
    "journal": "arXiv_CS",
    "title": "Automatically Detecting Amusing Games in Wordle",
    "link": "https://arxiv.org/abs/2506.05415",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05415v1 Announce Type: new \nAbstract: We explore automatically predicting which Wordle games Reddit users find amusing.\n  We scrape approximately 80k reactions by Reddit users to Wordle games from Reddit, classify the reactions as expressing amusement or not using OpenAI's GPT-3.5 using few-shot prompting, and verify that GPT-3.5's labels roughly correspond to human labels.\n  We then extract features from Wordle games that can predict user amusement. We demonstrate that the features indeed provide a (weak) signal that predicts user amusement as predicted by GPT-3.5.\n  Our results indicate that user amusement at Wordle games can be predicted computationally to some extent. We explore which features of the game contribute to user amusement.\n  We find that user amusement is predictable, indicating a measurable aspect of creativity infused into Wordle games through humor.",
    "authors": [
      "Ronaldo Luo, Gary Liang, Cindy Liu, Adam Kabbara, Minahil Bakhtawar, Kina Kim, Michael Guerzhoy"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.834549"
  },
  {
    "id": "oai:arXiv.org:2506.05416v1",
    "journal": "arXiv_CS",
    "title": "FERRET: Private Deep Learning Faster And Better Than DPSGD",
    "link": "https://arxiv.org/abs/2506.05416",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05416v1 Announce Type: new \nAbstract: We revisit 1-bit gradient compression through the lens of mutual-information differential privacy (MI-DP). Building on signSGD, we propose FERRET--Fast and Effective Restricted Release for Ethical Training--which transmits at most one sign bit per parameter group with Bernoulli masking.\n  Theory: We prove each fired group leaks at most ln 2 nats; after subsampling with rate s, the total privacy loss of G groups trained for T steps with firing probability p is epsilon = G * T * s * p * ln 2. Thus FERRET achieves MI-DP for epsilon in [0.1, 2] without additive noise.\n  Practice: We evaluate three granularities--FERRET-MAX (finest), FERRET-EIGHTH (medium), and FERRET-2 (coarsest)--on five LLMs (137M-1.8B parameters) against DPSGD and Non-DP baselines. All methods trained for 1, 3, and 5 epochs.\n  Utility: Across all settings, FERRET-MAX/EIGHTH beat DPSGD's perplexity. At epsilon=0.5, 5 epochs: FERRET-EIGHTH achieves 3.98 perplexity vs DPSGD's 11.61 (2.9x better), within 23% of Non-DP (3.25).\n  Privacy: MI-AUC stays at chance for FERRET-MAX/EIGHTH (~0.51), matching DPSGD vs Non-DP's 0.76-0.99. FERRET-2 shows higher leakage (~0.55) due to lower headroom.\n  Efficiency: Stricter budgets fire fewer signs, so FERRET uses 19-33% of DPSGD's training time and only 34-36% of Non-DP training time.\n  Take-away: Sign-based MI-DP gets closer to achieving all three qualities of the privacy, utility, performance trilemma: FERRET trains up to 5x faster, achieves 3x lower perplexity compared to DPSGD and 1.2x greater than Non-DP, all while providing formal, mathematically provable privacy guarantees using zero additive noise. The results also show that, in certain instances, masked 1-bit updates can match non-private training utility while safeguarding data.",
    "authors": [
      "David Zagardo"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.834557"
  },
  {
    "id": "oai:arXiv.org:2506.05417v1",
    "journal": "arXiv_CS",
    "title": "Better STEP, a format and dataset for boundary representation",
    "link": "https://arxiv.org/abs/2506.05417",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05417v1 Announce Type: new \nAbstract: Boundary representation (B-rep) generated from computer-aided design (CAD) is widely used in industry, with several large datasets available. However, the data in these datasets is represented in STEP format, requiring a CAD kernel to read and process it. This dramatically limits their scope and usage in large learning pipelines, as it constrains the possibility of deploying them on computing clusters due to the high cost of per-node licenses.\n  This paper introduces an alternative format based on the open, cross-platform format HDF5 and a corresponding dataset for STEP files, paired with an open-source library to query and process them. Our Python package also provides standard functionalities such as sampling, normals, and curvature to ease integration in existing pipelines.\n  To demonstrate the effectiveness of our format, we converted the Fusion 360 dataset and the ABC dataset. We developed four standard use cases (normal estimation, denoising, surface reconstruction, and segmentation) to assess the integrity of the data and its compliance with the original STEP files.",
    "authors": [
      "Nafiseh Izadyar, Sai Chandra Madduri, Teseo Schneider"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.834566"
  },
  {
    "id": "oai:arXiv.org:2506.05418v1",
    "journal": "arXiv_CS",
    "title": "Self-Predictive Dynamics for Generalization of Vision-based Reinforcement Learning",
    "link": "https://arxiv.org/abs/2506.05418",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05418v1 Announce Type: new \nAbstract: Vision-based reinforcement learning requires efficient and robust representations of image-based observations, especially when the images contain distracting (task-irrelevant) elements such as shadows, clouds, and light. It becomes more important if those distractions are not exposed during training. We design a Self-Predictive Dynamics (SPD) method to extract task-relevant features efficiently, even in unseen observations after training. SPD uses weak and strong augmentations in parallel, and learns representations by predicting inverse and forward transitions across the two-way augmented versions. In a set of MuJoCo visual control tasks and an autonomous driving task (CARLA), SPD outperforms previous studies in complex observations, and significantly improves the generalization performance for unseen observations. Our code is available at https://github.com/unigary/SPD.",
    "authors": [
      "Kyungsoo Kim, Jeongsoo Ha, Yusung Kim"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.834575"
  },
  {
    "id": "oai:arXiv.org:2506.05419v1",
    "journal": "arXiv_CS",
    "title": "Dream to Generalize: Zero-Shot Model-Based Reinforcement Learning for Unseen Visual Distractions",
    "link": "https://arxiv.org/abs/2506.05419",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05419v1 Announce Type: new \nAbstract: Model-based reinforcement learning (MBRL) has been used to efficiently solve vision-based control tasks in highdimensional image observations. Although recent MBRL algorithms perform well in trained observations, they fail when faced with visual distractions in observations. These task-irrelevant distractions (e.g., clouds, shadows, and light) may be constantly present in real-world scenarios. In this study, we propose a novel self-supervised method, Dream to Generalize (Dr. G), for zero-shot MBRL. Dr. G trains its encoder and world model with dual contrastive learning which efficiently captures task-relevant features among multi-view data augmentations. We also introduce a recurrent state inverse dynamics model that helps the world model to better understand the temporal structure. The proposed methods can enhance the robustness of the world model against visual distractions. To evaluate the generalization performance, we first train Dr. G on simple backgrounds and then test it on complex natural video backgrounds in the DeepMind Control suite, and the randomizing environments in Robosuite. Dr. G yields a performance improvement of 117% and 14% over prior works, respectively. Our code is open-sourced and available at https://github.com/JeongsooHa/DrG.git",
    "authors": [
      "Jeongsoo Ha, Kyungsoo Kim, Yusung Kim"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.834584"
  },
  {
    "id": "oai:arXiv.org:2506.05420v1",
    "journal": "arXiv_CS",
    "title": "Self-supervised One-Stage Learning for RF-based Multi-Person Pose Estimation",
    "link": "https://arxiv.org/abs/2506.05420",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05420v1 Announce Type: new \nAbstract: In the field of Multi-Person Pose Estimation (MPPE), Radio Frequency (RF)-based methods can operate effectively regardless of lighting conditions and obscured line-of-sight situations. Existing RF-based MPPE methods typically involve either 1) converting RF signals into heatmap images through complex preprocessing, or 2) applying a deep embedding network directly to raw RF signals. The first approach, while delivering decent performance, is computationally intensive and time-consuming. The second method, though simpler in preprocessing, results in lower MPPE accuracy and generalization performance. This paper proposes an efficient and lightweight one-stage MPPE model based on raw RF signals. By sub-grouping RF signals and embedding them using a shared single-layer CNN followed by multi-head attention, this model outperforms previous methods that embed all signals at once through a large and deep CNN. Additionally, we propose a new self-supervised learning (SSL) method that takes inputs from both one unmasked subgroup and the remaining masked subgroups to predict the latent representations of the masked data. Empirical results demonstrate that our model improves MPPE accuracy by up to 15 in PCKh@0.5 compared to previous methods using raw RF signals. Especially, the proposed SSL method has shown to significantly enhance performance improvements when placed in new locations or in front of obstacles at RF antennas, contributing to greater performance gains as the number of people increases. Our code and dataset is open at Github. https://github.com/sshnan7/SOSPE .",
    "authors": [
      "Seunghwan Shin, Yusung Kim"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.834592"
  },
  {
    "id": "oai:arXiv.org:2506.05421v1",
    "journal": "arXiv_CS",
    "title": "TRIDENT -- A Three-Tier Privacy-Preserving Propaganda Detection Model in Mobile Networks using Transformers, Adversarial Learning, and Differential Privacy",
    "link": "https://arxiv.org/abs/2506.05421",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05421v1 Announce Type: new \nAbstract: The proliferation of propaganda on mobile platforms raises critical concerns around detection accuracy and user privacy. To address this, we propose TRIDENT - a three-tier propaganda detection model implementing transformers, adversarial learning, and differential privacy which integrates syntactic obfuscation and label perturbation to mitigate privacy leakage while maintaining propaganda detection accuracy. TRIDENT leverages multilingual back-translation to introduce semantic variance, character-level noise, and entity obfuscation for differential privacy enforcement, and combines these techniques into a unified defense mechanism. Using a binary propaganda classification dataset, baseline transformer models (BERT, GPT-2) we achieved F1 scores of 0.89 and 0.90. Applying TRIDENT's third-tier defense yields a reduced but effective cumulative F1 of 0.83, demonstrating strong privacy protection across mobile ML deployments with minimal degradation.",
    "authors": [
      "Al Nahian Bin Emran, Dhiman Goswami, Md Hasan Ullah Sadi, Sanchari Das"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.834603"
  },
  {
    "id": "oai:arXiv.org:2506.05425v1",
    "journal": "arXiv_CS",
    "title": "SIV-Bench: A Video Benchmark for Social Interaction Understanding and Reasoning",
    "link": "https://arxiv.org/abs/2506.05425",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05425v1 Announce Type: new \nAbstract: The rich and multifaceted nature of human social interaction, encompassing multimodal cues, unobservable relations and mental states, and dynamical behavior, presents a formidable challenge for artificial intelligence. To advance research in this area, we introduce SIV-Bench, a novel video benchmark for rigorously evaluating the capabilities of Multimodal Large Language Models (MLLMs) across Social Scene Understanding (SSU), Social State Reasoning (SSR), and Social Dynamics Prediction (SDP). SIV-Bench features 2,792 video clips and 8,792 meticulously generated question-answer pairs derived from a human-LLM collaborative pipeline. It is originally collected from TikTok and YouTube, covering a wide range of video genres, presentation styles, and linguistic and cultural backgrounds. It also includes a dedicated setup for analyzing the impact of different textual cues-original on-screen text, added dialogue, or no text. Our comprehensive experiments on leading MLLMs reveal that while models adeptly handle SSU, they significantly struggle with SSR and SDP, where Relation Inference (RI) is an acute bottleneck, as further examined in our analysis. Our study also confirms the critical role of transcribed dialogue in aiding comprehension of complex social interactions. By systematically identifying current MLLMs' strengths and limitations, SIV-Bench offers crucial insights to steer the development of more socially intelligent AI. The dataset and code are available at https://kfq20.github.io/sivbench/.",
    "authors": [
      "Fanqi Kong, Weiqin Zu, Xinyu Chen, Yaodong Yang, Song-Chun Zhu, Xue Feng"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.834620"
  },
  {
    "id": "oai:arXiv.org:2506.05426v1",
    "journal": "arXiv_CS",
    "title": "Mixture-of-Experts Meets In-Context Reinforcement Learning",
    "link": "https://arxiv.org/abs/2506.05426",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05426v1 Announce Type: new \nAbstract: In-context reinforcement learning (ICRL) has emerged as a promising paradigm for adapting RL agents to downstream tasks through prompt conditioning. However, two notable challenges remain in fully harnessing in-context learning within RL domains: the intrinsic multi-modality of the state-action-reward data and the diverse, heterogeneous nature of decision tasks. To tackle these challenges, we propose \\textbf{T2MIR} (\\textbf{T}oken- and \\textbf{T}ask-wise \\textbf{M}oE for \\textbf{I}n-context \\textbf{R}L), an innovative framework that introduces architectural advances of mixture-of-experts (MoE) into transformer-based decision models. T2MIR substitutes the feedforward layer with two parallel layers: a token-wise MoE that captures distinct semantics of input tokens across multiple modalities, and a task-wise MoE that routes diverse tasks to specialized experts for managing a broad task distribution with alleviated gradient conflicts. To enhance task-wise routing, we introduce a contrastive learning method that maximizes the mutual information between the task and its router representation, enabling more precise capture of task-relevant information. The outputs of two MoE components are concatenated and fed into the next layer. Comprehensive experiments show that T2MIR significantly facilitates in-context learning capacity and outperforms various types of baselines. We bring the potential and promise of MoE to ICRL, offering a simple and scalable architectural enhancement to advance ICRL one step closer toward achievements in language and vision communities. Our code is available at https://github.com/NJU-RL/T2MIR.",
    "authors": [
      "Wenhao Wu, Fuhong Liu, Haoru Li, Zican Hu, Daoyi Dong, Chunlin Chen, Zhi Wang"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.834628"
  },
  {
    "id": "oai:arXiv.org:2506.05428v1",
    "journal": "arXiv_CS",
    "title": "Diffusion with a Linguistic Compass: Steering the Generation of Clinically Plausible Future sMRI Representations for Early MCI Conversion Prediction",
    "link": "https://arxiv.org/abs/2506.05428",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05428v1 Announce Type: new \nAbstract: Early prediction of Mild Cognitive Impairment (MCI) conversion is hampered by a trade-off between immediacy--making fast predictions from a single baseline sMRI--and accuracy--leveraging longitudinal scans to capture disease progression. We propose MCI-Diff, a diffusion-based framework that synthesizes clinically plausible future sMRI representations directly from baseline data, achieving both real-time risk assessment and high predictive performance. First, a multi-task sequence reconstruction strategy trains a shared denoising network on interpolation and extrapolation tasks to handle irregular follow-up sampling and learn robust latent trajectories. Second, an LLM-driven \"linguistic compass\" is introduced for clinical plausibility sampling: generated feature candidates are quantized, tokenized, and scored by a fine-tuned language model conditioned on expected structural biomarkers, guiding autoregressive generation toward realistic disease patterns. Experiments on ADNI and AIBL cohorts show that MCI-Diff outperforms state-of-the-art baselines, improving early conversion accuracy by 5-12%.",
    "authors": [
      "Zhihao Tang, Chaozhuo Li, Litian Zhang, Xi Zhang"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.834646"
  },
  {
    "id": "oai:arXiv.org:2506.05429v1",
    "journal": "arXiv_CS",
    "title": "Coordinated Robustness Evaluation Framework for Vision-Language Models",
    "link": "https://arxiv.org/abs/2506.05429",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05429v1 Announce Type: new \nAbstract: Vision-language models, which integrate computer vision and natural language processing capabilities, have demonstrated significant advancements in tasks such as image captioning and visual question and answering. However, similar to traditional models, they are susceptible to small perturbations, posing a challenge to their robustness, particularly in deployment scenarios. Evaluating the robustness of these models requires perturbations in both the vision and language modalities to learn their inter-modal dependencies. In this work, we train a generic surrogate model that can take both image and text as input and generate joint representation which is further used to generate adversarial perturbations for both the text and image modalities. This coordinated attack strategy is evaluated on the visual question and answering and visual reasoning datasets using various state-of-the-art vision-language models. Our results indicate that the proposed strategy outperforms other multi-modal attacks and single-modality attacks from the recent literature. Our results demonstrate their effectiveness in compromising the robustness of several state-of-the-art pre-trained multi-modal models such as instruct-BLIP, ViLT and others.",
    "authors": [
      "Ashwin Ramesh Babu, Sajad Mousavi, Vineet Gundecha, Sahand Ghorbanpour, Avisek Naug, Antonio Guillen, Ricardo Luna Gutierrez, Soumyendu Sarkar"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.834654"
  },
  {
    "id": "oai:arXiv.org:2506.05431v1",
    "journal": "arXiv_CS",
    "title": "Robustness Evaluation for Video Models with Reinforcement Learning",
    "link": "https://arxiv.org/abs/2506.05431",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05431v1 Announce Type: new \nAbstract: Evaluating the robustness of Video classification models is very challenging, specifically when compared to image-based models. With their increased temporal dimension, there is a significant increase in complexity and computational cost. One of the key challenges is to keep the perturbations to a minimum to induce misclassification. In this work, we propose a multi-agent reinforcement learning approach (spatial and temporal) that cooperatively learns to identify the given video's sensitive spatial and temporal regions. The agents consider temporal coherence in generating fine perturbations, leading to a more effective and visually imperceptible attack. Our method outperforms the state-of-the-art solutions on the Lp metric and the average queries. Our method enables custom distortion types, making the robustness evaluation more relevant to the use case. We extensively evaluate 4 popular models for video action recognition on two popular datasets, HMDB-51 and UCF-101.",
    "authors": [
      "Ashwin Ramesh Babu, Sajad Mousavi, Vineet Gundecha, Sahand Ghorbanpour, Avisek Naug, Antonio Guillen, Ricardo Luna Gutierrez, Soumyendu Sarkar"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.834670"
  },
  {
    "id": "oai:arXiv.org:2506.05432v1",
    "journal": "arXiv_CS",
    "title": "PCDVQ: Enhancing Vector Quantization for Large Language Models via Polar Coordinate Decoupling",
    "link": "https://arxiv.org/abs/2506.05432",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05432v1 Announce Type: new \nAbstract: Large Language Models (LLMs) face significant challenges in edge deployment due to their massive parameter scale. Vector Quantization (VQ), a clustering-based quantization method, serves as a prevalent solution to this issue for its extremely low-bit (even at 2-bit) and considerable accuracy. Since a vector is a quantity in mathematics and physics that has both direction and magnitude, existing VQ works typically quantize them in a coupled manner. However, we find that direction exhibits significantly greater sensitivity to quantization compared to the magnitude. For instance, when separately clustering the directions and magnitudes of weight vectors in LLaMA-2-7B, the accuracy drop of zero-shot tasks are 46.5\\% and 2.3\\%, respectively. This gap even increases with the reduction of clustering centers. Further, Euclidean distance, a common metric to access vector similarities in current VQ works, places greater emphasis on reducing the magnitude error. This property is contrary to the above finding, unavoidably leading to larger quantization errors. To these ends, this paper proposes Polar Coordinate Decoupled Vector Quantization (PCDVQ), an effective and efficient VQ framework consisting of two key modules: 1) Polar Coordinate Decoupling (PCD), which transforms vectors into their polar coordinate representations and perform independent quantization of the direction and magnitude parameters.2) Distribution Aligned Codebook Construction (DACC), which optimizes the direction and magnitude codebooks in accordance with the source distribution. Experimental results show that PCDVQ outperforms baseline methods at 2-bit level by at least 1.5\\% zero-shot accuracy, establishing a novel paradigm for accurate and highly compressed LLMs.",
    "authors": [
      "Yuxuan Yue, Zukang Xu, Zhihang Yuan, Dawei Yang, Jianglong Wu, Liqiang Nie"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.834679"
  },
  {
    "id": "oai:arXiv.org:2506.05434v1",
    "journal": "arXiv_CS",
    "title": "Efficient Robust Conformal Prediction via Lipschitz-Bounded Networks",
    "link": "https://arxiv.org/abs/2506.05434",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05434v1 Announce Type: new \nAbstract: Conformal Prediction (CP) has proven to be an effective post-hoc method for improving the trustworthiness of neural networks by providing prediction sets with finite-sample guarantees. However, under adversarial attacks, classical conformal guarantees do not hold anymore: this problem is addressed in the field of Robust Conformal Prediction. Several methods have been proposed to provide robust CP sets with guarantees under adversarial perturbations, but, for large scale problems, these sets are either too large or the methods are too computationally demanding to be deployed in real life scenarios. In this work, we propose a new method that leverages Lipschitz-bounded networks to precisely and efficiently estimate robust CP sets. When combined with a 1-Lipschitz robust network, we demonstrate that our lip-rcp method outperforms state-of-the-art results in both the size of the robust CP sets and computational efficiency in medium and large-scale scenarios such as ImageNet. Taking a different angle, we also study vanilla CP under attack, and derive new worst-case coverage bounds of vanilla CP sets, which are valid simultaneously for all adversarial attack levels. Our lip-rcp method makes this second approach as efficient as vanilla CP while also allowing robustness guarantees.",
    "authors": [
      "Thomas Massena (IRIT, DTIPG - SNCF, UT3), L\\'eo and\\'eol (IMT, DTIPG - SNCF, UT3), Thibaut Boissin (IRIT, UT3), Franck Mamalet (IRIT, UT3), Corentin Friedrich (IRIT, UT3), Mathieu Serrurier (IRIT, UT3), S\\'ebastien Gerchinovitz (IMT)"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.834695"
  },
  {
    "id": "oai:arXiv.org:2506.05435v1",
    "journal": "arXiv_CS",
    "title": "Event Classification of Accelerometer Data for Industrial Package Monitoring with Embedded Deep Learning",
    "link": "https://arxiv.org/abs/2506.05435",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05435v1 Announce Type: new \nAbstract: Package monitoring is an important topic in industrial applications, with significant implications for operational efficiency and ecological sustainability. In this study, we propose an approach that employs an embedded system, placed on reusable packages, to detect their state (on a Forklift, in a Truck, or in an undetermined location). We aim to design a system with a lifespan of several years, corresponding to the lifespan of reusable packages. Our analysis demonstrates that maximizing device lifespan requires minimizing wake time. We propose a pipeline that includes data processing, training, and evaluation of the deep learning model designed for imbalanced, multiclass time series data collected from an embedded sensor. The method uses a one-dimensional Convolutional Neural Network architecture to classify accelerometer data from the IoT device. Before training, two data augmentation techniques are tested to solve the imbalance problem of the dataset: the Synthetic Minority Oversampling TEchnique and the ADAptive SYNthetic sampling approach. After training, compression techniques are implemented to have a small model size. On the considered twoclass problem, the methodology yields a precision of 94.54% for the first class and 95.83% for the second class, while compression techniques reduce the model size by a factor of four. The trained model is deployed on the IoT device, where it operates with a power consumption of 316 mW during inference.",
    "authors": [
      "Manon Renault (IMT Atlantique), Hamoud Younes (IMT Atlantique), Hugo Tessier (IMT Atlantique), Ronan Le Roy (IMT Atlantique), Bastien Pasdeloup (IMT Atlantique), Mathieu L\\'eonardon (IMT Atlantique)"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.834704"
  },
  {
    "id": "oai:arXiv.org:2506.05437v1",
    "journal": "arXiv_CS",
    "title": "A MARL-based Approach for Easing MAS Organization Engineering",
    "link": "https://arxiv.org/abs/2506.05437",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05437v1 Announce Type: new \nAbstract: Multi-Agent Systems (MAS) have been successfully applied in industry for their ability to address complex, distributed problems, especially in IoT-based systems. Their efficiency in achieving given objectives and meeting design requirements is strongly dependent on the MAS organization during the engineering process of an application-specific MAS. To design a MAS that can achieve given goals, available methods rely on the designer's knowledge of the deployment environment. However, high complexity and low readability in some deployment environments make the application of these methods to be costly or raise safety concerns. In order to ease the MAS organization design regarding those concerns, we introduce an original Assisted MAS Organization Engineering Approach (AOMEA). AOMEA relies on combining a Multi-Agent Reinforcement Learning (MARL) process with an organizational model to suggest relevant organizational specifications to help in MAS engineering.",
    "authors": [
      "Julien Soul\\'e, Jean-Paul Jamont, Michel Occello, Louis-Marie Traonouez, Paul Th\\'eron"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.834712"
  },
  {
    "id": "oai:arXiv.org:2506.05438v1",
    "journal": "arXiv_CS",
    "title": "An Unsupervised Framework for Dynamic Health Indicator Construction and Its Application in Rolling Bearing Prognostics",
    "link": "https://arxiv.org/abs/2506.05438",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05438v1 Announce Type: new \nAbstract: Health indicator (HI) plays a key role in degradation assessment and prognostics of rolling bearings. Although various HI construction methods have been investigated, most of them rely on expert knowledge for feature extraction and overlook capturing dynamic information hidden in sequential degradation processes, which limits the ability of the constructed HI for degradation trend representation and prognostics. To address these concerns, a novel dynamic HI that considers HI-level temporal dependence is constructed through an unsupervised framework. Specifically, a degradation feature learning module composed of a skip-connection-based autoencoder first maps raw signals to a representative degradation feature space (DFS) to automatically extract essential degradation features without the need for expert knowledge. Subsequently, in this DFS, a new HI-generating module embedded with an inner HI-prediction block is proposed for dynamic HI construction, where the temporal dependence between past and current HI states is guaranteed and modeled explicitly. On this basis, the dynamic HI captures the inherent dynamic contents of the degradation process, ensuring its effectiveness for degradation tendency modeling and future degradation prognostics. The experiment results on two bearing lifecycle datasets demonstrate that the proposed HI construction method outperforms comparison methods, and the constructed dynamic HI is superior for prognostic tasks.",
    "authors": [
      "Tongda Sun, Chen Yin, Huailiang Zheng, Yining Dong"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.834722"
  },
  {
    "id": "oai:arXiv.org:2506.05439v1",
    "journal": "arXiv_CS",
    "title": "LLMs Can Compensate for Deficiencies in Visual Representations",
    "link": "https://arxiv.org/abs/2506.05439",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05439v1 Announce Type: new \nAbstract: Many vision-language models (VLMs) that prove very effective at a range of multimodal task, build on CLIP-based vision encoders, which are known to have various limitations. We investigate the hypothesis that the strong language backbone in VLMs compensates for possibly weak visual features by contextualizing or enriching them. Using three CLIP-based VLMs, we perform controlled self-attention ablations on a carefully designed probing task. Our findings show that despite known limitations, CLIP visual representations offer ready-to-read semantic information to the language decoder. However, in scenarios of reduced contextualization in the visual representations, the language decoder can largely compensate for the deficiency and recover performance. This suggests a dynamic division of labor in VLMs and motivates future architectures that offload more visual processing to the language decoder.",
    "authors": [
      "Sho Takishita, Jay Gala, Abdelrahman Mohamed, Kentaro Inui, Yova Kementchedjhieva"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.834730"
  },
  {
    "id": "oai:arXiv.org:2506.05442v1",
    "journal": "arXiv_CS",
    "title": "Structured Labeling Enables Faster Vision-Language Models for End-to-End Autonomous Driving",
    "link": "https://arxiv.org/abs/2506.05442",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05442v1 Announce Type: new \nAbstract: Vision-Language Models (VLMs) offer a promising approach to end-to-end autonomous driving due to their human-like reasoning capabilities. However, troublesome gaps remains between current VLMs and real-world autonomous driving applications. One major limitation is that existing datasets with loosely formatted language descriptions are not machine-friendly and may introduce redundancy. Additionally, high computational cost and massive scale of VLMs hinder the inference speed and real-world deployment. To bridge the gap, this paper introduces a structured and concise benchmark dataset, NuScenes-S, which is derived from the NuScenes dataset and contains machine-friendly structured representations. Moreover, we present FastDrive, a compact VLM baseline with 0.9B parameters. In contrast to existing VLMs with over 7B parameters and unstructured language processing(e.g., LLaVA-1.5), FastDrive understands structured and concise descriptions and generates machine-friendly driving decisions with high efficiency. Extensive experiments show that FastDrive achieves competitive performance on structured dataset, with approximately 20% accuracy improvement on decision-making tasks, while surpassing massive parameter baseline in inference speed with over 10x speedup. Additionally, ablation studies further focus on the impact of scene annotations (e.g., weather, time of day) on decision-making tasks, demonstrating their importance on decision-making tasks in autonomous driving.",
    "authors": [
      "Hao Jiang, Chuan Hu, Yukang Shi, Yuan He, Ke Wang, Xi Zhang, Zhipeng Zhang"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.834746"
  },
  {
    "id": "oai:arXiv.org:2506.05444v1",
    "journal": "arXiv_CS",
    "title": "U-NetMN and SegNetMN: Modified U-Net and SegNet models for bimodal SAR image segmentation",
    "link": "https://arxiv.org/abs/2506.05444",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05444v1 Announce Type: new \nAbstract: Segmenting Synthetic Aperture Radar (SAR) images is crucial for many remote sensing applications, particularly water body detection. However, deep learning-based segmentation models often face challenges related to convergence speed and stability, mainly due to the complex statistical distribution of this type of data. In this study, we evaluate the impact of mode normalization on two widely used semantic segmentation models, U-Net and SegNet. Specifically, we integrate mode normalization, to reduce convergence time while maintaining the performance of the baseline models. Experimental results demonstrate that mode normalization significantly accelerates convergence. Furthermore, cross-validation results indicate that normalized models exhibit increased stability in different zones. These findings highlight the effectiveness of normalization in improving computational efficiency and generalization in SAR image segmentation.",
    "authors": [
      "Marwane Kzadri, Franco Alberto Cardillo, Nan\\'ee Chahinian, Carole Delenne, Renaud Hostache, Jamal Riffi"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.834763"
  },
  {
    "id": "oai:arXiv.org:2506.05445v1",
    "journal": "arXiv_CS",
    "title": "Causal Policy Learning in Reinforcement Learning: Backdoor-Adjusted Soft Actor-Critic",
    "link": "https://arxiv.org/abs/2506.05445",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05445v1 Announce Type: new \nAbstract: Hidden confounders that influence both states and actions can bias policy learning in reinforcement learning (RL), leading to suboptimal or non-generalizable behavior. Most RL algorithms ignore this issue, learning policies from observational trajectories based solely on statistical associations rather than causal effects. We propose DoSAC (Do-Calculus Soft Actor-Critic with Backdoor Adjustment), a principled extension of the SAC algorithm that corrects for hidden confounding via causal intervention estimation. DoSAC estimates the interventional policy $\\pi(a | \\mathrm{do}(s))$ using the backdoor criterion, without requiring access to true confounders or causal labels. To achieve this, we introduce a learnable Backdoor Reconstructor that infers pseudo-past variables (previous state and action) from the current state to enable backdoor adjustment from observational data. This module is integrated into a soft actor-critic framework to compute both the interventional policy and its entropy. Empirical results on continuous control benchmarks show that DoSAC outperforms baselines under confounded settings, with improved robustness, generalization, and policy reliability.",
    "authors": [
      "Thanh Vinh Vo, Young Lee, Haozhe Ma, Chien Lu, Tze-Yun Leong"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.834772"
  },
  {
    "id": "oai:arXiv.org:2506.05450v1",
    "journal": "arXiv_CS",
    "title": "Degradation-Aware Image Enhancement via Vision-Language Classification",
    "link": "https://arxiv.org/abs/2506.05450",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05450v1 Announce Type: new \nAbstract: Image degradation is a prevalent issue in various real-world applications, affecting visual quality and downstream processing tasks. In this study, we propose a novel framework that employs a Vision-Language Model (VLM) to automatically classify degraded images into predefined categories. The VLM categorizes an input image into one of four degradation types: (A) super-resolution degradation (including noise, blur, and JPEG compression), (B) reflection artifacts, (C) motion blur, or (D) no visible degradation (high-quality image). Once classified, images assigned to categories A, B, or C undergo targeted restoration using dedicated models tailored for each specific degradation type. The final output is a restored image with improved visual quality. Experimental results demonstrate the effectiveness of our approach in accurately classifying image degradations and enhancing image quality through specialized restoration models. Our method presents a scalable and automated solution for real-world image enhancement tasks, leveraging the capabilities of VLMs in conjunction with state-of-the-art restoration techniques.",
    "authors": [
      "Jie Cai, Kangning Yang, Jiaming Ding, Lan Fu, Ling Ouyang, Jiang Li, Jinglin Shen, Zibo Meng"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.834803"
  },
  {
    "id": "oai:arXiv.org:2506.05451v1",
    "journal": "arXiv_CS",
    "title": "Interpretation Meets Safety: A Survey on Interpretation Methods and Tools for Improving LLM Safety",
    "link": "https://arxiv.org/abs/2506.05451",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05451v1 Announce Type: new \nAbstract: As large language models (LLMs) see wider real-world use, understanding and mitigating their unsafe behaviors is critical. Interpretation techniques can reveal causes of unsafe outputs and guide safety, but such connections with safety are often overlooked in prior surveys. We present the first survey that bridges this gap, introducing a unified framework that connects safety-focused interpretation methods, the safety enhancements they inform, and the tools that operationalize them. Our novel taxonomy, organized by LLM workflow stages, summarizes nearly 70 works at their intersections. We conclude with open challenges and future directions. This timely survey helps researchers and practitioners navigate key advancements for safer, more interpretable LLMs.",
    "authors": [
      "Seongmin Lee, Aeree Cho, Grace C. Kim, ShengYun Peng, Mansi Phute, Duen Horng Chau"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.834812"
  },
  {
    "id": "oai:arXiv.org:2506.05453v1",
    "journal": "arXiv_CS",
    "title": "MLLM-CL: Continual Learning for Multimodal Large Language Models",
    "link": "https://arxiv.org/abs/2506.05453",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05453v1 Announce Type: new \nAbstract: Recent Multimodal Large Language Models (MLLMs) excel in vision-language understanding but face challenges in adapting to dynamic real-world scenarios that require continuous integration of new knowledge and skills. While continual learning (CL) offers a potential solution, existing benchmarks and methods suffer from critical limitations. In this paper, we introduce MLLM-CL, a novel benchmark encompassing domain and ability continual learning, where the former focuses on independently and identically distributed (IID) evaluation across evolving mainstream domains, whereas the latter evaluates on non-IID scenarios with emerging model ability. Methodologically, we propose preventing catastrophic interference through parameter isolation, along with an MLLM-based routing mechanism. Extensive experiments demonstrate that our approach can integrate domain-specific knowledge and functional abilities with minimal forgetting, significantly outperforming existing methods.",
    "authors": [
      "Hongbo Zhao, Fei Zhu, Rundong Wang, Gaofeng Meng, Zhaoxiang Zhang"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.834821"
  },
  {
    "id": "oai:arXiv.org:2506.05454v1",
    "journal": "arXiv_CS",
    "title": "Zeroth-Order Optimization Finds Flat Minima",
    "link": "https://arxiv.org/abs/2506.05454",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05454v1 Announce Type: new \nAbstract: Zeroth-order methods are extensively used in machine learning applications where gradients are infeasible or expensive to compute, such as black-box attacks, reinforcement learning, and language model fine-tuning. Existing optimization theory focuses on convergence to an arbitrary stationary point, but less is known on the implicit regularization that provides a fine-grained characterization on which particular solutions are finally reached. We show that zeroth-order optimization with the standard two-point estimator favors solutions with small trace of Hessian, which is widely used in previous work to distinguish between sharp and flat minima. We further provide convergence rates of zeroth-order optimization to approximate flat minima for convex and sufficiently smooth functions, where flat minima are defined as the minimizers that achieve the smallest trace of Hessian among all optimal solutions. Experiments on binary classification tasks with convex losses and language model fine-tuning support our theoretical findings.",
    "authors": [
      "Liang Zhang, Bingcong Li, Kiran Koshy Thekumparampil, Sewoong Oh, Michael Muehlebach, Niao He"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.834829"
  },
  {
    "id": "oai:arXiv.org:2506.05466v1",
    "journal": "arXiv_CS",
    "title": "Towards Reliable Identification of Diffusion-based Image Manipulations",
    "link": "https://arxiv.org/abs/2506.05466",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05466v1 Announce Type: new \nAbstract: Changing facial expressions, gestures, or background details may dramatically alter the meaning conveyed by an image. Notably, recent advances in diffusion models greatly improve the quality of image manipulation while also opening the door to misuse. Identifying changes made to authentic images, thus, becomes an important task, constantly challenged by new diffusion-based editing tools. To this end, we propose a novel approach for ReliAble iDentification of inpainted AReas (RADAR). RADAR builds on existing foundation models and combines features from different image modalities. It also incorporates an auxiliary contrastive loss that helps to isolate manipulated image patches. We demonstrate these techniques to significantly improve both the accuracy of our method and its generalisation to a large number of diffusion models. To support realistic evaluation, we further introduce BBC-PAIR, a new comprehensive benchmark, with images tampered by 28 diffusion models. Our experiments show that RADAR achieves excellent results, outperforming the state-of-the-art in detecting and localising image edits made by both seen and unseen diffusion models. Our code, data and models will be publicly available at alex-costanzino.github.io/radar.",
    "authors": [
      "Alex Costanzino, Woody Bayliss, Juil Sock, Marc Gorriz Blanch, Danijela Horak, Ivan Laptev, Philip Torr, Fabio Pizzati"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.834837"
  },
  {
    "id": "oai:arXiv.org:2506.05473v1",
    "journal": "arXiv_CS",
    "title": "S2GO: Streaming Sparse Gaussian Occupancy Prediction",
    "link": "https://arxiv.org/abs/2506.05473",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05473v1 Announce Type: new \nAbstract: Despite the demonstrated efficiency and performance of sparse query-based representations for perception, state-of-the-art 3D occupancy prediction methods still rely on voxel-based or dense Gaussian-based 3D representations. However, dense representations are slow, and they lack flexibility in capturing the temporal dynamics of driving scenes. Distinct from prior work, we instead summarize the scene into a compact set of 3D queries which are propagated through time in an online, streaming fashion. These queries are then decoded into semantic Gaussians at each timestep. We couple our framework with a denoising rendering objective to guide the queries and their constituent Gaussians in effectively capturing scene geometry. Owing to its efficient, query-based representation, S2GO achieves state-of-the-art performance on the nuScenes and KITTI occupancy benchmarks, outperforming prior art (e.g., GaussianWorld) by 1.5 IoU with 5.9x faster inference.",
    "authors": [
      "Jinhyung Park, Yihan Hu, Chensheng Peng, Wenzhao Zheng, Kris Kitani, Wei Zhan"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.834845"
  },
  {
    "id": "oai:arXiv.org:2506.05479v1",
    "journal": "arXiv_CS",
    "title": "Learning-Augmented Algorithms for MTS with Bandit Access to Multiple Predictors",
    "link": "https://arxiv.org/abs/2506.05479",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05479v1 Announce Type: new \nAbstract: We consider the following problem: We are given $\\ell$ heuristics for Metrical Task Systems (MTS), where each might be tailored to a different type of input instances. While processing an input instance received online, we are allowed to query the action of only one of the heuristics at each time step. Our goal is to achieve performance comparable to the best of the given heuristics. The main difficulty of our setting comes from the fact that the cost paid by a heuristic at time $t$ cannot be estimated unless the same heuristic was also queried at time $t-1$. This is related to Bandit Learning against memory bounded adversaries (Arora et al., 2012). We show how to achieve regret of $O(\\text{OPT}^{2/3})$ and prove a tight lower bound based on the construction of Dekel et al. (2013).",
    "authors": [
      "Matei Gabriel Co\\c{s}a, Marek Eli\\'a\\v{s}"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.834854"
  },
  {
    "id": "oai:arXiv.org:2506.05480v1",
    "journal": "arXiv_CS",
    "title": "ODE-GS: Latent ODEs for Dynamic Scene Extrapolation with 3D Gaussian Splatting",
    "link": "https://arxiv.org/abs/2506.05480",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05480v1 Announce Type: new \nAbstract: We present ODE-GS, a novel method that unifies 3D Gaussian Splatting with latent neural ordinary differential equations (ODEs) to forecast dynamic 3D scenes far beyond the time span seen during training. Existing neural rendering systems - whether NeRF- or 3DGS-based - embed time directly in a deformation network and therefore excel at interpolation but collapse when asked to predict the future, where timestamps are strictly out-of-distribution. ODE-GS eliminates this dependency: after learning a high-fidelity, time-conditioned deformation model for the training window, we freeze it and train a Transformer encoder that summarizes past Gaussian trajectories into a latent state whose continuous evolution is governed by a neural ODE. Numerical integration of this latent flow yields smooth, physically plausible Gaussian trajectories that can be queried at any future instant and rendered in real time. Coupled with a variational objective and a lightweight second-derivative regularizer, ODE-GS attains state-of-the-art extrapolation on D-NeRF and NVFI benchmarks, improving PSNR by up to 10 dB and halving perceptual error (LPIPS) relative to the strongest baselines. Our results demonstrate that continuous-time latent dynamics are a powerful, practical route to photorealistic prediction of complex 3D scenes.",
    "authors": [
      "Daniel Wang, Patrick Rim, Tian Tian, Alex Wong, Ganesh Sundaramoorthi"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.834863"
  },
  {
    "id": "oai:arXiv.org:2506.05482v1",
    "journal": "arXiv_CS",
    "title": "OpenRR-5k: A Large-Scale Benchmark for Reflection Removal in the Wild",
    "link": "https://arxiv.org/abs/2506.05482",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05482v1 Announce Type: new \nAbstract: Removing reflections is a crucial task in computer vision, with significant applications in photography and image enhancement. Nevertheless, existing methods are constrained by the absence of large-scale, high-quality, and diverse datasets. In this paper, we present a novel benchmark for Single Image Reflection Removal (SIRR). We have developed a large-scale dataset containing 5,300 high-quality, pixel-aligned image pairs, each consisting of a reflection image and its corresponding clean version. Specifically, the dataset is divided into two parts: 5,000 images are used for training, and 300 images are used for validation. Additionally, we have included 100 real-world testing images without ground truth (GT) to further evaluate the practical performance of reflection removal methods. All image pairs are precisely aligned at the pixel level to guarantee accurate supervision. The dataset encompasses a broad spectrum of real-world scenarios, featuring various lighting conditions, object types, and reflection patterns, and is segmented into training, validation, and test sets to facilitate thorough evaluation. To validate the usefulness of our dataset, we train a U-Net-based model and evaluate it using five widely-used metrics, including PSNR, SSIM, LPIPS, DISTS, and NIQE. We will release both the dataset and the code on https://github.com/caijie0620/OpenRR-5k to facilitate future research in this field.",
    "authors": [
      "Jie Cai, Kangning Yang, Ling Ouyang, Lan Fu, Jiaming Ding, Jinglin Shen, Zibo Meng"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.834871"
  },
  {
    "id": "oai:arXiv.org:2506.05486v1",
    "journal": "arXiv_CS",
    "title": "The Artificial Benchmark for Community Detection with Outliers and Overlapping Communities (ABCD+$o^2$)",
    "link": "https://arxiv.org/abs/2506.05486",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05486v1 Announce Type: new \nAbstract: The Artificial Benchmark for Community Detection (ABCD) graph is a random graph model with community structure and power-law distribution for both degrees and community sizes. The model generates graphs similar to the well-known LFR model but it is faster, more interpretable, and can be investigated analytically. In this paper, we use the underlying ingredients of the ABCD model, and its generalization to include outliers (ABCD+$o$), and introduce another variant that allows for overlapping communities, ABCD+$o^2$.",
    "authors": [
      "Jordan Barrett, Ryan DeWolfe, Bogumi{\\l} Kami\\'nski, Pawe{\\l} Pra{\\l}at, Aaron Smith, Fran\\c{c}ois Th\\'eberge"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.834888"
  },
  {
    "id": "oai:arXiv.org:2506.05487v1",
    "journal": "arXiv_CS",
    "title": "A Neural Network Model of Spatial and Feature-Based Attention",
    "link": "https://arxiv.org/abs/2506.05487",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05487v1 Announce Type: new \nAbstract: Visual attention is a mechanism closely intertwined with vision and memory. Top-down information influences visual processing through attention. We designed a neural network model inspired by aspects of human visual attention. This model consists of two networks: one serves as a basic processor performing a simple task, while the other processes contextual information and guides the first network through attention to adapt to more complex tasks. After training the model and visualizing the learned attention response, we discovered that the model's emergent attention patterns corresponded to spatial and feature-based attention. This similarity between human visual attention and attention in computer vision suggests a promising direction for studying human cognition using neural network models.",
    "authors": [
      "Ruoyang Hu, Robert A. Jacobs"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.834896"
  },
  {
    "id": "oai:arXiv.org:2506.05488v1",
    "journal": "arXiv_CS",
    "title": "Implicit Neural Representation for Video Restoration",
    "link": "https://arxiv.org/abs/2506.05488",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05488v1 Announce Type: new \nAbstract: High-resolution (HR) videos play a crucial role in many computer vision applications. Although existing video restoration (VR) methods can significantly enhance video quality by exploiting temporal information across video frames, they are typically trained for fixed upscaling factors and lack the flexibility to handle scales or degradations beyond their training distribution. In this paper, we introduce VR-INR, a novel video restoration approach based on Implicit Neural Representations (INRs) that is trained only on a single upscaling factor ($\\times 4$) but generalizes effectively to arbitrary, unseen super-resolution scales at test time. Notably, VR-INR also performs zero-shot denoising on noisy input, despite never having seen noisy data during training. Our method employs a hierarchical spatial-temporal-texture encoding framework coupled with multi-resolution implicit hash encoding, enabling adaptive decoding of high-resolution and noise-suppressed frames from low-resolution inputs at any desired magnification. Experimental results show that VR-INR consistently maintains high-quality reconstructions at unseen scales and noise during training, significantly outperforming state-of-the-art approaches in sharpness, detail preservation, and denoising efficacy.",
    "authors": [
      "Mary Aiyetigbo, Wanqi Yuan, Feng Luo, Nianyi Li"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.834904"
  },
  {
    "id": "oai:arXiv.org:2506.05489v1",
    "journal": "arXiv_CS",
    "title": "F2T2-HiT: A U-Shaped FFT Transformer and Hierarchical Transformer for Reflection Removal",
    "link": "https://arxiv.org/abs/2506.05489",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05489v1 Announce Type: new \nAbstract: Single Image Reflection Removal (SIRR) technique plays a crucial role in image processing by eliminating unwanted reflections from the background. These reflections, often caused by photographs taken through glass surfaces, can significantly degrade image quality. SIRR remains a challenging problem due to the complex and varied reflections encountered in real-world scenarios. These reflections vary significantly in intensity, shapes, light sources, sizes, and coverage areas across the image, posing challenges for most existing methods to effectively handle all cases. To address these challenges, this paper introduces a U-shaped Fast Fourier Transform Transformer and Hierarchical Transformer (F2T2-HiT) architecture, an innovative Transformer-based design for SIRR. Our approach uniquely combines Fast Fourier Transform (FFT) Transformer blocks and Hierarchical Transformer blocks within a UNet framework. The FFT Transformer blocks leverage the global frequency domain information to effectively capture and separate reflection patterns, while the Hierarchical Transformer blocks utilize multi-scale feature extraction to handle reflections of varying sizes and complexities. Extensive experiments conducted on three publicly available testing datasets demonstrate state-of-the-art performance, validating the effectiveness of our approach.",
    "authors": [
      "Jie Cai, Kangning Yang, Ling Ouyang, Lan Fu, Jiaming Ding, Huiming Sun, Chiu Man Ho, Zibo Meng"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.834913"
  },
  {
    "id": "oai:arXiv.org:2506.05490v1",
    "journal": "arXiv_CS",
    "title": "Sentiment Analysis in Learning Management Systems Understanding Student Feedback at Scale",
    "link": "https://arxiv.org/abs/2506.05490",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05490v1 Announce Type: new \nAbstract: During the wake of the Covid-19 pandemic, the educational paradigm has experienced a major change from in person learning traditional to online platforms. The change of learning convention has impacted the teacher-student especially in non-verbal communication. The absent of non-verbal communication has led to a reliance on verbal feedback which diminished the efficacy of the educational experience. This paper explores the integration of sentiment analysis into learning management systems (LMS) to bridge the student-teacher's gap by offering an alternative approach to interpreting student feedback beyond its verbal context. The research involves data preparation, feature selection, and the development of a deep neural network model encompassing word embedding, LSTM, and attention mechanisms. This model is compared against a logistic regression baseline to evaluate its efficacy in understanding student feedback. The study aims to bridge the communication gap between instructors and students in online learning environments, offering insights into the emotional context of student feedback and ultimately improving the quality of online education.",
    "authors": [
      "Mohammed Almutairi"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.834921"
  },
  {
    "id": "oai:arXiv.org:2506.05495v1",
    "journal": "arXiv_CS",
    "title": "Learning-Augmented Hierarchical Clustering",
    "link": "https://arxiv.org/abs/2506.05495",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05495v1 Announce Type: new \nAbstract: Hierarchical clustering (HC) is an important data analysis technique in which the goal is to recursively partition a dataset into a tree-like structure while grouping together similar data points at each level of granularity. Unfortunately, for many of the proposed HC objectives, there exist strong barriers to approximation algorithms with the hardness of approximation. Thus, we consider the problem of hierarchical clustering given auxiliary information from natural oracles. Specifically, we focus on a *splitting oracle* which, when provided with a triplet of vertices $(u,v,w)$, answers (possibly erroneously) the pairs of vertices whose lowest common ancestor includes all three vertices in an optimal tree, i.e., identifying which vertex ``splits away'' from the others. Using such an oracle, we obtain the following results:\n  - A polynomial-time algorithm that outputs a hierarchical clustering tree with $O(1)$-approximation to the Dasgupta objective (Dasgupta [STOC'16]).\n  - A near-linear time algorithm that outputs a hierarchical clustering tree with $(1-o(1))$-approximation to the Moseley-Wang objective (Moseley and Wang [NeurIPS'17]).\n  Under the plausible Small Set Expansion Hypothesis, no polynomial-time algorithm can achieve any constant approximation for Dasgupta's objective or $(1-C)$-approximation for the Moseley-Wang objective for some constant $C>0$. As such, our results demonstrate that the splitting oracle enables algorithms to outperform standard HC approaches and overcome hardness constraints. Furthermore, our approaches extend to sublinear settings, in which we show new streaming and PRAM algorithms for HC with improved guarantees.",
    "authors": [
      "Vladimir Braverman, Jon C. Ergun, Chen Wang, Samson Zhou"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.834930"
  },
  {
    "id": "oai:arXiv.org:2506.05496v1",
    "journal": "arXiv_CS",
    "title": "Channel Estimation with Asynchronous Reception for User-Centric Cell-Free MIMO Systems",
    "link": "https://arxiv.org/abs/2506.05496",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05496v1 Announce Type: new \nAbstract: The user-centric, cell-free wireless network is a promising next-generation communication system, but signal synchronization issues arise due to distributed access points and lack of cellular structure. We propose a novel method to recover synchronous pilot reception by introducing new pilot sequences and a matched filter window, enabling orthogonality even with asynchronous reception. Our approach mimics synchronous transmission by extending training sequences. Analysis shows asynchronous reception's impact on channel estimation, and our method significantly improves performance with a small increase of training time overhead. Results demonstrate a 7.26 dB reduction in normalized mean square error and 40% increase in data rate, achieving performance levels comparable to the synchronous case.",
    "authors": [
      "Xuyang Sun, Hussein A. Ammar, Raviraj Adve, Israfil Bahceci, Gary Boudreau"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.834939"
  },
  {
    "id": "oai:arXiv.org:2506.05500v1",
    "journal": "arXiv_CS",
    "title": "The Generative Leap: Sharp Sample Complexity for Efficiently Learning Gaussian Multi-Index Models",
    "link": "https://arxiv.org/abs/2506.05500",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05500v1 Announce Type: new \nAbstract: In this work we consider generic Gaussian Multi-index models, in which the labels only depend on the (Gaussian) $d$-dimensional inputs through their projection onto a low-dimensional $r = O_d(1)$ subspace, and we study efficient agnostic estimation procedures for this hidden subspace. We introduce the \\emph{generative leap} exponent $k^\\star$, a natural extension of the generative exponent from [Damian et al.'24] to the multi-index setting. We first show that a sample complexity of $n=\\Theta(d^{1 \\vee \\k/2})$ is necessary in the class of algorithms captured by the Low-Degree-Polynomial framework. We then establish that this sample complexity is also sufficient, by giving an agnostic sequential estimation procedure (that is, requiring no prior knowledge of the multi-index model) based on a spectral U-statistic over appropriate Hermite tensors. We further compute the generative leap exponent for several examples including piecewise linear functions (deep ReLU networks with bias), and general deep neural networks (with $r$-dimensional first hidden layer).",
    "authors": [
      "Alex Damian, Jason D. Lee, Joan Bruna"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.834963"
  },
  {
    "id": "oai:arXiv.org:2506.05502v1",
    "journal": "arXiv_CS",
    "title": "StealthInk: A Multi-bit and Stealthy Watermark for Large Language Models",
    "link": "https://arxiv.org/abs/2506.05502",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05502v1 Announce Type: new \nAbstract: Watermarking for large language models (LLMs) offers a promising approach to identifying AI-generated text. Existing approaches, however, either compromise the distribution of original generated text by LLMs or are limited to embedding zero-bit information that only allows for watermark detection but ignores identification. We present StealthInk, a stealthy multi-bit watermarking scheme that preserves the original text distribution while enabling the embedding of provenance data, such as userID, TimeStamp, and modelID, within LLM-generated text. This enhances fast traceability without requiring access to the language model's API or prompts. We derive a lower bound on the number of tokens necessary for watermark detection at a fixed equal error rate, which provides insights on how to enhance the capacity. Comprehensive empirical evaluations across diverse tasks highlight the stealthiness, detectability, and resilience of StealthInk, establishing it as an effective solution for LLM watermarking applications.",
    "authors": [
      "Ya Jiang, Chuxiong Wu, Massieh Kordi Boroujeny, Brian Mark, Kai Zeng"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.834979"
  },
  {
    "id": "oai:arXiv.org:2506.05503v1",
    "journal": "arXiv_CS",
    "title": "On Differential Privacy for Adaptively Solving Search Problems via Sketching",
    "link": "https://arxiv.org/abs/2506.05503",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05503v1 Announce Type: new \nAbstract: Recently differential privacy has been used for a number of streaming, data structure, and dynamic graph problems as a means of hiding the internal randomness of the data structure, so that multiple possibly adaptive queries can be made without sacrificing the correctness of the responses. Although these works use differential privacy to show that for some problems it is possible to tolerate $T$ queries using $\\widetilde{O}(\\sqrt{T})$ copies of a data structure, such results only apply to numerical estimation problems, and only return the cost of an optimization problem rather than the solution itself. In this paper, we investigate the use of differential privacy for adaptive queries to search problems, which are significantly more challenging since the responses to queries can reveal much more about the internal randomness than a single numerical query. We focus on two classical search problems: nearest neighbor queries and regression with arbitrary turnstile updates. We identify key parameters to these problems, such as the number of $c$-approximate near neighbors and the matrix condition number, and use different differential privacy techniques to design algorithms returning the solution vector with memory and time depending on these parameters. We give algorithms for each of these problems that achieve similar tradeoffs.",
    "authors": [
      "Shiyuan Feng, Ying Feng, George Z. Li, Zhao Song, David P. Woodruff, Lichen Zhang"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.834987"
  },
  {
    "id": "oai:arXiv.org:2506.05508v1",
    "journal": "arXiv_CS",
    "title": "Beyond the Buzz: A Pragmatic Take on Inference Disaggregation",
    "link": "https://arxiv.org/abs/2506.05508",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05508v1 Announce Type: new \nAbstract: As inference scales to multi-node deployments, disaggregation - splitting inference into distinct phases - offers a promising path to improving the throughput-interactivity Pareto frontier. Despite growing enthusiasm and a surge of open-source efforts, practical deployment of disaggregated serving remains limited due to the complexity of the optimization search space and system-level coordination. In this paper, we present the first systematic study of disaggregated inference at scale, evaluating hundreds of thousands of design points across diverse workloads and hardware configurations. We find that disaggregation is most effective for prefill-heavy traffic patterns and larger models. Our results highlight the critical role of dynamic rate matching and elastic scaling in achieving Pareto-optimal performance. Our findings offer actionable insights for efficient disaggregated deployments to navigate the trade-off between system throughput and interactivity.",
    "authors": [
      "Tiyasa Mitra, Ritika Borkar, Nidhi Bhatia, Ramon Matas, Shivam Raj, Dheevatsa Mudigere, Ritchie Zhao, Maximilian Golub, Arpan Dutta, Sailaja Madduri, Dharmesh Jani, Brian Pharris, Bita Darvish Rouhani"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.834996"
  },
  {
    "id": "oai:arXiv.org:2506.05515v1",
    "journal": "arXiv_CS",
    "title": "Winner-takes-all for Multivariate Probabilistic Time Series Forecasting",
    "link": "https://arxiv.org/abs/2506.05515",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05515v1 Announce Type: new \nAbstract: We introduce TimeMCL, a method leveraging the Multiple Choice Learning (MCL) paradigm to forecast multiple plausible time series futures. Our approach employs a neural network with multiple heads and utilizes the Winner-Takes-All (WTA) loss to promote diversity among predictions. MCL has recently gained attention due to its simplicity and ability to address ill-posed and ambiguous tasks. We propose an adaptation of this framework for time-series forecasting, presenting it as an efficient method to predict diverse futures, which we relate to its implicit quantization objective. We provide insights into our approach using synthetic data and evaluate it on real-world time series, demonstrating its promising performance at a light computational cost.",
    "authors": [
      "Adrien Cort\\'es, R\\'emi Rehm, Victor Letzelter"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.835020"
  },
  {
    "id": "oai:arXiv.org:2506.05516v1",
    "journal": "arXiv_CS",
    "title": "Learning to Recover: Dynamic Reward Shaping with Wheel-Leg Coordination for Fallen Robots",
    "link": "https://arxiv.org/abs/2506.05516",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05516v1 Announce Type: new \nAbstract: Adaptive recovery from fall incidents are essential skills for the practical deployment of wheeled-legged robots, which uniquely combine the agility of legs with the speed of wheels for rapid recovery. However, traditional methods relying on preplanned recovery motions, simplified dynamics or sparse rewards often fail to produce robust recovery policies. This paper presents a learning-based framework integrating Episode-based Dynamic Reward Shaping and curriculum learning, which dynamically balances exploration of diverse recovery maneuvers with precise posture refinement. An asymmetric actor-critic architecture accelerates training by leveraging privileged information in simulation, while noise-injected observations enhance robustness against uncertainties. We further demonstrate that synergistic wheel-leg coordination reduces joint torque consumption by 15.8% and 26.2% and improves stabilization through energy transfer mechanisms. Extensive evaluations on two distinct quadruped platforms achieve recovery success rates up to 99.1% and 97.8% without platform-specific tuning. The supplementary material is available at https://boyuandeng.github.io/L2R-WheelLegCoordination/",
    "authors": [
      "Boyuan Deng, Luca Rossini, Jin Wang, Weijie Wang, Nikolaos Tsagarakis"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.835028"
  },
  {
    "id": "oai:arXiv.org:2506.05518v1",
    "journal": "arXiv_CS",
    "title": "Sorting by pile shuffles on queue-like and stack-like piles can be hard",
    "link": "https://arxiv.org/abs/2506.05518",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05518v1 Announce Type: new \nAbstract: Inspired by a common technique for shuffling a deck of cards on a table without riffling, we continue the study of a prequel paper on the pile shuffle and its capabilities as a sorting device. We study two sort feasibility problems of general interest concerning pile shuffle, first introduced in the prequel. These problems are characterized by: (1) bounds on the number of sequential rounds of shuffle, and piles created in each round; (2) the use of a heterogeneous mixture of queue-like and stack-like piles, as when each round of shuffle may have a combination of face-up and face-down piles; and (3) the ability of the dealer to choose the types of piles used during each round of shuffle. We prove by a sequence of reductions from the Boolean satisfiability problem (SAT) that the more general problem is NP-Hard. We leave as an open question the complexity of its arguably more natural companion, but discuss avenues for further investigation. Our analysis leverages a novel framework, introduced herein, which equates instances of shuffle to members of a particular class of deterministic finite automata.",
    "authors": [
      "Kyle B. Treleaven"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.835037"
  },
  {
    "id": "oai:arXiv.org:2506.05522v1",
    "journal": "arXiv_CS",
    "title": "Understanding Community-Level Blocklists in Decentralized Social Media",
    "link": "https://arxiv.org/abs/2506.05522",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05522v1 Announce Type: new \nAbstract: Community-level blocklists are key to content moderation practices in decentralized social media. These blocklists enable moderators to prevent other communities, such as those acting in bad faith, from interacting with their own -- and, if shared publicly, warn others about communities worth blocking. Prior work has examined blocklists in centralized social media, noting their potential for collective moderation outcomes, but has focused on blocklists as individual-level tools. To understand how moderators perceive and utilize community-level blocklists and what additional support they may need, we examine social media communities running Mastodon, an open-source microblogging software built on the ActivityPub protocol. We conducted (1) content analysis of the community-level blocklist ecosystem, and (2) semi-structured interviews with twelve Mastodon moderators. Our content analysis revealed wide variation in blocklist goals, inclusion criteria, and transparency. Interviews showed moderators balance proactive safety, reactive practices, and caution around false positives when using blocklists for moderation. They noted challenges and limitations in current blocklist use, suggesting design improvements like comment receipts, category filters, and collaborative voting. We discuss implications for decentralized content moderation, highlighting trade-offs between openness, safety, and nuance; the complexity of moderator roles; and opportunities for future design.",
    "authors": [
      "Owen Xingjian Zhang, Sohyeon Hwang, Yuhan Liu, Manoel Horta Ribeiro, Andr\\'es Monroy-Hern\\'andez"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.835053"
  },
  {
    "id": "oai:arXiv.org:2506.05523v1",
    "journal": "arXiv_CS",
    "title": "MORSE-500: A Programmatically Controllable Video Benchmark to Stress-Test Multimodal Reasoning",
    "link": "https://arxiv.org/abs/2506.05523",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05523v1 Announce Type: new \nAbstract: Despite rapid advances in vision-language models (VLMs), current benchmarks for multimodal reasoning fall short in three key dimensions. First, they overwhelmingly rely on static images, failing to capture the temporal complexity of real-world environments. Second, they narrowly focus on mathematical problem-solving, neglecting the broader spectrum of reasoning skills -- including abstract, physical, planning, spatial, and temporal capabilities -- required for robust multimodal intelligence. Third, many benchmarks quickly saturate, offering limited headroom for diagnosing failure modes or measuring continued progress. We introduce MORSE-500 (Multimodal Reasoning Stress-test Environment), a video benchmark composed of 500 fully scripted clips with embedded questions spanning six complementary reasoning categories. Each instance is programmatically generated using deterministic Python scripts (via Manim, Matplotlib, MoviePy), generative video models, and curated real footage. This script-driven design allows fine-grained control over visual complexity, distractor density, and temporal dynamics -- enabling difficulty to be scaled systematically as models improve. Unlike static benchmarks that become obsolete once saturated, MORSE-500 is built to evolve: its controllable generation pipeline supports the creation of arbitrarily challenging new instances, making it ideally suited for stress-testing next-generation models. Initial experiments with state-of-the-art systems -- including various Gemini 2.5 Pro and OpenAI o3 which represent the strongest available at the time, alongside strong open-source models -- reveal substantial performance gaps across all categories, with particularly large deficits in abstract and planning tasks. We release the full dataset, generation scripts, and evaluation harness to support transparent, reproducible, and forward-looking multimodal reasoning research.",
    "authors": [
      "Zikui Cai, Andrew Wang, Anirudh Satheesh, Ankit Nakhawa, Hyunwoo Jae, Keenan Powell, Minghui Liu, Neel Jay, Sungbin Oh, Xiyao Wang, Yongyuan Liang, Tom Goldstein, Furong Huang"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.835062"
  },
  {
    "id": "oai:arXiv.org:2506.05525v1",
    "journal": "arXiv_CS",
    "title": "Model Checking as Program Verification by Abstract Interpretation (Extended Version)",
    "link": "https://arxiv.org/abs/2506.05525",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05525v1 Announce Type: new \nAbstract: Abstract interpretation offers a powerful toolset for static analysis, tackling precision, complexity and state-explosion issues. In the literature, state partitioning abstractions based on (bi)simulation and property-preserving state relations have been successfully applied to abstract model checking. Here, we pursue a different track in which model checking is seen as an instance of program verification. To this purpose, we introduce a suitable language-called MOKA (for MOdel checking as abstract interpretation of Kleene Algebras)-which is used to encode temporal formulae as programs. In particular, we show that (universal fragments of) temporal logics, such as ACTL or, more generally, universal mu-calculus can be transformed into MOKA programs. Such programs return all and only the initial states which violate the formula. By applying abstract interpretation to MOKA programs, we pave the way for reusing more general abstractions than partitions as well as for tuning the precision of the abstraction to remove or avoid false alarms. We show how to perform model checking via a program logic that combines under-approximation and abstract interpretation analysis to avoid false alarms. The notion of locally complete abstraction is used to dynamically improve the analysis precision via counterexample-guided domain refinement.",
    "authors": [
      "Paolo Baldan, Roberto Bruni, Francesco Ranzato, Diletta Rigo"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.835081"
  },
  {
    "id": "oai:arXiv.org:2506.05526v1",
    "journal": "arXiv_CS",
    "title": "On Fitting Flow Models with Large Sinkhorn Couplings",
    "link": "https://arxiv.org/abs/2506.05526",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05526v1 Announce Type: new \nAbstract: Flow models transform data gradually from one modality (e.g. noise) onto another (e.g. images). Such models are parameterized by a time-dependent velocity field, trained to fit segments connecting pairs of source and target points. When the pairing between source and target points is given, training flow models boils down to a supervised regression problem. When no such pairing exists, as is the case when generating data from noise, training flows is much harder. A popular approach lies in picking source and target points independently. This can, however, lead to velocity fields that are slow to train, but also costly to integrate at inference time. In theory, one would greatly benefit from training flow models by sampling pairs from an optimal transport (OT) measure coupling source and target, since this would lead to a highly efficient flow solving the Benamou and Brenier dynamical OT problem. In practice, recent works have proposed to sample mini-batches of $n$ source and $n$ target points and reorder them using an OT solver to form better pairs. These works have advocated using batches of size $n\\approx 256$, and considered OT solvers that return couplings that are either sharp (using e.g. the Hungarian algorithm) or blurred (using e.g. entropic regularization, a.k.a. Sinkhorn). We follow in the footsteps of these works by exploring the benefits of increasing $n$ by three to four orders of magnitude, and look more carefully on the effect of the entropic regularization $\\varepsilon$ used in the Sinkhorn algorithm. Our analysis is facilitated by new scale invariant quantities to report the sharpness of a coupling, while our sharded computations across multiple GPU or GPU nodes allow scaling up $n$. We show that in both synthetic and image generation tasks, flow models greatly benefit when fitted with large Sinkhorn couplings, with a low entropic regularization $\\varepsilon$.",
    "authors": [
      "Michal Klein, Alireza Mousavi-Hosseini, Stephen Zhang, Marco Cuturi"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.835089"
  },
  {
    "id": "oai:arXiv.org:2506.05527v1",
    "journal": "arXiv_CS",
    "title": "Sequence Modeling for N-Agent Ad Hoc Teamwork",
    "link": "https://arxiv.org/abs/2506.05527",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05527v1 Announce Type: new \nAbstract: N-agent ad hoc teamwork (NAHT) is a newly introduced challenge in multi-agent reinforcement learning, where controlled subteams of varying sizes must dynamically collaborate with varying numbers and types of unknown teammates without pre-coordination. The existing learning algorithm (POAM) considers only independent learning for its flexibility in dealing with a changing number of agents. However, independent learning fails to fully capture the inter-agent dynamics essential for effective collaboration. Based on our observation that transformers deal effectively with sequences with varying lengths and have been shown to be highly effective for a variety of machine learning problems, this work introduces a centralized, transformer-based method for N-agent ad hoc teamwork. Our proposed approach incorporates historical observations and actions of all controlled agents, enabling optimal responses to diverse and unseen teammates in partially observable environments. Empirical evaluation on a StarCraft II task demonstrates that MAT-NAHT outperforms POAM, achieving superior sample efficiency and generalization, without auxiliary agent-modeling objectives.",
    "authors": [
      "Caroline Wang, Di Yang Shi, Elad Liebman, Ishan Durugkar, Arrasy Rahman, Peter Stone"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.835098"
  },
  {
    "id": "oai:arXiv.org:2506.05529v1",
    "journal": "arXiv_CS",
    "title": "Avoiding Death through Fear Intrinsic Conditioning",
    "link": "https://arxiv.org/abs/2506.05529",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05529v1 Announce Type: new \nAbstract: Biological and psychological concepts have inspired reinforcement learning algorithms to create new complex behaviors that expand agents' capacity. These behaviors can be seen in the rise of techniques like goal decomposition, curriculum, and intrinsic rewards, which have paved the way for these complex behaviors. One limitation in evaluating these methods is the requirement for engineered extrinsic for realistic environments. A central challenge in engineering the necessary reward function(s) comes from these environments containing states that carry high negative rewards, but provide no feedback to the agent. Death is one such stimuli that fails to provide direct feedback to the agent. In this work, we introduce an intrinsic reward function inspired by early amygdala development and produce this intrinsic reward through a novel memory-augmented neural network (MANN) architecture. We show how this intrinsic motivation serves to deter exploration of terminal states and results in avoidance behavior similar to fear conditioning observed in animals. Furthermore, we demonstrate how modifying a threshold where the fear response is active produces a range of behaviors that are described under the paradigm of general anxiety disorders (GADs). We demonstrate this behavior in the Miniworld Sidewalk environment, which provides a partially observable Markov decision process (POMDP) and a sparse reward with a non-descriptive terminal condition, i.e., death. In effect, this study results in a biologically-inspired neural architecture and framework for fear conditioning paradigms; we empirically demonstrate avoidance behavior in a constructed agent that is able to solve environments with non-descriptive terminal conditions.",
    "authors": [
      "Rodney Sanchez, Ferat Sahin, Alexander Ororbia, Jamison Heard"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.835106"
  },
  {
    "id": "oai:arXiv.org:2506.05530v1",
    "journal": "arXiv_CS",
    "title": "Spectral Graph Neural Networks are Incomplete on Graphs with a Simple Spectrum",
    "link": "https://arxiv.org/abs/2506.05530",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05530v1 Announce Type: new \nAbstract: Spectral features are widely incorporated within Graph Neural Networks (GNNs) to improve their expressive power, or their ability to distinguish among non-isomorphic graphs. One popular example is the usage of graph Laplacian eigenvectors for positional encoding in MPNNs and Graph Transformers. The expressive power of such Spectrally-enhanced GNNs (SGNNs) is usually evaluated via the k-WL graph isomorphism test hierarchy and homomorphism counting. Yet, these frameworks align poorly with the graph spectra, yielding limited insight into SGNNs' expressive power. We leverage a well-studied paradigm of classifying graphs by their largest eigenvalue multiplicity to introduce an expressivity hierarchy for SGNNs. We then prove that many SGNNs are incomplete even on graphs with distinct eigenvalues. To mitigate this deficiency, we adapt rotation equivariant neural networks to the graph spectra setting to propose a method to provably improve SGNNs' expressivity on simple spectrum graphs. We empirically verify our theoretical claims via an image classification experiment on the MNIST Superpixel dataset and eigenvector canonicalization on graphs from ZINC.",
    "authors": [
      "Snir Hordan, Maya Bechler-Speicher, Gur Lifshitz, Nadav Dym"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.835115"
  },
  {
    "id": "oai:arXiv.org:2506.05531v1",
    "journal": "arXiv_CS",
    "title": "Meta-analysis of Life Cycle Assessments for Li-Ion Batteries Production Emissions",
    "link": "https://arxiv.org/abs/2506.05531",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05531v1 Announce Type: new \nAbstract: This paper investigates the environmental impact of Li-Ion batteries by quantifying manufacturing-related emissions and analyzing how electricity mix and production scale affect emission intensity. To this end, we conduct a meta-analysis of life cycle assessments on lithium-ion batteries published over the past two decades, categorizing them by year, battery chemistry, functional unit, system boundaries, and electricity mix. We then carry out a cradle-to-gate assessment for a nickel manganese cobalt 811 battery with a silicon-coated graphite anode, analyzing how variations in the carbon intensity of the electricity mix affect emissions, with case studies for China, South Korea, and Sweden. Finally, we develop a set of regression models that link annual battery production and the carbon intensity of China's electricity mix to the average mass-specific emissions observed each year. The meta-analysis shows a median global warming potential of 17.63 kg CO2-eq./kg of battery, with a standard deviation of 7.34. Differences in electricity mix mainly influence emissions from the energy-intensive cell production, particularly from cathode material processing. We found that a multivariate linear regression using production volume and the carbon intensity of the Chinese electricity mix as predictors explains emissions with moderate accuracy. The environmental impact of battery manufacturing can be reduced by using clean energy sources in production processes. However, achieving substantial reductions requires clean energy throughout the entire supply chain, as importing materials from regions with carbon-intensive electricity mixes can undermine these efforts. Our findings also highlight the emission-reducing effect of learning associated with increased production scale, supporting the integration of learning effects in future life cycle assessment models.",
    "authors": [
      "Maurizio Clemente, Prapti Maharjan, Mauro Salazar, Theo Hofman"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.835123"
  },
  {
    "id": "oai:arXiv.org:2506.05533v1",
    "journal": "arXiv_CS",
    "title": "Personalized Interpretability -- Interactive Alignment of Prototypical Parts Networks",
    "link": "https://arxiv.org/abs/2506.05533",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05533v1 Announce Type: new \nAbstract: Concept-based interpretable neural networks have gained significant attention due to their intuitive and easy-to-understand explanations based on case-based reasoning, such as \"this bird looks like those sparrows\". However, a major limitation is that these explanations may not always be comprehensible to users due to concept inconsistency, where multiple visual features are inappropriately mixed (e.g., a bird's head and wings treated as a single concept). This inconsistency breaks the alignment between model reasoning and human understanding. Furthermore, users have specific preferences for how concepts should look, yet current approaches provide no mechanism for incorporating their feedback. To address these issues, we introduce YoursProtoP, a novel interactive strategy that enables the personalization of prototypical parts - the visual concepts used by the model - according to user needs. By incorporating user supervision, YoursProtoP adapts and splits concepts used for both prediction and explanation to better match the user's preferences and understanding. Through experiments on both the synthetic FunnyBirds dataset and a real-world scenario using the CUB, CARS, and PETS datasets in a comprehensive user study, we demonstrate the effectiveness of YoursProtoP in achieving concept consistency without compromising the accuracy of the model.",
    "authors": [
      "Tomasz Michalski, Adam Wr\\'obel, Andrea Bontempelli, Jakub Lu\\'styk, Mikolaj Kniejski, Stefano Teso, Andrea Passerini, Bartosz Zieli\\'nski, Dawid Rymarczyk"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.835132"
  },
  {
    "id": "oai:arXiv.org:2506.05535v1",
    "journal": "arXiv_CS",
    "title": "Approximation of the Pseudospectral Abscissa via Eigenvalue Perturbation Theory",
    "link": "https://arxiv.org/abs/2506.05535",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05535v1 Announce Type: new \nAbstract: Reliable and efficient computation of the pseudospectral abscissa in the large-scale setting is still not settled. Unlike the small-scale setting where there are globally convergent criss-cross algorithms, all algorithms in the large-scale setting proposed to date are at best locally convergent. We first describe how eigenvalue perturbation theory can be put in use to estimate the globally rightmost point in the $\\epsilon$-pseudospectrum if $\\epsilon$ is small. Our treatment addresses both general nonlinear eigenvalue problems, and the standard eigenvalue problem as a special case. For small $\\epsilon$, the estimates by eigenvalue perturbation theory are quite accurate. In the standard eigenvalue case, we even derive a formula with an ${\\mathcal O}(\\epsilon^3)$ error. For larger $\\epsilon$, the estimates can be used to initialize the locally convergent algorithms. We also propose fixed-point iterations built on the the perturbation theory ideas for large $\\epsilon$ that are suitable for the large-scale setting. The proposed fixed-point iterations initialized by using eigenvalue perturbation theory converge to the globally rightmost point in the pseudospectrum in a vast majority of the cases that we experiment with.",
    "authors": [
      "Waqar Ahmed, Emre Mengi"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.835140"
  },
  {
    "id": "oai:arXiv.org:2506.05538v1",
    "journal": "arXiv_CS",
    "title": "SocialDF: Benchmark Dataset and Detection Model for Mitigating Harmful Deepfake Content on Social Media Platforms",
    "link": "https://arxiv.org/abs/2506.05538",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05538v1 Announce Type: new \nAbstract: The rapid advancement of deep generative models has significantly improved the realism of synthetic media, presenting both opportunities and security challenges. While deepfake technology has valuable applications in entertainment and accessibility, it has emerged as a potent vector for misinformation campaigns, particularly on social media. Existing detection frameworks struggle to distinguish between benign and adversarially generated deepfakes engineered to manipulate public perception. To address this challenge, we introduce SocialDF, a curated dataset reflecting real-world deepfake challenges on social media platforms. This dataset encompasses high-fidelity deepfakes sourced from various online ecosystems, ensuring broad coverage of manipulative techniques. We propose a novel LLM-based multi-factor detection approach that combines facial recognition, automated speech transcription, and a multi-agent LLM pipeline to cross-verify audio-visual cues. Our methodology emphasizes robust, multi-modal verification techniques that incorporate linguistic, behavioral, and contextual analysis to effectively discern synthetic media from authentic content.",
    "authors": [
      "Arnesh Batra, Anushk Kumar, Jashn Khemani, Arush Gumber, Arhan Jain, Somil Gupta"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.835150"
  },
  {
    "id": "oai:arXiv.org:2506.05546v1",
    "journal": "arXiv_CS",
    "title": "Layered Motion Fusion: Lifting Motion Segmentation to 3D in Egocentric Videos",
    "link": "https://arxiv.org/abs/2506.05546",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05546v1 Announce Type: new \nAbstract: Computer vision is largely based on 2D techniques, with 3D vision still relegated to a relatively narrow subset of applications. However, by building on recent advances in 3D models such as neural radiance fields, some authors have shown that 3D techniques can at last improve outputs extracted from independent 2D views, by fusing them into 3D and denoising them. This is particularly helpful in egocentric videos, where the camera motion is significant, but only under the assumption that the scene itself is static. In fact, as shown in the recent analysis conducted by EPIC Fields, 3D techniques are ineffective when it comes to studying dynamic phenomena, and, in particular, when segmenting moving objects. In this paper, we look into this issue in more detail. First, we propose to improve dynamic segmentation in 3D by fusing motion segmentation predictions from a 2D-based model into layered radiance fields (Layered Motion Fusion). However, the high complexity of long, dynamic videos makes it challenging to capture the underlying geometric structure, and, as a result, hinders the fusion of motion cues into the (incomplete) scene geometry. We address this issue through test-time refinement, which helps the model to focus on specific frames, thereby reducing the data complexity. This results in a synergy between motion fusion and the refinement, and in turn leads to segmentation predictions of the 3D model that surpass the 2D baseline by a large margin. This demonstrates that 3D techniques can enhance 2D analysis even for dynamic phenomena in a challenging and realistic setting.",
    "authors": [
      "Vadim Tschernezki, Diane Larlus, Andrea Vedaldi, Iro Laina"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.835175"
  },
  {
    "id": "oai:arXiv.org:2506.05551v1",
    "journal": "arXiv_CS",
    "title": "When Semantics Mislead Vision: Mitigating Large Multimodal Models Hallucinations in Scene Text Spotting and Understanding",
    "link": "https://arxiv.org/abs/2506.05551",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05551v1 Announce Type: new \nAbstract: Large Multimodal Models (LMMs) have achieved impressive progress in visual perception and reasoning. However, when confronted with visually ambiguous or non-semantic scene text, they often struggle to accurately spot and understand the content, frequently generating semantically plausible yet visually incorrect answers, which we refer to as semantic hallucination. In this work, we investigate the underlying causes of semantic hallucination and identify a key finding: Transformer layers in LLM with stronger attention focus on scene text regions are less prone to producing semantic hallucinations. Thus, we propose a training-free semantic hallucination mitigation framework comprising two key components: (1) ZoomText, a coarse-to-fine strategy that identifies potential text regions without external detectors; and (2) Grounded Layer Correction, which adaptively leverages the internal representations from layers less prone to hallucination to guide decoding, correcting hallucinated outputs for non-semantic samples while preserving the semantics of meaningful ones. To enable rigorous evaluation, we introduce TextHalu-Bench, a benchmark of over 1,730 samples spanning both semantic and non-semantic cases, with manually curated question-answer pairs designed to probe model hallucinations. Extensive experiments demonstrate that our method not only effectively mitigates semantic hallucination but also achieves strong performance on public benchmarks for scene text spotting and understanding.",
    "authors": [
      "Yan Shu, Hangui Lin, Yexin Liu, Yan Zhang, Gangyan Zeng, Yan Li, Yu Zhou, Ser-Nam Lim, Harry Yang, Nicu Sebe"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.835185"
  },
  {
    "id": "oai:arXiv.org:2506.05554v1",
    "journal": "arXiv_CS",
    "title": "EX-4D: EXtreme Viewpoint 4D Video Synthesis via Depth Watertight Mesh",
    "link": "https://arxiv.org/abs/2506.05554",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05554v1 Announce Type: new \nAbstract: Generating high-quality camera-controllable videos from monocular input is a challenging task, particularly under extreme viewpoint. Existing methods often struggle with geometric inconsistencies and occlusion artifacts in boundaries, leading to degraded visual quality. In this paper, we introduce EX-4D, a novel framework that addresses these challenges through a Depth Watertight Mesh representation. The representation serves as a robust geometric prior by explicitly modeling both visible and occluded regions, ensuring geometric consistency in extreme camera pose. To overcome the lack of paired multi-view datasets, we propose a simulated masking strategy that generates effective training data only from monocular videos. Additionally, a lightweight LoRA-based video diffusion adapter is employed to synthesize high-quality, physically consistent, and temporally coherent videos. Extensive experiments demonstrate that EX-4D outperforms state-of-the-art methods in terms of physical consistency and extreme-view quality, enabling practical 4D video generation.",
    "authors": [
      "Tao Hu, Haoyang Peng, Xiao Liu, Yuewen Ma"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.835194"
  },
  {
    "id": "oai:arXiv.org:2506.05555v1",
    "journal": "arXiv_CS",
    "title": "Using Large Language Models to Simulate Human Behavioural Experiments: Port of Mars",
    "link": "https://arxiv.org/abs/2506.05555",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05555v1 Announce Type: new \nAbstract: Collective risk social dilemmas (CRSD) highlight a trade-off between individual preferences and the need for all to contribute toward achieving a group objective. Problems such as climate change are in this category, and so it is critical to understand their social underpinnings. However, rigorous CRSD methodology often demands large-scale human experiments but it is difficult to guarantee sufficient power and heterogeneity over socio-demographic factors. Generative AI offers a potential complementary approach to address thisproblem. By replacing human participants with large language models (LLM), it allows for a scalable empirical framework. This paper focuses on the validity of this approach and whether it is feasible to represent a large-scale human-like experiment with sufficient diversity using LLM. In particular, where previous literature has focused on political surveys, virtual towns and classical game-theoretic examples, we focus on a complex CRSD used in the institutional economics and sustainability literature known as Port of Mars",
    "authors": [
      "Oliver Slumbers, Joel Z. Leibo, Marco A. Janssen"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.835203"
  },
  {
    "id": "oai:arXiv.org:2506.05558v1",
    "journal": "arXiv_CS",
    "title": "On-the-fly Reconstruction for Large-Scale Novel View Synthesis from Unposed Images",
    "link": "https://arxiv.org/abs/2506.05558",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05558v1 Announce Type: new \nAbstract: Radiance field methods such as 3D Gaussian Splatting (3DGS) allow easy reconstruction from photos, enabling free-viewpoint navigation. Nonetheless, pose estimation using Structure from Motion and 3DGS optimization can still each take between minutes and hours of computation after capture is complete. SLAM methods combined with 3DGS are fast but struggle with wide camera baselines and large scenes. We present an on-the-fly method to produce camera poses and a trained 3DGS immediately after capture. Our method can handle dense and wide-baseline captures of ordered photo sequences and large-scale scenes. To do this, we first introduce fast initial pose estimation, exploiting learned features and a GPU-friendly mini bundle adjustment. We then introduce direct sampling of Gaussian primitive positions and shapes, incrementally spawning primitives where required, significantly accelerating training. These two efficient steps allow fast and robust joint optimization of poses and Gaussian primitives. Our incremental approach handles large-scale scenes by introducing scalable radiance field construction, progressively clustering 3DGS primitives, storing them in anchors, and offloading them from the GPU. Clustered primitives are progressively merged, keeping the required scale of 3DGS at any viewpoint. We evaluate our solution on a variety of datasets and show that our solution can provide on-the-fly processing of all the capture scenarios and scene sizes we target while remaining competitive with other methods that only handle specific capture styles or scene sizes in speed, image quality, or both.",
    "authors": [
      "Andreas Meuleman, Ishaan Shah, Alexandre Lanvin, Bernhard Kerbl, George Drettakis"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.835211"
  },
  {
    "id": "oai:arXiv.org:2506.05560v1",
    "journal": "arXiv_CS",
    "title": "Improving LLMs with a knowledge from databases",
    "link": "https://arxiv.org/abs/2506.05560",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05560v1 Announce Type: new \nAbstract: Large language models (LLMs) are achieving significant progress almost every moment now. Many advanced techniques have been introduced and widely accepted, like retrieval-augmentation generation (RAG), agents, and tools. Tools can query the database to answer questions from structured data files or perform groupings or other statistics. This unlocks huge opportunities, such as it can answer any question, but also poses threats, such as safety, because there is no control over the commands that are created. We would like to discuss whether we can create a new method that improves answers based on dataset/database via some interpretable ML methods, namely enhanced association rules. The advantage would be if the method can be also used in some safe technique like RAG. Association rules have a sound history. Since the introduction of CN2 and aproiri, many enhancements have been made. In parallel, enhanced association rules have been introduced and evolved over the last 40 years. The general problem is typically that there are too many rules. There are some techniques for handling it, but when LLM emerged, it turned out to be the best use case for the RAG technique for LLMs. We proposed a method that generates a ruleset based on defined knowledge patterns, then converts rules into text form via a rule-to-text converter, and includes the result as an RAG into LLM. We compared this method with ChatGPT (even with using agents) and we have discovered a significant improvement in answering questions based on the dataset. We have also tried several strategies how much rules to generate. We found this improvement interesting. Moreover, it can also be improved in many ways as future work, like incorporating other patterns, the use of rule mining as an agent, and many others.",
    "authors": [
      "Petr M\\'a\\v{s}a"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.835219"
  },
  {
    "id": "oai:arXiv.org:2506.05563v1",
    "journal": "arXiv_CS",
    "title": "VoxelSplat: Dynamic Gaussian Splatting as an Effective Loss for Occupancy and Flow Prediction",
    "link": "https://arxiv.org/abs/2506.05563",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05563v1 Announce Type: new \nAbstract: Recent advancements in camera-based occupancy prediction have focused on the simultaneous prediction of 3D semantics and scene flow, a task that presents significant challenges due to specific difficulties, e.g., occlusions and unbalanced dynamic environments. In this paper, we analyze these challenges and their underlying causes. To address them, we propose a novel regularization framework called VoxelSplat. This framework leverages recent developments in 3D Gaussian Splatting to enhance model performance in two key ways: (i) Enhanced Semantics Supervision through 2D Projection: During training, our method decodes sparse semantic 3D Gaussians from 3D representations and projects them onto the 2D camera view. This provides additional supervision signals in the camera-visible space, allowing 2D labels to improve the learning of 3D semantics. (ii) Scene Flow Learning: Our framework uses the predicted scene flow to model the motion of Gaussians, and is thus able to learn the scene flow of moving objects in a self-supervised manner using the labels of adjacent frames. Our method can be seamlessly integrated into various existing occupancy models, enhancing performance without increasing inference time. Extensive experiments on benchmark datasets demonstrate the effectiveness of VoxelSplat in improving the accuracy of both semantic occupancy and scene flow estimation. The project page and codes are available at https://zzy816.github.io/VoxelSplat-Demo/.",
    "authors": [
      "Ziyue Zhu, Shenlong Wang, Jin Xie, Jiang-jiang Liu, Jingdong Wang, Jian Yang"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.835228"
  },
  {
    "id": "oai:arXiv.org:2506.05565v1",
    "journal": "arXiv_CS",
    "title": "Applying Informer for Option Pricing: A Transformer-Based Approach",
    "link": "https://arxiv.org/abs/2506.05565",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05565v1 Announce Type: new \nAbstract: Accurate option pricing is essential for effective trading and risk management in financial markets, yet it remains challenging due to market volatility and the limitations of traditional models like Black-Scholes. In this paper, we investigate the application of the Informer neural network for option pricing, leveraging its ability to capture long-term dependencies and dynamically adjust to market fluctuations. This research contributes to the field of financial forecasting by introducing Informer's efficient architecture to enhance prediction accuracy and provide a more adaptable and resilient framework compared to existing methods. Our results demonstrate that Informer outperforms traditional approaches in option pricing, advancing the capabilities of data-driven financial forecasting in this domain.",
    "authors": [
      "Feliks Ba\\'nka, Jaros{\\l}aw A. Chudziak"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.835237"
  },
  {
    "id": "oai:arXiv.org:2506.05566v1",
    "journal": "arXiv_CS",
    "title": "ScaleRTL: Scaling LLMs with Reasoning Data and Test-Time Compute for Accurate RTL Code Generation",
    "link": "https://arxiv.org/abs/2506.05566",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05566v1 Announce Type: new \nAbstract: Recent advances in large language models (LLMs) have enabled near-human performance on software coding benchmarks, but their effectiveness in RTL code generation remains limited due to the scarcity of high-quality training data. While prior efforts have fine-tuned LLMs for RTL tasks, they do not fundamentally overcome the data bottleneck and lack support for test-time scaling due to their non-reasoning nature. In this work, we introduce ScaleRTL, the first reasoning LLM for RTL coding that scales up both high-quality reasoning data and test-time compute. Specifically, we curate a diverse set of long chain-of-thought reasoning traces averaging 56K tokens each, resulting in a dataset of 3.5B tokens that captures rich RTL knowledge. Fine-tuning a general-purpose reasoning model on this corpus yields ScaleRTL that is capable of deep RTL reasoning. Subsequently, we further enhance the performance of ScaleRTL through a novel test-time scaling strategy that extends the reasoning process via iteratively reflecting on and self-correcting previous reasoning steps. Experimental results show that ScaleRTL achieves state-of-the-art performance on VerilogEval and RTLLM, outperforming 18 competitive baselines by up to 18.4% on VerilogEval and 12.7% on RTLLM.",
    "authors": [
      "Chenhui Deng, Yun-Da Tsai, Guan-Ting Liu, Zhongzhi Yu, Haoxing Ren"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.835246"
  },
  {
    "id": "oai:arXiv.org:2506.05568v1",
    "journal": "arXiv_CS",
    "title": "Ravan: Multi-Head Low-Rank Adaptation for Federated Fine-Tuning",
    "link": "https://arxiv.org/abs/2506.05568",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05568v1 Announce Type: new \nAbstract: Large language models (LLMs) have not yet effectively leveraged the vast amounts of edge-device data, and federated learning (FL) offers a promising paradigm to collaboratively fine-tune LLMs without transferring private edge data to the cloud. To operate within the computation and communication constraints of edge devices, recent literature on federated fine-tuning of LLMs proposes the use of low-rank adaptation (LoRA) and similar parameter-efficient methods. However, LoRA-based methods suffer from accuracy degradation in FL settings, primarily because of data and computational heterogeneity across clients. We propose \\textsc{Ravan}, an adaptive multi-head LoRA method that balances parameter efficiency and model expressivity by reparameterizing the weight updates as the sum of multiple LoRA heads $s_i\\textbf{B}_i\\textbf{H}_i\\textbf{A}_i$ in which only the core matrices $\\textbf{H}_i$ and their lightweight scaling factors $s_i$ are trained. These trainable scaling factors let the optimization focus on the most useful heads, recovering a higher-rank approximation of the full update without increasing the number of communicated parameters since clients upload $s_i\\textbf{H}_i$ directly. Experiments on vision and language benchmarks show that \\textsc{Ravan} improves test accuracy by 2-8\\% over prior parameter-efficient baselines, making it a robust and scalable solution for federated fine-tuning of LLMs.",
    "authors": [
      "Arian Raje, Baris Askin, Divyansh Jhunjhunwala, Gauri Joshi"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.835255"
  },
  {
    "id": "oai:arXiv.org:2506.05569v1",
    "journal": "arXiv_CS",
    "title": "Fluid Antenna System-Assisted Self-Interference Cancellation for In-Band Full Duplex Communications",
    "link": "https://arxiv.org/abs/2506.05569",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05569v1 Announce Type: new \nAbstract: In-band full-duplex (IBFD) systems are expected to double the spectral efficiency compared to half-duplex systems, provided that loopback self-interference (SI) can be effectively suppressed. The inherent interference mitigation capabilities of the emerging fluid antenna system (FAS) technology make it a promising candidate for addressing the SI challenge in IBFD systems. This paper thus proposes a FAS-assisted self-interference cancellation (SIC) framework, which leverages a receiver-side FAS to dynamically select an interference-free port. Analytical results include a lower bound and an approximation of the residual SI (RSI) power, both derived for rich-scattering channels by considering the joint spatial correlation amongst the FAS ports. Simulations of RSI power and forward link rates validate the analysis, showing that the SIC performance improves with the number of FAS ports. Additionally, simulations under practical conditions, such as finite-scattering environments and wideband integrated access and backhaul (IAB) channels, reveal that the proposed approach offers superior SIC capability and significant forward rate gains over conventional IBFD SIC schemes.",
    "authors": [
      "Hanjiang Hong, Kai-Kit Wong, Hao Xu, Yiyan Wu, Sai Xu, Chan-Byoung Chae, Baiyang Liu, Kin-Fai Tong"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.835264"
  },
  {
    "id": "oai:arXiv.org:2506.05573v1",
    "journal": "arXiv_CS",
    "title": "PartCrafter: Structured 3D Mesh Generation via Compositional Latent Diffusion Transformers",
    "link": "https://arxiv.org/abs/2506.05573",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05573v1 Announce Type: new \nAbstract: We introduce PartCrafter, the first structured 3D generative model that jointly synthesizes multiple semantically meaningful and geometrically distinct 3D meshes from a single RGB image. Unlike existing methods that either produce monolithic 3D shapes or follow two-stage pipelines, i.e., first segmenting an image and then reconstructing each segment, PartCrafter adopts a unified, compositional generation architecture that does not rely on pre-segmented inputs. Conditioned on a single image, it simultaneously denoises multiple 3D parts, enabling end-to-end part-aware generation of both individual objects and complex multi-object scenes. PartCrafter builds upon a pretrained 3D mesh diffusion transformer (DiT) trained on whole objects, inheriting the pretrained weights, encoder, and decoder, and introduces two key innovations: (1) A compositional latent space, where each 3D part is represented by a set of disentangled latent tokens; (2) A hierarchical attention mechanism that enables structured information flow both within individual parts and across all parts, ensuring global coherence while preserving part-level detail during generation. To support part-level supervision, we curate a new dataset by mining part-level annotations from large-scale 3D object datasets. Experiments show that PartCrafter outperforms existing approaches in generating decomposable 3D meshes, including parts that are not directly visible in input images, demonstrating the strength of part-aware generative priors for 3D understanding and synthesis. Code and training data will be released.",
    "authors": [
      "Yuchen Lin, Chenguo Lin, Panwang Pan, Honglei Yan, Yiqiang Feng, Yadong Mu, Katerina Fragkiadaki"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.835273"
  },
  {
    "id": "oai:arXiv.org:2506.05576v1",
    "journal": "arXiv_CS",
    "title": "TD-TOG Dataset: Benchmarking Zero-Shot and One-Shot Task-Oriented Grasping for Object Generalization",
    "link": "https://arxiv.org/abs/2506.05576",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05576v1 Announce Type: new \nAbstract: Task-oriented grasping (TOG) is an essential preliminary step for robotic task execution, which involves predicting grasps on regions of target objects that facilitate intended tasks. Existing literature reveals there is a limited availability of TOG datasets for training and benchmarking despite large demand, which are often synthetic or have artifacts in mask annotations that hinder model performance. Moreover, TOG solutions often require affordance masks, grasps, and object masks for training, however, existing datasets typically provide only a subset of these annotations. To address these limitations, we introduce the Top-down Task-oriented Grasping (TD-TOG) dataset, designed to train and evaluate TOG solutions. TD-TOG comprises 1,449 real-world RGB-D scenes including 30 object categories and 120 subcategories, with hand-annotated object masks, affordances, and planar rectangular grasps. It also features a test set for a novel challenge that assesses a TOG solution's ability to distinguish between object subcategories. To contribute to the demand for TOG solutions that can adapt and manipulate previously unseen objects without re-training, we propose a novel TOG framework, Binary-TOG. Binary-TOG uses zero-shot for object recognition, and one-shot learning for affordance recognition. Zero-shot learning enables Binary-TOG to identify objects in multi-object scenes through textual prompts, eliminating the need for visual references. In multi-object settings, Binary-TOG achieves an average task-oriented grasp accuracy of 68.9%. Lastly, this paper contributes a comparative analysis between one-shot and zero-shot learning for object generalization in TOG to be used in the development of future TOG solutions.",
    "authors": [
      "Valerija Holomjova, Jamie Grech, Dewei Yi, Bruno Yun, Andrew Starkey, Pascal Mei{\\ss}ner"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.835282"
  },
  {
    "id": "oai:arXiv.org:2506.05582v1",
    "journal": "arXiv_CS",
    "title": "Combating Misinformation in the Arab World: Challenges & Opportunities",
    "link": "https://arxiv.org/abs/2506.05582",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05582v1 Announce Type: new \nAbstract: Misinformation and disinformation pose significant risks globally, with the Arab region facing unique vulnerabilities due to geopolitical instabilities, linguistic diversity, and cultural nuances. We explore these challenges through the key facets of combating misinformation: detection, tracking, mitigation and community-engagement. We shed light on how connecting with grass-roots fact-checking organizations, understanding cultural norms, promoting social correction, and creating strong collaborative information networks can create opportunities for a more resilient information ecosystem in the Arab world.",
    "authors": [
      "Azza Abouzied, Firoj Alam, Raian Ali, Paolo Papotti"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.835306"
  },
  {
    "id": "oai:arXiv.org:2506.05583v1",
    "journal": "arXiv_CS",
    "title": "Conformal Prediction Adaptive to Unknown Subpopulation Shifts",
    "link": "https://arxiv.org/abs/2506.05583",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05583v1 Announce Type: new \nAbstract: Conformal prediction is widely used to equip black-box machine learning models with uncertainty quantification enjoying formal coverage guarantees. However, these guarantees typically break down in the presence of distribution shifts, where the data distribution at test time differs from the training (or calibration-time) distribution. In this work, we address subpopulation shifts, where the test environment exhibits an unknown and differing mixture of subpopulations compared to the calibration data. We propose new methods that provably adapt conformal prediction to such shifts, ensuring valid coverage without requiring explicit knowledge of subpopulation structure. Our algorithms scale to high-dimensional settings and perform effectively in realistic machine learning tasks. Extensive experiments on vision (with vision transformers) and language (with large language models) benchmarks demonstrate that our methods reliably maintain coverage and controls risk in scenarios where standard conformal prediction fails.",
    "authors": [
      "Nien-Shao Wang, Duygu Nur Yaldiz, Yavuz Faruk Bakman, Sai Praneeth Karimireddy"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.835314"
  },
  {
    "id": "oai:arXiv.org:2506.05584v1",
    "journal": "arXiv_CS",
    "title": "TabFlex: Scaling Tabular Learning to Millions with Linear Attention",
    "link": "https://arxiv.org/abs/2506.05584",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05584v1 Announce Type: new \nAbstract: Leveraging the in-context learning (ICL) capability of Large Language Models (LLMs) for tabular classification has gained significant attention for its training-free adaptability across diverse datasets. Recent advancements, like TabPFN, excel in small-scale tabular datasets but struggle to scale for large and complex datasets. Our work enhances the efficiency and scalability of TabPFN for larger datasets by incorporating linear attention mechanisms as a scalable alternative to complexity-quadratic self-attention. Our model, TabFlex, efficiently handles tabular datasets with thousands of features and hundreds of classes, scaling seamlessly to millions of samples. For instance, TabFlex processes the poker-hand dataset with over a million samples in just 5 seconds. Our extensive evaluations demonstrate that TabFlex can achieve over a 2x speedup compared to TabPFN and a 1.5x speedup over XGBoost, outperforming 25 tested baselines in terms of efficiency across a diverse range of datasets. Furthermore, TabFlex remains highly effective on large-scale datasets, delivering strong performance with significantly reduced computational costs, especially when combined with data-efficient techniques such as dimensionality reduction and data sampling.",
    "authors": [
      "Yuchen Zeng, Tuan Dinh, Wonjun Kang, Andreas C Mueller"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.835322"
  },
  {
    "id": "oai:arXiv.org:2506.05586v1",
    "journal": "arXiv_CS",
    "title": "CoFrNets: Interpretable Neural Architecture Inspired by Continued Fractions",
    "link": "https://arxiv.org/abs/2506.05586",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05586v1 Announce Type: new \nAbstract: In recent years there has been a considerable amount of research on local post hoc explanations for neural networks. However, work on building interpretable neural architectures has been relatively sparse. In this paper, we present a novel neural architecture, CoFrNet, inspired by the form of continued fractions which are known to have many attractive properties in number theory, such as fast convergence of approximations to real numbers. We show that CoFrNets can be efficiently trained as well as interpreted leveraging their particular functional form. Moreover, we prove that such architectures are universal approximators based on a proof strategy that is different than the typical strategy used to prove universal approximation results for neural networks based on infinite width (or depth), which is likely to be of independent interest. We experiment on nonlinear synthetic functions and are able to accurately model as well as estimate feature attributions and even higher order terms in some cases, which is a testament to the representational power as well as interpretability of such architectures. To further showcase the power of CoFrNets, we experiment on seven real datasets spanning tabular, text and image modalities, and show that they are either comparable or significantly better than other interpretable models and multilayer perceptrons, sometimes approaching the accuracies of state-of-the-art models.",
    "authors": [
      "Isha Puri, Amit Dhurandhar, Tejaswini Pedapati, Kartikeyan Shanmugam, Dennis Wei, Kush R. Varshney"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.835331"
  },
  {
    "id": "oai:arXiv.org:2506.05587v1",
    "journal": "arXiv_CS",
    "title": "MMTU: A Massive Multi-Task Table Understanding and Reasoning Benchmark",
    "link": "https://arxiv.org/abs/2506.05587",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05587v1 Announce Type: new \nAbstract: Tables and table-based use cases play a crucial role in many important real-world applications, such as spreadsheets, databases, and computational notebooks, which traditionally require expert-level users like data engineers, data analysts, and database administrators to operate. Although LLMs have shown remarkable progress in working with tables (e.g., in spreadsheet and database copilot scenarios), comprehensive benchmarking of such capabilities remains limited. In contrast to an extensive and growing list of NLP benchmarks, evaluations of table-related tasks are scarce, and narrowly focus on tasks like NL-to-SQL and Table-QA, overlooking the broader spectrum of real-world tasks that professional users face. This gap limits our understanding and model progress in this important area.\n  In this work, we introduce MMTU, a large-scale benchmark with over 30K questions across 25 real-world table tasks, designed to comprehensively evaluate models ability to understand, reason, and manipulate real tables at the expert-level. These tasks are drawn from decades' worth of computer science research on tabular data, with a focus on complex table tasks faced by professional users. We show that MMTU require a combination of skills -- including table understanding, reasoning, and coding -- that remain challenging for today's frontier models, where even frontier reasoning models like OpenAI o4-mini and DeepSeek R1 score only around 60%, suggesting significant room for improvement. We highlight key findings in our evaluation using MMTU and hope that this benchmark drives further advances in understanding and developing foundation models for structured data processing and analysis. Our code and data are available at https://github.com/MMTU-Benchmark/MMTU and https://huggingface.co/datasets/MMTU-benchmark/MMTU.",
    "authors": [
      "Junjie Xing, Yeye He, Mengyu Zhou, Haoyu Dong, Shi Han, Lingjiao Chen, Dongmei Zhang, Surajit Chaudhuri, H. V. Jagadish"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.835339"
  },
  {
    "id": "oai:arXiv.org:2506.05588v1",
    "journal": "arXiv_CS",
    "title": "Preprocessing Methods for Memristive Reservoir Computing for Image Recognition",
    "link": "https://arxiv.org/abs/2506.05588",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05588v1 Announce Type: new \nAbstract: Reservoir computing (RC) has attracted attention as an efficient recurrent neural network architecture due to its simplified training, requiring only its last perceptron readout layer to be trained. When implemented with memristors, RC systems benefit from their dynamic properties, which make them ideal for reservoir construction. However, achieving high performance in memristor-based RC remains challenging, as it critically depends on the input preprocessing method and reservoir size. Despite growing interest, a comprehensive evaluation that quantifies the impact of these factors is still lacking. This paper systematically compares various preprocessing methods for memristive RC systems, assessing their effects on accuracy and energy consumption. We also propose a parity-based preprocessing method that improves accuracy by 2-6% while requiring only a modest increase in device count compared to other methods. Our findings highlight the importance of informed preprocessing strategies to improve the efficiency and scalability of memristive RC systems.",
    "authors": [
      "Rishona Daniels, Duna Wattad, Ronny Ronen, David Saad, Shahar Kvatinsky"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.835348"
  },
  {
    "id": "oai:arXiv.org:2506.05589v1",
    "journal": "arXiv_CS",
    "title": "UTSA-NLP at ArchEHR-QA 2025: Improving EHR Question Answering via Self-Consistency Prompting",
    "link": "https://arxiv.org/abs/2506.05589",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05589v1 Announce Type: new \nAbstract: We describe our system for the ArchEHR-QA Shared Task on answering clinical questions using electronic health records (EHRs). Our approach uses large language models in two steps: first, to find sentences in the EHR relevant to a clinician's question, and second, to generate a short, citation-supported response based on those sentences. We use few-shot prompting, self-consistency, and thresholding to improve the sentence classification step to decide which sentences are essential. We compare several models and find that a smaller 8B model performs better than a larger 70B model for identifying relevant information. Our results show that accurate sentence selection is critical for generating high-quality responses and that self-consistency with thresholding helps make these decisions more reliable.",
    "authors": [
      "Sara Shields-Menard, Zach Reimers, Joshua Gardner, David Perry, Anthony Rios"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.835357"
  },
  {
    "id": "oai:arXiv.org:2506.05593v1",
    "journal": "arXiv_CS",
    "title": "Improving Neural Diarization through Speaker Attribute Attractors and Local Dependency Modeling",
    "link": "https://arxiv.org/abs/2506.05593",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05593v1 Announce Type: new \nAbstract: In recent years, end-to-end approaches have made notable progress in addressing the challenge of speaker diarization, which involves segmenting and identifying speakers in multi-talker recordings. One such approach, Encoder-Decoder Attractors (EDA), has been proposed to handle variable speaker counts as well as better guide the network during training. In this study, we extend the attractor paradigm by moving beyond direct speaker modeling and instead focus on representing more detailed `speaker attributes' through a multi-stage process of intermediate representations. Additionally, we enhance the architecture by replacing transformers with conformers, a convolution-augmented transformer, to model local dependencies. Experiments demonstrate improved diarization performance on the CALLHOME dataset.",
    "authors": [
      "David Palzer, Matthew Maciejewski, Eric Fosler-Lussier"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.835366"
  },
  {
    "id": "oai:arXiv.org:2506.05594v1",
    "journal": "arXiv_CS",
    "title": "SoK: Are Watermarks in LLMs Ready for Deployment?",
    "link": "https://arxiv.org/abs/2506.05594",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05594v1 Announce Type: new \nAbstract: Large Language Models (LLMs) have transformed natural language processing, demonstrating impressive capabilities across diverse tasks. However, deploying these models introduces critical risks related to intellectual property violations and potential misuse, particularly as adversaries can imitate these models to steal services or generate misleading outputs. We specifically focus on model stealing attacks, as they are highly relevant to proprietary LLMs and pose a serious threat to their security, revenue, and ethical deployment. While various watermarking techniques have emerged to mitigate these risks, it remains unclear how far the community and industry have progressed in developing and deploying watermarks in LLMs.\n  To bridge this gap, we aim to develop a comprehensive systematization for watermarks in LLMs by 1) presenting a detailed taxonomy for watermarks in LLMs, 2) proposing a novel intellectual property classifier to explore the effectiveness and impacts of watermarks on LLMs under both attack and attack-free environments, 3) analyzing the limitations of existing watermarks in LLMs, and 4) discussing practical challenges and potential future directions for watermarks in LLMs. Through extensive experiments, we show that despite promising research outcomes and significant attention from leading companies and community to deploy watermarks, these techniques have yet to reach their full potential in real-world applications due to their unfavorable impacts on model utility of LLMs and downstream tasks. Our findings provide an insightful understanding of watermarks in LLMs, highlighting the need for practical watermarks solutions tailored to LLM deployment.",
    "authors": [
      "Kieu Dang, Phung Lai, NhatHai Phan, Yelong Shen, Ruoming Jin, Abdallah Khreishah, My Thai"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.835374"
  },
  {
    "id": "oai:arXiv.org:2506.05597v1",
    "journal": "arXiv_CS",
    "title": "FaCTR: Factorized Channel-Temporal Representation Transformers for Efficient Time Series Forecasting",
    "link": "https://arxiv.org/abs/2506.05597",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05597v1 Announce Type: new \nAbstract: While Transformers excel in language and vision-where inputs are semantically rich and exhibit univariate dependency structures-their architectural complexity leads to diminishing returns in time series forecasting. Time series data is characterized by low per-timestep information density and complex dependencies across channels and covariates, requiring conditioning on structured variable interactions. To address this mismatch and overparameterization, we propose FaCTR, a lightweight spatiotemporal Transformer with an explicitly structural design. FaCTR injects dynamic, symmetric cross-channel interactions-modeled via a low-rank Factorization Machine into temporally contextualized patch embeddings through a learnable gating mechanism. It further encodes static and dynamic covariates for multivariate conditioning. Despite its compact design, FaCTR achieves state-of-the-art performance on eleven public forecasting benchmarks spanning both short-term and long-term horizons, with its largest variant using close to only 400K parameters-on average 50x smaller than competitive spatiotemporal transformer baselines. In addition, its structured design enables interpretability through cross-channel influence scores-an essential requirement for real-world decision-making. Finally, FaCTR supports self-supervised pretraining, positioning it as a compact yet versatile foundation for downstream time series tasks.",
    "authors": [
      "Yash Vijay, Harini Subramanyan"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.835383"
  },
  {
    "id": "oai:arXiv.org:2506.05598v1",
    "journal": "arXiv_CS",
    "title": "SynthesizeMe! Inducing Persona-Guided Prompts for Personalized Reward Models in LLMs",
    "link": "https://arxiv.org/abs/2506.05598",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05598v1 Announce Type: new \nAbstract: Recent calls for pluralistic alignment of Large Language Models (LLMs) encourage adapting models to diverse user preferences. However, most prior work on personalized reward models heavily rely on additional identity information, such as demographic details or a predefined set of preference categories. To this end, we introduce SynthesizeMe, an approach to inducing synthetic user personas from user interactions for personalized reward modeling. SynthesizeMe first generates and verifies reasoning to explain user preferences, then induces synthetic user personas from that reasoning, and finally filters to informative prior user interactions in order to build personalized prompts for a particular user. We show that using SynthesizeMe induced prompts improves personalized LLM-as-a-judge accuracy by 4.4% on Chatbot Arena. Combining SynthesizeMe derived prompts with a reward model achieves top performance on PersonalRewardBench: a new curation of user-stratified interactions with chatbots collected from 854 users of Chatbot Arena and PRISM.",
    "authors": [
      "Michael J Ryan, Omar Shaikh, Aditri Bhagirath, Daniel Frees, William Held, Diyi Yang"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.835392"
  },
  {
    "id": "oai:arXiv.org:2506.05599v1",
    "journal": "arXiv_CS",
    "title": "UniRes: Universal Image Restoration for Complex Degradations",
    "link": "https://arxiv.org/abs/2506.05599",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05599v1 Announce Type: new \nAbstract: Real-world image restoration is hampered by diverse degradations stemming from varying capture conditions, capture devices and post-processing pipelines. Existing works make improvements through simulating those degradations and leveraging image generative priors, however generalization to in-the-wild data remains an unresolved problem. In this paper, we focus on complex degradations, i.e., arbitrary mixtures of multiple types of known degradations, which is frequently seen in the wild. A simple yet flexible diffusionbased framework, named UniRes, is proposed to address such degradations in an end-to-end manner. It combines several specialized models during the diffusion sampling steps, hence transferring the knowledge from several well-isolated restoration tasks to the restoration of complex in-the-wild degradations. This only requires well-isolated training data for several degradation types. The framework is flexible as extensions can be added through a unified formulation, and the fidelity-quality trade-off can be adjusted through a new paradigm. Our proposed method is evaluated on both complex-degradation and single-degradation image restoration datasets. Extensive qualitative and quantitative experimental results show consistent performance gain especially for images with complex degradations.",
    "authors": [
      "Mo Zhou, Keren Ye, Mauricio Delbracio, Peyman Milanfar, Vishal M. Patel, Hossein Talebi"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.835401"
  },
  {
    "id": "oai:arXiv.org:2506.05601v1",
    "journal": "arXiv_CS",
    "title": "Network Hexagons Under Attack: Secure Crowdsourcing of Geo-Referenced Data",
    "link": "https://arxiv.org/abs/2506.05601",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05601v1 Announce Type: new \nAbstract: A critical requirement for modern-day Intelligent Transportation Systems (ITS) is the ability to collect geo-referenced data from connected vehicles and mobile devices in a safe, secure and anonymous way. The Nexagon protocol, which builds on the IETF Locator/ID Separation Protocol (LISP) and the Hierarchical Hexagonal Clustering (H3) geo-spatial indexing system, offers a promising framework for dynamic, privacy-preserving data aggregation. Seeking to address the critical security and privacy vulnerabilities that persist in its current specification, we apply the STRIDE and LINDDUN threat modelling frameworks and prove among other that the Nexagon protocol is susceptible to user re-identification, session linkage, and sparse-region attacks. To address these challenges, we propose an enhanced security architecture that combines public key infrastructure (PKI) with ephemeral pseudonym certificates. Our solution guarantees user and device anonymity through randomized key rotation and adaptive geospatial resolution, thereby effectively mitigating re-identification and surveillance risks in sparse environments. A prototype implementation over a microservice-based overlay network validates the approach and underscores its readiness for real-world deployment. Our results show that it is possible to achieve the required level of security without increasing latency by more than 25% or reducing the throughput by more than 7%.",
    "authors": [
      "Okemawo Obadofin, Joao Barros"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.835410"
  },
  {
    "id": "oai:arXiv.org:2506.05605v1",
    "journal": "arXiv_CS",
    "title": "Scenarios in Computing Research: A Systematic Review of the Use of Scenario Methods for Exploring the Future of Computing Technologies in Society",
    "link": "https://arxiv.org/abs/2506.05605",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05605v1 Announce Type: new \nAbstract: Scenario building is an established method to anticipate the future of emerging technologies. Its primary goal is to use narratives to map future trajectories of technology development and sociotechnical adoption. Following this process, risks and benefits can be identified early on, and strategies can be developed that strive for desirable futures. In recent years, computer science has adopted this method and applied it to various technologies, including Artificial Intelligence (AI). Because computing technologies play such an important role in shaping modern societies, it is worth exploring how scenarios are being used as an anticipatory tool in the field -- and what possible traditional uses of scenarios are not yet covered but have the potential to enrich the field. We address this gap by conducting a systematic literature review on the use of scenario building methods in computer science over the last decade (n = 59). We guide the review along two main questions. First, we aim to uncover how scenarios are used in computing literature, focusing especially on the rationale for why scenarios are used. Second, in following the potential of scenario building to enhance inclusivity in research, we dive deeper into the participatory element of the existing scenario building literature in computer science.",
    "authors": [
      "Julia Barnett, Kimon Kieslich, Jasmine Sinchai, Nicholas Diakopoulos"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.835427"
  },
  {
    "id": "oai:arXiv.org:2506.05606v1",
    "journal": "arXiv_CS",
    "title": "OPeRA: A Dataset of Observation, Persona, Rationale, and Action for Evaluating LLMs on Human Online Shopping Behavior Simulation",
    "link": "https://arxiv.org/abs/2506.05606",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05606v1 Announce Type: new \nAbstract: Can large language models (LLMs) accurately simulate the next web action of a specific user? While LLMs have shown promising capabilities in generating ``believable'' human behaviors, evaluating their ability to mimic real user behaviors remains an open challenge, largely due to the lack of high-quality, publicly available datasets that capture both the observable actions and the internal reasoning of an actual human user. To address this gap, we introduce OPERA, a novel dataset of Observation, Persona, Rationale, and Action collected from real human participants during online shopping sessions. OPERA is the first public dataset that comprehensively captures: user personas, browser observations, fine-grained web actions, and self-reported just-in-time rationales. We developed both an online questionnaire and a custom browser plugin to gather this dataset with high fidelity. Using OPERA, we establish the first benchmark to evaluate how well current LLMs can predict a specific user's next action and rationale with a given persona and  history. This dataset lays the groundwork for future research into LLM agents that aim to act as personalized digital twins for human.",
    "authors": [
      "Ziyi Wang, Yuxuan Lu, Wenbo Li, Amirali Amini, Bo Sun, Yakov Bart, Weimin Lyu, Jiri Gesi, Tian Wang, Jing Huang, Yu Su, Upol Ehsan, Malihe Alikhani, Toby Jia-Jun Li, Lydia Chilton, Dakuo Wang"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.835436"
  },
  {
    "id": "oai:arXiv.org:2506.05607v1",
    "journal": "arXiv_CS",
    "title": "Controlled Data Rebalancing in Multi-Task Learning for Real-World Image Super-Resolution",
    "link": "https://arxiv.org/abs/2506.05607",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05607v1 Announce Type: new \nAbstract: Real-world image super-resolution (Real-SR) is a challenging problem due to the complex degradation patterns in low-resolution images. Unlike approaches that assume a broadly encompassing degradation space, we focus specifically on achieving an optimal balance in how SR networks handle different degradation patterns within a fixed degradation space. We propose an improved paradigm that frames Real-SR as a data-heterogeneous multi-task learning problem, our work addresses task imbalance in the paradigm through coordinated advancements in task definition, imbalance quantification, and adaptive data rebalancing. Specifically, we introduce a novel task definition framework that segments the degradation space by setting parameter-specific boundaries for degradation operators, effectively reducing the task quantity while maintaining task discrimination. We then develop a focal loss based multi-task weighting mechanism that precisely quantifies task imbalance dynamics during model training. Furthermore, to prevent sporadic outlier samples from dominating the gradient optimization of the shared multi-task SR model, we strategically convert the quantified task imbalance into controlled data rebalancing through deliberate regulation of task-specific training volumes. Extensive quantitative and qualitative experiments demonstrate that our method achieves consistent superiority across all degradation tasks.",
    "authors": [
      "Shuchen Lin, Mingtao Feng, Weisheng Dong, Fangfang Wu, Jianqiao Luo, Yaonan Wang, Guangming Shi"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.835445"
  },
  {
    "id": "oai:arXiv.org:2506.05610v1",
    "journal": "arXiv_CS",
    "title": "Mitigating Confounding in Speech-Based Dementia Detection through Weight Masking",
    "link": "https://arxiv.org/abs/2506.05610",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05610v1 Announce Type: new \nAbstract: Deep transformer models have been used to detect linguistic anomalies in patient transcripts for early Alzheimer's disease (AD) screening. While pre-trained neural language models (LMs) fine-tuned on AD transcripts perform well, little research has explored the effects of the gender of the speakers represented by these transcripts. This work addresses gender confounding in dementia detection and proposes two methods: the $\\textit{Extended Confounding Filter}$ and the $\\textit{Dual Filter}$, which isolate and ablate weights associated with gender. We evaluate these methods on dementia datasets with first-person narratives from patients with cognitive impairment and healthy controls. Our results show transformer models tend to overfit to training data distributions. Disrupting gender-related weights results in a deconfounded dementia classifier, with the trade-off of slightly reduced dementia detection performance.",
    "authors": [
      "Zhecheng Sheng, Xiruo Ding, Brian Hur, Changye Li, Trevor Cohen, Serguei Pakhomov"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.835454"
  },
  {
    "id": "oai:arXiv.org:2506.05611v1",
    "journal": "arXiv_CS",
    "title": "Breaking Anonymity at Scale: Re-identifying the Trajectories of 100K Real Users in Japan",
    "link": "https://arxiv.org/abs/2506.05611",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05611v1 Announce Type: new \nAbstract: Mobility traces represent a critical class of personal data, often subjected to privacy-preserving transformations before public release. In this study, we analyze the anonymized Yjmob100k dataset, which captures the trajectories of 100,000 users in Japan, and demonstrate how existing anonymization techniques fail to protect their sensitive attributes. We leverage population density patterns, structural correlations, and temporal activity profiles to re-identify the dataset's real-world location and timing. Our results reveal that the anonymization process carried out for Yjmob100k is inefficient and preserves enough spatial and temporal structure to enable re-identification. This work underscores the limitations of current trajectory anonymization methods and calls for more robust privacy mechanisms in the publication of mobility data.",
    "authors": [
      "Abhishek Kumar Mishra, Mathieu Cunche, Heber H. Arcolezi"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.835463"
  },
  {
    "id": "oai:arXiv.org:2506.05613v1",
    "journal": "arXiv_CS",
    "title": "Beating the Logarithmic Barrier for the Subadditive Maximin Share Problem",
    "link": "https://arxiv.org/abs/2506.05613",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05613v1 Announce Type: new \nAbstract: We study the problem of fair allocation of indivisible goods for subadditive agents. While constant-\\textsf{MMS} bounds have been given for additive and fractionally subadditive agents, the best existential bound for the case of subadditive agents is $1/O(\\log n \\log \\log n)$. In this work, we improve this bound to a $1/O((\\log \\log n)^2)$-\\textsf{MMS} guarantee. To this end, we introduce new matching techniques and rounding methods for subadditive valuations that we believe are of independent interest and will find their applications in future work.",
    "authors": [
      "Masoud Seddighin, Saeed Seddighin"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.835471"
  },
  {
    "id": "oai:arXiv.org:2506.05614v1",
    "journal": "arXiv_CS",
    "title": "Which Prompting Technique Should I Use? An Empirical Investigation of Prompting Techniques for Software Engineering Tasks",
    "link": "https://arxiv.org/abs/2506.05614",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05614v1 Announce Type: new \nAbstract: A growing variety of prompt engineering techniques has been proposed for Large Language Models (LLMs), yet systematic evaluation of each technique on individual software engineering (SE) tasks remains underexplored. In this study, we present a systematic evaluation of 14 established prompt techniques across 10 SE tasks using four LLM models. As identified in the prior literature, the selected prompting techniques span six core dimensions (Zero-Shot, Few-Shot, Thought Generation, Ensembling, Self-Criticism, and Decomposition). They are evaluated on tasks such as code generation, bug fixing, and code-oriented question answering, to name a few. Our results show which prompting techniques are most effective for SE tasks requiring complex logic and intensive reasoning versus those that rely more on contextual understanding and example-driven scenarios. We also analyze correlations between the linguistic characteristics of prompts and the factors that contribute to the effectiveness of prompting techniques in enhancing performance on SE tasks. Additionally, we report the time and token consumption for each prompting technique when applied to a specific task and model, offering guidance for practitioners in selecting the optimal prompting technique for their use cases.",
    "authors": [
      "E. G. Santana Jr, Gabriel Benjamin, Melissa Araujo, Harrison Santos, David Freitas, Eduardo Almeida, Paulo Anselmo da M. S. Neto, Jiawei Li, Jina Chun, Iftekhar Ahmed"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.835481"
  },
  {
    "id": "oai:arXiv.org:2506.05615v1",
    "journal": "arXiv_CS",
    "title": "When Maximum Entropy Misleads Policy Optimization",
    "link": "https://arxiv.org/abs/2506.05615",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05615v1 Announce Type: new \nAbstract: The Maximum Entropy Reinforcement Learning (MaxEnt RL) framework is a leading approach for achieving efficient learning and robust performance across many RL tasks. However, MaxEnt methods have also been shown to struggle with performance-critical control problems in practice, where non-MaxEnt algorithms can successfully learn. In this work, we analyze how the trade-off between robustness and optimality affects the performance of MaxEnt algorithms in complex control tasks: while entropy maximization enhances exploration and robustness, it can also mislead policy optimization, leading to failure in tasks that require precise, low-entropy policies. Through experiments on a variety of control problems, we concretely demonstrate this misleading effect. Our analysis leads to better understanding of how to balance reward design and entropy maximization in challenging control problems.",
    "authors": [
      "Ruipeng Zhang, Ya-Chien Chang, Sicun Gao"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.835489"
  },
  {
    "id": "oai:arXiv.org:2506.05616v1",
    "journal": "arXiv_CS",
    "title": "Toward Greater Autonomy in Materials Discovery Agents: Unifying Planning, Physics, and Scientists",
    "link": "https://arxiv.org/abs/2506.05616",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05616v1 Announce Type: new \nAbstract: We aim at designing language agents with greater autonomy for crystal materials discovery. While most of existing studies restrict the agents to perform specific tasks within predefined workflows, we aim to automate workflow planning given high-level goals and scientist intuition. To this end, we propose Materials Agent unifying Planning, Physics, and Scientists, known as MAPPS. MAPPS consists of a Workflow Planner, a Tool Code Generator, and a Scientific Mediator. The Workflow Planner uses large language models (LLMs) to generate structured and multi-step workflows. The Tool Code Generator synthesizes executable Python code for various tasks, including invoking a force field foundation model that encodes physics. The Scientific Mediator coordinates communications, facilitates scientist feedback, and ensures robustness through error reflection and recovery. By unifying planning, physics, and scientists, MAPPS enables flexible and reliable materials discovery with greater autonomy, achieving a five-fold improvement in stability, uniqueness, and novelty rates compared with prior generative models when evaluated on the MP-20 data. We provide extensive experiments across diverse tasks to show that MAPPS is a promising framework for autonomous materials discovery.",
    "authors": [
      "Lianhao Zhou, Hongyi Ling, Keqiang Yan, Kaiji Zhao, Xiaoning Qian, Raymundo Arr\\'oyave, Xiaofeng Qian, Shuiwang Ji"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.835498"
  },
  {
    "id": "oai:arXiv.org:2506.05617v1",
    "journal": "arXiv_CS",
    "title": "LFA applied to CNNs: Efficient Singular Value Decomposition of Convolutional Mappings by Local Fourier Analysis",
    "link": "https://arxiv.org/abs/2506.05617",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05617v1 Announce Type: new \nAbstract: The singular values of convolutional mappings encode interesting spectral properties, which can be used, e.g., to improve generalization and robustness of convolutional neural networks as well as to facilitate model compression. However, the computation of singular values is typically very resource-intensive. The naive approach involves unrolling the convolutional mapping along the input and channel dimensions into a large and sparse two-dimensional matrix, making the exact calculation of all singular values infeasible due to hardware limitations. In particular, this is true for matrices that represent convolutional mappings with large inputs and a high number of channels. Existing efficient methods leverage the Fast Fourier transformation (FFT) to transform convolutional mappings into the frequency domain, enabling the computation of singular values for matrices representing convolutions with larger input and channel dimensions. For a constant number of channels in a given convolution, an FFT can compute N singular values in O(N log N) complexity. In this work, we propose an approach of complexity O(N) based on local Fourier analysis, which additionally exploits the shift invariance of convolutional operators. We provide a theoretical analysis of our algorithm's runtime and validate its efficiency through numerical experiments. Our results demonstrate that our proposed method is scalable and offers a practical solution to calculate the entire set of singular values - along with the corresponding singular vectors if needed - for high-dimensional convolutional mappings.",
    "authors": [
      "Antonia van Betteray, Matthias Rottmann, Karsten Kahl"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.835508"
  },
  {
    "id": "oai:arXiv.org:2506.05619v1",
    "journal": "arXiv_CS",
    "title": "Population-Proportional Preference Learning from Human Feedback: An Axiomatic Approach",
    "link": "https://arxiv.org/abs/2506.05619",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05619v1 Announce Type: new \nAbstract: Conventional preference learning methods often prioritize opinions held more widely when aggregating preferences from multiple evaluators. This may result in policies that are biased in favor of some types of opinions or groups. The objective of this paper is to develop a novel preference learning framework capable of aligning aggregate opinions and policies proportionally with the true population distribution of evaluator preferences. Our approach infers the feasible set of evaluator population distributions directly from pairwise comparison data. Using these estimates, the algorithm constructs a policy that satisfies foundational axioms from social choice theory, namely monotonicity and Pareto efficiency, as well as our newly-introduced axioms of population-proportional representation and population-bounded robustness. We propose a soft-max relaxation method that smoothly trade-offs population-proportional representation with the selection of the Condorcet winner (which beats all other options in pairwise comparisons). Finally, we validate the effectiveness and scalability of our approach through experiments on both tabular recommendation tasks and large-scale language model alignment.",
    "authors": [
      "Kihyun Kim, Jiawei Zhang, Asuman Ozdaglar, Pablo A. Parrilo"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.835517"
  },
  {
    "id": "oai:arXiv.org:2506.05623v1",
    "journal": "arXiv_CS",
    "title": "Deployability-Centric Infrastructure-as-Code Generation: An LLM-based Iterative Framework",
    "link": "https://arxiv.org/abs/2506.05623",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05623v1 Announce Type: new \nAbstract: Infrastructure-as-Code (IaC) generation holds significant promise for automating cloud infrastructure provisioning. Recent advances in Large Language Models (LLMs) present a promising opportunity to democratize IaC development by generating deployable infrastructure templates from natural language descriptions, but current evaluation focuses on syntactic correctness while ignoring deployability, the fatal measure of IaC template utility. We address this gap through two contributions: (1) IaCGen, an LLM-based deployability-centric framework that uses iterative feedback mechanism to generate IaC templates, and (2) DPIaC-Eval, a deployability-centric IaC template benchmark consists of 153 real-world scenarios that can evaluate syntax, deployment, user intent, and security. Our evaluation reveals that state-of-the-art LLMs initially performed poorly, with Claude-3.5 and Claude-3.7 achieving only 30.2% and 26.8% deployment success on the first attempt respectively. However, IaCGen transforms this performance dramatically: all evaluated models reach over 90% passItr@25, with Claude-3.5 and Claude-3.7 achieving 98% success rate. Despite these improvements, critical challenges remain in user intent alignment (25.2% accuracy) and security compliance (8.4% pass rate), highlighting areas requiring continued research. Our work provides the first comprehensive assessment of deployability-centric IaC template generation and establishes a foundation for future research.",
    "authors": [
      "Tianyi Zhang, Shidong Pan, Zejun Zhang, Zhenchang Xing, Xiaoyu Sun"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.835526"
  },
  {
    "id": "oai:arXiv.org:2506.05625v1",
    "journal": "arXiv_CS",
    "title": "Heterogeneous Sequel-Aware Graph Neural Networks for Sequential Learning",
    "link": "https://arxiv.org/abs/2506.05625",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05625v1 Announce Type: new \nAbstract: Graph-based recommendation systems use higher-order user and item embeddings for next-item predictions. Dynamically adding collaborative signals from neighbors helps to use similar users' preferences during learning. While item-item correlations and their impact on recommendations have been studied, the efficacy of temporal item sequences for recommendations is much less explored. In this paper, we examine temporal item sequence (sequel-aware) embeddings along with higher-order user embeddings and show that sequel-aware Graph Neural Networks have better (or comparable) recommendation performance than graph-based recommendation systems that do not consider sequel information. Extensive empirical results comparing Heterogeneous Sequel-aware Graph Neural Networks (HSAL-GNNs) to other algorithms for sequential learning (such as transformers, graph neural networks, auto-encoders) are presented on three synthetic and three real-world datasets. Our results indicate that the incorporation of sequence information from items greatly enhances recommendations.",
    "authors": [
      "Anushka Tiwari, Haimonti Dutta, Shahrzad Khanizadeh"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.835535"
  },
  {
    "id": "oai:arXiv.org:2506.05626v1",
    "journal": "arXiv_CS",
    "title": "Two-dimensional Taxonomy for N-ary Knowledge Representation Learning Methods",
    "link": "https://arxiv.org/abs/2506.05626",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05626v1 Announce Type: new \nAbstract: Real-world knowledge can take various forms, including structured, semi-structured, and unstructured data. Among these, knowledge graphs are a form of structured human knowledge that integrate heterogeneous data sources into structured representations but typically reduce complex n-ary relations to simple triples, thereby losing higher-order relational details. In contrast, hypergraphs naturally represent n-ary relations with hyperedges, which directly connect multiple entities together. Yet hypergraph representation learning often overlooks entity roles in hyperedges, limiting the fine-grained semantic modelling. To address these issues, knowledge hypergraphs and hyper-relational knowledge graphs combine the advantages of knowledge graphs and hypergraphs to better capture the complex structures and role-specific semantics of real-world knowledge. This survey provides a comprehensive review of methods handling n-ary relational data, covering both knowledge hypergraphs and hyper-relational knowledge graphs literatures. We propose a two-dimensional taxonomy: the first dimension categorises models based on their methodology, i.e., translation-based models, tensor factorisation-based models, deep neural network-based models, logic rules-based models, and hyperedge expansion-based models. The second dimension classifies models according to their awareness of entity roles and positions in n-ary relations, dividing them into aware-less, position-aware, and role-aware approaches. Finally, we discuss existing datasets, negative sampling strategies, and outline open challenges to inspire future research.",
    "authors": [
      "Xiaohua Lu, Liubov Tupikina, Mehwish Alam"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.835544"
  },
  {
    "id": "oai:arXiv.org:2506.05628v1",
    "journal": "arXiv_CS",
    "title": "GP-MoLFormer-Sim: Test Time Molecular Optimization through Contextual Similarity Guidance",
    "link": "https://arxiv.org/abs/2506.05628",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05628v1 Announce Type: new \nAbstract: The ability to design molecules while preserving similarity to a target molecule and/or property is crucial for various applications in drug discovery, chemical design, and biology. We introduce in this paper an efficient training-free method for navigating and sampling from the molecular space with a generative Chemical Language Model (CLM), while using the molecular similarity to the target as a guide. Our method leverages the contextual representations learned from the CLM itself to estimate the molecular similarity, which is then used to adjust the autoregressive sampling strategy of the CLM. At each step of the decoding process, the method tracks the distance of the current generations from the target and updates the logits to encourage the preservation of similarity in generations. We implement the method using a recently proposed $\\sim$47M parameter SMILES-based CLM, GP-MoLFormer, and therefore refer to the method as GP-MoLFormer-Sim, which enables a test-time update of the deep generative policy to reflect the contextual similarity to a set of guide molecules. The method is further integrated into a genetic algorithm (GA) and tested on a set of standard molecular optimization benchmarks involving property optimization, molecular rediscovery, and structure-based drug design. Results show that, GP-MoLFormer-Sim, combined with GA (GP-MoLFormer-Sim+GA) outperforms existing training-free baseline methods, when the oracle remains black-box. The findings in this work are a step forward in understanding and guiding the generative mechanisms of CLMs.",
    "authors": [
      "Jiri Navratil, Jarret Ross, Payel Das, Youssef Mroueh, Samuel C Hoffman, Vijil Chenthamarakshan, Brian Belgodere"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.835553"
  },
  {
    "id": "oai:arXiv.org:2506.05629v1",
    "journal": "arXiv_CS",
    "title": "Leveraging Self-Attention for Input-Dependent Soft Prompting in LLMs",
    "link": "https://arxiv.org/abs/2506.05629",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05629v1 Announce Type: new \nAbstract: The performance of large language models in domain-specific tasks necessitates fine-tuning, which is computationally expensive and technically challenging. This paper focuses on parameter-efficient fine-tuning using soft prompting, a promising approach that adapts pre-trained models to downstream tasks by learning a small set of parameters. We propose a novel Input Dependent Soft Prompting technique with a self-Attention Mechanism (ID-SPAM) that generates soft prompts based on the input tokens and attends different tokens with varying importance. Our method is simple and efficient, keeping the number of trainable parameters small. We show the merits of the proposed approach compared to state-of-the-art techniques on various tasks and show the improved zero shot domain transfer capability.",
    "authors": [
      "Ananth Muppidi, Abhilash Nandy, Sambaran Bandyopadhyay"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.835561"
  },
  {
    "id": "oai:arXiv.org:2506.05632v1",
    "journal": "arXiv_CS",
    "title": "List-Level Distribution Coupling with Applications to Speculative Decoding and Lossy Compression",
    "link": "https://arxiv.org/abs/2506.05632",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05632v1 Announce Type: new \nAbstract: We study a relaxation of the problem of coupling probability distributions -- a list of samples is generated from one distribution and an accept is declared if any one of these samples is identical to the sample generated from the other distribution. We propose a novel method for generating samples, which extends the Gumbel-max sampling suggested in Daliri et al. (arXiv:2408.07978) for coupling probability distributions. We also establish a corresponding lower bound on the acceptance probability, which we call the list matching lemma. We next discuss two applications of our setup. First, we develop a new mechanism for multi-draft speculative sampling that is simple to implement and achieves performance competitive with baselines such as SpecTr and SpecInfer across a range of language tasks. Our method also guarantees a certain degree of drafter invariance with respect to the output tokens which is not supported by existing schemes. We also provide a theoretical lower bound on the token level acceptance probability. As our second application, we consider distributed lossy compression with side information in a setting where a source sample is compressed and available to multiple decoders, each with independent side information. We propose a compression technique that is based on our generalization of Gumbel-max sampling and show that it provides significant gains in experiments involving synthetic Gaussian sources and the MNIST image dataset.",
    "authors": [
      "Joseph Rowan, Buu Phan, Ashish Khisti"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.835570"
  },
  {
    "id": "oai:arXiv.org:2506.05634v1",
    "journal": "arXiv_CS",
    "title": "AutoQD: Automatic Discovery of Diverse Behaviors with Quality-Diversity Optimization",
    "link": "https://arxiv.org/abs/2506.05634",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05634v1 Announce Type: new \nAbstract: Quality-Diversity (QD) algorithms have shown remarkable success in discovering diverse, high-performing solutions, but rely heavily on hand-crafted behavioral descriptors that constrain exploration to predefined notions of diversity. Leveraging the equivalence between policies and occupancy measures, we present a theoretically grounded approach to automatically generate behavioral descriptors by embedding the occupancy measures of policies in Markov Decision Processes. Our method, AutoQD, leverages random Fourier features to approximate the Maximum Mean Discrepancy (MMD) between policy occupancy measures, creating embeddings whose distances reflect meaningful behavioral differences. A low-dimensional projection of these embeddings that captures the most behaviorally significant dimensions is then used as behavioral descriptors for off-the-shelf QD methods. We prove that our embeddings converge to true MMD distances between occupancy measures as the number of sampled trajectories and embedding dimensions increase. Through experiments in multiple continuous control tasks we demonstrate AutoQD's ability in discovering diverse policies without predefined behavioral descriptors, presenting a well-motivated alternative to prior methods in unsupervised Reinforcement Learning and QD optimization. Our approach opens new possibilities for open-ended learning and automated behavior discovery in sequential decision making settings without requiring domain-specific knowledge.",
    "authors": [
      "Saeed Hedayatian, Stefanos Nikolaidis"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.835580"
  },
  {
    "id": "oai:arXiv.org:2506.05635v1",
    "journal": "arXiv_CS",
    "title": "IYKYK: Using language models to decode extremist cryptolects",
    "link": "https://arxiv.org/abs/2506.05635",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05635v1 Announce Type: new \nAbstract: Extremist groups develop complex in-group language, also referred to as cryptolects, to exclude or mislead outsiders. We investigate the ability of current language technologies to detect and interpret the cryptolects of two online extremist platforms. Evaluating eight models across six tasks, our results indicate that general purpose LLMs cannot consistently detect or decode extremist language. However, performance can be significantly improved by domain adaptation and specialised prompting techniques. These results provide important insights to inform the development and deployment of automated moderation technologies. We further develop and release novel labelled and unlabelled datasets, including 19.4M posts from extremist platforms and lexicons validated by human experts.",
    "authors": [
      "Christine de Kock, Arij Riabi, Zeerak Talat, Michael Sejr Schlichtkrull, Pranava Madhyastha, Ed Hovy"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.835588"
  },
  {
    "id": "oai:arXiv.org:2506.05636v1",
    "journal": "arXiv_CS",
    "title": "Bayesian Inference for Correlated Human Experts and Classifiers",
    "link": "https://arxiv.org/abs/2506.05636",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05636v1 Announce Type: new \nAbstract: Applications of machine learning often involve making predictions based on both model outputs and the opinions of human experts. In this context, we investigate the problem of querying experts for class label predictions, using as few human queries as possible, and leveraging the class probability estimates of pre-trained classifiers. We develop a general Bayesian framework for this problem, modeling expert correlation via a joint latent representation, enabling simulation-based inference about the utility of additional expert queries, as well as inference of posterior distributions over unobserved expert labels. We apply our approach to two real-world medical classification problems, as well as to CIFAR-10H and ImageNet-16H, demonstrating substantial reductions relative to baselines in the cost of querying human experts while maintaining high prediction accuracy.",
    "authors": [
      "Markelle Kelly, Alex Boyd, Sam Showalter, Mark Steyvers, Padhraic Smyth"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.835597"
  },
  {
    "id": "oai:arXiv.org:2506.05637v1",
    "journal": "arXiv_CS",
    "title": "Joint User Association and Beamforming Design for ISAC Networks with Large Language Models",
    "link": "https://arxiv.org/abs/2506.05637",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05637v1 Announce Type: new \nAbstract: Integrated sensing and communication (ISAC) has been envisioned to play a more important role in future wireless networks. However, the design of ISAC networks is challenging, especially when there are multiple communication and sensing (C\\&amp;S) nodes and multiple sensing targets. We investigate a multi-base station (BS) ISAC network in which multiple BSs equipped with multiple antennas simultaneously provide C\\&amp;S services for multiple ground communication users (CUs) and targets. To enhance the overall performance of C\\&amp;S, we formulate a joint user association (UA) and multi-BS transmit beamforming optimization problem with the objective of maximizing the total sum rate of all CUs while ensuring both the minimum target detection and parameter estimation requirements. To efficiently solve the highly non-convex mixed integer nonlinear programming (MINLP) optimization problem, we propose an alternating optimization (AO)-based algorithm that decomposes the problem into two sub-problems, i.e., UA optimization and multi-BS transmit beamforming optimization. Inspired by large language models (LLMs) for prediction and inference, we propose a unified framework integrating LLMs with convex-based optimization methods. First, we propose a comprehensive design of prompt engineering, including few-shot, chain of thought, and self-reflection techniques to guide LLMs in solving the binary integer programming UA optimization problem. Second, we utilize convex-based optimization methods to handle the non-convex beamforming optimization problem based on fractional programming (FP), majorization minimization (MM), and the alternating direction method of multipliers (ADMM) with an optimized UA from LLMs. Numerical results demonstrate that our proposed LLM-enabled AO-based algorithm achieves fast convergence and near upper-bound performance with the GPT-o1 model, outperforming various benchmark schemes.",
    "authors": [
      "Haoyun Li, Ming Xiao, Kezhi Wang, Robert Schober, Dong In Kim, Yong Liang Guan"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.835606"
  },
  {
    "id": "oai:arXiv.org:2506.05638v1",
    "journal": "arXiv_CS",
    "title": "Smallest Suffixient Sets as a Repetitiveness Measure",
    "link": "https://arxiv.org/abs/2506.05638",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05638v1 Announce Type: new \nAbstract: Suffixient sets are a novel combinatorial object that capture the essential information of repetitive strings in a way that, provided with a random-access mechanism, supports various forms of pattern matching. In this paper we study the size $\\chi$ of the smallest suffixient set as a repetitiveness measure: we place it between known measures and study its sensitivity to various string operations.",
    "authors": [
      "Gonzalo Navarro, Giuseppe Romana, Cristian Urbina"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.835614"
  },
  {
    "id": "oai:arXiv.org:2506.05639v1",
    "journal": "arXiv_CS",
    "title": "A Fictional Q&A Dataset for Studying Memorization and Knowledge Acquisition",
    "link": "https://arxiv.org/abs/2506.05639",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05639v1 Announce Type: new \nAbstract: When language models are trained on textual data, they acquire both knowledge about the structure of language as well as knowledge of facts about the world. At inference time, their knowledge of facts can be leveraged to solve interesting problems and perform useful knowledge work for users. It is well known that language models can verbatim memorize long sequences from their training data. However, it is much less well understood how language models memorize facts seen during training. In this work, we propose a new dataset to specifically empower researchers to study the dual processes of fact memorization and verbatim sequence memorization. The dataset consists of synthetically-generated, webtext-like documents about fictional events, as well as question-answer pairs about the events. We conduct training experiments showing how synthetic data about fictional events can be effective in teasing apart different forms of memorization. We also document the challenges in effectively building realistic, fictional synthetic data.",
    "authors": [
      "John Kirchenbauer, Janny Mongkolsupawan, Yuxin Wen, Tom Goldstein, Daphne Ippolito"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.835623"
  },
  {
    "id": "oai:arXiv.org:2506.05640v1",
    "journal": "arXiv_CS",
    "title": "FedShield-LLM: A Secure and Scalable Federated Fine-Tuned Large Language Model",
    "link": "https://arxiv.org/abs/2506.05640",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05640v1 Announce Type: new \nAbstract: Federated Learning (FL) offers a decentralized framework for training and fine-tuning Large Language Models (LLMs) by leveraging computational resources across organizations while keeping sensitive data on local devices. It addresses privacy and security concerns while navigating challenges associated with the substantial computational demands of LLMs, which can be prohibitive for small and medium-sized organizations. FL supports the development of task-specific LLMs for cross-silo applications through fine-tuning but remains vulnerable to inference attacks, such as membership inference and gradient inversion, which threaten data privacy. Prior studies have utilized Differential Privacy (DP) in LLM fine-tuning, which, despite being effective at preserving privacy, can degrade model performance. To overcome these challenges, we propose a novel method, FedShield-LLM, that uses pruning with Fully Homomorphic Encryption (FHE) for Low-Rank Adaptation (LoRA) parameters, enabling secure computations on encrypted model updates while mitigating the attack surface by deactivating less important LoRA parameters. Furthermore, optimized federated algorithms for cross-silo environments enhance scalability and efficiency. Parameter-efficient fine-tuning techniques like LoRA substantially reduce computational and communication overhead, making FL feasible for resource-constrained clients. Experimental results show that the proposed method outperforms existing methods while maintaining robust privacy protection, enabling organizations to collaboratively train secure and efficient LLMs.\n  The code and data are available at, https://github.com/solidlabnetwork/fedshield-llm",
    "authors": [
      "Md Jueal Mia, M. Hadi Amini"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.835632"
  },
  {
    "id": "oai:arXiv.org:2506.05641v1",
    "journal": "arXiv_CS",
    "title": "Projectable Models: One-Shot Generation of Small Specialized Transformers from Large Ones",
    "link": "https://arxiv.org/abs/2506.05641",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05641v1 Announce Type: new \nAbstract: Modern Foundation Models (FMs) are typically trained on corpora spanning a wide range of different data modalities, topics and downstream tasks. Utilizing these models can be very computationally expensive and is out of reach for most consumer devices. Furthermore, most of the broad FM knowledge may actually be irrelevant for a specific task at hand. Here we explore a technique for mapping parameters of a large Transformer to parameters of a smaller specialized model. By making this transformation task-specific, we aim to capture a narrower scope of the knowledge needed for performing a specific task by a smaller model. We study our method on image modeling tasks, showing that performance of generated models exceeds that of universal conditional models.",
    "authors": [
      "Andrey Zhmoginov, Jihwan Lee, Mark Sandler"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.835640"
  },
  {
    "id": "oai:arXiv.org:2506.05647v1",
    "journal": "arXiv_CS",
    "title": "Learning to Weight Parameters for Data Attribution",
    "link": "https://arxiv.org/abs/2506.05647",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05647v1 Announce Type: new \nAbstract: We study data attribution in generative models, aiming to identify which training examples most influence a given output. Existing methods achieve this by tracing gradients back to training data. However, they typically treat all network parameters uniformly, ignoring the fact that different layers encode different types of information and may thus draw information differently from the training set. We propose a method that models this by learning parameter importance weights tailored for attribution, without requiring labeled data. This allows the attribution process to adapt to the structure of the model, capturing which training examples contribute to specific semantic aspects of an output, such as subject, style, or background. Our method improves attribution accuracy across diffusion models and enables fine-grained insights into how outputs borrow from training data.",
    "authors": [
      "Shuangqi Li, Hieu Le, Jingyi Xu, Mathieu Salzmann"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.835648"
  },
  {
    "id": "oai:arXiv.org:2506.05648v1",
    "journal": "arXiv_CS",
    "title": "A Modular Haptic Display with Reconfigurable Signals for Personalized Information Transfer",
    "link": "https://arxiv.org/abs/2506.05648",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05648v1 Announce Type: new \nAbstract: We present a customizable soft haptic system that integrates modular hardware with an information-theoretic algorithm to personalize feedback for different users and tasks. Our platform features modular, multi-degree-of-freedom pneumatic displays, where different signal types, such as pressure, frequency, and contact area, can be activated or combined using fluidic logic circuits. These circuits simplify control by reducing reliance on specialized electronics and enabling coordinated actuation of multiple haptic elements through a compact set of inputs. Our approach allows rapid reconfiguration of haptic signal rendering through hardware-level logic switching without rewriting code. Personalization of the haptic interface is achieved through the combination of modular hardware and software-driven signal selection. To determine which display configurations will be most effective, we model haptic communication as a signal transmission problem, where an agent must convey latent information to the user. We formulate the optimization problem to identify the haptic hardware setup that maximizes the information transfer between the intended message and the user's interpretation, accounting for individual differences in sensitivity, preferences, and perceptual salience. We evaluate this framework through user studies where participants interact with reconfigurable displays under different signal combinations. Our findings support the role of modularity and personalization in creating multimodal haptic interfaces and advance the development of reconfigurable systems that adapt with users in dynamic human-machine interaction contexts.",
    "authors": [
      "Antonio Alvarez Valdivia, Benjamin A. Christie, Dylan P. Losey, Laura H. Blumenschein"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.835657"
  },
  {
    "id": "oai:arXiv.org:2506.05651v1",
    "journal": "arXiv_CS",
    "title": "Hallucinate, Ground, Repeat: A Framework for Generalized Visual Relationship Detection",
    "link": "https://arxiv.org/abs/2506.05651",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05651v1 Announce Type: new \nAbstract: Understanding relationships between objects is central to visual intelligence, with applications in embodied AI, assistive systems, and scene understanding. Yet, most visual relationship detection (VRD) models rely on a fixed predicate set, limiting their generalization to novel interactions. A key challenge is the inability to visually ground semantically plausible, but unannotated, relationships hypothesized from external knowledge. This work introduces an iterative visual grounding framework that leverages large language models (LLMs) as structured relational priors. Inspired by expectation-maximization (EM), our method alternates between generating candidate scene graphs from detected objects using an LLM (expectation) and training a visual model to align these hypotheses with perceptual evidence (maximization). This process bootstraps relational understanding beyond annotated data and enables generalization to unseen predicates. Additionally, we introduce a new benchmark for open-world VRD on Visual Genome with 21 held-out predicates and evaluate under three settings: seen, unseen, and mixed. Our model outperforms LLM-only, few-shot, and debiased baselines, achieving mean recall (mR@50) of 15.9, 13.1, and 11.7 on predicate classification on these three sets. These results highlight the promise of grounded LLM priors for scalable open-world visual understanding.",
    "authors": [
      "Shanmukha Vellamcheti, Sanjoy Kundu, Sathyanarayanan N. Aakur"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.835666"
  },
  {
    "id": "oai:arXiv.org:2506.05653v1",
    "journal": "arXiv_CS",
    "title": "Towards Autonomous In-situ Soil Sampling and Mapping in Large-Scale Agricultural Environments",
    "link": "https://arxiv.org/abs/2506.05653",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05653v1 Announce Type: new \nAbstract: Traditional soil sampling and analysis methods are labor-intensive, time-consuming, and limited in spatial resolution, making them unsuitable for large-scale precision agriculture. To address these limitations, we present a robotic solution for real-time sampling, analysis and mapping of key soil properties. Our system consists of two main sub-systems: a Sample Acquisition System (SAS) for precise, automated in-field soil sampling; and a Sample Analysis Lab (Lab) for real-time soil property analysis. The system's performance was validated through extensive field trials at a large-scale Australian farm. Experimental results show that the SAS can consistently acquire soil samples with a mass of 50g at a depth of 200mm, while the Lab can process each sample within 10 minutes to accurately measure pH and macronutrients. These results demonstrate the potential of the system to provide farmers with timely, data-driven insights for more efficient and sustainable soil management and fertilizer application.",
    "authors": [
      "Thien Hoang Nguyen, Erik Muller, Michael Rubin, Xiaofei Wang, Fiorella Sibona, Salah Sukkarieh"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.835675"
  },
  {
    "id": "oai:arXiv.org:2506.05655v1",
    "journal": "arXiv_CS",
    "title": "Aerial Multi-View Stereo via Adaptive Depth Range Inference and Normal Cues",
    "link": "https://arxiv.org/abs/2506.05655",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05655v1 Announce Type: new \nAbstract: Three-dimensional digital urban reconstruction from multi-view aerial images is a critical application where deep multi-view stereo (MVS) methods outperform traditional techniques. However, existing methods commonly overlook the key differences between aerial and close-range settings, such as varying depth ranges along epipolar lines and insensitive feature-matching associated with low-detailed aerial images. To address these issues, we propose an Adaptive Depth Range MVS (ADR-MVS), which integrates monocular geometric cues to improve multi-view depth estimation accuracy. The key component of ADR-MVS is the depth range predictor, which generates adaptive range maps from depth and normal estimates using cross-attention discrepancy learning. In the first stage, the range map derived from monocular cues breaks through predefined depth boundaries, improving feature-matching discriminability and mitigating convergence to local optima. In later stages, the inferred range maps are progressively narrowed, ultimately aligning with the cascaded MVS framework for precise depth regression. Moreover, a normal-guided cost aggregation operation is specially devised for aerial stereo images to improve geometric awareness within the cost volume. Finally, we introduce a normal-guided depth refinement module that surpasses existing RGB-guided techniques. Experimental results demonstrate that ADR-MVS achieves state-of-the-art performance on the WHU, LuoJia-MVS, and M\\\"unchen datasets, while exhibits superior computational complexity.",
    "authors": [
      "Yimei Liu, Yakun Ju, Yuan Rao, Hao Fan, Junyu Dong, Feng Gao, Qian Du"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.835683"
  },
  {
    "id": "oai:arXiv.org:2506.05660v1",
    "journal": "arXiv_CS",
    "title": "TissUnet: Improved Extracranial Tissue and Cranium Segmentation for Children through Adulthood",
    "link": "https://arxiv.org/abs/2506.05660",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05660v1 Announce Type: new \nAbstract: Extracranial tissues visible on brain magnetic resonance imaging (MRI) may hold significant value for characterizing health conditions and clinical decision-making, yet they are rarely quantified. Current tools have not been widely validated, particularly in settings of developing brains or underlying pathology. We present TissUnet, a deep learning model that segments skull bone, subcutaneous fat, and muscle from routine three-dimensional T1-weighted MRI, with or without contrast enhancement. The model was trained on 155 paired MRI-computed tomography (CT) scans and validated across nine datasets covering a wide age range and including individuals with brain tumors. In comparison to AI-CT-derived labels from 37 MRI-CT pairs, TissUnet achieved a median Dice coefficient of 0.79 [IQR: 0.77-0.81] in a healthy adult cohort. In a second validation using expert manual annotations, median Dice was 0.83 [IQR: 0.83-0.84] in healthy individuals and 0.81 [IQR: 0.78-0.83] in tumor cases, outperforming previous state-of-the-art method. Acceptability testing resulted in an 89% acceptance rate after adjudication by a tie-breaker(N=108 MRIs), and TissUnet demonstrated excellent performance in the blinded comparative review (N=45 MRIs), including both healthy and tumor cases in pediatric populations. TissUnet enables fast, accurate, and reproducible segmentation of extracranial tissues, supporting large-scale studies on craniofacial morphology, treatment effects, and cardiometabolic risk using standard brain T1w MRI.",
    "authors": [
      "Markian Mandzak, Elvira Yang, Anna Zapaishchykova, Yu-Hui Chen, Lucas Heilbroner, John Zielke, Divyanshu Tak, Reza Mojahed-Yazdi, Francesca Romana Mussa, Zezhong Ye, Sridhar Vajapeyam, Viviana Benitez, Ralph Salloum, Susan N. Chi, Houman Sotoudeh, Jakob Seidlitz, Sabine Mueller, Hugo J. W. L. Aerts, Tina Y. Poussaint, Benjamin H. Kann"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.835692"
  },
  {
    "id": "oai:arXiv.org:2506.05664v1",
    "journal": "arXiv_CS",
    "title": "BAQ: Efficient Bit Allocation Quantization for Large Language Models",
    "link": "https://arxiv.org/abs/2506.05664",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05664v1 Announce Type: new \nAbstract: Post-training model quantization is a widely adopted technique for reducing the memory and computational costs of large language models (LLMs). However, most existing methods rely on uniform or heuristic bitwidth assignments, failing to account for the nonuniform sensitivity of weights to quantization noise. In this paper, we propose a novel framework for allocating quantization bitwidths based on sensitivity metrics derived from a Hessian proxy. We make key assumptions, which allow the layer/component-wise loss function to be expressed as an explicit function of the bitwidths. This enables a neat formulation of the bit allocation problem as a convex optimization task, whose closed-form solution adapts precision across weights to minimize the layer-wise quantization loss. Inspecting the solution provides several insights (such as the equal-loss structure), which are then exploited to design the proposed \\textbf{BAQ} (Bit Allocation Quantization) algorithm. The proposed algorithm achieves a good trade-off between loss minimization and complexity and allows BAQ to be integrated into standard quantization pipelines with minimal overhead. Experimental results show that BAQ consistently outperforms GPTQ, achieving up to 56$\\times$ lower perplexity at the same bitwidth on large language models ranging from 125M to 30B parameters. Leveraging our analytical results derived from solving the optimal bit allocation problem, we also provide a theoretical explanation for the observed gains. All codes of this paper are available at https://github.com/CSU-ModelCompression/BAQ.",
    "authors": [
      "Chao Zhang, Li Wang, Samson Lasaulce, Merouane Debbah"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.835709"
  },
  {
    "id": "oai:arXiv.org:2506.05667v1",
    "journal": "arXiv_CS",
    "title": "DriveAction: A Benchmark for Exploring Human-like Driving Decisions in VLA Models",
    "link": "https://arxiv.org/abs/2506.05667",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05667v1 Announce Type: new \nAbstract: Vision-Language-Action (VLA) models have advanced autonomous driving, but existing benchmarks still lack scenario diversity, reliable action-level annotation, and evaluation protocols aligned with human preferences. To address these limitations, we introduce DriveAction, the first action-driven benchmark specifically designed for VLA models, comprising 16,185 QA pairs generated from 2,610 driving scenarios. DriveAction leverages real-world driving data proactively collected by users of production-level autonomous vehicles to ensure broad and representative scenario coverage, offers high-level discrete action labels collected directly from users' actual driving operations, and implements an action-rooted tree-structured evaluation framework that explicitly links vision, language, and action tasks, supporting both comprehensive and task-specific assessment. Our experiments demonstrate that state-of-the-art vision-language models (VLMs) require both vision and language guidance for accurate action prediction: on average, accuracy drops by 3.3% without vision input, by 4.1% without language input, and by 8.0% without either. Our evaluation supports precise identification of model bottlenecks with robust and consistent results, thus providing new insights and a rigorous foundation for advancing human-like decisions in autonomous driving.",
    "authors": [
      "Yuhan Hao, Zhengning Li, Lei Sun, Weilong Wang, Naixin Yi, Sheng Song, Caihong Qin, Mofan Zhou, Yifei Zhan, Peng Jia, Xianpeng Lang"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.835718"
  },
  {
    "id": "oai:arXiv.org:2506.05668v1",
    "journal": "arXiv_CS",
    "title": "RNE: a plug-and-play framework for diffusion density estimation and inference-time control",
    "link": "https://arxiv.org/abs/2506.05668",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05668v1 Announce Type: new \nAbstract: In this paper, we introduce the Radon-Nikodym Estimator (RNE), a flexible, plug-and-play framework for diffusion inference-time density estimation and control, based on the concept of the density ratio between path distributions. RNE connects and unifies a variety of existing density estimation and inference-time control methods under a single and intuitive perspective, stemming from basic variational inference and probabilistic principles therefore offering both theoretical clarity and practical versatility. Experiments demonstrate that RNE achieves promising performances in diffusion density estimation and inference-time control tasks, including annealing, composition of diffusion models, and reward-tilting.",
    "authors": [
      "Jiajun He, Jos\\'e Miguel Hern\\'andez-Lobato, Yuanqi Du, Francisco Vargas"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.835727"
  },
  {
    "id": "oai:arXiv.org:2506.05672v1",
    "journal": "arXiv_CS",
    "title": "Contextually Guided Transformers via Low-Rank Adaptation",
    "link": "https://arxiv.org/abs/2506.05672",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05672v1 Announce Type: new \nAbstract: Large Language Models (LLMs) based on Transformers excel at text processing, but their reliance on prompts for specialized behavior introduces computational overhead. We propose a modification to a Transformer architecture that eliminates the need for explicit prompts by learning to encode context into the model's weights. Our Contextually Guided Transformer (CGT) model maintains a contextual summary at each sequence position, allowing it to update the weights on the fly based on the preceding context. This approach enables the model to self-specialize, effectively creating a tailored model for processing information following a given prefix. We demonstrate the effectiveness of our method on synthetic in-context learning tasks and language modeling benchmarks. Furthermore, we introduce techniques for enhancing the interpretability of the learned contextual representations, drawing connections to Variational Autoencoders and promoting smoother, more consistent context encoding. This work offers a novel direction for efficient and adaptable language modeling by integrating context directly into the model's architecture.",
    "authors": [
      "Andrey Zhmoginov, Jihwan Lee, Max Vladymyrov, Mark Sandler"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.835743"
  },
  {
    "id": "oai:arXiv.org:2506.05673v1",
    "journal": "arXiv_CS",
    "title": "Peer-Ranked Precision: Creating a Foundational Dataset for Fine-Tuning Vision Models from DataSeeds' Annotated Imagery",
    "link": "https://arxiv.org/abs/2506.05673",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05673v1 Announce Type: new \nAbstract: The development of modern Artificial Intelligence (AI) models, particularly diffusion-based models employed in computer vision and image generation tasks, is undergoing a paradigmatic shift in development methodologies. Traditionally dominated by a \"Model Centric\" approach, in which performance gains were primarily pursued through increasingly complex model architectures and hyperparameter optimization, the field is now recognizing a more nuanced \"Data-Centric\" approach. This emergent framework foregrounds the quality, structure, and relevance of training data as the principal driver of model performance. To operationalize this paradigm shift, we introduce the DataSeeds.AI sample dataset (the \"DSD\"), initially comprised of approximately 10,610 high-quality human peer-ranked photography images accompanied by extensive multi-tier annotations. The DSD is a foundational computer vision dataset designed to usher in a new standard for commercial image datasets. Representing a small fraction of DataSeed.AI's 100 million-plus image catalog, the DSD provides a scalable foundation necessary for robust commercial and multimodal AI development. Through this in-depth exploratory analysis, we document the quantitative improvements generated by the DSD on specific models against known benchmarks and make the code and the trained models used in our evaluation publicly available.",
    "authors": [
      "Sajjad Abdoli, Freeman Lewin, Gediminas Vasiliauskas, Fabian Schonholz"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.835752"
  },
  {
    "id": "oai:arXiv.org:2506.05675v1",
    "journal": "arXiv_CS",
    "title": "Zero-Shot Event Causality Identification via Multi-source Evidence Fuzzy Aggregation with Large Language Models",
    "link": "https://arxiv.org/abs/2506.05675",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05675v1 Announce Type: new \nAbstract: Event Causality Identification (ECI) aims to detect causal relationships between events in textual contexts. Existing ECI models predominantly rely on supervised methodologies, suffering from dependence on large-scale annotated data. Although Large Language Models (LLMs) enable zero-shot ECI, they are prone to causal hallucination-erroneously establishing spurious causal links. To address these challenges, we propose MEFA, a novel zero-shot framework based on Multi-source Evidence Fuzzy Aggregation. First, we decompose causality reasoning into three main tasks (temporality determination, necessity analysis, and sufficiency verification) complemented by three auxiliary tasks. Second, leveraging meticulously designed prompts, we guide LLMs to generate uncertain responses and deterministic outputs. Finally, we quantify LLM's responses of sub-tasks and employ fuzzy aggregation to integrate these evidence for causality scoring and causality determination. Extensive experiments on three benchmarks demonstrate that MEFA outperforms second-best unsupervised baselines by 6.2% in F1-score and 9.3% in precision, while significantly reducing hallucination-induced errors. In-depth analysis verify the effectiveness of task decomposition and the superiority of fuzzy aggregation.",
    "authors": [
      "Zefan Zeng, Xingchen Hu, Qing Cheng, Weiping Ding, Wentao Li, Zhong Liu"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.835761"
  },
  {
    "id": "oai:arXiv.org:2506.05676v1",
    "journal": "arXiv_CS",
    "title": "Topology-aware Neural Flux Prediction Guided by Physics",
    "link": "https://arxiv.org/abs/2506.05676",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05676v1 Announce Type: new \nAbstract: Graph Neural Networks (GNNs) often struggle in preserving high-frequency components of nodal signals when dealing with directed graphs. Such components are crucial for modeling flow dynamics, without which a traditional GNN tends to treat a graph with forward and reverse topologies equal.To make GNNs sensitive to those high-frequency components thereby being capable to capture detailed topological differences, this paper proposes a novel framework that combines 1) explicit difference matrices that model directional gradients and 2) implicit physical constraints that enforce messages passing within GNNs to be consistent with natural laws. Evaluations on two real-world directed graph data, namely, water flux network and urban traffic flow network, demonstrate the effectiveness of our proposal.",
    "authors": [
      "Haoyang Jiang, Jindong Wang, Xingquan Zhu, Yi He"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.835770"
  },
  {
    "id": "oai:arXiv.org:2506.05678v1",
    "journal": "arXiv_CS",
    "title": "Numerical Investigation of Sequence Modeling Theory using Controllable Memory Functions",
    "link": "https://arxiv.org/abs/2506.05678",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05678v1 Announce Type: new \nAbstract: The evolution of sequence modeling architectures, from recurrent neural networks and convolutional models to Transformers and structured state-space models, reflects ongoing efforts to address the diverse temporal dependencies inherent in sequential data. Despite this progress, systematically characterizing the strengths and limitations of these architectures remains a fundamental challenge.In this work, we propose a synthetic benchmarking framework to evaluate how effectively different sequence models capture distinct temporal structures. The core of this approach is to generate synthetic targets, each characterized by a memory function and a parameter that determines the strength of temporal dependence. This setup allows us to produce a continuum of tasks that vary in temporal complexity, enabling fine-grained analysis of model behavior concerning specific memory properties. We focus on four representative memory functions, each corresponding to a distinct class of temporal structures.Experiments on several sequence modeling architectures confirm existing theoretical insights and reveal new findings.These results demonstrate the effectiveness of the proposed method in advancing theoretical understandingand highlight the importance of using controllable targets with clearly defined structures for evaluating sequence modeling architectures.",
    "authors": [
      "Haotian Jiang, Zeyu Bao, Shida Wang, Qianxiao Li"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.835779"
  },
  {
    "id": "oai:arXiv.org:2506.05679v1",
    "journal": "arXiv_CS",
    "title": "Integer Binary-Range Alignment Neuron for Spiking Neural Networks",
    "link": "https://arxiv.org/abs/2506.05679",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05679v1 Announce Type: new \nAbstract: Spiking Neural Networks (SNNs) are noted for their brain-like computation and energy efficiency, but their performance lags behind Artificial Neural Networks (ANNs) in tasks like image classification and object detection due to the limited representational capacity. To address this, we propose a novel spiking neuron, Integer Binary-Range Alignment Leaky Integrate-and-Fire to exponentially expand the information expression capacity of spiking neurons with only a slight energy increase. This is achieved through Integer Binary Leaky Integrate-and-Fire and range alignment strategy. The Integer Binary Leaky Integrate-and-Fire allows integer value activation during training and maintains spike-driven dynamics with binary conversion expands virtual timesteps during inference. The range alignment strategy is designed to solve the spike activation limitation problem where neurons fail to activate high integer values. Experiments show our method outperforms previous SNNs, achieving 74.19% accuracy on ImageNet and 66.2% mAP@50 and 49.1% mAP@50:95 on COCO, surpassing previous bests with the same architecture by +3.45% and +1.6% and +1.8%, respectively. Notably, our SNNs match or exceed ANNs' performance with the same architecture, and the energy efficiency is improved by 6.3${\\times}$.",
    "authors": [
      "Binghao Ye, Wenjuan Li, Dong Wang, Man Yao, Bing Li, Weiming Hu, Dong Liang, Kun Shang"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.835787"
  },
  {
    "id": "oai:arXiv.org:2506.05680v1",
    "journal": "arXiv_CS",
    "title": "Learning Design-Score Manifold to Guide Diffusion Models for Offline Optimization",
    "link": "https://arxiv.org/abs/2506.05680",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05680v1 Announce Type: new \nAbstract: Optimizing complex systems, from discovering therapeutic drugs to designing high-performance materials, remains a fundamental challenge across science and engineering, as the underlying rules are often unknown and costly to evaluate. Offline optimization aims to optimize designs for target scores using pre-collected datasets without system interaction. However, conventional approaches may fail beyond training data, predicting inaccurate scores and generating inferior designs. This paper introduces ManGO, a diffusion-based framework that learns the design-score manifold, capturing the design-score interdependencies holistically. Unlike existing methods that treat design and score spaces in isolation, ManGO unifies forward prediction and backward generation, attaining generalization beyond training data. Key to this is its derivative-free guidance for conditional generation, coupled with adaptive inference-time scaling that dynamically optimizes denoising paths. Extensive evaluations demonstrate that ManGO outperforms 24 single- and 10 multi-objective optimization methods across diverse domains, including synthetic tasks, robot control, material design, DNA sequence, and real-world engineering optimization.",
    "authors": [
      "Tailin Zhou, Zhilin Chen, Wenlong Lyu, Zhitang Chen, Danny H. K. Tsang, Jun Zhang"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.835796"
  },
  {
    "id": "oai:arXiv.org:2506.05682v1",
    "journal": "arXiv_CS",
    "title": "Lumina: Real-Time Mobile Neural Rendering by Exploiting Computational Redundancy",
    "link": "https://arxiv.org/abs/2506.05682",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05682v1 Announce Type: new \nAbstract: 3D Gaussian Splatting (3DGS) has vastly advanced the pace of neural rendering, but it remains computationally demanding on today's mobile SoCs. To address this challenge, we propose Lumina, a hardware-algorithm co-designed system, which integrates two principal optimizations: a novel algorithm, S^2, and a radiance caching mechanism, RC, to improve the efficiency of neural rendering. S2 algorithm exploits temporal coherence in rendering to reduce the computational overhead, while RC leverages the color integration process of 3DGS to decrease the frequency of intensive rasterization computations. Coupled with these techniques, we propose an accelerator architecture, LuminCore, to further accelerate cache lookup and address the fundamental inefficiencies in Rasterization. We show that Lumina achieves 4.5x speedup and 5.3x energy reduction against a mobile Volta GPU, with a marginal quality loss (< 0.2 dB peak signal-to-noise ratio reduction) across synthetic and real-world datasets.",
    "authors": [
      "Yu Feng, Weikai Lin, Yuge Cheng, Zihan Liu, Jingwen Leng, Minyi Guo, Chen Chen, Shixuan Sun, Yuhao Zhu"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.835805"
  },
  {
    "id": "oai:arXiv.org:2506.05683v1",
    "journal": "arXiv_CS",
    "title": "Multi-Modal Multi-Task Federated Foundation Models for Next-Generation Extended Reality Systems: Towards Privacy-Preserving Distributed Intelligence in AR/VR/MR",
    "link": "https://arxiv.org/abs/2506.05683",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05683v1 Announce Type: new \nAbstract: Extended reality (XR) systems, which consist of virtual reality (VR), augmented reality (AR), and mixed reality (XR), offer a transformative interface for immersive, multi-modal, and embodied human-computer interaction. In this paper, we envision that multi-modal multi-task (M3T) federated foundation models (FedFMs) can offer transformative capabilities for XR systems through integrating the representational strength of M3T foundation models (FMs) with the privacy-preserving model training principles of federated learning (FL). We present a modular architecture for FedFMs, which entails different coordination paradigms for model training and aggregations. Central to our vision is the codification of XR challenges that affect the implementation of FedFMs under the SHIFT dimensions: (1) Sensor and modality diversity, (2) Hardware heterogeneity and system-level constraints, (3) Interactivity and embodied personalization, (4) Functional/task variability, and (5) Temporality and environmental variability. We illustrate the manifestation of these dimensions across a set of emerging and anticipated applications of XR systems. Finally, we propose evaluation metrics, dataset requirements, and design tradeoffs necessary for the development of resource-aware FedFMs in XR. This perspective aims to chart the technical and conceptual foundations for context-aware privacy-preserving intelligence in the next generation of XR systems.",
    "authors": [
      "Fardis Nadimi, Payam Abdisarabshali, Kasra Borazjani, Jacob Chakareski, Seyyedali Hosseinalipour"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.835815"
  },
  {
    "id": "oai:arXiv.org:2506.05685v1",
    "journal": "arXiv_CS",
    "title": "NGA: Non-autoregressive Generative Auction with Global Externalities for Advertising Systems",
    "link": "https://arxiv.org/abs/2506.05685",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05685v1 Announce Type: new \nAbstract: Online advertising auctions are fundamental to internet commerce, demanding solutions that not only maximize revenue but also ensure incentive compatibility, high-quality user experience, and real-time efficiency. While recent learning-based auction frameworks have improved context modeling by capturing intra-list dependencies among ads, they remain limited in addressing global externalities and often suffer from inefficiencies caused by sequential processing. In this work, we introduce the Non-autoregressive Generative Auction with global externalities (NGA), a novel end-to-end framework designed for industrial online advertising. NGA explicitly models global externalities by jointly capturing the relationships among ads as well as the effects of adjacent organic content. To further enhance efficiency, NGA utilizes a non-autoregressive, constraint-based decoding strategy and a parallel multi-tower evaluator for unified list-wise reward and payment computation. Extensive offline experiments and large-scale online A/B testing on commercial advertising platforms demonstrate that NGA consistently outperforms existing methods in both effectiveness and efficiency.",
    "authors": [
      "Zuowu Zheng, Ze Wang, Fan Yang, Wenqing Ye, Weihua Huang, Wenqiang He, Teng Zhang, Xingxing Wang"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.835825"
  },
  {
    "id": "oai:arXiv.org:2506.05686v1",
    "journal": "arXiv_CS",
    "title": "A Unified Representation for Continuity and Discontinuity: Syntactic and Computational Motivations",
    "link": "https://arxiv.org/abs/2506.05686",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05686v1 Announce Type: new \nAbstract: This paper advances a unified representation of linguistic structure for three grammar formalisms, namely, Phrase Structure Grammar (PSG), Dependency Grammar (DG) and Categorial Grammar (CG) from the perspective of syntactic and computational complexity considerations. The correspondence principle is proposed to enable a unified representation of the representational principles from PSG, DG, and CG. To that end, the paper first illustrates a series of steps in achieving a unified representation for a discontinuous subordinate clause from Turkish as an illustrative case. This affords a new way of approaching discontinuity in natural language from a theoretical point of view that unites and integrates the basic tenets of PSG, DG, and CG, with significant consequences for syntactic analysis. Then this paper demonstrates that a unified representation can simplify computational complexity with regards to the neurocognitive representation and processing of both continuous and discontinuous sentences vis-\\`a-vis the basic principles of PSG, DG, and CG.",
    "authors": [
      "Ratna Kandala, Prakash Mondal"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.835834"
  },
  {
    "id": "oai:arXiv.org:2506.05688v1",
    "journal": "arXiv_CS",
    "title": "Voice Impression Control in Zero-Shot TTS",
    "link": "https://arxiv.org/abs/2506.05688",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05688v1 Announce Type: new \nAbstract: Para-/non-linguistic information in speech is pivotal in shaping the listeners' impression. Although zero-shot text-to-speech (TTS) has achieved high speaker fidelity, modulating subtle para-/non-linguistic information to control perceived voice characteristics, i.e., impressions, remains challenging. We have therefore developed a voice impression control method in zero-shot TTS that utilizes a low-dimensional vector to represent the intensities of various voice impression pairs (e.g., dark-bright). The results of both objective and subjective evaluations have demonstrated our method's effectiveness in impression control. Furthermore, generating this vector via a large language model enables target-impression generation from a natural language description of the desired impression, thus eliminating the need for manual optimization.",
    "authors": [
      "Keinichi Fujita, Shota Horiguchi, Yusuke Ijima"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.835850"
  },
  {
    "id": "oai:arXiv.org:2506.05689v1",
    "journal": "arXiv_CS",
    "title": "Pts3D-LLM: Studying the Impact of Token Structure for 3D Scene Understanding With Large Language Models",
    "link": "https://arxiv.org/abs/2506.05689",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05689v1 Announce Type: new \nAbstract: Effectively representing 3D scenes for Multimodal Large Language Models (MLLMs) is crucial yet challenging. Existing approaches commonly only rely on 2D image features and use varied tokenization approaches. This work presents a rigorous study of 3D token structures, systematically comparing video-based and point-based representations while maintaining consistent model backbones and parameters. We propose a novel approach that enriches visual tokens by incorporating 3D point cloud features from a Sonata pretrained Point Transformer V3 encoder. Our experiments demonstrate that merging explicit 3D features significantly boosts performance. Furthermore, we show that point-based token structures can rival video-based ones when the points are cleverly sampled and ordered. Our best models from both structures achieve state-of-the-art results on multiple 3D understanding benchmarks. We emphasize our analysis of token structures as a key contribution, alongside transparent reporting of results averaged over multiple seeds, a practice we believe is vital for robust progress in the field.",
    "authors": [
      "Hugues Thomas, Chen Chen, Jian Zhang"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.835859"
  },
  {
    "id": "oai:arXiv.org:2506.05690v1",
    "journal": "arXiv_CS",
    "title": "When to use Graphs in RAG: A Comprehensive Analysis for Graph Retrieval-Augmented Generation",
    "link": "https://arxiv.org/abs/2506.05690",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05690v1 Announce Type: new \nAbstract: Graph retrieval-augmented generation (GraphRAG) has emerged as a powerful paradigm for enhancing large language models (LLMs) with external knowledge. It leverages graphs to model the hierarchical structure between specific concepts, enabling more coherent and effective knowledge retrieval for accurate reasoning.Despite its conceptual promise, recent studies report that GraphRAG frequently underperforms vanilla RAG on many real-world tasks. This raises a critical question: Is GraphRAG really effective, and in which scenarios do graph structures provide measurable benefits for RAG systems? To address this, we propose GraphRAG-Bench, a comprehensive benchmark designed to evaluate GraphRAG models onboth hierarchical knowledge retrieval and deep contextual reasoning. GraphRAG-Bench features a comprehensive dataset with tasks of increasing difficulty, coveringfact retrieval, complex reasoning, contextual summarization, and creative generation, and a systematic evaluation across the entire pipeline, from graph constructionand knowledge retrieval to final generation. Leveraging this novel benchmark, we systematically investigate the conditions when GraphRAG surpasses traditional RAG and the underlying reasons for its success, offering guidelines for its practical application. All related resources and analyses are collected for the community at https://github.com/GraphRAG-Bench/GraphRAG-Benchmark.",
    "authors": [
      "Zhishang Xiang, Chuanjie Wu, Qinggang Zhang, Shengyuan Chen, Zijin Hong, Xiao Huang, Jinsong Su"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.835868"
  },
  {
    "id": "oai:arXiv.org:2506.05692v1",
    "journal": "arXiv_CS",
    "title": "SafeGenBench: A Benchmark Framework for Security Vulnerability Detection in LLM-Generated Code",
    "link": "https://arxiv.org/abs/2506.05692",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05692v1 Announce Type: new \nAbstract: The code generation capabilities of large language models(LLMs) have emerged as a critical dimension in evaluating their overall performance. However, prior research has largely overlooked the security risks inherent in the generated code. In this work, we introduce \\benchmark, a benchmark specifically designed to assess the security of LLM-generated code. The dataset encompasses a wide range of common software development scenarios and vulnerability types. Building upon this benchmark, we develop an automatic evaluation framework that leverages both static application security testing(SAST) and LLM-based judging to assess the presence of security vulnerabilities in model-generated code. Through the empirical evaluation of state-of-the-art LLMs on \\benchmark, we reveal notable deficiencies in their ability to produce vulnerability-free code. Our findings highlight pressing challenges and offer actionable insights for future advancements in the secure code generation performance of LLMs. The data and code will be released soon.",
    "authors": [
      "Xinghang Li, Jingzhe Ding, Chao Peng, Bing Zhao, Xiang Gao, Hongwan Gao, Xinchen Gu"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.835877"
  },
  {
    "id": "oai:arXiv.org:2506.05693v1",
    "journal": "arXiv_CS",
    "title": "Resilient Auto-Scaling of Microservice Architectures with Efficient Resource Management",
    "link": "https://arxiv.org/abs/2506.05693",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05693v1 Announce Type: new \nAbstract: Horizontal Pod Auto-scalers (HPAs) are crucial for managing resource allocation in microservice architectures to handle fluctuating workloads. However, traditional HPAs fail to address resource disruptions caused by faults, cyberattacks, maintenance, and other operational challenges. These disruptions result in resource wastage, service unavailability, and HPA performance degradation. To address these challenges, we extend our prior work on Smart HPA and propose SecureSmart HPA, which offers resilient and resource-efficient auto-scaling for microservice architectures. SecureSmart HPA monitors microservice resource demands, detects disruptions, evaluates resource wastage, and dynamically adjusts scaling decisions to enhance the resilience of auto-scaling operations. Furthermore, SecureSmart HPA enables resource sharing among microservices, optimizing scaling efficiency in resource-constrained environments. Experimental evaluation at varying disruption severities, with 25%, 50%, and 75% resource wastage, demonstrates that SecureSmart HPA performs effectively across different levels of disruptions. It achieves up to a 57.2% reduction in CPU overutilization and a 51.1% increase in resource allocation compared to Smart HPA, highlighting its ability to deliver resilient and efficient auto-scaling operations in volatile and resource-constrained environments.",
    "authors": [
      "Hussain Ahmad, Christoph Treude, Markus Wagner, Claudia Szabo"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.835886"
  },
  {
    "id": "oai:arXiv.org:2506.05695v1",
    "journal": "arXiv_CS",
    "title": "Being Strong Progressively! Enhancing Knowledge Distillation of Large Language Models through a Curriculum Learning Framework",
    "link": "https://arxiv.org/abs/2506.05695",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05695v1 Announce Type: new \nAbstract: Knowledge Distillation (KD) compresses large language models (LLMs) by transferring the teacher model's capabilities to a smaller student model, reducing inference cost and memory usage while maintaining performance. However, existing KD methods for LLMs often fail to prevent significant shifts in the student model's distribution during training, leading to issues such as catastrophic forgetting, mode collapse, and training-inference mismatch. To address these challenges, we propose a novel, plug-in curriculum learning framework inspired by the strength training principle of \"progressive overload\" (POCL), which can be seamlessly integrated into existing white-box KD approaches with minimal computational overhead. The framework comprises two core components: (1) a difficulty measurer that ranks and partitions training samples from easy to hard, and (2) a training scheduler that incrementally introduces these subsets into the distillation process at fixed intervals while applying loss functions with progressively rising temperatures. By starting with the easiest samples and progressively increasing the difficulty, the approach enhances both the stability and efficiency of learning. Extensive experiments in instruction-following settings demonstrate that POCL consistently improves the performance of distilled student models across various white-box KD methods and model families. Our findings highlight the effectiveness of sorted training samples in KD for LLMs. More generally, our work demonstrates how to structure training data within the KD process to enhance the stability and performance of distilled LLMs.",
    "authors": [
      "Lingyuan Liu, Mengxiang Zhang"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.835895"
  },
  {
    "id": "oai:arXiv.org:2506.05696v1",
    "journal": "arXiv_CS",
    "title": "MoralCLIP: Contrastive Alignment of Vision-and-Language Representations with Moral Foundations Theory",
    "link": "https://arxiv.org/abs/2506.05696",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05696v1 Announce Type: new \nAbstract: Recent advances in vision-language models have enabled rich semantic understanding across modalities. However, these encoding methods lack the ability to interpret or reason about the moral dimensions of content-a crucial aspect of human cognition. In this paper, we address this gap by introducing MoralCLIP, a novel embedding representation method that extends multimodal learning with explicit moral grounding based on Moral Foundations Theory (MFT). Our approach integrates visual and textual moral cues into a unified embedding space, enabling cross-modal moral alignment. MoralCLIP is grounded on the multi-label dataset Social-Moral Image Database to identify co-occurring moral foundations in visual content. For MoralCLIP training, we design a moral data augmentation strategy to scale our annotated dataset to 15,000 image-text pairs labeled with MFT-aligned dimensions. Our results demonstrate that explicit moral supervision improves both unimodal and multimodal understanding of moral content, establishing a foundation for morally-aware AI systems capable of recognizing and aligning with human moral values.",
    "authors": [
      "Ana Carolina Condez, Diogo Tavares, Jo\\~ao Magalh\\~aes"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.835904"
  },
  {
    "id": "oai:arXiv.org:2506.05698v1",
    "journal": "arXiv_CS",
    "title": "Simulation Everywhere: An Evolutionary Expansion of Discrete-Event Modeling and Simulation research and practice",
    "link": "https://arxiv.org/abs/2506.05698",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05698v1 Announce Type: new \nAbstract: Simulation was launched in the 1950s, nicknamed a tool of \"last resort.\" Over the years, this Operations Research (OR) method has made significant progress, and utilizing the accelerated advances in computer science (hardware and software, processing speed, and advanced information visualization capabilities) to improve simulation usability in research and practice. After overcoming the initial obstacles and the scare of outliving its usefulness in the 2000s, computer simulation has remained a popular OR tool applied in diverse industries and sectors, earning its popularity leading to the term \"simulation everywhere.\" This study uses bibliographic data from research and practice literature to evaluate the evolutionary expansion in simulation, focusing on discrete-event simulation (DES). The results show asymmetrical but positive yearly literature out-put, broadened DES adoption in diverse fields, and sustained relevance as a scientific method for tackling old, new, and emerging issues. Also, DES is an essential tool in Industry 4.0 and plays a central role in digital transformation that has swept the industrial space, from manufacturing to healthcare and other sectors. With the emergence, ongoing adoption, and deployment of generative artificial intelligence (GenAI), future studies seek ways to integrate GenAI in DES to remain relevant and improve the modeling and simulation processes.",
    "authors": [
      "Ikpe Justice Akpan, Godwin E. Etti"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.835913"
  },
  {
    "id": "oai:arXiv.org:2506.05700v1",
    "journal": "arXiv_CS",
    "title": "RKEFino1: A Regulation Knowledge-Enhanced Large Language Model",
    "link": "https://arxiv.org/abs/2506.05700",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05700v1 Announce Type: new \nAbstract: Recent advances in large language models (LLMs) hold great promise for financial applications but introduce critical accuracy and compliance challenges in Digital Regulatory Reporting (DRR). To address these issues, we propose RKEFino1, a regulation knowledge-enhanced financial reasoning model built upon Fino1, fine-tuned with domain knowledge from XBRL, CDM, and MOF. We formulate two QA tasks-knowledge-based and mathematical reasoning-and introduce a novel Numerical NER task covering financial entities in both sentences and tables. Experimental results demonstrate the effectiveness and generalization capacity of RKEFino1 in compliance-critical financial tasks. We have released our model on Hugging Face.",
    "authors": [
      "Yan Wang, Yueru He, Ruoyu Xiang, Jeff Zhao"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.835929"
  },
  {
    "id": "oai:arXiv.org:2506.05702v1",
    "journal": "arXiv_CS",
    "title": "Action-Adaptive Continual Learning: Enabling Policy Generalization under Dynamic Action Spaces",
    "link": "https://arxiv.org/abs/2506.05702",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05702v1 Announce Type: new \nAbstract: Continual Learning (CL) is a powerful tool that enables agents to learn a sequence of tasks, accumulating knowledge learned in the past and using it for problem-solving or future task learning. However, existing CL methods often assume that the agent's capabilities remain static within dynamic environments, which doesn't reflect real-world scenarios where capabilities dynamically change. This paper introduces a new and realistic problem: Continual Learning with Dynamic Capabilities (CL-DC), posing a significant challenge for CL agents: How can policy generalization across different action spaces be achieved? Inspired by the cortical functions, we propose an Action-Adaptive Continual Learning framework (AACL) to address this challenge. Our framework decouples the agent's policy from the specific action space by building an action representation space. For a new action space, the encoder-decoder of action representations is adaptively fine-tuned to maintain a balance between stability and plasticity. Furthermore, we release a benchmark based on three environments to validate the effectiveness of methods for CL-DC. Experimental results demonstrate that our framework outperforms popular methods by generalizing the policy across action spaces.",
    "authors": [
      "Chaofan Pan, Jiafen Liu, Yanhua Li, Linbo Xiong, Fan Min, Wei Wei, Xin Yang"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.835946"
  },
  {
    "id": "oai:arXiv.org:2506.05705v1",
    "journal": "arXiv_CS",
    "title": "Multi-Project Contracts",
    "link": "https://arxiv.org/abs/2506.05705",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05705v1 Announce Type: new \nAbstract: We study a new class of contract design problems where a principal delegates the execution of multiple projects to a set of agents. The principal's expected reward from each project is a combinatorial function of the agents working on it. Each agent has limited capacity and can work on at most one project, and the agents are heterogeneous, with different costs and contributions for participating in different projects. The main challenge of the principal is to decide how to allocate the agents to projects when the number of projects grows in scale.\n  We analyze this problem under different assumptions on the structure of the expected reward functions. As our main result, for XOS functions we show how to derive a constant approximation to the optimal multi-project contract in polynomial time, given access to value and demand oracles. Along the way (and of possible independent interest), we develop approximate demand queries for \\emph{capped} subadditive functions, by reducing to demand queries for the original functions. Our work paves the way to combinatorial contract design in richer settings.",
    "authors": [
      "Tal Alon, Matteo Castiglioni, Junjie Chen, Tomer Ezra, Yingkai Li, Inbal Talgam-Cohen"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.835954"
  },
  {
    "id": "oai:arXiv.org:2506.05710v1",
    "journal": "arXiv_CS",
    "title": "Latent Diffusion Model Based Denoising Receiver for 6G Semantic Communication: From Stochastic Differential Theory to Application",
    "link": "https://arxiv.org/abs/2506.05710",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05710v1 Announce Type: new \nAbstract: In this paper, a novel semantic communication framework empowered by generative artificial intelligence (GAI) is proposed, specifically leveraging the capabilities of diffusion models (DMs). A rigorous theoretical foundation is established based on stochastic differential equations (SDEs), which elucidates the denoising properties of DMs in mitigating additive white Gaussian noise (AWGN) in latent semantic representations. Crucially, a closed-form analytical relationship between the signal-to-noise ratio (SNR) and the denoising timestep is derived, enabling the optimal selection of diffusion parameters for any given channel condition. To address the distribution mismatch between the received signal and the DM's training data, a mathematically principled scaling mechanism is introduced, ensuring robust performance across a wide range of SNRs without requiring model fine-tuning. Built upon this theoretical insight, we develop a latent diffusion model (LDM)-based semantic transceiver, wherein a variational autoencoder (VAE) is employed for efficient semantic compression, and a pretrained DM serves as a universal denoiser. Notably, the proposed architecture is fully training-free at inference time, offering high modularity and compatibility with large-scale pretrained LDMs. This design inherently supports zero-shot generalization and mitigates the challenges posed by out-of-distribution inputs. Extensive experimental evaluations demonstrate that the proposed framework significantly outperforms conventional neural-network-based semantic communication baselines, particularly under low SNR conditions and distributional shifts, thereby establishing a promising direction for GAI-driven robust semantic transmission in future 6G systems.",
    "authors": [
      "Xiucheng Wang, Honggang Jia, Nan Cheng, Dusit Niyato"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.835980"
  },
  {
    "id": "oai:arXiv.org:2506.05711v1",
    "journal": "arXiv_CS",
    "title": "A symmetric LWE-based Multi-Recipient Cryptosystem",
    "link": "https://arxiv.org/abs/2506.05711",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05711v1 Announce Type: new \nAbstract: This article describes a post-quantum multirecipient symmetric cryptosystem whose security is based on the hardness of the LWE problem. In this scheme a single sender encrypts multiple messages for multiple recipients generating a single ciphertext which is broadcast to the recipients. Each recipient decrypts the ciphertext with her secret key to recover the message intended for her. In this process, the recipient cannot efficiently extract any information about the other messages. This scheme is intended for messages like images and sound that can tolerate a small amount of noise. This article introduces the scheme and establishes its security based on the LWE problem. Further, an example is given to demonstrate the application of this scheme for encrypting multiple images.",
    "authors": [
      "Saikat Gope, Srinivasan Krishnaswamy, Chayan Bhawal"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.835987"
  },
  {
    "id": "oai:arXiv.org:2506.05713v1",
    "journal": "arXiv_CS",
    "title": "Come Together, But Not Right Now: A Progressive Strategy to Boost Low-Rank Adaptation",
    "link": "https://arxiv.org/abs/2506.05713",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05713v1 Announce Type: new \nAbstract: Low-rank adaptation (LoRA) has emerged as a leading parameter-efficient fine-tuning technique for adapting large foundation models, yet it often locks adapters into suboptimal minima near their initialization. This hampers model generalization and limits downstream operators such as adapter merging and pruning. Here, we propose CoTo, a progressive training strategy that gradually increases adapters' activation probability over the course of fine-tuning. By stochastically deactivating adapters, CoTo encourages more balanced optimization and broader exploration of the loss landscape. We provide a theoretical analysis showing that CoTo promotes layer-wise dropout stability and linear mode connectivity, and we adopt a cooperative-game approach to quantify each adapter's marginal contribution. Extensive experiments demonstrate that CoTo consistently boosts single-task performance, enhances multi-task merging accuracy, improves pruning robustness, and reduces training overhead, all while remaining compatible with diverse LoRA variants. Code is available at https://github.com/zwebzone/coto.",
    "authors": [
      "Zhan Zhuang, Xiequn Wang, Wei Li, Yulong Zhang, Qiushi Huang, Shuhao Chen, Xuehao Wang, Yanbin Wei, Yuhe Nie, Kede Ma, Yu Zhang, Ying Wei"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.835996"
  },
  {
    "id": "oai:arXiv.org:2506.05714v1",
    "journal": "arXiv_CS",
    "title": "Advancement and Field Evaluation of a Dual-arm Apple Harvesting Robot",
    "link": "https://arxiv.org/abs/2506.05714",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05714v1 Announce Type: new \nAbstract: Apples are among the most widely consumed fruits worldwide. Currently, apple harvesting fully relies on manual labor, which is costly, drudging, and hazardous to workers. Hence, robotic harvesting has attracted increasing attention in recent years. However, existing systems still fall short in terms of performance, effectiveness, and reliability for complex orchard environments. In this work, we present the development and evaluation of a dual-arm harvesting robot. The system integrates a ToF camera, two 4DOF robotic arms, a centralized vacuum system, and a post-harvest handling module. During harvesting, suction force is dynamically assigned to either arm via the vacuum system, enabling efficient apple detachment while reducing power consumption and noise. Compared to our previous design, we incorporated a platform movement mechanism that enables both in-out and up-down adjustments, enhancing the robot's dexterity and adaptability to varying canopy structures. On the algorithmic side, we developed a robust apple localization pipeline that combines a foundation-model-based detector, segmentation, and clustering-based depth estimation, which improves performance in orchards. Additionally, pressure sensors were integrated into the system, and a novel dual-arm coordination strategy was introduced to respond to harvest failures based on sensor feedback, further improving picking efficiency. Field demos were conducted in two commercial orchards in MI, USA, with different canopy structures. The system achieved success rates of 0.807 and 0.797, with an average picking cycle time of 5.97s. The proposed strategy reduced harvest time by 28% compared to a single-arm baseline. The dual-arm harvesting robot enhances the reliability and efficiency of apple picking. With further advancements, the system holds strong potential for autonomous operation and commercialization for the apple industry.",
    "authors": [
      "Keyi Zhu, Kyle Lammers, Kaixiang Zhang, Chaaran Arunachalam, Siddhartha Bhattacharya, Jiajia Li, Renfu Lu, Zhaojian Li"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.836004"
  },
  {
    "id": "oai:arXiv.org:2506.05716v1",
    "journal": "arXiv_CS",
    "title": "Ensemble Elastic DQN: A novel multi-step ensemble approach to address overestimation in deep value-based reinforcement learning",
    "link": "https://arxiv.org/abs/2506.05716",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05716v1 Announce Type: new \nAbstract: While many algorithmic extensions to Deep Q-Networks (DQN) have been proposed, there remains limited understanding of how different improvements interact. In particular, multi-step and ensemble style extensions have shown promise in reducing overestimation bias, thereby improving sample efficiency and algorithmic stability. In this paper, we introduce a novel algorithm called Ensemble Elastic Step DQN (EEDQN), which unifies ensembles with elastic step updates to stabilise algorithmic performance. EEDQN is designed to address two major challenges in deep reinforcement learning: overestimation bias and sample efficiency. We evaluated EEDQN against standard and ensemble DQN variants across the MinAtar benchmark, a set of environments that emphasise behavioral learning while reducing representational complexity. Our results show that EEDQN achieves consistently robust performance across all tested environments, outperforming baseline DQN methods and matching or exceeding state-of-the-art ensemble DQNs in final returns on most of the MinAtar environments. These findings highlight the potential of systematically combining algorithmic improvements and provide evidence that ensemble and multi-step methods, when carefully integrated, can yield substantial gains.",
    "authors": [
      "Adrian Ly, Richard Dazeley, Peter Vamplew, Francisco Cruz, Sunil Aryal"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.836014"
  },
  {
    "id": "oai:arXiv.org:2506.05718v1",
    "journal": "arXiv_CS",
    "title": "Grokking Beyond the Euclidean Norm of Model Parameters",
    "link": "https://arxiv.org/abs/2506.05718",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05718v1 Announce Type: new \nAbstract: Grokking refers to a delayed generalization following overfitting when optimizing artificial neural networks with gradient-based methods. In this work, we demonstrate that grokking can be induced by regularization, either explicit or implicit. More precisely, we show that when there exists a model with a property $P$ (e.g., sparse or low-rank weights) that generalizes on the problem of interest, gradient descent with a small but non-zero regularization of $P$ (e.g., $\\ell_1$ or nuclear norm regularization) results in grokking. This extends previous work showing that small non-zero weight decay induces grokking. Moreover, our analysis shows that over-parameterization by adding depth makes it possible to grok or ungrok without explicitly using regularization, which is impossible in shallow cases. We further show that the $\\ell_2$ norm is not a reliable proxy for generalization when the model is regularized toward a different property $P$, as the $\\ell_2$ norm grows in many cases where no weight decay is used, but the model generalizes anyway. We also show that grokking can be amplified solely through data selection, with any other hyperparameter fixed.",
    "authors": [
      "Pascal Jr Tikeng Notsawo, Guillaume Dumas, Guillaume Rabusseau"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.836022"
  },
  {
    "id": "oai:arXiv.org:2506.05719v1",
    "journal": "arXiv_CS",
    "title": "You Only Estimate Once: Unified, One-stage, Real-Time Category-level Articulated Object 6D Pose Estimation for Robotic Grasping",
    "link": "https://arxiv.org/abs/2506.05719",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05719v1 Announce Type: new \nAbstract: This paper addresses the problem of category-level pose estimation for articulated objects in robotic manipulation tasks. Recent works have shown promising results in estimating part pose and size at the category level. However, these approaches primarily follow a complex multi-stage pipeline that first segments part instances in the point cloud and then estimates the Normalized Part Coordinate Space (NPCS) representation for 6D poses. These approaches suffer from high computational costs and low performance in real-time robotic tasks. To address these limitations, we propose YOEO, a single-stage method that simultaneously outputs instance segmentation and NPCS representations in an end-to-end manner. We use a unified network to generate point-wise semantic labels and centroid offsets, allowing points from the same part instance to vote for the same centroid. We further utilize a clustering algorithm to distinguish points based on their estimated centroid distances. Finally, we first separate the NPCS region of each instance. Then, we align the separated regions with the real point cloud to recover the final pose and size. Experimental results on the GAPart dataset demonstrate the pose estimation capabilities of our proposed single-shot method. We also deploy our synthetically-trained model in a real-world setting, providing real-time visual feedback at 200Hz, enabling a physical Kinova robot to interact with unseen articulated objects. This showcases the utility and effectiveness of our proposed method.",
    "authors": [
      "Jingshun Huang, Haitao Lin, Tianyu Wang, Yanwei Fu, Yu-Gang Jiang, Xiangyang Xue"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.836032"
  },
  {
    "id": "oai:arXiv.org:2506.05720v1",
    "journal": "arXiv_CS",
    "title": "A Survey of Earable Technology: Trends, Tools, and the Road Ahead",
    "link": "https://arxiv.org/abs/2506.05720",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05720v1 Announce Type: new \nAbstract: Earable devices, wearables positioned in or around the ear, are undergoing a rapid transformation from audio-centric accessories into multifunctional systems for interaction, contextual awareness, and health monitoring. This evolution is driven by commercial trends emphasizing sensor integration and by a surge of academic interest exploring novel sensing capabilities. Building on the foundation established by earlier surveys, this work presents a timely and comprehensive review of earable research published since 2022. We analyze over one hundred recent studies to characterize this shifting research landscape, identify emerging applications and sensing modalities, and assess progress relative to prior efforts. In doing so, we address three core questions: how has earable research evolved in recent years, what enabling resources are now available, and what opportunities remain for future exploration. Through this survey, we aim to provide both a retrospective and forward-looking view of earable technology as a rapidly expanding frontier in ubiquitous computing. In particular, this review reveals that over the past three years, researchers have discovered a variety of novel sensing principles, developed many new earable sensing applications, enhanced the accuracy of existing sensing tasks, and created substantial new resources to advance research in the field. Based on this, we further discuss open challenges and propose future directions for the next phase of earable research.",
    "authors": [
      "Changshuo Hu, Qiang Yang, Yang Liu, Tobias R\\\"oddiger, Kayla-Jade Butkow, Mathias Ciliberto, Adam Luke Pullin, Jake Stuchbury-Wass, Mahbub Hassan, Cecilia Mascolo, Dong Ma"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.836040"
  },
  {
    "id": "oai:arXiv.org:2506.05721v1",
    "journal": "arXiv_CS",
    "title": "Any-Class Presence Likelihood for Robust Multi-Label Classification with Abundant Negative Data",
    "link": "https://arxiv.org/abs/2506.05721",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05721v1 Announce Type: new \nAbstract: Multi-label Classification (MLC) assigns an instance to one or more non-exclusive classes. A challenge arises when the dataset contains a large proportion of instances with no assigned class, referred to as negative data, which can overwhelm the learning process and hinder the accurate identification and classification of positive instances. Nevertheless, it is common in MLC applications such as industrial defect detection, agricultural disease identification, and healthcare diagnosis to encounter large amounts of negative data. Assigning a separate negative class to these instances further complicates the learning objective and introduces unnecessary redundancies. To address this challenge, we redesign standard MLC loss functions by deriving a likelihood of any class being present, formulated by a normalized weighted geometric mean of the predicted class probabilities. We introduce a regularization parameter that controls the relative contribution of the absent class probabilities to the any-class presence likelihood in positive instances. The any-class presence likelihood complements the multi-label learning by encouraging the network to become more aware of implicit positive instances and improve the label classification within those positive instances. Experiments on large-scale datasets with negative data: SewerML, modified COCO, and ChestX-ray14, across various networks and base loss functions show that our loss functions consistently improve MLC performance of their standard loss counterparts, achieving gains of up to 6.01 percentage points in F1, 8.06 in F2, and 3.11 in mean average precision, all without additional parameters or computational complexity. Code available at: https://github.com/ML-for-Sensor-Data-Western/gmean-mlc",
    "authors": [
      "Dumindu Tissera, Omar Awadallah, Muhammad Umair Danish, Ayan Sadhu, Katarina Grolinger"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.836050"
  },
  {
    "id": "oai:arXiv.org:2506.05725v1",
    "journal": "arXiv_CS",
    "title": "Large Language Models are Good Relational Learners",
    "link": "https://arxiv.org/abs/2506.05725",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05725v1 Announce Type: new \nAbstract: Large language models (LLMs) have demonstrated remarkable capabilities across various domains, yet their application to relational deep learning (RDL) remains underexplored. Existing approaches adapt LLMs by traversing relational links between entities in a database and converting the structured data into flat text documents. Still, this text-based serialization disregards critical relational structures, introduces redundancy, and often exceeds standard LLM context lengths. We introduce Rel-LLM, a novel architecture that utilizes a graph neural network (GNN)- based encoder to generate structured relational prompts for LLMs within a retrieval-augmented generation (RAG) framework. Unlike traditional text-based serialization approaches, our method preserves the inherent relational structure of databases while enabling LLMs to effectively process and reason over complex entity relationships. Specifically, the GNN encoder extracts a local subgraph around an entity to build feature representations that contain relevant entity relationships and temporal dependencies. These representations are transformed into structured prompts using a denormalization process, effectively allowing the LLM to reason over relational structures. Through extensive experiments, we demonstrate that Rel-LLM outperforms existing methods on key RDL tasks, offering a scalable and efficient approach to integrating LLMs with structured data sources. Code is available at https://github.com/smiles724/Rel-LLM.",
    "authors": [
      "Fang Wu, Vijay Prakash Dwivedi, Jure Leskovec"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.836058"
  },
  {
    "id": "oai:arXiv.org:2506.05728v1",
    "journal": "arXiv_CS",
    "title": "The Geometry of Extended Kalman Filters on Manifolds with Affine Connection",
    "link": "https://arxiv.org/abs/2506.05728",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05728v1 Announce Type: new \nAbstract: The extended Kalman filter (EKF) has been the industry standard for state estimation problems over the past sixty years. The classical formulation of the EKF is posed for nonlinear systems defined on global Euclidean spaces. The design methodology is regularly applied to systems on smooth manifolds by choosing local coordinates, however, it is well known that this approach is not intrinsic to the manifold and performance depends heavily on choosing 'good' coordinates. In this paper, we propose an extended Kalman filter that is adapted to the specific geometry of the manifold in question. We show that an affine connection and the concepts of parallel transport, torsion, and curvature are the key geometric structures that allow the formulation of a suitable family of intrinsic Gaussian-like distributions and provide the tools to understand how to propagate state estimates and fuse measurements. This leads us to propose novel geometric modifications to the propagation and update steps of the EKF and revisit recent work on the geometry of the reset step. The relative performance of the proposed geometric modifications are benchmarked against classical EKF and iterated EKF algorithms on a simplified inertial navigation system with direct pose measurements and no bias.",
    "authors": [
      "Yixiao Ge, Pieter van Goor, Robert Mahony"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.836067"
  },
  {
    "id": "oai:arXiv.org:2506.05735v1",
    "journal": "arXiv_CS",
    "title": "Do LLMs Really Forget? Evaluating Unlearning with Knowledge Correlation and Confidence Awareness",
    "link": "https://arxiv.org/abs/2506.05735",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05735v1 Announce Type: new \nAbstract: Machine unlearning techniques aim to mitigate unintended memorization in large language models (LLMs). However, existing approaches predominantly focus on the explicit removal of isolated facts, often overlooking latent inferential dependencies and the non-deterministic nature of knowledge within LLMs. Consequently, facts presumed forgotten may persist implicitly through correlated information. To address these challenges, we propose a knowledge unlearning evaluation framework that more accurately captures the implicit structure of real-world knowledge by representing relevant factual contexts as knowledge graphs with associated confidence scores. We further develop an inference-based evaluation protocol leveraging powerful LLMs as judges; these judges reason over the extracted knowledge subgraph to determine unlearning success. Our LLM judges utilize carefully designed prompts and are calibrated against human evaluations to ensure their trustworthiness and stability. Extensive experiments on our newly constructed benchmark demonstrate that our framework provides a more realistic and rigorous assessment of unlearning performance. Moreover, our findings reveal that current evaluation strategies tend to overestimate unlearning effectiveness. Our code is publicly available at https://github.com/Graph-COM/Knowledge_Unlearning.git.",
    "authors": [
      "Rongzhe Wei, Peizhi Niu, Hans Hao-Hsun Hsu, Ruihan Wu, Haoteng Yin, Mohsen Ghassemi, Yifan Li, Vamsi K. Potluru, Eli Chien, Kamalika Chaudhuri, Olgica Milenkovic, Pan Li"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.836105"
  },
  {
    "id": "oai:arXiv.org:2506.05736v1",
    "journal": "arXiv_CS",
    "title": "Generalized Incremental Learning under Concept Drift across Evolving Data Streams",
    "link": "https://arxiv.org/abs/2506.05736",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05736v1 Announce Type: new \nAbstract: Real-world data streams exhibit inherent non-stationarity characterized by concept drift, posing significant challenges for adaptive learning systems. While existing methods address isolated distribution shifts, they overlook the critical co-evolution of label spaces and distributions under limited supervision and persistent uncertainty. To address this, we formalize Generalized Incremental Learning under Concept Drift (GILCD), characterizing the joint evolution of distributions and label spaces in open-environment streaming contexts, and propose a novel framework called Calibrated Source-Free Adaptation (CSFA). First, CSFA introduces a training-free prototype calibration mechanism that dynamically fuses emerging prototypes with base representations, enabling stable new-class identification without optimization overhead. Second, we design a novel source-free adaptation algorithm, i.e., Reliable Surrogate Gap Sharpness-aware (RSGS) minimization. It integrates sharpness-aware perturbation loss optimization with surrogate gap minimization, while employing entropy-based uncertainty filtering to discard unreliable samples. This mechanism ensures robust distribution alignment and mitigates generalization degradation caused by uncertainties. Therefore, CSFA establishes a unified framework for stable adaptation to evolving semantics and distributions in open-world streaming scenarios. Extensive experiments validate the superior performance and effectiveness of CSFA compared to state-of-the-art approaches.",
    "authors": [
      "En Yu, Jie Lu, Guangquan Zhang"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.836114"
  },
  {
    "id": "oai:arXiv.org:2506.05738v1",
    "journal": "arXiv_CS",
    "title": "Differential Spectrum and Boomerang Spectrum of Some Power Mapping",
    "link": "https://arxiv.org/abs/2506.05738",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05738v1 Announce Type: new \nAbstract: Let $f(x)=x^{s(p^m-1)}$ be a power mapping over $\\mathbb{F}_{p^n}$, where $n=2m$ and $\\gcd(s,p^m+1)=t$. In \\cite{kpm-1}, Hu et al. determined the differential spectrum and boomerang spectrum of the power function $f$, where $t=1$. So what happens if $t\\geq1$? In this paper, we extend the result of \\cite{kpm-1} from $t=1$ to general case. We use a different method than in \\cite{kpm-1} to determine the differential spectrum and boomerang spectrum of $f$ by studying the number of rational points on some curves. This method may be helpful for calculating the differential spectrum and boomerang spectrum of some Niho type power functions.",
    "authors": [
      "Yuehui Cui, Jinquan Luo"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.836123"
  },
  {
    "id": "oai:arXiv.org:2506.05740v1",
    "journal": "arXiv_CS",
    "title": "FIST: A Structured Threat Modeling Framework for Fraud Incidents",
    "link": "https://arxiv.org/abs/2506.05740",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05740v1 Announce Type: new \nAbstract: Fraudulent activities are rapidly evolving, employing increasingly diverse and sophisticated methods that pose serious threats to individuals, organizations, and society. This paper proposes the FIST Framework (Fraud Incident Structured Threat Framework), an innovative structured threat modeling methodology specifically designed for fraud scenarios. Inspired by MITRE ATT\\&amp;CK and DISARM, FIST systematically incorporates social engineering tactics, stage-based behavioral decomposition, and detailed attack technique mapping into a reusable knowledge base. FIST aims to enhance the efficiency of fraud detection and the standardization of threat intelligence sharing, promoting collaboration and a unified language across organizations and sectors. The framework integrates interdisciplinary insights from cybersecurity, criminology, and behavioral science, addressing both technical vectors and psychological manipulation mechanisms in fraud. This approach enables fine-grained analysis of fraud incidents, supporting automated detection, quantitative risk assessment, and standardized incident reporting. The effectiveness of the framework is further validated through real-world case studies, demonstrating its value in bridging academic research and practical applications, and laying the foundation for an intelligence-driven anti-fraud ecosystem. To the best of our knowledge, FIST is the first systematic, open-source fraud threat modeling framework that unifies both technical and psychological aspects, and is made freely available to foster collaboration between academia and industry.",
    "authors": [
      "Yu-Chen Dai, Lu-An Chen, Sy-Jye Her, Yu-Xian Jiang"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.836139"
  },
  {
    "id": "oai:arXiv.org:2506.05741v1",
    "journal": "arXiv_CS",
    "title": "A Soft Robotic Module with Pneumatic Actuation and Enhanced Controllability Using a Shape Memory Alloy Wire",
    "link": "https://arxiv.org/abs/2506.05741",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05741v1 Announce Type: new \nAbstract: In this paper, a compressed air-actuated soft robotic module was developed by incorporating a shape memory alloy (SMA) wire into its structure to achieve the desired bending angle with greater precision. First, a fiber-reinforced bending module with a strain-limiting layer made of polypropylene was fabricated. The SMA wire was then placed in a silicon matrix, which was used as a new strain-limiting layer. A simple closed-loop control algorithm was used to regulate the bending angle of the soft robot within its workspace. A camera was utilized to measure the angular changes in the vertical plane. Different angles, ranging from 0 to 65 degrees, were covered to evaluate the performance of the module and the bending angle control algorithm. The experimental tests demonstrate that using the SMA wire results in more precise control of bending in the vertical plane. In addition, it is possible to bend more with less working pressure. The error range was reduced from an average of 5 degrees to 2 degrees, and the rise time was reduced from an average of 19 seconds to 3 seconds.",
    "authors": [
      "Mohammadnavid Golchin"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.836148"
  },
  {
    "id": "oai:arXiv.org:2506.05742v1",
    "journal": "arXiv_CS",
    "title": "Malicious node aware wireless multi hop networks: a systematic review of the literature and recommendations for future research",
    "link": "https://arxiv.org/abs/2506.05742",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05742v1 Announce Type: new \nAbstract: Wireless communication provides great advantages that are not available through their wired counterparts such as flexibility, ease of deployment and use, cost reductions, and convenience. Wireless multi-hop networks (WMN) do not have any centralized management infrastructure. Wireless multi-hop networks have many benefits since proposed. In such networks when a node wants to send a packet to a destination where is not in the transmission range, depend on some intermediate nodes. In this type of networks packet sending is in the form of multiple hop until destination and this work is dynamic. Lack of centralized management cause that some nodes show malicious function. Malicious nodes are that receive packets and drop them maliciously. These malicious nodes could have many reasons such as hardware failure, software failure or lack of power. Such nodes make multiple packets drop from the network and the performance of network strongly decreases. As a result, the throughput of the network decrease, increase end-to-end delay and increase overhead. Therefore, we must aware from presence of malicious node in the network and do routing based on this awareness. Therefore, this paper aims to study and review the present malicious node detection methods that proposed in literatures. We categorized networks in groups, including ad hoc networks, MANET, DTN, Opportunistic networks, WSN, VANET and other wireless networks and compare malicious node detection met",
    "authors": [
      "Shahram Pourdehghan, Nahideh Derakhshanfard"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.836157"
  },
  {
    "id": "oai:arXiv.org:2506.05743v1",
    "journal": "arXiv_CS",
    "title": "When Better Features Mean Greater Risks: The Performance-Privacy Trade-Off in Contrastive Learning",
    "link": "https://arxiv.org/abs/2506.05743",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05743v1 Announce Type: new \nAbstract: With the rapid advancement of deep learning technology, pre-trained encoder models have demonstrated exceptional feature extraction capabilities, playing a pivotal role in the research and application of deep learning. However, their widespread use has raised significant concerns about the risk of training data privacy leakage. This paper systematically investigates the privacy threats posed by membership inference attacks (MIAs) targeting encoder models, focusing on contrastive learning frameworks. Through experimental analysis, we reveal the significant impact of model architecture complexity on membership privacy leakage: As more advanced encoder frameworks improve feature-extraction performance, they simultaneously exacerbate privacy-leakage risks. Furthermore, this paper proposes a novel membership inference attack method based on the p-norm of feature vectors, termed the Embedding Lp-Norm Likelihood Attack (LpLA). This method infers membership status, by leveraging the statistical distribution characteristics of the p-norm of feature vectors. Experimental results across multiple datasets and model architectures demonstrate that LpLA outperforms existing methods in attack performance and robustness, particularly under limited attack knowledge and query volumes. This study not only uncovers the potential risks of privacy leakage in contrastive learning frameworks, but also provides a practical basis for privacy protection research in encoder models. We hope that this work will draw greater attention to the privacy risks associated with self-supervised learning models and shed light on the importance of a balance between model utility and training data privacy. Our code is publicly available at: https://github.com/SeroneySun/LpLA_code.",
    "authors": [
      "Ruining Sun, Hongsheng Hu, Wei Luo, Zhaoxi Zhang, Yanjun Zhang, Haizhuan Yuan, Leo Yu Zhang"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.836167"
  },
  {
    "id": "oai:arXiv.org:2506.05744v1",
    "journal": "arXiv_CS",
    "title": "Topology of Reasoning: Understanding Large Reasoning Models through Reasoning Graph Properties",
    "link": "https://arxiv.org/abs/2506.05744",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05744v1 Announce Type: new \nAbstract: Recent large-scale reasoning models have achieved state-of-the-art performance on challenging mathematical benchmarks, yet the internal mechanisms underlying their success remain poorly understood. In this work, we introduce the notion of a reasoning graph, extracted by clustering hidden-state representations at each reasoning step, and systematically analyze three key graph-theoretic properties: cyclicity, diameter, and small-world index, across multiple tasks (GSM8K, MATH500, AIME 2024). Our findings reveal that distilled reasoning models (e.g., DeepSeek-R1-Distill-Qwen-32B) exhibit significantly more recurrent cycles (about 5 per sample), substantially larger graph diameters, and pronounced small-world characteristics (about 6x) compared to their base counterparts. Notably, these structural advantages grow with task difficulty and model capacity, with cycle detection peaking at the 14B scale and exploration diameter maximized in the 32B variant, correlating positively with accuracy. Furthermore, we show that supervised fine-tuning on an improved dataset systematically expands reasoning graph diameters in tandem with performance gains, offering concrete guidelines for dataset design aimed at boosting reasoning capabilities. By bridging theoretical insights into reasoning graph structures with practical recommendations for data construction, our work advances both the interpretability and the efficacy of large reasoning models.",
    "authors": [
      "Gouki Minegishi, Hiroki Furuta, Takeshi Kojima, Yusuke Iwasawa, Yutaka Matsuo"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.836176"
  },
  {
    "id": "oai:arXiv.org:2506.05745v1",
    "journal": "arXiv_CS",
    "title": "SPRINT: Enabling Interleaved Planning and Parallelized Execution in Reasoning Models",
    "link": "https://arxiv.org/abs/2506.05745",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05745v1 Announce Type: new \nAbstract: Large reasoning models (LRMs) excel at complex reasoning tasks but typically generate lengthy sequential chains-of-thought, resulting in long inference times before arriving at the final answer. To address this challenge, we introduce SPRINT, a novel post-training and inference-time framework designed to enable LRMs to dynamically identify and exploit opportunities for parallelization during their reasoning process. SPRINT incorporates an innovative data curation pipeline that reorganizes natural language reasoning trajectories into structured rounds of long-horizon planning and parallel execution. By fine-tuning LRMs on a small amount of such curated data, the models learn to dynamically identify independent subtasks within extended reasoning processes and effectively execute them in parallel. Through extensive evaluations, we show that the models fine-tuned with the SPRINT framework match the performance of reasoning models on complex domains such as mathematics while generating up to ~39% fewer sequential tokens on problems requiring more than 8000 output tokens. Finally, we observe consistent results transferred to two out-of-distribution tasks of GPQA and Countdown with up to 45% and 65% reduction in average sequential tokens for longer reasoning trajectories, while achieving the performance of the fine-tuned reasoning model.",
    "authors": [
      "Emil Biju, Shayan Talaei, Zhemin Huang, Mohammadreza Pourreza, Azalia Mirhoseini, Amin Saberi"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.836185"
  },
  {
    "id": "oai:arXiv.org:2506.05746v1",
    "journal": "arXiv_CS",
    "title": "LLM-Symbolic Integration for Robust Temporal Tabular Reasoning",
    "link": "https://arxiv.org/abs/2506.05746",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05746v1 Announce Type: new \nAbstract: Temporal tabular question answering presents a significant challenge for Large Language Models (LLMs), requiring robust reasoning over structured data, which is a task where traditional prompting methods often fall short. These methods face challenges such as memorization, sensitivity to table size, and reduced performance on complex queries. To overcome these limitations, we introduce TempTabQA-C, a synthetic dataset designed for systematic and controlled evaluations, alongside a symbolic intermediate representation that transforms tables into database schemas. This structured approach allows LLMs to generate and execute SQL queries, enhancing generalization and mitigating biases. By incorporating adaptive few-shot prompting with contextually tailored examples, our method achieves superior robustness, scalability, and performance. Experimental results consistently highlight improvements across key challenges, setting a new benchmark for robust temporal reasoning with LLMs.",
    "authors": [
      "Atharv Kulkarni, Kushagra Dixit, Vivek Srikumar, Dan Roth, Vivek Gupta"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.836193"
  },
  {
    "id": "oai:arXiv.org:2506.05748v1",
    "journal": "arXiv_CS",
    "title": "Efficient Online RFT with Plug-and-Play LLM Judges: Unlocking State-of-the-Art Performance",
    "link": "https://arxiv.org/abs/2506.05748",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05748v1 Announce Type: new \nAbstract: Reward-model training is the cost bottleneck in modern Reinforcement Learning Human Feedback (RLHF) pipelines, often requiring tens of billions of parameters and an offline preference-tuning phase. In the proposed method, a frozen, instruction-tuned 7B LLM is augmented with only a one line JSON rubric and a rank-16 LoRA adapter (affecting just 0.8% of the model's parameters), enabling it to serve as a complete substitute for the previously used heavyweight evaluation models. The plug-and-play judge achieves 96.2% accuracy on RewardBench, outperforming specialized reward networks ranging from 27B to 70B parameters. Additionally, it allows a 7B actor to outperform the top 70B DPO baseline, which scores 61.8%, by achieving 92% exact match accuracy on GSM-8K utilizing online PPO. Thorough ablations indicate that (i) six in context demonstrations deliver the majority of the zero-to-few-shot improvements (+2pp), and (ii) the LoRA effectively addresses the remaining disparity, particularly in the safety and adversarial Chat-Hard segments. The proposed model introduces HH-Rationales, a subset of 10,000 pairs from Anthropic HH-RLHF, to examine interpretability, accompanied by human generated justifications. GPT-4 scoring indicates that our LoRA judge attains approximately = 9/10 in similarity to human explanations, while zero-shot judges score around =5/10. These results indicate that the combination of prompt engineering and tiny LoRA produces a cost effective, transparent, and easily adjustable reward function, removing the offline phase while achieving new state-of-the-art outcomes for both static evaluation and online RLHF.",
    "authors": [
      "Rudransh Agnihotri, Ananya Pandey"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.836202"
  },
  {
    "id": "oai:arXiv.org:2506.05749v1",
    "journal": "arXiv_CS",
    "title": "Investigating the Relationship between Weighted Figure of Merit and Rosin's Measure",
    "link": "https://arxiv.org/abs/2506.05749",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05749v1 Announce Type: new \nAbstract: Many studies had been conducted to solve the problem of approximating a digital boundary by piece straight-line segments for further processing required in computer vision applications. The authors of these studies compared their schemes to determine the best one. The initial measure used to assess the goodness of a polygonal approximation was figure of merit. Later, it was pointed out that this measure was not an appropriate metric for a valid reason and this is why Rosin - through mathematical analysis - introduced a measure called merit. However, this measure involves optimal scheme of polygonal approximation and so it is time-consuming to compute it to assess the goodness of an approximation. This led many researchers to use weighted figure of merit as a substitute for Rosin's measure to compare among sub-optimal schemes. An attempt is made in this communication to investigate whether the two measures - weighted figure of merit and Rosin's measure - are related so that one can be used instead of the other and towards this end theoretical analysis, experimental investigation and statistical analysis are carried out. The mathematical formula for weighted figure of merit and Rosin's measure are analyzed and through proof of theorems it is found that the two measures are independent of each other theoretically. The graphical analysis of experiments carried out using public dataset supports theoretical analysis. The statistical analysis using Pearson's correlation coefficient also establishes that the two measures are uncorrelated. This analysis leads one to conclude that if a sub-optimal scheme is found to be better (worse) than some other sub-optimal scheme as indicated by Rosin's measure then the same conclusion cannot be drawn using weighted figure of merit and so one cannot use weighted figure of merit instead of Rosin's measure.",
    "authors": [
      "Bimal Kumar Ray"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.836211"
  },
  {
    "id": "oai:arXiv.org:2506.05751v1",
    "journal": "arXiv_CS",
    "title": "An Ontology for Representing Curriculum and Learning Material",
    "link": "https://arxiv.org/abs/2506.05751",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05751v1 Announce Type: new \nAbstract: Educational, learning, and training materials have become extremely commonplace across the Internet. Yet, they frequently remain disconnected from each other, fall into platform silos, and so on. One way to overcome this is to provide a mechanism to integrate the material and provide cross-links across topics.\n  In this paper, we present the Curriculum KG Ontology, which we use as a framework for the dense interlinking of educational materials, by first starting with organizational and broad pedagogical principles. We provide a materialized graph for the Prototype Open Knowledge Network use-case, and validate it using competency questions sourced from domain experts and educators.",
    "authors": [
      "Antrea Christou, Chris Davis Jaldi, Joseph Zalewski, Hande K\\\"u\\c{c}\\\"uk McGinty, Pascal Hitzler, Cogan Shimizu"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.836219"
  },
  {
    "id": "oai:arXiv.org:2506.05755v1",
    "journal": "arXiv_CS",
    "title": "FlowOE: Imitation Learning with Flow Policy from Ensemble RL Experts for Optimal Execution under Heston Volatility and Concave Market Impacts",
    "link": "https://arxiv.org/abs/2506.05755",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05755v1 Announce Type: new \nAbstract: Optimal execution in financial markets refers to the process of strategically transacting a large volume of assets over a period to achieve the best possible outcome by balancing the trade-off between market impact costs and timing or volatility risks. Traditional optimal execution strategies, such as static Almgren-Chriss models, often prove suboptimal in dynamic financial markets. This paper propose flowOE, a novel imitation learning framework based on flow matching models, to address these limitations. FlowOE learns from a diverse set of expert traditional strategies and adaptively selects the most suitable expert behavior for prevailing market conditions. A key innovation is the incorporation of a refining loss function during the imitation process, enabling flowOE not only to mimic but also to improve upon the learned expert actions. To the best of our knowledge, this work is the first to apply flow matching models in a stochastic optimal execution problem. Empirical evaluations across various market conditions demonstrate that flowOE significantly outperforms both the specifically calibrated expert models and other traditional benchmarks, achieving higher profits with reduced risk. These results underscore the practical applicability and potential of flowOE to enhance adaptive optimal execution.",
    "authors": [
      "Yang Li, Zhi Chen"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.836243"
  },
  {
    "id": "oai:arXiv.org:2506.05760v1",
    "journal": "arXiv_CS",
    "title": "Writing-RL: Advancing Long-form Writing via Adaptive Curriculum Reinforcement Learning",
    "link": "https://arxiv.org/abs/2506.05760",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05760v1 Announce Type: new \nAbstract: Recent advances in Large Language Models (LLMs) have enabled strong performance in long-form writing, yet existing supervised fine-tuning (SFT) approaches suffer from limitations such as data saturation and restricted learning capacity bounded by teacher signals. In this work, we present Writing-RL: an Adaptive Curriculum Reinforcement Learning framework to advance long-form writing capabilities beyond SFT. The framework consists of three key components: Margin-aware Data Selection strategy that prioritizes samples with high learning potential, Pairwise Comparison Reward mechanism that provides discriminative learning signals in the absence of verifiable rewards, and Dynamic Reference Scheduling approach, which plays a particularly critical role by adaptively adjusting task difficulty based on evolving model performance. Experiments on 7B-scale writer models show that our RL framework largely improves long-form writing performance over strong SFT baselines. Furthermore, we observe that models trained with long-output RL generalize surprisingly well to long-input reasoning tasks, potentially offering a promising perspective for rethinking long-context training.",
    "authors": [
      "Xuanyu Lei, Chenliang Li, Yuning Wu, Kaiming Liu, Weizhou Shen, Peng Li, Ming Yan, Ji Zhang, Fei Huang, Yang Liu"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.836252"
  },
  {
    "id": "oai:arXiv.org:2506.05762v1",
    "journal": "arXiv_CS",
    "title": "BiTrajDiff: Bidirectional Trajectory Generation with Diffusion Models for Offline Reinforcement Learning",
    "link": "https://arxiv.org/abs/2506.05762",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05762v1 Announce Type: new \nAbstract: Recent advances in offline Reinforcement Learning (RL) have proven that effective policy learning can benefit from imposing conservative constraints on pre-collected datasets. However, such static datasets often exhibit distribution bias, resulting in limited generalizability. To address this limitation, a straightforward solution is data augmentation (DA), which leverages generative models to enrich data distribution. Despite the promising results, current DA techniques focus solely on reconstructing future trajectories from given states, while ignoring the exploration of history transitions that reach them. This single-direction paradigm inevitably hinders the discovery of diverse behavior patterns, especially those leading to critical states that may have yielded high-reward outcomes. In this work, we introduce Bidirectional Trajectory Diffusion (BiTrajDiff), a novel DA framework for offline RL that models both future and history trajectories from any intermediate states. Specifically, we decompose the trajectory generation task into two independent yet complementary diffusion processes: one generating forward trajectories to predict future dynamics, and the other generating backward trajectories to trace essential history transitions.BiTrajDiff can efficiently leverage critical states as anchors to expand into potentially valuable yet underexplored regions of the state space, thereby facilitating dataset diversity. Extensive experiments on the D4RL benchmark suite demonstrate that BiTrajDiff achieves superior performance compared to other advanced DA methods across various offline RL backbones.",
    "authors": [
      "Yunpeng Qing, Shuo Chen, Yixiao Chi, Shunyu Liu, Sixu Lin, Changqing Zou"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.836261"
  },
  {
    "id": "oai:arXiv.org:2506.05763v1",
    "journal": "arXiv_CS",
    "title": "Where Is The Ball: 3D Ball Trajectory Estimation From 2D Monocular Tracking",
    "link": "https://arxiv.org/abs/2506.05763",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05763v1 Announce Type: new \nAbstract: We present a method for 3D ball trajectory estimation from a 2D tracking sequence. To overcome the ambiguity in 3D from 2D estimation, we design an LSTM-based pipeline that utilizes a novel canonical 3D representation that is independent of the camera's location to handle arbitrary views and a series of intermediate representations that encourage crucial invariance and reprojection consistency. We evaluated our method on four synthetic and three real datasets and conducted extensive ablation studies on our design choices. Despite training solely on simulated data, our method achieves state-of-the-art performance and can generalize to real-world scenarios with multiple trajectories, opening up a range of applications in sport analysis and virtual replay. Please visit our page: https://where-is-the-ball.github.io.",
    "authors": [
      "Puntawat Ponglertnapakorn, Supasorn Suwajanakorn"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.836270"
  },
  {
    "id": "oai:arXiv.org:2506.05764v1",
    "journal": "arXiv_CS",
    "title": "Exploring Microstructural Dynamics in Cryptocurrency Limit Order Books: Better Inputs Matter More Than Stacking Another Hidden Layer",
    "link": "https://arxiv.org/abs/2506.05764",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05764v1 Announce Type: new \nAbstract: Cryptocurrency price dynamics are driven largely by microstructural supply demand imbalances in the limit order book (LOB), yet the highly noisy nature of LOB data complicates the signal extraction process. Prior research has demonstrated that deep-learning architectures can yield promising predictive performance on pre-processed equity and futures LOB data, but they often treat model complexity as an unqualified virtue. In this paper, we aim to examine whether adding extra hidden layers or parameters to \"blackbox ish\" neural networks genuinely enhances short term price forecasting, or if gains are primarily attributable to data preprocessing and feature engineering. We benchmark a spectrum of models from interpretable baselines, logistic regression, XGBoost to deep architectures (DeepLOB, Conv1D+LSTM) on BTC/USDT LOB snapshots sampled at 100 ms to multi second intervals using publicly available Bybit data. We introduce two data filtering pipelines (Kalman, Savitzky Golay) and evaluate both binary (up/down) and ternary (up/flat/down) labeling schemes. Our analysis compares models on out of sample accuracy, latency, and robustness to noise. Results reveal that, with data preprocessing and hyperparameter tuning, simpler models can match and even exceed the performance of more complex networks, offering faster inference and greater interpretability.",
    "authors": [
      "Haochuan (Kevin),  Wang"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.836280"
  },
  {
    "id": "oai:arXiv.org:2506.05765v1",
    "journal": "arXiv_CS",
    "title": "Do Large Vision-Language Models Distinguish between the Actual and Apparent Features of Illusions?",
    "link": "https://arxiv.org/abs/2506.05765",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05765v1 Announce Type: new \nAbstract: Humans are susceptible to optical illusions, which serve as valuable tools for investigating sensory and cognitive processes. Inspired by human vision studies, research has begun exploring whether machines, such as large vision language models (LVLMs), exhibit similar susceptibilities to visual illusions. However, studies often have used non-abstract images and have not distinguished actual and apparent features, leading to ambiguous assessments of machine cognition. To address these limitations, we introduce a visual question answering (VQA) dataset, categorized into genuine and fake illusions, along with corresponding control images. Genuine illusions present discrepancies between actual and apparent features, whereas fake illusions have the same actual and apparent features even though they look illusory due to the similar geometric configuration. We evaluate the performance of LVLMs for genuine and fake illusion VQA tasks and investigate whether the models discern actual and apparent features. Our findings indicate that although LVLMs may appear to recognize illusions by correctly answering questions about both feature types, they predict the same answers for both Genuine Illusion and Fake Illusion VQA questions. This suggests that their responses might be based on prior knowledge of illusions rather than genuine visual understanding. The dataset is available at https://github.com/ynklab/FILM",
    "authors": [
      "Taiga Shinozaki, Tomoki Doi, Satoshi Nishida, Hitomi Yanaka"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.836290"
  },
  {
    "id": "oai:arXiv.org:2506.05766v1",
    "journal": "arXiv_CS",
    "title": "BioMol-MQA: A Multi-Modal Question Answering Dataset For LLM Reasoning Over Bio-Molecular Interactions",
    "link": "https://arxiv.org/abs/2506.05766",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05766v1 Announce Type: new \nAbstract: Retrieval augmented generation (RAG) has shown great power in improving Large Language Models (LLMs). However, most existing RAG-based LLMs are dedicated to retrieving single modality information, mainly text; while for many real-world problems, such as healthcare, information relevant to queries can manifest in various modalities such as knowledge graph, text (clinical notes), and complex molecular structure. Thus, being able to retrieve relevant multi-modality domain-specific information, and reason and synthesize diverse knowledge to generate an accurate response is important. To address the gap, we present BioMol-MQA, a new question-answering (QA) dataset on polypharmacy, which is composed of two parts (i) a multimodal knowledge graph (KG) with text and molecular structure for information retrieval; and (ii) challenging questions that designed to test LLM capabilities in retrieving and reasoning over multimodal KG to answer questions. Our benchmarks indicate that existing LLMs struggle to answer these questions and do well only when given the necessary background data, signaling the necessity for strong RAG frameworks.",
    "authors": [
      "Saptarshi Sengupta, Shuhua Yang, Paul Kwong Yu, Fali Wang, Suhang Wang"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.836299"
  },
  {
    "id": "oai:arXiv.org:2506.05767v1",
    "journal": "arXiv_CS",
    "title": "dots.llm1 Technical Report",
    "link": "https://arxiv.org/abs/2506.05767",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05767v1 Announce Type: new \nAbstract: Mixture of Experts (MoE) models have emerged as a promising paradigm for scaling language models efficiently by activating only a subset of parameters for each input token. In this report, we present dots.llm1, a large-scale MoE model that activates 14B parameters out of a total of 142B parameters, delivering performance on par with state-of-the-art models while reducing training and inference costs. Leveraging our meticulously crafted and efficient data processing pipeline, dots.llm1 achieves performance comparable to Qwen2.5-72B after pretraining on 11.2T high-quality tokens and post-training to fully unlock its capabilities. Notably, no synthetic data is used during pretraining. To foster further research, we open-source intermediate training checkpoints at every one trillion tokens, providing valuable insights into the learning dynamics of large language models.",
    "authors": [
      "Bi Huo, Bin Tu, Cheng Qin, Da Zheng, Debing Zhang, Dongjie Zhang, En Li, Fu Guo, Jian Yao, Jie Lou, Junfeng Tian, Li Hu, Ran Zhu, Shengdong Chen, Shuo Liu, Su Guang, Te Wo, Weijun Zhang, Xiaoming Shi, Xinxin Peng, Xing Wu, Yawen Liu, Yuqiu Ji, Ze Wen, Zhenhai Liu, Zichao Li, Zilong Liao"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.836307"
  },
  {
    "id": "oai:arXiv.org:2506.05774v1",
    "journal": "arXiv_CS",
    "title": "Evaluating Neuron Explanations: A Unified Framework with Sanity Checks",
    "link": "https://arxiv.org/abs/2506.05774",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05774v1 Announce Type: new \nAbstract: Understanding the function of individual units in a neural network is an important building block for mechanistic interpretability. This is often done by generating a simple text explanation of the behavior of individual neurons or units. For these explanations to be useful, we must understand how reliable and truthful they are. In this work we unify many existing explanation evaluation methods under one mathematical framework. This allows us to compare existing evaluation metrics, understand the evaluation pipeline with increased clarity and apply existing statistical methods on the evaluation. In addition, we propose two simple sanity checks on the evaluation metrics and show that many commonly used metrics fail these tests and do not change their score after massive changes to the concept labels. Based on our experimental and theoretical results, we propose guidelines that future evaluations should follow and identify a set of reliable evaluation metrics.",
    "authors": [
      "Tuomas Oikarinen, Ge Yan, Tsui-Wei Weng"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.836316"
  },
  {
    "id": "oai:arXiv.org:2506.05779v1",
    "journal": "arXiv_CS",
    "title": "Pegasus: A Universal Framework for Scalable Deep Learning Inference on the Dataplane",
    "link": "https://arxiv.org/abs/2506.05779",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05779v1 Announce Type: new \nAbstract: The paradigm of Intelligent DataPlane (IDP) embeds deep learning (DL) models on the network dataplane to enable intelligent traffic analysis at line-speed. However, the current use of the match-action table (MAT) abstraction on the dataplane is misaligned with DL inference, leading to several key limitations, including accuracy degradation, limited scale, and lack of generality. This paper proposes Pegasus to address these limitations. Pegasus translates DL operations into three dataplane-oriented primitives to achieve generality: Partition, Map, and SumReduce. Specifically, Partition \"divides\" high-dimensional features into multiple low-dimensional vectors, making them more suitable for the dataplane; Map \"conquers\" computations on the low-dimensional vectors in parallel with the technique of fuzzy matching, while SumReduce \"combines\" the computation results. Additionally, Pegasus employs Primitive Fusion to merge computations, improving scalability. Finally, Pegasus adopts full precision weights with fixed-point activations to improve accuracy. Our implementation on a P4 switch demonstrates that Pegasus can effectively support various types of DL models, including Multi-Layer Perceptron (MLP), Recurrent Neural Network (RNN), Convolutional Neural Network (CNN), and AutoEncoder models on the dataplane. Meanwhile, Pegasus outperforms state-of-the-art approaches with an average accuracy improvement of up to 22.8%, along with up to 248x larger model size and 212x larger input scale.",
    "authors": [
      "Yinchao Zhang, Su Yao, Yong Feng, Kang Chen, Tong Li, Zhuotao Liu, Yi Zhao, Lexuan Zhang, Xiangyu Gao, Feng Xiong, Qi Li, Ke Xu"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.836324"
  },
  {
    "id": "oai:arXiv.org:2506.05781v1",
    "journal": "arXiv_CS",
    "title": "Generating Long Semantic IDs in Parallel for Recommendation",
    "link": "https://arxiv.org/abs/2506.05781",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05781v1 Announce Type: new \nAbstract: Semantic ID-based recommendation models tokenize each item into a small number of discrete tokens that preserve specific semantics, leading to better performance, scalability, and memory efficiency. While recent models adopt a generative approach, they often suffer from inefficient inference due to the reliance on resource-intensive beam search and multiple forward passes through the neural sequence model. As a result, the length of semantic IDs is typically restricted (e.g. to just 4 tokens), limiting their expressiveness. To address these challenges, we propose RPG, a lightweight framework for semantic ID-based recommendation. The key idea is to produce unordered, long semantic IDs, allowing the model to predict all tokens in parallel. We train the model to predict each token independently using a multi-token prediction loss, directly integrating semantics into the learning objective. During inference, we construct a graph connecting similar semantic IDs and guide decoding to avoid generating invalid IDs. Experiments show that scaling up semantic ID length to 64 enables RPG to outperform generative baselines by an average of 12.6% on the NDCG@10, while also improving inference efficiency. Code is available at: https://github.com/facebookresearch/RPG_KDD2025.",
    "authors": [
      "Yupeng Hou, Jiacheng Li, Ashley Shin, Jinsung Jeon, Abhishek Santhanam, Wei Shao, Kaveh Hassani, Ning Yao, Julian McAuley"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.836340"
  },
  {
    "id": "oai:arXiv.org:2506.05782v1",
    "journal": "arXiv_CS",
    "title": "GazeNLQ @ Ego4D Natural Language Queries Challenge 2025",
    "link": "https://arxiv.org/abs/2506.05782",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05782v1 Announce Type: new \nAbstract: This report presents our solution to the Ego4D Natural Language Queries (NLQ) Challenge at CVPR 2025. Egocentric video captures the scene from the wearer's perspective, where gaze serves as a key non-verbal communication cue that reflects visual attention and offer insights into human intention and cognition. Motivated by this, we propose a novel approach, GazeNLQ, which leverages gaze to retrieve video segments that match given natural language queries. Specifically, we introduce a contrastive learning-based pretraining strategy for gaze estimation directly from video. The estimated gaze is used to augment video representations within proposed model, thereby enhancing localization accuracy. Experimental results show that GazeNLQ achieves R1@IoU0.3 and R1@IoU0.5 scores of 27.82 and 18.68, respectively. Our code is available at https://github.com/stevenlin510/GazeNLQ.",
    "authors": [
      "Wei-Cheng Lin, Chih-Ming Lien, Chen Lo, Chia-Hung Yeh"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.836348"
  },
  {
    "id": "oai:arXiv.org:2506.05787v1",
    "journal": "arXiv_CS",
    "title": "EASG-Bench: Video Q&A Benchmark with Egocentric Action Scene Graphs",
    "link": "https://arxiv.org/abs/2506.05787",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05787v1 Announce Type: new \nAbstract: We introduce EASG-Bench, a question-answering benchmark for egocentric videos where the question-answering pairs are created from spatio-temporally grounded dynamic scene graphs capturing intricate relationships among actors, actions, and objects. We propose a systematic evaluation framework and evaluate several language-only and video large language models (video-LLMs) on this benchmark. We observe a performance gap in language-only and video-LLMs, especially on questions focusing on temporal ordering, thus identifying a research gap in the area of long-context video understanding. To promote the reproducibility of our findings and facilitate further research, the benchmark and accompanying code are available at the following GitHub page: https://github.com/fpv-iplab/EASG-bench.",
    "authors": [
      "Ivan Rodin, Tz-Ying Wu, Kyle Min, Sharath Nittur Sridhar, Antonino Furnari, Subarna Tripathi, Giovanni Maria Farinella"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.836357"
  },
  {
    "id": "oai:arXiv.org:2506.05790v1",
    "journal": "arXiv_CS",
    "title": "Discrete Minds in a Continuous World: Do Language Models Know Time Passes?",
    "link": "https://arxiv.org/abs/2506.05790",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05790v1 Announce Type: new \nAbstract: While Large Language Models (LLMs) excel at temporal reasoning tasks like event ordering and duration estimation, their ability to perceive the actual passage of time remains unexplored. We investigate whether LLMs perceive the passage of time and adapt their decision-making accordingly through three complementary experiments. First, we introduce the Token-Time Hypothesis, positing that LLMs can map discrete token counts to continuous wall-clock time, and validate this through a dialogue duration judgment task. Second, we demonstrate that LLMs could use this awareness to adapt their response length while maintaining accuracy when users express urgency in question answering tasks. Finally, we develop BombRush, an interactive navigation challenge that examines how LLMs modify behavior under progressive time pressure in dynamic environments. Our findings indicate that LLMs possess certain awareness of time passage, enabling them to bridge discrete linguistic tokens and continuous physical time, though this capability varies with model size and reasoning abilities. This work establishes a theoretical foundation for enhancing temporal awareness in LLMs for time-sensitive applications.",
    "authors": [
      "Minghan Wang, Ye Bai, Thuy-Trang Vu, Ehsan Shareghi, Gholamreza Haffari"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.836365"
  },
  {
    "id": "oai:arXiv.org:2506.05791v1",
    "journal": "arXiv_CS",
    "title": "Exploiting Similarity for Computation and Communication-Efficient Decentralized Optimization",
    "link": "https://arxiv.org/abs/2506.05791",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05791v1 Announce Type: new \nAbstract: Reducing communication complexity is critical for efficient decentralized optimization. The proximal decentralized optimization (PDO) framework is particularly appealing, as methods within this framework can exploit functional similarity among nodes to reduce communication rounds. Specifically, when local functions at different nodes are similar, these methods achieve faster convergence with fewer communication steps. However, existing PDO methods often require highly accurate solutions to subproblems associated with the proximal operator, resulting in significant computational overhead. In this work, we propose the Stabilized Proximal Decentralized Optimization (SPDO) method, which achieves state-of-the-art communication and computational complexities within the PDO framework. Additionally, we refine the analysis of existing PDO methods by relaxing subproblem accuracy requirements and leveraging average functional similarity. Experimental results demonstrate that SPDO significantly outperforms existing methods.",
    "authors": [
      "Yuki Takezawa, Xiaowen Jiang, Anton Rodomanov, Sebastian U. Stich"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.836375"
  },
  {
    "id": "oai:arXiv.org:2506.05793v1",
    "journal": "arXiv_CS",
    "title": "ShyLU node: On-node Scalable Solvers and Preconditioners Recent Progresses and Current Performance",
    "link": "https://arxiv.org/abs/2506.05793",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05793v1 Announce Type: new \nAbstract: ShyLU-node is an open-source software package that implements linear solvers and preconditioners on shared-memory multicore CPUs or on a GPU. It is part of the Trilinos software framework and designed to provide a robust and efficient solution of large-scale linear systems from real-world applications on the current and emerging computers. In this paper, we discuss two sparse direct solvers, Basker and Tacho, and an algebraic preconditioner, FastILU, in ShyLU-node package. These ShyLU solvers and preconditioner can be used as a stand-alone global problem solver, as a local subdomain solver for domain decomposition (DD) preconditioner, or as the coarse-problem solver in algebraic multi-grid preconditioner. We present performance results with the sparse direct solvers for real application problems, namely, Basker for Xyce Circuit Simulations and Tacho for Albany Land-Ice Simulation of Antarctica. FastILU has been also used in real-world applications, but in this paper, we illustrate its performance using 3D model problems.",
    "authors": [
      "Ichitaro Yamazaki, Nathan Ellingwood, Sivasankaran Rajamanickam"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.836384"
  },
  {
    "id": "oai:arXiv.org:2506.05797v1",
    "journal": "arXiv_CS",
    "title": "EqCollide: Equivariant and Collision-Aware Deformable Objects Neural Simulator",
    "link": "https://arxiv.org/abs/2506.05797",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05797v1 Announce Type: new \nAbstract: Simulating collisions of deformable objects is a fundamental yet challenging task due to the complexity of modeling solid mechanics and multi-body interactions. Existing data-driven methods often suffer from lack of equivariance to physical symmetries, inadequate handling of collisions, and limited scalability. Here we introduce EqCollide, the first end-to-end equivariant neural fields simulator for deformable objects and their collisions. We propose an equivariant encoder to map object geometry and velocity into latent control points. A subsequent equivariant Graph Neural Network-based Neural Ordinary Differential Equation models the interactions among control points via collision-aware message passing. To reconstruct velocity fields, we query a neural field conditioned on control point features, enabling continuous and resolution-independent motion predictions. Experimental results show that EqCollide achieves accurate, stable, and scalable simulations across diverse object configurations, and our model achieves 24.34% to 35.82% lower rollout MSE even compared with the best-performing baseline model. Furthermore, our model could generalize to more colliding objects and extended temporal horizons, and stay robust to input transformed with group action.",
    "authors": [
      "Qianyi Chen, Tianrun Gao, Chenbo Jiang, Tailin Wu"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.836393"
  },
  {
    "id": "oai:arXiv.org:2506.05799v1",
    "journal": "arXiv_CS",
    "title": "Option Pricing Using Ensemble Learning",
    "link": "https://arxiv.org/abs/2506.05799",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05799v1 Announce Type: new \nAbstract: Ensemble learning is characterized by flexibility, high precision, and refined structure. As a critical component within computational finance, option pricing with machine learning requires both high predictive accuracy and reduced structural complexity-features that align well with the inherent advantages of ensemble learning. This paper investigates the application of ensemble learning to option pricing, and conducts a comparative analysis with classical machine learning models to assess their performance in terms of accuracy, local feature extraction, and robustness to noise. A novel experimental strategy is introduced, leveraging parameter transfer across experiments to improve robustness and realism in financial simulations.Building upon this strategy, an evaluation mechanism is developed that incorporates a scoring strategy and a weighted evaluation strategy explicitly emphasizing the foundational role of financial theory. This mechanism embodies an orderly integration of theoretical finance and computational methods. In addition, the study examines the interaction between sliding window technique and noise, revealing nuanced patterns that suggest a potential connection relevant to ongoing research in machine learning and data science.",
    "authors": [
      "Zeyuan Li, Qingdao Huang"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.836401"
  },
  {
    "id": "oai:arXiv.org:2506.05808v1",
    "journal": "arXiv_CS",
    "title": "Where Do We Look When We Teach? Analyzing Human Gaze Behavior Across Demonstration Devices in Robot Imitation Learning",
    "link": "https://arxiv.org/abs/2506.05808",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05808v1 Announce Type: new \nAbstract: Imitation learning for acquiring generalizable policies often requires a large volume of demonstration data, making the process significantly costly. One promising strategy to address this challenge is to leverage the cognitive and decision-making skills of human demonstrators with strong generalization capability, particularly by extracting task-relevant cues from their gaze behavior. However, imitation learning typically involves humans collecting data using demonstration devices that emulate a robot's embodiment and visual condition. This raises the question of how such devices influence gaze behavior. We propose an experimental framework that systematically analyzes demonstrators' gaze behavior across a spectrum of demonstration devices. Our experimental results indicate that devices emulating (1) a robot's embodiment or (2) visual condition impair demonstrators' capability to extract task-relevant cues via gaze behavior, with the extent of impairment depending on the degree of emulation. Additionally, gaze data collected using devices that capture natural human behavior improves the policy's task success rate from 18.8% to 68.8% under environmental shifts.",
    "authors": [
      "Yutaro Ishida, Takamitsu Matsubara, Takayuki Kanai, Kazuhiro Shintani, Hiroshi Bito"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.836426"
  },
  {
    "id": "oai:arXiv.org:2506.05810v1",
    "journal": "arXiv_CS",
    "title": "Trajectory Entropy: Modeling Game State Stability from Multimodality Trajectory Prediction",
    "link": "https://arxiv.org/abs/2506.05810",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05810v1 Announce Type: new \nAbstract: Complex interactions among agents present a significant challenge for autonomous driving in real-world scenarios. Recently, a promising approach has emerged, which formulates the interactions of agents as a level-k game framework. It effectively decouples agent policies by hierarchical game levels. However, this framework ignores both the varying driving complexities among agents and the dynamic changes in agent states across game levels, instead treating them uniformly. Consequently, redundant and error-prone computations are introduced into this framework. To tackle the issue, this paper proposes a metric, termed as Trajectory Entropy, to reveal the game status of agents within the level-k game framework. The key insight stems from recognizing the inherit relationship between agent policy uncertainty and the associated driving complexity. Specifically, Trajectory Entropy extracts statistical signals representing uncertainty from the multimodality trajectory prediction results of agents in the game. Then, the signal-to-noise ratio of this signal is utilized to quantify the game status of agents. Based on the proposed Trajectory Entropy, we refine the current level-k game framework through a simple gating mechanism, significantly improving overall accuracy while reducing computational costs. Our method is evaluated on the Waymo and nuPlan datasets, in terms of trajectory prediction, open-loop and closed-loop planning tasks. The results demonstrate the state-of-the-art performance of our method, with precision improved by up to 19.89% for prediction and up to 16.48% for planning.",
    "authors": [
      "Yesheng Zhang, Wenjian Sun, Yuheng Chen, Qingwei Liu, Qi Lin, Rui Zhang, Xu Zhao"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.836435"
  },
  {
    "id": "oai:arXiv.org:2506.05811v1",
    "journal": "arXiv_CS",
    "title": "Synchronous Clock and RF Carrier Transmission for Radio Access Network Fronthaul",
    "link": "https://arxiv.org/abs/2506.05811",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05811v1 Announce Type: new \nAbstract: We simultaneously achieve clock synchronisation, clock-synchronised data transmission and ultra-low noise RF carrier generation by combining clock phase caching and frequency comb transmission in radio access networks (RAN). We demonstrate <100fs jitter for 25GHz RF carrier and 2.5GHz clock, and 16-hour 6.6ps RMS wander.",
    "authors": [
      "Kari Aaron Clark, Zun Htay, Zichuan Zhou, Amany Kassem, Andrea Pertoldi, Benjamin Rudin, Florian Emaury, Izzat Darwazeh, Zhixin Liu"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.836443"
  },
  {
    "id": "oai:arXiv.org:2506.05812v1",
    "journal": "arXiv_CS",
    "title": "Optimal Robotic Velcro Peeling with Force Feedback",
    "link": "https://arxiv.org/abs/2506.05812",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05812v1 Announce Type: new \nAbstract: We study the problem of peeling a Velcro strap from a surface using a robotic manipulator. The surface geometry is arbitrary and unknown. The robot has access to only the force feedback and its end-effector position. This problem is challenging due to the partial observability of the environment and the incompleteness of the sensor feedback. To solve it, we first model the system with simple analytic state and action models based on quasi-static dynamics assumptions. We then study the fully-observable case where the state of both the Velcro and the robot are given. For this case, we obtain the optimal solution in closed-form which minimizes the total energy cost. Next, for the partially-observable case, we design a state estimator which estimates the underlying state using only force and position feedback. Then, we present a heuristics-based controller that balances exploratory and exploitative behaviors in order to peel the velcro efficiently. Finally, we evaluate our proposed method in environments with complex geometric uncertainties and sensor noises, achieving 100% success rate with less than 80% increase in energy cost compared to the optimal solution when the environment is fully-observable, outperforming the baselines by a large margin.",
    "authors": [
      "Jiacheng Yuan, Changhyun Choi, Volkan Isler"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.836452"
  },
  {
    "id": "oai:arXiv.org:2506.05813v1",
    "journal": "arXiv_CS",
    "title": "MAPLE: Multi-Agent Adaptive Planning with Long-Term Memory for Table Reasoning",
    "link": "https://arxiv.org/abs/2506.05813",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05813v1 Announce Type: new \nAbstract: Table-based question answering requires complex reasoning capabilities that current LLMs struggle to achieve with single-pass inference. Existing approaches, such as Chain-of-Thought reasoning and question decomposition, lack error detection mechanisms and discard problem-solving experiences, contrasting sharply with how humans tackle such problems. In this paper, we propose MAPLE (Multi-agent Adaptive Planning with Long-term mEmory), a novel framework that mimics human problem-solving through specialized cognitive agents working in a feedback-driven loop. MAPLE integrates 4 key components: (1) a Solver using the ReAct paradigm for reasoning, (2) a Checker for answer verification, (3) a Reflector for error diagnosis and strategy correction, and (4) an Archiver managing long-term memory for experience reuse and evolution. Experiments on WiKiTQ and TabFact demonstrate significant improvements over existing methods, achieving state-of-the-art performance across multiple LLM backbones.",
    "authors": [
      "Ye Bai, Minghan Wang, Thuy-Trang Vu"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.836461"
  },
  {
    "id": "oai:arXiv.org:2506.05814v1",
    "journal": "arXiv_CS",
    "title": "Positional Encoding meets Persistent Homology on Graphs",
    "link": "https://arxiv.org/abs/2506.05814",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05814v1 Announce Type: new \nAbstract: The local inductive bias of message-passing graph neural networks (GNNs) hampers their ability to exploit key structural information (e.g., connectivity and cycles). Positional encoding (PE) and Persistent Homology (PH) have emerged as two promising approaches to mitigate this issue. PE schemes endow GNNs with location-aware features, while PH methods enhance GNNs with multiresolution topological features. However, a rigorous theoretical characterization of the relative merits and shortcomings of PE and PH has remained elusive. We bridge this gap by establishing that neither paradigm is more expressive than the other, providing novel constructions where one approach fails but the other succeeds. Our insights inform the design of a novel learnable method, PiPE (Persistence-informed Positional Encoding), which is provably more expressive than both PH and PE. PiPE demonstrates strong performance across a variety of tasks (e.g., molecule property prediction, graph classification, and out-of-distribution generalization), thereby advancing the frontiers of graph representation learning. Code is available at https://github.com/Aalto-QuML/PIPE.",
    "authors": [
      "Yogesh Verma, Amauri H. Souza, Vikas Garg"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.836469"
  },
  {
    "id": "oai:arXiv.org:2506.05815v1",
    "journal": "arXiv_CS",
    "title": "NTIRE 2025 Challenge on HR Depth from Images of Specular and Transparent Surfaces",
    "link": "https://arxiv.org/abs/2506.05815",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05815v1 Announce Type: new \nAbstract: This paper reports on the NTIRE 2025 challenge on HR Depth From images of Specular and Transparent surfaces, held in conjunction with the New Trends in Image Restoration and Enhancement (NTIRE) workshop at CVPR 2025. This challenge aims to advance the research on depth estimation, specifically to address two of the main open issues in the field: high-resolution and non-Lambertian surfaces. The challenge proposes two tracks on stereo and single-image depth estimation, attracting about 177 registered participants. In the final testing stage, 4 and 4 participating teams submitted their models and fact sheets for the two tracks.",
    "authors": [
      "Pierluigi Zama Ramirez, Fabio Tosi, Luigi Di Stefano, Radu Timofte, Alex Costanzino, Matteo Poggi, Samuele Salti, Stefano Mattoccia, Zhe Zhang, Yang Yang, Wu Chen, Anlong Ming, Mingshuai Zhao, Mengying Yu, Shida Gao, Xiangfeng Wang, Feng Xue, Jun Shi, Yong Yang, Yong A, Yixiang Jin, Dingzhe Li, Aryan Shukla, Liam Frija-Altarac, Matthew Toews, Hui Geng, Tianjiao Wan, Zijian Gao, Qisheng Xu, Kele Xu, Zijian Zang, Jameer Babu Pinjari, Kuldeep Purohit, Mykola Lavreniuk, Jing Cao, Shenyi Li, Kui Jiang, Junjun Jiang, Yong Huang"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.836478"
  },
  {
    "id": "oai:arXiv.org:2506.05817v1",
    "journal": "arXiv_CS",
    "title": "CodeContests+: High-Quality Test Case Generation for Competitive Programming",
    "link": "https://arxiv.org/abs/2506.05817",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05817v1 Announce Type: new \nAbstract: Competitive programming, due to its high reasoning difficulty and precise correctness feedback, has become a key task for both training and evaluating the reasoning capabilities of large language models (LLMs). However, while a large amount of public problem data, such as problem statements and solutions, is available, the test cases of these problems are often difficult to obtain. Therefore, test case generation is a necessary task for building large-scale datasets, and the quality of the test cases directly determines the accuracy of the evaluation. In this paper, we introduce an LLM-based agent system that creates high-quality test cases for competitive programming problems. We apply this system to the CodeContests dataset and propose a new version with improved test cases, named CodeContests+. We evaluated the quality of test cases in CodeContestsPlus. First, we used 1.72 million submissions with pass/fail labels to examine the accuracy of these test cases in evaluation. The results indicated that CodeContests+ achieves significantly higher accuracy than CodeContests, particularly with a notably higher True Positive Rate (TPR). Subsequently, our experiments in LLM Reinforcement Learning (RL) further confirmed that improvements in test case quality yield considerable advantages for RL.",
    "authors": [
      "Zihan Wang, Siyao Liu, Yang Sun, Hongyan Li, Kai Shen"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.836487"
  },
  {
    "id": "oai:arXiv.org:2506.05820v1",
    "journal": "arXiv_CS",
    "title": "DeformCL: Learning Deformable Centerline Representation for Vessel Extraction in 3D Medical Image",
    "link": "https://arxiv.org/abs/2506.05820",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05820v1 Announce Type: new \nAbstract: In the field of 3D medical imaging, accurately extracting and representing the blood vessels with curvilinear structures holds paramount importance for clinical diagnosis. Previous methods have commonly relied on discrete representation like mask, often resulting in local fractures or scattered fragments due to the inherent limitations of the per-pixel classification paradigm. In this work, we introduce DeformCL, a new continuous representation based on Deformable Centerlines, where centerline points act as nodes connected by edges that capture spatial relationships. Compared with previous representations, DeformCL offers three key advantages: natural connectivity, noise robustness, and interaction facility. We present a comprehensive training pipeline structured in a cascaded manner to fully exploit these favorable properties of DeformCL. Extensive experiments on four 3D vessel segmentation datasets demonstrate the effectiveness and superiority of our method. Furthermore, the visualization of curved planar reformation images validates the clinical significance of the proposed framework. We release the code in https://github.com/barry664/DeformCL",
    "authors": [
      "Ziwei Zhao, Zhixing Zhang, Yuhang Liu, Zhao Zhang, Haojun Yu, Dong Wang, Liwei Wang"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.836496"
  },
  {
    "id": "oai:arXiv.org:2506.05821v1",
    "journal": "arXiv_CS",
    "title": "FuseUNet: A Multi-Scale Feature Fusion Method for U-like Networks",
    "link": "https://arxiv.org/abs/2506.05821",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05821v1 Announce Type: new \nAbstract: Medical image segmentation is a critical task in computer vision, with UNet serving as a milestone architecture. The typical component of UNet family is the skip connection, however, their skip connections face two significant limitations: (1) they lack effective interaction between features at different scales, and (2) they rely on simple concatenation or addition operations, which constrain efficient information integration. While recent improvements to UNet have focused on enhancing encoder and decoder capabilities, these limitations remain overlooked. To overcome these challenges, we propose a novel multi-scale feature fusion method that reimagines the UNet decoding process as solving an initial value problem (IVP), treating skip connections as discrete nodes. By leveraging principles from the linear multistep method, we propose an adaptive ordinary differential equation method to enable effective multi-scale feature fusion. Our approach is independent of the encoder and decoder architectures, making it adaptable to various U-Net-like networks. Experiments on ACDC, KiTS2023, MSD brain tumor, and ISIC2017/2018 skin lesion segmentation datasets demonstrate improved feature utilization, reduced network parameters, and maintained high performance. The code is available at https://github.com/nayutayuki/FuseUNet.",
    "authors": [
      "Quansong He, Xiangde Min, Kaishen Wang, Tao He"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.836505"
  },
  {
    "id": "oai:arXiv.org:2506.05822v1",
    "journal": "arXiv_CS",
    "title": "Towards Mixed-Criticality Software Architectures for Centralized HPC Platforms in Software-Defined Vehicles: A Systematic Literature Review",
    "link": "https://arxiv.org/abs/2506.05822",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05822v1 Announce Type: new \nAbstract: Centralized electrical/electronic architectures and High-Performance Computers (HPCs) are redefining automotive software development, challenging traditional microcontroller-based approaches. Ensuring real-time, safety, and scalability in software-defined vehicles necessitates reevaluating how mixed-criticality software is integrated into centralized architectures. While existing research on automotive SoftWare Architectures (SWAs) is relevant to the industry, it often lacks validation through systematic, empirical methods. To address this gap, we conduct a systematic literature review focusing on automotive mixed-criticality SWAs. Our goal is to provide practitioner-oriented guidelines that assist automotive software architects and developers design centralized, mixed-criticality SWAs based on a rigorous and transparent methodology. First, we set up a systematic review protocol grounded in established guidelines. Second, we apply this protocol to identify relevant studies. Third, we extract key functional domains, constraints, and enabling technologies that drive changes in automotive SWAs, thereby assessing the protocol's effectiveness. Additionally, we extract techniques, architectural patterns, and design practices for integrating mixed-criticality requirements into HPC-based SWAs, further demonstrating the protocol's applicability. Based on these insights, we propose an exemplary SWA for a microprocessor-based system-on-chip. In conclusion, this study provides a structured approach to explore and realize mixed-criticality software integration for next-generation automotive SWAs, offering valuable insights for industry and research applications.",
    "authors": [
      "Lucas Mauser, Eva Zimmermann, Pavel Nedv\\v{e}dick\\'y, Tobias Eisenreich, Moritz W\\\"aschle, Stefan Wagner"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.836515"
  },
  {
    "id": "oai:arXiv.org:2506.05824v1",
    "journal": "arXiv_CS",
    "title": "Positive Varieties of Lattice Languages",
    "link": "https://arxiv.org/abs/2506.05824",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05824v1 Announce Type: new \nAbstract: While a language assigns a value of either `yes' or `no' to each word, a lattice language assigns an element of a given lattice to each word. An advantage of lattice languages is that joins and meets of languages can be defined as generalizations of unions and intersections. This fact also allows for the definition of positive varieties -- classes closed under joins, meets, quotients, and inverse homomorphisms -- of lattice languages. In this paper, we extend Pin's positive variety theorem, proving a one-to-one correspondence between positive varieties of regular lattice languages and pseudo-varieties of finite ordered monoids. Additionally, we briefly explore algebraic approaches to finite-state Markov chains as an application of our framework.",
    "authors": [
      "Yusuke Inoue, Yuji Komatsu"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.836523"
  },
  {
    "id": "oai:arXiv.org:2506.05825v1",
    "journal": "arXiv_CS",
    "title": "High Throughput Event Filtering: The Interpolation-based DIF Algorithm Hardware Architecture",
    "link": "https://arxiv.org/abs/2506.05825",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05825v1 Announce Type: new \nAbstract: In recent years, there has been rapid development in the field of event vision. It manifests itself both on the technical side, as better and better event sensors are available, and on the algorithmic side, as more and more applications of this technology are proposed and scientific papers are published. However, the data stream from these sensors typically contains a significant amount of noise, which varies depending on factors such as the degree of illumination in the observed scene or the temperature of the sensor. We propose a hardware architecture of the Distance-based Interpolation with Frequency Weights (DIF) filter and implement it on an FPGA chip. To evaluate the algorithm and compare it with other solutions, we have prepared a new high-resolution event dataset, which we are also releasing to the community. Our architecture achieved a throughput of 403.39 million events per second (MEPS) for a sensor resolution of 1280 x 720 and 428.45 MEPS for a resolution of 640 x 480. The average values of the Area Under the Receiver Operating Characteristic (AUROC) index ranged from 0.844 to 0.999, depending on the dataset, which is comparable to the state-of-the-art filtering solutions, but with much higher throughput and better operation over a wide range of noise levels.",
    "authors": [
      "Marcin Kowalczyk, Tomasz Kryjak"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.836532"
  },
  {
    "id": "oai:arXiv.org:2506.05826v1",
    "journal": "arXiv_CS",
    "title": "Learning Along the Arrow of Time: Hyperbolic Geometry for Backward-Compatible Representation Learning",
    "link": "https://arxiv.org/abs/2506.05826",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05826v1 Announce Type: new \nAbstract: Backward compatible representation learning enables updated models to integrate seamlessly with existing ones, avoiding to reprocess stored data. Despite recent advances, existing compatibility approaches in Euclidean space neglect the uncertainty in the old embedding model and force the new model to reconstruct outdated representations regardless of their quality, thereby hindering the learning process of the new model. In this paper, we propose to switch perspectives to hyperbolic geometry, where we treat time as a natural axis for capturing a model's confidence and evolution. By lifting embeddings into hyperbolic space and constraining updated embeddings to lie within the entailment cone of the old ones, we maintain generational consistency across models while accounting for uncertainties in the representations. To further enhance compatibility, we introduce a robust contrastive alignment loss that dynamically adjusts alignment weights based on the uncertainty of the old embeddings. Experiments validate the superiority of the proposed method in achieving compatibility, paving the way for more resilient and adaptable machine learning systems.",
    "authors": [
      "Ngoc Bui, Menglin Yang, Runjin Chen, Leonardo Neves, Mingxuan Ju, Rex Ying, Neil Shah, Tong Zhao"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.836541"
  },
  {
    "id": "oai:arXiv.org:2506.05828v1",
    "journal": "arXiv_CS",
    "title": "FinanceReasoning: Benchmarking Financial Numerical Reasoning More Credible, Comprehensive and Challenging",
    "link": "https://arxiv.org/abs/2506.05828",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05828v1 Announce Type: new \nAbstract: We introduce FinanceReasoning, a novel benchmark designed to evaluate the reasoning capabilities of large reasoning models (LRMs) in financial numerical reasoning problems. Compared to existing benchmarks, our work provides three key advancements. (1) Credibility: We update 15.6% of the questions from four public datasets, annotating 908 new questions with detailed Python solutions and rigorously refining evaluation standards. This enables an accurate assessment of the reasoning improvements of LRMs. (2) Comprehensiveness: FinanceReasoning covers 67.8% of financial concepts and formulas, significantly surpassing existing datasets. Additionally, we construct 3,133 Python-formatted functions, which enhances LRMs' financial reasoning capabilities through refined knowledge (e.g., 83.2% $\\rightarrow$ 91.6% for GPT-4o). (3) Challenge: Models are required to apply multiple financial formulas for precise numerical reasoning on 238 Hard problems. The best-performing model (i.e., OpenAI o1 with PoT) achieves 89.1% accuracy, yet LRMs still face challenges in numerical precision. We demonstrate that combining Reasoner and Programmer models can effectively enhance LRMs' performance (e.g., 83.2% $\\rightarrow$ 87.8% for DeepSeek-R1). Our work paves the way for future research on evaluating and improving LRMs in domain-specific complex reasoning tasks.",
    "authors": [
      "Zichen Tang, Haihong E, Ziyan Ma, Haoyang He, Jiacheng Liu, Zhongjun Yang, Zihua Rong, Rongjin Li, Kun Ji, Qing Huang, Xinyang Hu, Yang Liu, Qianhe Zheng"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.836551"
  },
  {
    "id": "oai:arXiv.org:2506.05831v1",
    "journal": "arXiv_CS",
    "title": "Heartcare Suite: Multi-dimensional Understanding of ECG with Raw Multi-lead Signal Modeling",
    "link": "https://arxiv.org/abs/2506.05831",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05831v1 Announce Type: new \nAbstract: We present Heartcare Suite, a multimodal comprehensive framework for finegrained electrocardiogram (ECG) understanding. It comprises three key components: (i) Heartcare-220K, a high-quality, structured, and comprehensive multimodal ECG dataset covering essential tasks such as disease diagnosis, waveform morphology analysis, and rhythm interpretation. (ii) Heartcare-Bench, a systematic and multi-dimensional benchmark designed to evaluate diagnostic intelligence and guide the optimization of Medical Multimodal Large Language Models (Med-MLLMs) in ECG scenarios. and (iii) HeartcareGPT with a tailored tokenizer Bidirectional ECG Abstract Tokenization (Beat), which compresses raw multi-lead signals into semantically rich discrete tokens via duallevel vector quantization and query-guided bidirectional diffusion mechanism. Built upon Heartcare-220K, HeartcareGPT achieves strong generalization and SoTA performance across multiple clinically meaningful tasks. Extensive experiments demonstrate that Heartcare Suite is highly effective in advancing ECGspecific multimodal understanding and evaluation. Our project is available at https://github.com/Wznnnnn/Heartcare-Suite .",
    "authors": [
      "Yihan Xie, Sijing Li, Tianwei Lin, Zhuonan Wang, Chenglin Yang, Yu Zhong, Wenqiao Zhang, Haoyuan Li, Hao Jiang, Fengda Zhang, Qishan Chen, Jun Xiao, Yueting Zhuang, Beng Chin Ooi"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.836560"
  },
  {
    "id": "oai:arXiv.org:2506.05832v1",
    "journal": "arXiv_CS",
    "title": "Properties of UTxO Ledgers and Programs Implemented on Them",
    "link": "https://arxiv.org/abs/2506.05832",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05832v1 Announce Type: new \nAbstract: Trace-based properties are the gold standard for program behaviour analysis. One of the domains of application of this type of analysis is cryptocurrency ledgers, both for the purpose of analyzing the behaviour of the ledger itself, and any user-defined programs called by it, known as smart contracts. The (extended) UTxO ledger model is a kind of ledger model where all smart contract code is stateless, and additional work must be done to model stateful programs. We formalize the application of trace-based analysis to UTxO ledgers and contracts, expressing it in the languages of topology, as well as graph and category theory. To describe valid traces of UTxO ledger executions, and their relation to the behaviour of stateful programs implemented on the ledger, we define a category of simple graphs, infinite paths in which form an ultra-metric space. Maps in this category are arbitrary partial sieve-define homomorphisms of simple graphs. Programs implemented on the ledger correspond to non-expanding maps out of the graph of valid UTxO execution traces. We reason about safety properties in this framework, and prove properties of valid UTxO ledger traces.",
    "authors": [
      "Polina Vinogradova (Input Output Global), Alexey Sorokin (Input Output Global)"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.836568"
  },
  {
    "id": "oai:arXiv.org:2506.05833v1",
    "journal": "arXiv_CS",
    "title": "Fuzzy Lattice-based Description Logic",
    "link": "https://arxiv.org/abs/2506.05833",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05833v1 Announce Type: new \nAbstract: Recently, description logic LE-ALC was introduced for reasoning in the semantic environment of enriched formal contexts, and a polynomial-time tableaux algorithm was developed to check the consistency of knowledge bases with acyclic TBoxes. In this work, we introduce a fuzzy generalization of LE-ALC  called  LE-FALC which provides a description logic counterpart of many-valued normal non-distributive logic a.k.a. many-valued LE-logic. This description logic can be used to represent and reason about knowledge in the formal framework  of fuzzy formal contexts and fuzzy formal concepts. We provide a tableaux algorithm that provides a complete and sound polynomial-time decision procedure to check the consistency of  LE-FALC  ABoxes. As a result, we also obtain an exponential-time decision procedure for checking the consistency of  LE-FALC  with acyclic TBoxes by unraveling.",
    "authors": [
      "Yiwen Ding, Krishna Manoorkar"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.836576"
  },
  {
    "id": "oai:arXiv.org:2506.05834v1",
    "journal": "arXiv_CS",
    "title": "Regional, Lattice and Logical Representations of Neural Networks",
    "link": "https://arxiv.org/abs/2506.05834",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05834v1 Announce Type: new \nAbstract: A possible path to the interpretability of neural networks is to (approximately) represent them in the regional format of piecewise linear functions, where regions of inputs are associated to linear functions computing the network outputs. We present an algorithm for the translation of feedforward neural networks with ReLU activation functions in hidden layers and truncated identity activation functions in the output layer. We also empirically investigate the complexity of regional representations outputted by our method for neural networks with varying sizes. Lattice and logical representations of neural networks are straightforward from regional representations as long as they satisfy a specific property. So we empirically investigate to what extent the translations by our algorithm satisfy such property.",
    "authors": [
      "Sandro Preto (Federal University of ABC, Brazil), Marcelo Finger (University of Sao Paulo, Brazil)"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.836584"
  },
  {
    "id": "oai:arXiv.org:2506.05835v1",
    "journal": "arXiv_CS",
    "title": "Nominal Equational Rewriting and Narrowing",
    "link": "https://arxiv.org/abs/2506.05835",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05835v1 Announce Type: new \nAbstract: Narrowing is a well-known technique that adds to term rewriting mechanisms the required power to search for solutions to equational problems. Rewriting and narrowing are well-studied in first-order term languages, but several problems remain to be investigated when dealing with languages with binders using nominal techniques. Applications in programming languages and theorem proving require reasoning modulo alpha-equivalence considering structural congruences generated by equational axioms, such as commutativity.  This paper presents the first definitions of nominal rewriting and narrowing modulo an equational theory. We establish a property called nominal E-coherence and demonstrate its role in identifying normal forms of nominal terms. Additionally, we prove the nominal E-Lifting theorem, which ensures the correspondence between sequences of nominal equational rewriting steps and narrowing, crucial for developing a correct algorithm for nominal equational unification via nominal equational narrowing. We illustrate our results using the equational theory for commutativity.",
    "authors": [
      "Mauricio Ayala-Rinc\\'on (University of Bras\\'ilia, Brazil), Maribel Fern\\'andez (King's College London, UK), Daniele Nantes-Sobrinho (University of Bras\\'ilia, Brazil,Imperial College London, UK), Daniella Santaguida (University of Bras\\'ilia, Brazil)"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.836593"
  },
  {
    "id": "oai:arXiv.org:2506.05836v1",
    "journal": "arXiv_CS",
    "title": "Analysis of cost-efficiency of serverless approaches",
    "link": "https://arxiv.org/abs/2506.05836",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05836v1 Announce Type: new \nAbstract: In this paper, we present a survey of research studies related to the cost-effectiveness of serverless approach and corresponding cost savings. We conducted a systematic literature review using Google Scholar search engine, covering the period from 2010 to 2024. We identified 34 related studies, from which we extracted 17 parameters that might influence the relative cost savings of applying the serverless approach.",
    "authors": [
      "Nakhat Syeda, Harsh Shah, Rajvinder Singh, Suraj Jaju, Sumedha Kumar, Gourav Chhabra, Maria Spichkova"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.836601"
  },
  {
    "id": "oai:arXiv.org:2506.05837v1",
    "journal": "arXiv_CS",
    "title": "Towards an Analysis of Proofs in Arithmetic",
    "link": "https://arxiv.org/abs/2506.05837",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05837v1 Announce Type: new \nAbstract: Inductive proofs can be represented as proof schemata, i.e. as parameterized sequences of proofs defined in a primitive recursive way. Applications of proof schemata can be found in the area of automated proof analysis where the schemata admit (schematic) cut-elimination and the construction of Herbrand systems. This work focuses on the expressivity of proof schemata. We show that proof schemata can simulate primitive recursive arithmetic. The translation of proofs in arithmetic to proof schemata can be considered as a crucial step in the analysis of inductive proofs.",
    "authors": [
      "Alexander Leitsch, Anela Loli\\'c, Stella Mahler"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.836609"
  },
  {
    "id": "oai:arXiv.org:2506.05839v1",
    "journal": "arXiv_CS",
    "title": "An Execution Model for RICE",
    "link": "https://arxiv.org/abs/2506.05839",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05839v1 Announce Type: new \nAbstract: In this paper, we build on the previous work of the RICE compiler by giving its execution model.  We show the restrictions to the FlatCurry language that were made to produce executable code, and  present the execution model using operational semantics similar to Launchbury.  Finally, we show that the execution model conforms with the standard operational semantics for Curry.",
    "authors": [
      "Steven Libby"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.836618"
  },
  {
    "id": "oai:arXiv.org:2506.05840v1",
    "journal": "arXiv_CS",
    "title": "Paraconsistent Relations as a Variant of Kleene Algebras",
    "link": "https://arxiv.org/abs/2506.05840",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05840v1 Announce Type: new \nAbstract: Kleene algebras (KA) and Kleene algebras with tests (KAT) provide an algebraic framework to capture the behavior of conventional programming constructs. This paper explores a broader understanding of these structures, in order to enable the expression of programs and tests yielding vague or inconsistent outcomes. Within this context, we introduce the concept of a paraconsistent Kleene Algebra with tests (PKAT), capable of capturing vague and contradictory computations. Finally, to establish the semantics of such a structure, we introduce two algebras parametric on a class of twisted structures. We believe this sort of structures, for their huge flexibility, have an interesting application potential.",
    "authors": [
      "Juliana Cunha, Alexandre Madeira, Lu\\'is S. Barbosa"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.836626"
  },
  {
    "id": "oai:arXiv.org:2506.05843v1",
    "journal": "arXiv_CS",
    "title": "FontAdapter: Instant Font Adaptation in Visual Text Generation",
    "link": "https://arxiv.org/abs/2506.05843",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05843v1 Announce Type: new \nAbstract: Text-to-image diffusion models have significantly improved the seamless integration of visual text into diverse image contexts. Recent approaches further improve control over font styles through fine-tuning with predefined font dictionaries. However, adapting unseen fonts outside the preset is computationally expensive, often requiring tens of minutes, making real-time customization impractical. In this paper, we present FontAdapter, a framework that enables visual text generation in unseen fonts within seconds, conditioned on a reference glyph image. To this end, we find that direct training on font datasets fails to capture nuanced font attributes, limiting generalization to new glyphs. To overcome this, we propose a two-stage curriculum learning approach: FontAdapter first learns to extract font attributes from isolated glyphs and then integrates these styles into diverse natural backgrounds. To support this two-stage training scheme, we construct synthetic datasets tailored to each stage, leveraging large-scale online fonts effectively. Experiments demonstrate that FontAdapter enables high-quality, robust font customization across unseen fonts without additional fine-tuning during inference. Furthermore, it supports visual text editing, font style blending, and cross-lingual font transfer, positioning FontAdapter as a versatile framework for font customization tasks.",
    "authors": [
      "Myungkyu Koo, Subin Kim, Sangkyung Kwak, Jaehyun Nam, Seojin Kim, Jinwoo Shin"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.836635"
  },
  {
    "id": "oai:arXiv.org:2506.05844v1",
    "journal": "arXiv_CS",
    "title": "$\\text{C}^{2}\\text{BNVAE}$: Dual-Conditional Deep Generation of Network Traffic Data for Network Intrusion Detection System Balancing",
    "link": "https://arxiv.org/abs/2506.05844",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05844v1 Announce Type: new \nAbstract: Network Intrusion Detection Systems (NIDS) face challenges due to class imbalance, affecting their ability to detect novel and rare attacks. This paper proposes a Dual-Conditional Batch Normalization Variational Autoencoder ($\\text{C}^{2}\\text{BNVAE}$) for generating balanced and labeled network traffic data. $\\text{C}^{2}\\text{BNVAE}$ improves the model's adaptability to different data categories and generates realistic category-specific data by incorporating Conditional Batch Normalization (CBN) into the Conditional Variational Autoencoder (CVAE). Experiments on the NSL-KDD dataset show the potential of $\\text{C}^{2}\\text{BNVAE}$ in addressing imbalance and improving NIDS performance with lower computational overhead compared to some baselines.",
    "authors": [
      "Yifan Zeng"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.836645"
  },
  {
    "id": "oai:arXiv.org:2506.05850v1",
    "journal": "arXiv_CS",
    "title": "Cross-lingual Collapse: How Language-Centric Foundation Models Shape Reasoning in Large Language Models",
    "link": "https://arxiv.org/abs/2506.05850",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05850v1 Announce Type: new \nAbstract: We identify \\textbf{Cross-lingual Collapse}, a systematic drift in which the chain-of-thought (CoT) of a multilingual language model reverts to its dominant pre-training language even when the prompt is expressed in a different language. Recent large language models (LLMs) with reinforcement learning with verifiable reward (RLVR) have achieved strong logical reasoning performances by exposing their intermediate reasoning traces, giving rise to large reasoning models (LRMs). However, the mechanism behind multilingual reasoning in LRMs is not yet fully explored. To investigate the issue, we fine-tune multilingual LRMs with Group-Relative Policy Optimization (GRPO) on translated versions of the GSM$8$K and SimpleRL-Zoo datasets in three different languages: Chinese, Korean, and Ukrainian. During training, we monitor both task accuracy and language consistency of the reasoning chains. Our experiments reveal three key findings: (i) GRPO rapidly amplifies pre-training language imbalances, leading to the erosion of low-resource languages within just a few hundred updates; (ii) language consistency reward mitigates this drift but does so at the expense of an almost 5 - 10 pp drop in accuracy. and (iii) the resulting language collapse is severely damaging and largely irreversible, as subsequent fine-tuning struggles to steer the model back toward its original target-language reasoning capabilities. Together, these findings point to a remarkable conclusion: \\textit{not all languages are trained equally for reasoning}. Furthermore, our paper sheds light on the roles of reward shaping, data difficulty, and pre-training priors in eliciting multilingual reasoning.",
    "authors": [
      "Cheonbok Park, Jeonghoon Kim, Joosung Lee, Sanghwan Bae, Jaegul Choo, Kangmin Yoo"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.836654"
  },
  {
    "id": "oai:arXiv.org:2506.05851v1",
    "journal": "arXiv_CS",
    "title": "DeepFake Doctor: Diagnosing and Treating Audio-Video Fake Detection",
    "link": "https://arxiv.org/abs/2506.05851",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05851v1 Announce Type: new \nAbstract: Generative AI advances rapidly, allowing the creation of very realistic manipulated video and audio. This progress presents a significant security and ethical threat, as malicious users can exploit DeepFake techniques to spread misinformation. Recent DeepFake detection approaches explore the multimodal (audio-video) threat scenario. In particular, there is a lack of reproducibility and critical issues with existing datasets - such as the recently uncovered silence shortcut in the widely used FakeAVCeleb dataset. Considering the importance of this topic, we aim to gain a deeper understanding of the key issues affecting benchmarking in audio-video DeepFake detection. We examine these challenges through the lens of the three core benchmarking pillars: datasets, detection methods, and evaluation protocols. To address these issues, we spotlight the recent DeepSpeak v1 dataset and are the first to propose an evaluation protocol and benchmark it using SOTA models. We introduce SImple Multimodal BAseline (SIMBA), a competitive yet minimalistic approach that enables the exploration of diverse design choices. We also deepen insights into the issue of audio shortcuts and present a promising mitigation strategy. Finally, we analyze and enhance the evaluation scheme on the widely used FakeAVCeleb dataset. Our findings offer a way forward in the complex area of audio-video DeepFake detection.",
    "authors": [
      "Marcel Klemt, Carlotta Segna, Anna Rohrbach"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.836663"
  },
  {
    "id": "oai:arXiv.org:2506.05856v1",
    "journal": "arXiv_CS",
    "title": "Cross-View Multi-Modal Segmentation @ Ego-Exo4D Challenges 2025",
    "link": "https://arxiv.org/abs/2506.05856",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05856v1 Announce Type: new \nAbstract: In this report, we present a cross-view multi-modal object segmentation approach for the object correspondence task in the Ego-Exo4D Correspondence Challenges 2025. Given object queries from one perspective (e.g., ego view), the goal is to predict the corresponding object masks in another perspective (e.g., exo view). To tackle this task, we propose a multimodal condition fusion module that enhances object localization by leveraging both visual masks and textual descriptions as segmentation conditions. Furthermore, to address the visual domain gap between ego and exo views, we introduce a cross-view object alignment module that enforces object-level consistency across perspectives, thereby improving the model's robustness to viewpoint changes. Our proposed method ranked second on the leaderboard of the large-scale Ego-Exo4D object correspondence benchmark. Code will be made available at https://github.com/lovelyqian/ObjectRelator.",
    "authors": [
      "Yuqian Fu, Runze Wang, Yanwei Fu, Danda Pani Paudel, Luc Van Gool"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.836687"
  },
  {
    "id": "oai:arXiv.org:2506.05857v1",
    "journal": "arXiv_CS",
    "title": "Wavelet-based Disentangled Adaptive Normalization for Non-stationary Times Series Forecasting",
    "link": "https://arxiv.org/abs/2506.05857",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05857v1 Announce Type: new \nAbstract: Forecasting non-stationary time series is a challenging task because their statistical properties often change over time, making it hard for deep models to generalize well. Instance-level normalization techniques can help address shifts in temporal distribution. However, most existing methods overlook the multi-component nature of time series, where different components exhibit distinct non-stationary behaviors. In this paper, we propose Wavelet-based Disentangled Adaptive Normalization (WDAN), a model-agnostic framework designed to address non-stationarity in time series forecasting. WDAN uses discrete wavelet transforms to break down the input into low-frequency trends and high-frequency fluctuations. It then applies tailored normalization strategies to each part. For trend components that exhibit strong non-stationarity, we apply first-order differencing to extract stable features used for predicting normalization parameters. Extensive experiments on multiple benchmarks demonstrate that WDAN consistently improves forecasting accuracy across various backbone model. Code is available at this repository: https://github.com/MonBG/WDAN.",
    "authors": [
      "Junpeng Lin, Tian Lan, Bo Zhang, Ke Lin, Dandan Miao, Huiru He, Jiantao Ye, Chen Zhang, Yan-fu Li"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.836696"
  },
  {
    "id": "oai:arXiv.org:2506.05862v1",
    "journal": "arXiv_CS",
    "title": "Improved Allergy Wheal Detection for the Skin Prick Automated Test Device",
    "link": "https://arxiv.org/abs/2506.05862",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05862v1 Announce Type: new \nAbstract: Background: The skin prick test (SPT) is the gold standard for diagnosing sensitization to inhalant allergies. The Skin Prick Automated Test (SPAT) device was designed for increased consistency in test results, and captures 32 images to be jointly used for allergy wheal detection and delineation, which leads to a diagnosis.\n  Materials and Methods: Using SPAT data from $868$ patients with suspected inhalant allergies, we designed an automated method to detect and delineate wheals on these images. To this end, $10,416$ wheals were manually annotated by drawing detailed polygons along the edges. The unique data-modality of the SPAT device, with $32$ images taken under distinct lighting conditions, requires a custom-made approach. Our proposed method consists of two parts: a neural network component that segments the wheals on the pixel level, followed by an algorithmic and interpretable approach for detecting and delineating the wheals.\n  Results: We evaluate the performance of our method on a hold-out validation set of $217$ patients. As a baseline we use a single conventionally lighted image per SPT as input to our method.\n  Conclusion: Using the $32$ SPAT images under various lighting conditions offers a considerably higher accuracy than a single image in conventional, uniform light.",
    "authors": [
      "Rembert Daems, Sven Seys, Val\\'erie Hox, Adam Chaker, Glynnis De Greve, Winde Lemmens, Anne-Lise Poirrier, Eline Beckers, Zuzana Diamant, Carmen Dierickx, Peter W. Hellings, Caroline Huart, Claudia Jerin, Mark Jorissen, Hanne Osc\\'e, Karolien Roux, Mark Thompson, Sophie Tombu, Saartje Uyttebroek, Andrzej Zarowski, Senne Gorris, Laura Van Gerven, Dirk Loeckx, Thomas Demeester"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.836711"
  },
  {
    "id": "oai:arXiv.org:2506.05864v1",
    "journal": "arXiv_CS",
    "title": "CryoFastAR: Fast Cryo-EM Ab Initio Reconstruction Made Easy",
    "link": "https://arxiv.org/abs/2506.05864",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05864v1 Announce Type: new \nAbstract: Pose estimation from unordered images is fundamental for 3D reconstruction, robotics, and scientific imaging. Recent geometric foundation models, such as DUSt3R, enable end-to-end dense 3D reconstruction but remain underexplored in scientific imaging fields like cryo-electron microscopy (cryo-EM) for near-atomic protein reconstruction. In cryo-EM, pose estimation and 3D reconstruction from unordered particle images still depend on time-consuming iterative optimization, primarily due to challenges such as low signal-to-noise ratios (SNR) and distortions from the contrast transfer function (CTF). We introduce CryoFastAR, the first geometric foundation model that can directly predict poses from Cryo-EM noisy images for Fast ab initio Reconstruction. By integrating multi-view features and training on large-scale simulated cryo-EM data with realistic noise and CTF modulations, CryoFastAR enhances pose estimation accuracy and generalization. To enhance training stability, we propose a progressive training strategy that first allows the model to extract essential features under simpler conditions before gradually increasing difficulty to improve robustness. Experiments show that CryoFastAR achieves comparable quality while significantly accelerating inference over traditional iterative approaches on both synthetic and real datasets.",
    "authors": [
      "Jiakai Zhang, Shouchen Zhou, Haizhao Dai, Xinhang Liu, Peihao Wang, Zhiwen Fan, Yuan Pei, Jingyi Yu"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.836720"
  },
  {
    "id": "oai:arXiv.org:2506.05867v1",
    "journal": "arXiv_CS",
    "title": "Stealix: Model Stealing via Prompt Evolution",
    "link": "https://arxiv.org/abs/2506.05867",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05867v1 Announce Type: new \nAbstract: Model stealing poses a significant security risk in machine learning by enabling attackers to replicate a black-box model without access to its training data, thus jeopardizing intellectual property and exposing sensitive information. Recent methods that use pre-trained diffusion models for data synthesis improve efficiency and performance but rely heavily on manually crafted prompts, limiting automation and scalability, especially for attackers with little expertise. To assess the risks posed by open-source pre-trained models, we propose a more realistic threat model that eliminates the need for prompt design skills or knowledge of class names. In this context, we introduce Stealix, the first approach to perform model stealing without predefined prompts. Stealix uses two open-source pre-trained models to infer the victim model's data distribution, and iteratively refines prompts through a genetic algorithm, progressively improving the precision and diversity of synthetic images. Our experimental results demonstrate that Stealix significantly outperforms other methods, even those with access to class names or fine-grained prompts, while operating under the same query budget. These findings highlight the scalability of our approach and suggest that the risks posed by pre-trained generative models in model stealing may be greater than previously recognized.",
    "authors": [
      "Zhixiong Zhuang, Hui-Po Wang, Maria-Irina Nicolae, Mario Fritz"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.836728"
  },
  {
    "id": "oai:arXiv.org:2506.05868v1",
    "journal": "arXiv_CS",
    "title": "Detecting Coordination on Short-Video Platforms: The Challenge of Multimodality and Complex Similarity on TikTok",
    "link": "https://arxiv.org/abs/2506.05868",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05868v1 Announce Type: new \nAbstract: Research on online coordinated behaviour has predominantly focused on text-based social media platforms, where coordination manifests clearly through the frequent posting of identical hyperlinks or the frequent re-sharing of the same textual content by the same group of users. However, the rise of short-video platforms like TikTok introduces distinct challenges, by supporting integrated multimodality within posts and complex similarity between them. In this paper, we propose an approach to detecting coordination that addresses these characteristic challenges. Our methodology, based on multilayer network analysis, is tailored to capture coordination across multiple modalities, including video, audio, and text, and explicitly handles complex forms of similarity inherent in video and audio content. We test this approach on political videos posted on TikTok and extracted via the TikTok researcher API. This application demonstrates the capacity of the approach to identify coordination, while also critically highlighting potential pitfalls and limitations.",
    "authors": [
      "Inga K. Wohlert, Davide Vega, Matteo Magnani, Alexandra Sergerberg"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.836738"
  },
  {
    "id": "oai:arXiv.org:2506.05869v1",
    "journal": "arXiv_CS",
    "title": "Loss Functions for Predictor-based Neural Architecture Search",
    "link": "https://arxiv.org/abs/2506.05869",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05869v1 Announce Type: new \nAbstract: Evaluation is a critical but costly procedure in neural architecture search (NAS). Performance predictors have been widely adopted to reduce evaluation costs by directly estimating architecture performance. The effectiveness of predictors is heavily influenced by the choice of loss functions. While traditional predictors employ regression loss functions to evaluate the absolute accuracy of architectures, recent approaches have explored various ranking-based loss functions, such as pairwise and listwise ranking losses, to focus on the ranking of architecture performance. Despite their success in NAS, the effectiveness and characteristics of these loss functions have not been thoroughly investigated. In this paper, we conduct the first comprehensive study on loss functions in performance predictors, categorizing them into three main types: regression, ranking, and weighted loss functions. Specifically, we assess eight loss functions using a range of NAS-relevant metrics on 13 tasks across five search spaces. Our results reveal that specific categories of loss functions can be effectively combined to enhance predictor-based NAS. Furthermore, our findings could provide practical guidance for selecting appropriate loss functions for various tasks. We hope this work provides meaningful insights to guide the development of loss functions for predictor-based methods in the NAS community.",
    "authors": [
      "Han Ji, Yuqi Feng, Jiahao Fan, Yanan Sun"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.836746"
  },
  {
    "id": "oai:arXiv.org:2506.05871v1",
    "journal": "arXiv_CS",
    "title": "BestServe: Serving Strategies with Optimal Goodput in Collocation and Disaggregation Architectures",
    "link": "https://arxiv.org/abs/2506.05871",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05871v1 Announce Type: new \nAbstract: Serving large language models (LLMs) to millions of users requires efficient resource allocation and parallelism strategies. It is a labor intensive trial-and-error process to find such a strategy. We present BestServe, a novel framework for ranking serving strategies by estimating goodput under various operating scenarios. Supporting both collocated and disaggregated architectures, BestServe leverages an inference simulator built on an adapted roofline model and CPU-GPU dispatch dynamics. Our framework determines the optimal strategy in minutes on a single standard CPU, eliminating the need for costly benchmarking, while achieving predictions within a $20\\%$ error margin. It appeals to be practical for rapid deployment planning because of its lightweight design and strong extensibility.",
    "authors": [
      "Xiannan Hu, Tianyou Zeng, Xiaoming Yuan, Liwei Song, Guangyuan Zhang, Bangzheng He"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.836755"
  },
  {
    "id": "oai:arXiv.org:2506.05873v1",
    "journal": "arXiv_CS",
    "title": "Research on Personalized Financial Product Recommendation by Integrating Large Language Models and Graph Neural Networks",
    "link": "https://arxiv.org/abs/2506.05873",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05873v1 Announce Type: new \nAbstract: With the rapid growth of fintech, personalized financial product recommendations have become increasingly important. Traditional methods like collaborative filtering or content-based models often fail to capture users' latent preferences and complex relationships. We propose a hybrid framework integrating large language models (LLMs) and graph neural networks (GNNs). A pre-trained LLM encodes text data (e.g., user reviews) into rich feature vectors, while a heterogeneous user-product graph models interactions and social ties. Through a tailored message-passing mechanism, text and graph information are fused within the GNN to jointly optimize embeddings. Experiments on public and real-world financial datasets show our model outperforms standalone LLM or GNN in accuracy, recall, and NDCG, with strong interpretability. This work offers new insights for personalized financial recommendations and cross-modal fusion in broader recommendation tasks.",
    "authors": [
      "Yushang Zhao, Yike Peng, Dannier Li, Yuxin Yang, Chengrui Zhou, Jing Dong"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.836772"
  },
  {
    "id": "oai:arXiv.org:2506.05877v1",
    "journal": "arXiv_CS",
    "title": "Interpretable Clustering Ensemble",
    "link": "https://arxiv.org/abs/2506.05877",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05877v1 Announce Type: new \nAbstract: Clustering ensemble has emerged as an important research topic in the field of machine learning. Although numerous methods have been proposed to improve clustering quality, most existing approaches overlook the need for interpretability in high-stakes applications. In domains such as medical diagnosis and financial risk assessment, algorithms must not only be accurate but also interpretable to ensure transparent and trustworthy decision-making. Therefore, to fill the gap of lack of interpretable algorithms in the field of clustering ensemble, we propose the first interpretable clustering ensemble algorithm in the literature. By treating base partitions as categorical variables, our method constructs a decision tree in the original feature space and use the statistical association test to guide the tree building process. Experimental results demonstrate that our algorithm achieves comparable performance to state-of-the-art (SOTA) clustering ensemble methods while maintaining an additional feature of interpretability. To the best of our knowledge, this is the first interpretable algorithm specifically designed for clustering ensemble, offering a new perspective for future research in interpretable clustering.",
    "authors": [
      "Hang Lv, Lianyu Hu, Mudi Jiang, Xinying Liu, Zengyou He"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.836788"
  },
  {
    "id": "oai:arXiv.org:2506.05878v1",
    "journal": "arXiv_CS",
    "title": "A projection-based framework for gradient-free and parallel learning",
    "link": "https://arxiv.org/abs/2506.05878",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05878v1 Announce Type: new \nAbstract: We present a feasibility-seeking approach to neural network training. This mathematical optimization framework is distinct from conventional gradient-based loss minimization and uses projection operators and iterative projection algorithms. We reformulate training as a large-scale feasibility problem: finding network parameters and states that satisfy local constraints derived from its elementary operations. Training then involves projecting onto these constraints, a local operation that can be parallelized across the network. We introduce PJAX, a JAX-based software framework that enables this paradigm. PJAX composes projection operators for elementary operations, automatically deriving the solution operators for the feasibility problems (akin to autodiff for derivatives). It inherently supports GPU/TPU acceleration, provides a familiar NumPy-like API, and is extensible. We train diverse architectures (MLPs, CNNs, RNNs) on standard benchmarks using PJAX, demonstrating its functionality and generality. Our results show that this approach is as a compelling alternative to gradient-based training, with clear advantages in parallelism and the ability to handle non-differentiable operations.",
    "authors": [
      "Andreas Bergmeister, Manish Krishan Lal, Stefanie Jegelka, Suvrit Sra"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.836796"
  },
  {
    "id": "oai:arXiv.org:2506.05880v1",
    "journal": "arXiv_CS",
    "title": "NILMFormer: Non-Intrusive Load Monitoring that Accounts for Non-Stationarity",
    "link": "https://arxiv.org/abs/2506.05880",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05880v1 Announce Type: new \nAbstract: Millions of smart meters have been deployed worldwide, collecting the total power consumed by individual households. Based on these data, electricity suppliers offer their clients energy monitoring solutions to provide feedback on the consumption of their individual appliances. Historically, such estimates have relied on statistical methods that use coarse-grained total monthly consumption and static customer data, such as appliance ownership. Non-Intrusive Load Monitoring (NILM) is the problem of disaggregating a household's collected total power consumption to retrieve the consumed power for individual appliances. Current state-of-the-art (SotA) solutions for NILM are based on deep-learning (DL) and operate on subsequences of an entire household consumption reading. However, the non-stationary nature of real-world smart meter data leads to a drift in the data distribution within each segmented window, which significantly affects model performance. This paper introduces NILMFormer, a Transformer-based architecture that incorporates a new subsequence stationarization/de-stationarization scheme to mitigate the distribution drift and that uses a novel positional encoding that relies only on the subsequence's timestamp information. Experiments with 4 real-world datasets show that NILMFormer significantly outperforms the SotA approaches. Our solution has been deployed as the backbone algorithm for EDF's (Electricit\\'e De France) consumption monitoring service, delivering detailed insights to millions of customers about their individual appliances' power consumption. This paper appeared in KDD 2025.",
    "authors": [
      "Adrien Petralia, Philippe Charpentier, Youssef Kadhi, Themis Palpanas"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.836813"
  },
  {
    "id": "oai:arXiv.org:2506.05886v1",
    "journal": "arXiv_CS",
    "title": "Inf-sup stable space-time discretization of the wave equation based on a first-order-in-time variational formulation",
    "link": "https://arxiv.org/abs/2506.05886",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05886v1 Announce Type: new \nAbstract: In this paper, we present a conforming space-time discretization of the wave equation based on a first-order-in-time variational formulation with exponential weights in time. We analyze the method, showing its stability without imposing any restrictions on the mesh size or time step, and proving quasi-optimal convergence for any choice of space-time tensor product discrete spaces that satisfies standard approximation assumptions. Numerical examples are provided to support the theoretical findings.",
    "authors": [
      "Matteo Ferrari, Ilaria Perugia, Enrico Zampa"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.836829"
  },
  {
    "id": "oai:arXiv.org:2506.05890v1",
    "journal": "arXiv_CS",
    "title": "Unleashing the Potential of Consistency Learning for Detecting and Grounding Multi-Modal Media Manipulation",
    "link": "https://arxiv.org/abs/2506.05890",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05890v1 Announce Type: new \nAbstract: To tackle the threat of fake news, the task of detecting and grounding multi-modal media manipulation DGM4 has received increasing attention. However, most state-of-the-art methods fail to explore the fine-grained consistency within local content, usually resulting in an inadequate perception of detailed forgery and unreliable results. In this paper, we propose a novel approach named Contextual-Semantic Consistency Learning (CSCL) to enhance the fine-grained perception ability of forgery for DGM4. Two branches for image and text modalities are established, each of which contains two cascaded decoders, i.e., Contextual Consistency Decoder (CCD) and Semantic Consistency Decoder (SCD), to capture within-modality contextual consistency and across-modality semantic consistency, respectively. Both CCD and SCD adhere to the same criteria for capturing fine-grained forgery details. To be specific, each module first constructs consistency features by leveraging additional supervision from the heterogeneous information of each token pair. Then, the forgery-aware reasoning or aggregating is adopted to deeply seek forgery cues based on the consistency features. Extensive experiments on DGM4 datasets prove that CSCL achieves new state-of-the-art performance, especially for the results of grounding manipulated content. Codes and weights are avaliable at https://github.com/liyih/CSCL.",
    "authors": [
      "Yiheng Li, Yang Yang, Zichang Tan, Huan Liu, Weihua Chen, Xu Zhou, Zhen Lei"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.836846"
  },
  {
    "id": "oai:arXiv.org:2506.05891v1",
    "journal": "arXiv_CS",
    "title": "WAKE: Watermarking Audio with Key Enrichment",
    "link": "https://arxiv.org/abs/2506.05891",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05891v1 Announce Type: new \nAbstract: As deep learning advances in audio generation, challenges in audio security and copyright protection highlight the need for robust audio watermarking. Recent neural network-based methods have made progress but still face three main issues: preventing unauthorized access, decoding initial watermarks after multiple embeddings, and embedding varying lengths of watermarks. To address these issues, we propose WAKE, the first key-controllable audio watermark framework. WAKE embeds watermarks using specific keys and recovers them with corresponding keys, enhancing security by making incorrect key decoding impossible. It also resolves the overwriting issue by allowing watermark decoding after multiple embeddings and supports variable-length watermark insertion. WAKE outperforms existing models in both watermarked audio quality and watermark detection accuracy. Code, more results, and demo page: https://thuhcsi.github.io/WAKE.",
    "authors": [
      "Yaoxun Xu, Jianwei Yu, Hangting Chen, Zhiyong Wu, Xixin Wu, Dong Yu, Rongzhi Gu, Yi Luo"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.836854"
  },
  {
    "id": "oai:arXiv.org:2506.05895v1",
    "journal": "arXiv_CS",
    "title": "Few Labels are all you need: A Weakly Supervised Framework for Appliance Localization in Smart-Meter Series",
    "link": "https://arxiv.org/abs/2506.05895",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05895v1 Announce Type: new \nAbstract: Improving smart grid system management is crucial in the fight against climate change, and enabling consumers to play an active role in this effort is a significant challenge for electricity suppliers. In this regard, millions of smart meters have been deployed worldwide in the last decade, recording the main electricity power consumed in individual households. This data produces valuable information that can help them reduce their electricity footprint; nevertheless, the collected signal aggregates the consumption of the different appliances running simultaneously in the house, making it difficult to apprehend. Non-Intrusive Load Monitoring (NILM) refers to the challenge of estimating the power consumption, pattern, or on/off state activation of individual appliances using the main smart meter signal. Recent methods proposed to tackle this task are based on a fully supervised deep-learning approach that requires both the aggregate signal and the ground truth of individual appliance power. However, such labels are expensive to collect and extremely scarce in practice, as they require conducting intrusive surveys in households to monitor each appliance. In this paper, we introduce CamAL, a weakly supervised approach for appliance pattern localization that only requires information on the presence of an appliance in a household to be trained. CamAL merges an ensemble of deep-learning classifiers combined with an explainable classification method to be able to localize appliance patterns. Our experimental evaluation, conducted on 4 real-world datasets, demonstrates that CamAL significantly outperforms existing weakly supervised baselines and that current SotA fully supervised NILM approaches require significantly more labels to reach CamAL performances. The source of our experiments is available at: https://github.com/adrienpetralia/CamAL. This paper appeared in ICDE 2025.",
    "authors": [
      "Adrien Petralia, Paul Boniol, Philippe Charpentier, Themis Palpanas"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.836870"
  },
  {
    "id": "oai:arXiv.org:2506.05896v1",
    "journal": "arXiv_CS",
    "title": "Object Navigation with Structure-Semantic Reasoning-Based Multi-level Map and Multimodal Decision-Making LLM",
    "link": "https://arxiv.org/abs/2506.05896",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05896v1 Announce Type: new \nAbstract: The zero-shot object navigation (ZSON) in unknown open-ended environments coupled with semantically novel target often suffers from the significant decline in performance due to the neglect of high-dimensional implicit scene information and the long-range target searching task. To address this, we proposed an active object navigation framework with Environmental Attributes Map (EAM) and MLLM Hierarchical Reasoning module (MHR) to improve its success rate and efficiency. EAM is constructed by reasoning observed environments with SBERT and predicting unobserved ones with Diffusion, utilizing human space regularities that underlie object-room correlations and area adjacencies. MHR is inspired by EAM to perform frontier exploration decision-making, avoiding the circuitous trajectories in long-range scenarios to improve path efficiency. Experimental results demonstrate that the EAM module achieves 64.5\\% scene mapping accuracy on MP3D dataset, while the navigation task attains SPLs of 28.4\\% and 26.3\\% on HM3D and MP3D benchmarks respectively - representing absolute improvements of 21.4\\% and 46.0\\% over baseline methods.",
    "authors": [
      "Chongshang Yan, Jiaxuan He, Delun Li, Yi Yang, Wenjie Song"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.836879"
  },
  {
    "id": "oai:arXiv.org:2506.05897v1",
    "journal": "arXiv_CS",
    "title": "Query Nearby: Offset-Adjusted Mask2Former enhances small-organ segmentation",
    "link": "https://arxiv.org/abs/2506.05897",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05897v1 Announce Type: new \nAbstract: Medical segmentation plays an important role in clinical applications like radiation therapy and surgical guidance, but acquiring clinically acceptable results is difficult. In recent years, progress has been witnessed with the success of utilizing transformer-like models, such as combining the attention mechanism with CNN. In particular, transformer-based segmentation models can extract global information more effectively, compensating for the drawbacks of CNN modules that focus on local features. However, utilizing transformer architecture is not easy, because training transformer-based models can be resource-demanding. Moreover, due to the distinct characteristics in the medical field, especially when encountering mid-sized and small organs with compact regions, their results often seem unsatisfactory. For example, using ViT to segment medical images directly only gives a DSC of less than 50\\%, which is far lower than the clinically acceptable score of 80\\%. In this paper, we used Mask2Former with deformable attention to reduce computation and proposed offset adjustment strategies to encourage sampling points within the same organs during attention weights computation, thereby integrating compact foreground information better. Additionally, we utilized the 4th feature map in Mask2Former to provide a coarse location of organs, and employed an FCN-based auxiliary head to help train Mask2Former more quickly using Dice loss. We show that our model achieves SOTA (State-of-the-Art) performance on the HaNSeg and SegRap2023 datasets, especially on mid-sized and small organs.Our code is available at link https://github.com/earis/Offsetadjustment\\_Background-location\\_Decoder\\_Mask2former.",
    "authors": [
      "Xin Zhang, Dongdong Meng, Sheng Li"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.836888"
  },
  {
    "id": "oai:arXiv.org:2506.05899v1",
    "journal": "arXiv_CS",
    "title": "WhisQ: Cross-Modal Representation Learning for Text-to-Music MOS Prediction",
    "link": "https://arxiv.org/abs/2506.05899",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05899v1 Announce Type: new \nAbstract: Mean Opinion Score (MOS) prediction for text to music systems requires evaluating both overall musical quality and text prompt alignment. This paper introduces WhisQ, a multimodal architecture that addresses this dual-assessment challenge through sequence level co-attention and optimal transport regularization. WhisQ employs the Whisper Base pretrained model for temporal audio encoding and Qwen 3, a 0.6B Small Language Model (SLM), for text encoding, with both maintaining sequence structure for fine grained cross-modal modeling. The architecture features specialized prediction pathways: OMQ is predicted from pooled audio embeddings, while TA leverages bidirectional sequence co-attention between audio and text. Sinkhorn optimal transport loss further enforce semantic alignment in the shared embedding space. On the MusicEval Track-1 dataset, WhisQ achieves substantial improvements over the baseline: 7% improvement in Spearman correlation for OMQ and 14% for TA. Ablation studies reveal that optimal transport regularization provides the largest performance gain (10% SRCC improvement), demonstrating the importance of explicit cross-modal alignment for text-to-music evaluation.",
    "authors": [
      "Jakaria Islam Emon, Kazi Tamanna Alam, Md. Abu Salek"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.836896"
  },
  {
    "id": "oai:arXiv.org:2506.05900v1",
    "journal": "arXiv_CS",
    "title": "Differentially Private Explanations for Clusters",
    "link": "https://arxiv.org/abs/2506.05900",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05900v1 Announce Type: new \nAbstract: The dire need to protect sensitive data has led to various flavors of privacy definitions. Among these, Differential privacy (DP) is considered one of the most rigorous and secure notions of privacy, enabling data analysis while preserving the privacy of data contributors. One of the fundamental tasks of data analysis is clustering , which is meant to unravel hidden patterns within complex datasets. However, interpreting clustering results poses significant challenges, and often necessitates an extensive analytical process. Interpreting clustering results under DP is even more challenging, as analysts are provided with noisy responses to queries, and longer, manual exploration sessions require additional noise to meet privacy constraints. While increasing attention has been given to clustering explanation frameworks that aim at assisting analysts by automatically uncovering the characteristics of each cluster, such frameworks may also disclose sensitive information within the dataset, leading to a breach in privacy. To address these challenges, we present DPClustX, a framework that provides explanations for black-box clustering results while satisfying DP. DPClustX takes as input the sensitive dataset alongside privately computed clustering labels, and outputs a global explanation, emphasizing prominent characteristics of each cluster while guaranteeing DP. We perform an extensive experimental analysis of DPClustX on real data, showing that it provides insightful and accurate explanations even under tight privacy constraints.",
    "authors": [
      "Amir Gilad, Tova Milo, Kathy Razmadze, Ron Zadicario"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.836904"
  },
  {
    "id": "oai:arXiv.org:2506.05901v1",
    "journal": "arXiv_CS",
    "title": "Route-and-Reason: Scaling Large Language Model Reasoning with Reinforced Model Router",
    "link": "https://arxiv.org/abs/2506.05901",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05901v1 Announce Type: new \nAbstract: Multi-step reasoning has proven essential for enhancing the problem-solving capabilities of Large Language Models (LLMs) by decomposing complex tasks into intermediate steps, either explicitly or implicitly. Extending the reasoning chain at test time through deeper thought processes or broader exploration, can furthur improve performance, but often incurs substantial costs due to the explosion in token usage. Yet, many reasoning steps are relatively simple and can be handled by more efficient smaller-scale language models (SLMs). This motivates hybrid approaches that allocate subtasks across models of varying capacities. However, realizing such collaboration requires accurate task decomposition and difficulty-aware subtask allocation, which is challenging. To address this, we propose R2-Reasoner, a novel framework that enables collaborative reasoning across heterogeneous LLMs by dynamically routing sub-tasks based on estimated complexity. At the core of our framework is a Reinforced Model Router, composed of a task decomposer and a subtask allocator. The task decomposer segments complex input queries into logically ordered subtasks, while the subtask allocator assigns each subtask to the most appropriate model, ranging from lightweight SLMs to powerful LLMs, balancing accuracy and efficiency. To train this router, we introduce a staged pipeline that combines supervised fine-tuning on task-specific datasets with Group Relative Policy Optimization algorithm, enabling self-supervised refinement through iterative reinforcement learning. Extensive experiments across four challenging benchmarks demonstrate that R2-Reasoner reduces API costs by 86.85% while maintaining or surpassing baseline accuracy. Our framework paves the way for more cost-effective and adaptive LLM reasoning. The code is open-source at https://anonymous.4open.science/r/R2_Reasoner .",
    "authors": [
      "Chenyang Shao, Xinyang Liu, Yutang Lin, Fengli Xu, Yong Li"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.836914"
  },
  {
    "id": "oai:arXiv.org:2506.05902v1",
    "journal": "arXiv_CS",
    "title": "A Driving Regime-Embedded Deep Learning Framework for Modeling Intra-Driver Heterogeneity in Multi-Scale Car-Following Dynamics",
    "link": "https://arxiv.org/abs/2506.05902",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05902v1 Announce Type: new \nAbstract: A fundamental challenge in car-following modeling lies in accurately representing the multi-scale complexity of driving behaviors, particularly the intra-driver heterogeneity where a single driver's actions fluctuate dynamically under varying conditions. While existing models, both conventional and data-driven, address behavioral heterogeneity to some extent, they often emphasize inter-driver heterogeneity or rely on simplified assumptions, limiting their ability to capture the dynamic heterogeneity of a single driver under different driving conditions. To address this gap, we propose a novel data-driven car-following framework that systematically embeds discrete driving regimes (e.g., steady-state following, acceleration, cruising) into vehicular motion predictions. Leveraging high-resolution traffic trajectory datasets, the proposed hybrid deep learning architecture combines Gated Recurrent Units for discrete driving regime classification with Long Short-Term Memory networks for continuous kinematic prediction, unifying discrete decision-making processes and continuous vehicular dynamics to comprehensively represent inter- and intra-driver heterogeneity. Driving regimes are identified using a bottom-up segmentation algorithm and Dynamic Time Warping, ensuring robust characterization of behavioral states across diverse traffic scenarios. Comparative analyses demonstrate that the framework significantly reduces prediction errors for acceleration (maximum MSE improvement reached 58.47\\%), speed, and spacing metrics while reproducing critical traffic phenomena, such as stop-and-go wave propagation and oscillatory dynamics.",
    "authors": [
      "Shirui Zhou, Jiying Yan, Junfang Tian, Tao Wang, Yongfu Li, Shiquan Zhong"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.836924"
  },
  {
    "id": "oai:arXiv.org:2506.05903v1",
    "journal": "arXiv_CS",
    "title": "The NetMob25 Dataset: A High-resolution Multi-layered View of Individual Mobility in Greater Paris Region",
    "link": "https://arxiv.org/abs/2506.05903",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05903v1 Announce Type: new \nAbstract: High-quality mobility data remains scarce despite growing interest from researchers and urban stakeholders in understanding individual-level movement patterns. The Netmob25 Data Challenge addresses this gap by releasing a unique GPS-based mobility dataset derived from the EMG 2023 GNSS-based mobility survey conducted in the Ile-de-France region (Greater Paris area), France. This dataset captures detailed daily mobility over a full week for 3,337 volunteer residents aged 16 to 80, collected between October 2022 and May 2023. Each participant was equipped with a dedicated GPS tracking device configured to record location points every 2-3 seconds and was asked to maintain a digital or paper logbook of their trips. All inferred mobility traces were algorithmically processed and validated through follow-up phone interviews.\n  The dataset includes three components: (i) an Individuals database describing demographic, socioeconomic, and household characteristics; (ii) a Trips database with over 80,000 annotated displacements including timestamps, transport modes, and trip purposes; and (iii) a Raw GPS Traces database comprising about 500 million high-frequency points. A statistical weighting mechanism is provided to support population-level estimates. An extensive anonymization pipeline was applied to the GPS traces to ensure GDPR compliance while preserving analytical value. Access to the dataset requires acceptance of the challenge's Terms and Conditions and signing a Non-Disclosure Agreement. This paper describes the survey design, collection protocol, processing methodology, and characteristics of the released dataset.",
    "authors": [
      "Alexandre Chasse, Anne J. Kouam, Aline C. Viana, Razvan Stanica, Wellington V. Lobato, Geymerson Ramos, Geoffrey Deperle, Abdelmounaim Bouroudi, Suzanne Bussod, Fernando Molano"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.836933"
  },
  {
    "id": "oai:arXiv.org:2506.05904v1",
    "journal": "arXiv_CS",
    "title": "Proactive Assistant Dialogue Generation from Streaming Egocentric Videos",
    "link": "https://arxiv.org/abs/2506.05904",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05904v1 Announce Type: new \nAbstract: Recent advances in conversational AI have been substantial, but developing real-time systems for perceptual task guidance remains challenging. These systems must provide interactive, proactive assistance based on streaming visual inputs, yet their development is constrained by the costly and labor-intensive process of data collection and system evaluation. To address these limitations, we present a comprehensive framework with three key contributions. First, we introduce a novel data curation pipeline that synthesizes dialogues from annotated egocentric videos, resulting in \\dataset, a large-scale synthetic dialogue dataset spanning multiple domains. Second, we develop a suite of automatic evaluation metrics, validated through extensive human studies. Third, we propose an end-to-end model that processes streaming video inputs to generate contextually appropriate responses, incorporating novel techniques for handling data imbalance and long-duration videos. This work lays the foundation for developing real-time, proactive AI assistants capable of guiding users through diverse tasks. Project page: https://pro-assist.github.io/",
    "authors": [
      "Yichi Zhang, Xin Luna Dong, Zhaojiang Lin, Andrea Madotto, Anuj Kumar, Babak Damavandi, Joyce Chai, Seungwhan Moon"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.836941"
  },
  {
    "id": "oai:arXiv.org:2506.05908v1",
    "journal": "arXiv_CS",
    "title": "QualitEye: Public and Privacy-preserving Gaze Data Quality Verification",
    "link": "https://arxiv.org/abs/2506.05908",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05908v1 Announce Type: new \nAbstract: Gaze-based applications are increasingly advancing with the availability of large datasets but ensuring data quality presents a substantial challenge when collecting data at scale. It further requires different parties to collaborate, therefore, privacy concerns arise. We propose QualitEye--the first method for verifying image-based gaze data quality. QualitEye employs a new semantic representation of eye images that contains the information required for verification while excluding irrelevant information for better domain adaptation. QualitEye covers a public setting where parties can freely exchange data and a privacy-preserving setting where parties cannot reveal their raw data nor derive gaze features/labels of others with adapted private set intersection protocols. We evaluate QualitEye on the MPIIFaceGaze and GazeCapture datasets and achieve a high verification performance (with a small overhead in runtime for privacy-preserving versions). Hence, QualitEye paves the way for new gaze analysis methods at the intersection of machine learning, human-computer interaction, and cryptography.",
    "authors": [
      "Mayar Elfares, Pascal Reisert, Ralf K\\\"usters, Andreas Bulling"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.836950"
  },
  {
    "id": "oai:arXiv.org:2506.05912v1",
    "journal": "arXiv_CS",
    "title": "DeviceScope: An Interactive App to Detect and Localize Appliance Patterns in Electricity Consumption Time Series",
    "link": "https://arxiv.org/abs/2506.05912",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05912v1 Announce Type: new \nAbstract: In recent years, electricity suppliers have installed millions of smart meters worldwide to improve the management of the smart grid system. These meters collect a large amount of electrical consumption data to produce valuable information to help consumers reduce their electricity footprint. However, having non-expert users (e.g., consumers or sales advisors) understand these data and derive usage patterns for different appliances has become a significant challenge for electricity suppliers because these data record the aggregated behavior of all appliances. At the same time, ground-truth labels (which could train appliance detection and localization models) are expensive to collect and extremely scarce in practice. This paper introduces DeviceScope, an interactive tool designed to facilitate understanding smart meter data by detecting and localizing individual appliance patterns within a given time period. Our system is based on CamAL (Class Activation Map-based Appliance Localization), a novel weakly supervised approach for appliance localization that only requires the knowledge of the existence of an appliance in a household to be trained. This paper appeared in ICDE 2025.",
    "authors": [
      "Adrien Petralia, Paul Boniol, Philippe Charpentier, Themis Palpanas"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.836960"
  },
  {
    "id": "oai:arXiv.org:2506.05917v1",
    "journal": "arXiv_CS",
    "title": "Rethinking Semi-supervised Segmentation Beyond Accuracy: Reliability and Robustness",
    "link": "https://arxiv.org/abs/2506.05917",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05917v1 Announce Type: new \nAbstract: Semantic segmentation is critical for scene understanding but demands costly pixel-wise annotations, attracting increasing attention to semi-supervised approaches to leverage abundant unlabeled data. While semi-supervised segmentation is often promoted as a path toward scalable, real-world deployment, it is astonishing that current evaluation protocols exclusively focus on segmentation accuracy, entirely overlooking reliability and robustness. These qualities, which ensure consistent performance under diverse conditions (robustness) and well-calibrated model confidences as well as meaningful uncertainties (reliability), are essential for safety-critical applications like autonomous driving, where models must handle unpredictable environments and avoid sudden failures at all costs. To address this gap, we introduce the Reliable Segmentation Score (RSS), a novel metric that combines predictive accuracy, calibration, and uncertainty quality measures via a harmonic mean. RSS penalizes deficiencies in any of its components, providing an easy and intuitive way of holistically judging segmentation models. Comprehensive evaluations of UniMatchV2 against its predecessor and a supervised baseline show that semi-supervised methods often trade reliability for accuracy. While out-of-domain evaluations demonstrate UniMatchV2's robustness, they further expose persistent reliability shortcomings. We advocate for a shift in evaluation protocols toward more holistic metrics like RSS to better align semi-supervised learning research with real-world deployment needs.",
    "authors": [
      "Steven Landgraf, Markus Hillemann, Markus Ulrich"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.836969"
  },
  {
    "id": "oai:arXiv.org:2506.05918v1",
    "journal": "arXiv_CS",
    "title": "Over-PINNs: Enhancing Physics-Informed Neural Networks via Higher-Order Partial Derivative Overdetermination of PDEs",
    "link": "https://arxiv.org/abs/2506.05918",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05918v1 Announce Type: new \nAbstract: Partial differential equations (PDEs) serve as the cornerstone of mathematical physics. In recent years, Physics-Informed Neural Networks (PINNs) have significantly reduced the dependence on large datasets by embedding physical laws directly into the training of neural networks. However, when dealing with complex problems, the accuracy of PINNs still has room for improvement. To address this issue, we introduce the Over-PINNs framework, which leverages automatic differentiation (AD) to generate higher-order auxiliary equations that impose additional physical constraints. These equations are incorporated as extra loss terms in the training process, effectively enhancing the model's ability to capture physical information through an \"overdetermined\" approach. Numerical results illustrate that this method exhibits strong versatility in solving various types of PDEs. It achieves a significant improvement in solution accuracy without incurring substantial additional computational costs.",
    "authors": [
      "Wenxuan Huo, Qiang He, Gang Zhu, Weifeng Huang"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.836978"
  },
  {
    "id": "oai:arXiv.org:2506.05925v1",
    "journal": "arXiv_CS",
    "title": "Small Models, Big Support: A Local LLM Framework for Teacher-Centric Content Creation and Assessment using RAG and CAG",
    "link": "https://arxiv.org/abs/2506.05925",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05925v1 Announce Type: new \nAbstract: While Large Language Models (LLMs) are increasingly utilized as student-facing educational aids, their potential to directly support educators, particularly through locally deployable and customizable open-source solutions, remains significantly underexplored. Many existing educational solutions rely on cloud-based infrastructure or proprietary tools, which are costly and may raise privacy concerns. Regulated industries with limited budgets require affordable, self-hosted solutions. We introduce an end-to-end, open-source framework leveraging small (3B-7B parameters), locally deployed LLMs for customized teaching material generation and assessment. Our system uniquely incorporates an interactive loop crucial for effective small-model refinement, and an auxiliary LLM verifier to mitigate jailbreaking risks, enhancing output reliability and safety. Utilizing Retrieval and Context Augmented Generation (RAG/CAG), it produces factually accurate, customized pedagogically-styled content. Deployed on-premises for data privacy and validated through an evaluation pipeline and a college physics pilot, our findings show that carefully engineered small LLM systems can offer robust, affordable, practical, and safe educator support, achieving utility comparable to larger models for targeted tasks.",
    "authors": [
      "Zarreen Reza, Alexander Mazur, Michael T. Dugdale, Robin Ray-Chaudhuri"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.837003"
  },
  {
    "id": "oai:arXiv.org:2506.05928v1",
    "journal": "arXiv_CS",
    "title": "MoA: Heterogeneous Mixture of Adapters for Parameter-Efficient Fine-Tuning of Large Language Models",
    "link": "https://arxiv.org/abs/2506.05928",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05928v1 Announce Type: new \nAbstract: Recent studies integrate Low-Rank Adaptation (LoRA) and Mixture-of-Experts (MoE) to further enhance the performance of parameter-efficient fine-tuning (PEFT) methods in Large Language Model (LLM) applications. Existing methods employ \\emph{homogeneous} MoE-LoRA architectures composed of LoRA experts with either similar or identical structures and capacities. However, these approaches often suffer from representation collapse and expert load imbalance, which negatively impact the potential of LLMs. To address these challenges, we propose a \\emph{heterogeneous} \\textbf{Mixture-of-Adapters (MoA)} approach. This method dynamically integrates PEFT adapter experts with diverse structures, leveraging their complementary representational capabilities to foster expert specialization, thereby enhancing the effective transfer of pre-trained knowledge to downstream tasks. MoA supports two variants: \\textbf{(i)} \\textit{Soft MoA} achieves fine-grained integration by performing a weighted fusion of all expert outputs; \\textbf{(ii)} \\textit{Sparse MoA} activates adapter experts sparsely based on their contribution, achieving this with negligible performance degradation. Experimental results demonstrate that heterogeneous MoA outperforms homogeneous MoE-LoRA methods in both performance and parameter efficiency. Our project is available at https://github.com/DCDmllm/MoA.",
    "authors": [
      "Jie Cao, Tianwei Lin, Hongyang He, Rolan Yan, Wenqiao Zhang, Juncheng Li, Dongping Zhang, Siliang Tang, Yueting Zhuang"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.837020"
  },
  {
    "id": "oai:arXiv.org:2506.05930v1",
    "journal": "arXiv_CS",
    "title": "Neural Visibility Cache for Real-Time Light Sampling",
    "link": "https://arxiv.org/abs/2506.05930",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05930v1 Announce Type: new \nAbstract: Direct illumination with many lights is an inherent component of physically-based rendering, remaining challenging, especially in real-time scenarios. We propose an online-trained neural cache that stores visibility between lights and 3D positions. We feed light visibility to weighted reservoir sampling (WRS) to sample a light source. The cache is implemented as a fully-fused multilayer perceptron (MLP) with multi-resolution hash-grid encoding, enabling online training and efficient inference on modern GPUs in real-time frame rates. The cache can be seamlessly integrated into existing rendering frameworks and can be used in combination with other real-time techniques such as spatiotemporal reservoir sampling (ReSTIR).",
    "authors": [
      "Jakub Bok\\v{s}ansk\\'y, Daniel Meister"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.837028"
  },
  {
    "id": "oai:arXiv.org:2506.05934v1",
    "journal": "arXiv_CS",
    "title": "FADE: Frequency-Aware Diffusion Model Factorization for Video Editing",
    "link": "https://arxiv.org/abs/2506.05934",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05934v1 Announce Type: new \nAbstract: Recent advancements in diffusion frameworks have significantly enhanced video editing, achieving high fidelity and strong alignment with textual prompts. However, conventional approaches using image diffusion models fall short in handling video dynamics, particularly for challenging temporal edits like motion adjustments. While current video diffusion models produce high-quality results, adapting them for efficient editing remains difficult due to the heavy computational demands that prevent the direct application of previous image editing techniques. To overcome these limitations, we introduce FADE, a training-free yet highly effective video editing approach that fully leverages the inherent priors from pre-trained video diffusion models via frequency-aware factorization. Rather than simply using these models, we first analyze the attention patterns within the video model to reveal how video priors are distributed across different components. Building on these insights, we propose a factorization strategy to optimize each component's specialized role. Furthermore, we devise spectrum-guided modulation to refine the sampling trajectory with frequency domain cues, preventing information leakage and supporting efficient, versatile edits while preserving the basic spatial and temporal structure. Extensive experiments on real-world videos demonstrate that our method consistently delivers high-quality, realistic and temporally coherent editing results both qualitatively and quantitatively. Code is available at https://github.com/EternalEvan/FADE .",
    "authors": [
      "Yixuan Zhu, Haolin Wang, Shilin Ma, Wenliang Zhao, Yansong Tang, Lei Chen, Jie Zhou"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.837052"
  },
  {
    "id": "oai:arXiv.org:2506.05936v1",
    "journal": "arXiv_CS",
    "title": "DynamicMind: A Tri-Mode Thinking System for Large Language Models",
    "link": "https://arxiv.org/abs/2506.05936",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05936v1 Announce Type: new \nAbstract: Modern large language models (LLMs) often struggle to dynamically adapt their reasoning depth to varying task complexities, leading to suboptimal performance or inefficient resource utilization. To address this, we introduce DynamicMind, a novel tri-mode thinking system. DynamicMind empowers LLMs to autonomously select between Fast, Normal, and Slow thinking modes for zero-shot question answering (ZSQA) tasks through cognitive-inspired prompt engineering. Our framework's core innovations include: (1) expanding the established dual-process framework of fast and slow thinking into a tri-mode thinking system involving a normal thinking mode to preserve the intrinsic capabilities of LLM; (2) proposing the Thinking Density metric, which aligns computational resource allocation with problem complexity; and (3) developing the Thinking Mode Capacity (TMC) dataset and a lightweight Mind Router to predict the optimal thinking mode. Extensive experiments across diverse mathematical, commonsense, and scientific QA benchmarks demonstrate that DynamicMind achieves superior ZSQA capabilities while establishing an effective trade-off between performance and computational efficiency.",
    "authors": [
      "Wei Li, Yanbin Wei, Qiushi Huang, Jiangyue Yan, Yang Chen, James T. Kwok, Yu Zhang"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.837069"
  },
  {
    "id": "oai:arXiv.org:2506.05939v1",
    "journal": "arXiv_CS",
    "title": "Respecting Temporal-Causal Consistency: Entity-Event Knowledge Graphs for Retrieval-Augmented Generation",
    "link": "https://arxiv.org/abs/2506.05939",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05939v1 Announce Type: new \nAbstract: Retrieval-augmented generation (RAG) based on large language models often falters on narrative documents with inherent temporal structures. Standard unstructured RAG methods rely solely on embedding-similarity matching and lack any general mechanism to encode or exploit chronological information, while knowledge graph RAG (KG-RAG) frameworks collapse every mention of an entity into a single node, erasing the evolving context that drives many queries. To formalize this challenge and draw the community's attention, we construct ChronoQA, a robust and discriminative QA benchmark that measures temporal, causal, and character consistency understanding in narrative documents (e.g., novels) under the RAG setting. We then introduce Entity-Event RAG (E^2RAG), a dual-graph framework that keeps separate entity and event subgraphs linked by a bipartite mapping, thereby preserving the temporal and causal facets needed for fine-grained reasoning. Across ChronoQA, our approach outperforms state-of-the-art unstructured and KG-based RAG baselines, with notable gains on causal and character consistency queries. E^2RAG therefore offers a practical path to more context-aware retrieval for tasks that require precise answers grounded in chronological information.",
    "authors": [
      "Ze Yu Zhang, Zitao Li, Yaliang Li, Bolin Ding, Bryan Kian Hsiang Low"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.837092"
  },
  {
    "id": "oai:arXiv.org:2506.05940v1",
    "journal": "arXiv_CS",
    "title": "Exponential Family Variational Flow Matching for Tabular Data Generation",
    "link": "https://arxiv.org/abs/2506.05940",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05940v1 Announce Type: new \nAbstract: While denoising diffusion and flow matching have driven major advances in generative modeling, their application to tabular data remains limited, despite its ubiquity in real-world applications. To this end, we develop TabbyFlow, a variational Flow Matching (VFM) method for tabular data generation. To apply VFM to data with mixed continuous and discrete features, we introduce Exponential Family Variational Flow Matching (EF-VFM), which represents heterogeneous data types using a general exponential family distribution. We hereby obtain an efficient, data-driven objective based on moment matching, enabling principled learning of probability paths over mixed continuous and discrete variables. We also establish a connection between variational flow matching and generalized flow matching objectives based on Bregman divergences. Evaluation on tabular data benchmarks demonstrates state-of-the-art performance compared to baselines.",
    "authors": [
      "Andr\\'es Guzm\\'an-Cordero, Floor Eijkelboom, Jan-Willem van de Meent"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.837100"
  },
  {
    "id": "oai:arXiv.org:2506.05942v1",
    "journal": "arXiv_CS",
    "title": "Additive decomposition of one-dimensional signals using Transformers",
    "link": "https://arxiv.org/abs/2506.05942",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05942v1 Announce Type: new \nAbstract: One-dimensional signal decomposition is a well-established and widely used technique across various scientific fields. It serves as a highly valuable pre-processing step for data analysis. While traditional decomposition techniques often rely on mathematical models, recent research suggests that applying the latest deep learning models to this problem presents an exciting, unexplored area with promising potential. This work presents a novel method for the additive decomposition of one-dimensional signals. We leverage the Transformer architecture to decompose signals into their constituent components: piece-wise constant, smooth (low-frequency oscillatory), textured (high-frequency oscillatory), and a noise component. Our model, trained on synthetic data, achieves excellent accuracy in modeling and decomposing input signals from the same distribution, as demonstrated by the experimental results.",
    "authors": [
      "Samuele Salti, Andrea Pinto, Alessandro Lanza, Serena Morigi"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.837116"
  },
  {
    "id": "oai:arXiv.org:2506.05943v1",
    "journal": "arXiv_CS",
    "title": "Nonlinear symbols combining for Power Amplifier-distorted OFDM signal reception",
    "link": "https://arxiv.org/abs/2506.05943",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05943v1 Announce Type: new \nAbstract: Nonlinear distortion of a multicarrier signal by a transmitter Power Amplifier (PA) can be a serious problem when designing new highly energy-efficient wireless systems. Although the performance of standard reception algorithms is seriously deteriorated by the nonlinear distortion, the more advanced solutions allow the utilization of additional frequency diversity caused by nonlinear PA. However, while most of the advanced receivers are decision-aided, their gains are observed mostly in a relatively low Bit Error Rate (BER) region, not targeted by adaptive Modulation Coding Schemes utilizing Forward Error Correction (FEC). In this paper, a non-decision-aided Higher-Order Combining (HOC) reception scheme is proposed. While the analytical formulas for finding symbols combining coefficients are not known, machine learning is used for deriving them. The simulation results show an improved BER performance with respect to a standard reception and one of the established decision-aided receivers. However, as HOC has computational complexity that increases rapidly with the number of subcarriers utilized, more studies are needed to apply it in a wideband system.",
    "authors": [
      "Pawel Kryszkiewicz, Hanna Bogucka"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.837124"
  },
  {
    "id": "oai:arXiv.org:2506.05947v1",
    "journal": "arXiv_CS",
    "title": "IntentionESC: An Intention-Centered Framework for Enhancing Emotional Support in Dialogue Systems",
    "link": "https://arxiv.org/abs/2506.05947",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05947v1 Announce Type: new \nAbstract: In emotional support conversations, unclear intentions can lead supporters to employ inappropriate strategies, inadvertently imposing their expectations or solutions on the seeker. Clearly defined intentions are essential for guiding both the supporter's motivations and the overall emotional support process. In this paper, we propose the Intention-centered Emotional Support Conversation (IntentionESC) framework, which defines the possible intentions of supporters in emotional support conversations, identifies key emotional state aspects for inferring these intentions, and maps them to appropriate support strategies. While Large Language Models (LLMs) excel in text generating, they fundamentally operate as probabilistic models trained on extensive datasets, lacking a true understanding of human thought processes and intentions. To address this limitation, we introduce the Intention Centric Chain-of-Thought (ICECoT) mechanism. ICECoT enables LLMs to mimic human reasoning by analyzing emotional states, inferring intentions, and selecting suitable support strategies, thereby generating more effective emotional support responses. To train the model with ICECoT and integrate expert knowledge, we design an automated annotation pipeline that produces high-quality training data. Furthermore, we develop a comprehensive evaluation scheme to assess emotional support efficacy and conduct extensive experiments to validate our framework. Our data and code are available at https://github.com/43zxj/IntentionESC_ICECoT.",
    "authors": [
      "Xinjie Zhang, Wenxuan Wang, Qin Jin"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.837134"
  },
  {
    "id": "oai:arXiv.org:2506.05949v1",
    "journal": "arXiv_CS",
    "title": "NameTag 3: A Tool and a Service for Multilingual/Multitagset NER",
    "link": "https://arxiv.org/abs/2506.05949",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05949v1 Announce Type: new \nAbstract: We introduce NameTag 3, an open-source tool and cloud-based web service for multilingual, multidataset, and multitagset named entity recognition (NER), supporting both flat and nested entities. NameTag 3 achieves state-of-the-art results on 21 test datasets in 15 languages and remains competitive on the rest, even against larger models. It is available as a command-line tool and as a cloud-based service, enabling use without local installation. NameTag 3 web service currently provides flat NER for 17 languages, trained on 21 corpora and three NE tagsets, all powered by a single 355M-parameter fine-tuned model; and nested NER for Czech, powered by a 126M fine-tuned model. The source code is licensed under open-source MPL 2.0, while the models are distributed under non-commercial CC BY-NC-SA 4.0. Documentation is available at https://ufal.mff.cuni.cz/nametag, source code at https://github.com/ufal/nametag3, and trained models via https://lindat.cz. The REST service and the web application can be found at https://lindat.mff.cuni.cz/services/nametag/. A demonstration video is available at https://www.youtube.com/watch?v=-gaGnP0IV8A.",
    "authors": [
      "Jana Strakov\\'a, Milan Straka"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.837142"
  },
  {
    "id": "oai:arXiv.org:2506.05950v1",
    "journal": "arXiv_CS",
    "title": "Elementary Math Word Problem Generation using Large Language Models",
    "link": "https://arxiv.org/abs/2506.05950",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05950v1 Announce Type: new \nAbstract: Mathematics is often perceived as a complex subject by students, leading to high failure rates in exams. To improve Mathematics skills, it is important to provide sample questions for students to practice problem-solving. Manually creating Math Word Problems (MWPs) is time consuming for tutors, because they have to type in natural language while adhering to grammar and spelling rules of the language. Existing Deep Learning techniques for MWP generation either require a tutor to provide the initial portion of the MWP, and/or additional information such as an equation. In this paper, we present an MWP generation system based on Large Language Models (LLMs) that overcome the need for additional input - the only input to our system is the number of MWPs needed, the grade and the type of question (e.g. addition, subtraction). Unlike the existing LLM-based solutions for MWP generation, we carried out an extensive set of experiments involving different LLMs, prompting strategies, techniques to improve the diversity of questions, as well as techniques that employ human feedback to improve LLM performance. Human and automated evaluations confirmed that the generated MWPs are high in quality, with minimal spelling and grammar issues. However, LLMs still struggle to generate questions that adhere to the specified grade and question type requirements.",
    "authors": [
      "Nimesh Ariyarathne, Harshani Bandara, Yasith Heshan, Omega Gamage, Surangika Ranathunga, Dilan Nayanajith, Yutharsan Sivapalan, Gayathri Lihinikaduarachchi, Tharoosha Vihidun, Meenambika Chandirakumar, Sanujen Premakumar, Sanjula Gathsara"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.837150"
  },
  {
    "id": "oai:arXiv.org:2506.05952v1",
    "journal": "arXiv_CS",
    "title": "MOGO: Residual Quantized Hierarchical Causal Transformer for High-Quality and Real-Time 3D Human Motion Generation",
    "link": "https://arxiv.org/abs/2506.05952",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05952v1 Announce Type: new \nAbstract: Recent advances in transformer-based text-to-motion generation have led to impressive progress in synthesizing high-quality human motion. Nevertheless, jointly achieving high fidelity, streaming capability, real-time responsiveness, and scalability remains a fundamental challenge. In this paper, we propose MOGO (Motion Generation with One-pass), a novel autoregressive framework tailored for efficient and real-time 3D motion generation. MOGO comprises two key components: (1) MoSA-VQ, a motion scale-adaptive residual vector quantization module that hierarchically discretizes motion sequences with learnable scaling to produce compact yet expressive representations; and (2) RQHC-Transformer, a residual quantized hierarchical causal transformer that generates multi-layer motion tokens in a single forward pass, significantly reducing inference latency. To enhance semantic fidelity, we further introduce a text condition alignment mechanism that improves motion decoding under textual control. Extensive experiments on benchmark datasets including HumanML3D, KIT-ML, and CMP demonstrate that MOGO achieves competitive or superior generation quality compared to state-of-the-art transformer-based methods, while offering substantial improvements in real-time performance, streaming generation, and generalization under zero-shot settings.",
    "authors": [
      "Dongjie Fu, Tengjiao Sun, Pengcheng Fang, Xiaohao Cai, Hansung Kim"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.837159"
  },
  {
    "id": "oai:arXiv.org:2506.05957v1",
    "journal": "arXiv_CS",
    "title": "Pruning Spurious Subgraphs for Graph Out-of-Distribtuion Generalization",
    "link": "https://arxiv.org/abs/2506.05957",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05957v1 Announce Type: new \nAbstract: Graph Neural Networks (GNNs) often encounter significant performance degradation under distribution shifts between training and test data, hindering their applicability in real-world scenarios. Recent studies have proposed various methods to address the out-of-distribution generalization challenge, with many methods in the graph domain focusing on directly identifying an invariant subgraph that is predictive of the target label. However, we argue that identifying the edges from the invariant subgraph directly is challenging and error-prone, especially when some spurious edges exhibit strong correlations with the targets. In this paper, we propose PrunE, the first pruning-based graph OOD method that eliminates spurious edges to improve OOD generalizability. By pruning spurious edges, \\mine{} retains the invariant subgraph more comprehensively, which is critical for OOD generalization. Specifically, PrunE employs two regularization terms to prune spurious edges: 1) graph size constraint to exclude uninformative spurious edges, and 2) $\\epsilon$-probability alignment to further suppress the occurrence of spurious edges. Through theoretical analysis and extensive experiments, we show that PrunE achieves superior OOD performance and outperforms previous state-of-the-art methods significantly. Codes are available at: \\href{https://github.com/tianyao-aka/PrunE-GraphOOD}{https://github.com/tianyao-aka/PrunE-GraphOOD}.",
    "authors": [
      "Tianjun Yao, Haoxuan Li, Yongqiang Chen, Tongliang Liu, Le Song, Eric Xing, Zhiqiang Shen"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.837175"
  },
  {
    "id": "oai:arXiv.org:2506.05960v1",
    "journal": "arXiv_CS",
    "title": "AQUATIC-Diff: Additive Quantization for Truly Tiny Compressed Diffusion Models",
    "link": "https://arxiv.org/abs/2506.05960",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05960v1 Announce Type: new \nAbstract: Significant investments have been made towards the commodification of diffusion models for generation of diverse media. Their mass-market adoption is however still hobbled by the intense hardware resource requirements of diffusion model inference. Model quantization strategies tailored specifically towards diffusion models have been useful in easing this burden, yet have generally explored the Uniform Scalar Quantization (USQ) family of quantization methods. In contrast, Vector Quantization (VQ) methods, which operate on groups of multiple related weights as the basic unit of compression, have seen substantial success in Large Language Model (LLM) quantization. In this work, we apply codebook-based additive vector quantization to the problem of diffusion model compression. Our resulting approach achieves a new Pareto frontier for the extremely low-bit weight quantization on the standard class-conditional benchmark of LDM-4 on ImageNet at 20 inference time steps. Notably, we report sFID 1.92 points lower than the full-precision model at W4A8 and the best-reported results for FID, sFID and ISC at W2A8. We are also able to demonstrate FLOPs savings on arbitrary hardware via an efficient inference kernel, as opposed to savings resulting from small integer operations which may lack broad hardware support.",
    "authors": [
      "Adil Hasan, Thomas Peyrin"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.837193"
  },
  {
    "id": "oai:arXiv.org:2506.05965v1",
    "journal": "arXiv_CS",
    "title": "Dy3DGS-SLAM: Monocular 3D Gaussian Splatting SLAM for Dynamic Environments",
    "link": "https://arxiv.org/abs/2506.05965",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05965v1 Announce Type: new \nAbstract: Current Simultaneous Localization and Mapping (SLAM) methods based on Neural Radiance Fields (NeRF) or 3D Gaussian Splatting excel in reconstructing static 3D scenes but struggle with tracking and reconstruction in dynamic environments, such as real-world scenes with moving elements. Existing NeRF-based SLAM approaches addressing dynamic challenges typically rely on RGB-D inputs, with few methods accommodating pure RGB input. To overcome these limitations, we propose Dy3DGS-SLAM, the first 3D Gaussian Splatting (3DGS) SLAM method for dynamic scenes using monocular RGB input. To address dynamic interference, we fuse optical flow masks and depth masks through a probabilistic model to obtain a fused dynamic mask. With only a single network iteration, this can constrain tracking scales and refine rendered geometry. Based on the fused dynamic mask, we designed a novel motion loss to constrain the pose estimation network for tracking. In mapping, we use the rendering loss of dynamic pixels, color, and depth to eliminate transient interference and occlusion caused by dynamic objects. Experimental results demonstrate that Dy3DGS-SLAM achieves state-of-the-art tracking and rendering in dynamic environments, outperforming or matching existing RGB-D methods.",
    "authors": [
      "Mingrui Li, Yiming Zhou, Hongxing Zhou, Xinggang Hu, Florian Roemer, Hongyu Wang, Ahmad Osman"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.837203"
  },
  {
    "id": "oai:arXiv.org:2506.05968v1",
    "journal": "arXiv_CS",
    "title": "Gradual Transition from Bellman Optimality Operator to Bellman Operator in Online Reinforcement Learning",
    "link": "https://arxiv.org/abs/2506.05968",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05968v1 Announce Type: new \nAbstract: For continuous action spaces, actor-critic methods are widely used in online reinforcement learning (RL). However, unlike RL algorithms for discrete actions, which generally model the optimal value function using the Bellman optimality operator, RL algorithms for continuous actions typically model Q-values for the current policy using the Bellman operator. These algorithms for continuous actions rely exclusively on policy updates for improvement, which often results in low sample efficiency. This study examines the effectiveness of incorporating the Bellman optimality operator into actor-critic frameworks. Experiments in a simple environment show that modeling optimal values accelerates learning but leads to overestimation bias. To address this, we propose an annealing approach that gradually transitions from the Bellman optimality operator to the Bellman operator, thereby accelerating learning while mitigating bias. Our method, combined with TD3 and SAC, significantly outperforms existing approaches across various locomotion and manipulation tasks, demonstrating improved performance and robustness to hyperparameters related to optimality.",
    "authors": [
      "Motoki Omura, Kazuki Ota, Takayuki Osa, Yusuke Mukuta, Tatsuya Harada"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.837219"
  },
  {
    "id": "oai:arXiv.org:2506.05970v1",
    "journal": "arXiv_CS",
    "title": "Let's Put Ourselves in Sally's Shoes: Shoes-of-Others Prefixing Improves Theory of Mind in Large Language Models",
    "link": "https://arxiv.org/abs/2506.05970",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05970v1 Announce Type: new \nAbstract: Recent studies have shown that Theory of Mind (ToM) in large language models (LLMs) has not reached human-level performance yet. Since fine-tuning LLMs on ToM datasets often degrades their generalization, several inference-time methods have been proposed to enhance ToM in LLMs. However, existing inference-time methods for ToM are specialized for inferring beliefs from contexts involving changes in the world state. In this study, we present a new inference-time method for ToM, Shoes-of-Others (SoO) prefixing, which makes fewer assumptions about contexts and is applicable to broader scenarios. SoO prefixing simply specifies the beginning of LLM outputs with ``Let's put ourselves in A's shoes.'', where A denotes the target character's name. We evaluate SoO prefixing on two benchmarks that assess ToM in conversational and narrative contexts without changes in the world state and find that it consistently improves ToM across five categories of mental states. Our analysis suggests that SoO prefixing elicits faithful thoughts, thereby improving the ToM performance.",
    "authors": [
      "Kazutoshi Shinoda, Nobukatsu Hojo, Kyosuke Nishida, Yoshihiro Yamazaki, Keita Suzuki, Hiroaki Sugiyama, Kuniko Saito"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.837229"
  },
  {
    "id": "oai:arXiv.org:2506.05971v1",
    "journal": "arXiv_CS",
    "title": "On Measuring Long-Range Interactions in Graph Neural Networks",
    "link": "https://arxiv.org/abs/2506.05971",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05971v1 Announce Type: new \nAbstract: Long-range graph tasks -- those dependent on interactions between distant nodes -- are an open problem in graph neural network research. Real-world benchmark tasks, especially the Long Range Graph Benchmark, have become popular for validating the long-range capability of proposed architectures. However, this is an empirical approach that lacks both robustness and theoretical underpinning; a more principled characterization of the long-range problem is required. To bridge this gap, we formalize long-range interactions in graph tasks, introduce a range measure for operators on graphs, and validate it with synthetic experiments. We then leverage our measure to examine commonly used tasks and architectures, and discuss to what extent they are, in fact, long-range. We believe our work advances efforts to define and address the long-range problem on graphs, and that our range measure will aid evaluation of new datasets and architectures.",
    "authors": [
      "Jacob Bamberger, Benjamin Gutteridge, Scott le Roux, Michael M. Bronstein, Xiaowen Dong"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.837238"
  },
  {
    "id": "oai:arXiv.org:2506.05976v1",
    "journal": "arXiv_CS",
    "title": "LTG at SemEval-2025 Task 10: Optimizing Context for Classification of Narrative Roles",
    "link": "https://arxiv.org/abs/2506.05976",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05976v1 Announce Type: new \nAbstract: Our contribution to the SemEval 2025 shared task 10, subtask 1 on entity framing, tackles the challenge of providing the necessary segments from longer documents as context for classification with a masked language model. We show that a simple entity-oriented heuristics for context selection can enable text classification using models with limited context window. Our context selection approach and the XLM-RoBERTa language model is on par with, or outperforms, Supervised Fine-Tuning with larger generative language models.",
    "authors": [
      "Egil R{\\o}nningstad, Gaurav Negi"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.837255"
  },
  {
    "id": "oai:arXiv.org:2506.05977v1",
    "journal": "arXiv_CS",
    "title": "Mitigating Catastrophic Forgetting with Adaptive Transformer Block Expansion in Federated Fine-Tuning",
    "link": "https://arxiv.org/abs/2506.05977",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05977v1 Announce Type: new \nAbstract: Federated fine-tuning (FedFT) of large language models (LLMs) has emerged as a promising solution for adapting models to distributed data environments while ensuring data privacy.\n  Existing FedFT methods predominantly utilize parameter-efficient fine-tuning (PEFT) techniques to reduce communication and computation overhead.\n  However, they often fail to adequately address the catastrophic forgetting, a critical challenge arising from continual adaptation in distributed environments. The traditional centralized fine-tuning methods, which are not designed for the heterogeneous and privacy-constrained nature of federated environments, struggle to mitigate this issue effectively. Moreover, the challenge is further exacerbated by significant variation in data distributions and device capabilities across clients, which leads to intensified forgetting and degraded model generalization. To tackle these issues, we propose FedBE, a novel FedFT framework that integrates an adaptive transformer block expansion mechanism with a dynamic trainable-block allocation strategy. Specifically, FedBE expands trainable blocks within the model architecture, structurally separating newly learned task-specific knowledge from the original pre-trained representations. Additionally, FedBE dynamically assigns these trainable blocks to clients based on their data distributions and computational capabilities. This enables the framework to better accommodate heterogeneous federated environments and enhances the generalization ability of the model.Extensive experiments show that compared with existing federated fine-tuning methods, FedBE achieves 12-74% higher accuracy retention on general tasks after fine-tuning and a model convergence acceleration ratio of 1.9-3.1x without degrading the accuracy of downstream tasks.",
    "authors": [
      "Yujia Huo, Jianchun Liu, Hongli Xu, Zhenguo Ma, Shilong Wang, Liusheng Huang"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.837264"
  },
  {
    "id": "oai:arXiv.org:2506.05979v1",
    "journal": "arXiv_CS",
    "title": "Tau-Eval: A Unified Evaluation Framework for Useful and Private Text Anonymization",
    "link": "https://arxiv.org/abs/2506.05979",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05979v1 Announce Type: new \nAbstract: Text anonymization is the process of removing or obfuscating information from textual data to protect the privacy of individuals. This process inherently involves a complex trade-off between privacy protection and information preservation, where stringent anonymization methods can significantly impact the text's utility for downstream applications. Evaluating the effectiveness of text anonymization proves challenging from both privacy and utility perspectives, as there is no universal benchmark that can comprehensively assess anonymization techniques across diverse, and sometimes contradictory contexts. We present Tau-Eval, an open-source framework for benchmarking text anonymization methods through the lens of privacy and utility task sensitivity. A Python library, code, documentation and tutorials are publicly available.",
    "authors": [
      "Gabriel Loiseau, Damien Sileo, Damien Riquet, Maxime Meyer, Marc Tommasi"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.837273"
  },
  {
    "id": "oai:arXiv.org:2506.05980v1",
    "journal": "arXiv_CS",
    "title": "AMPED: Adaptive Multi-objective Projection for balancing Exploration and skill Diversification",
    "link": "https://arxiv.org/abs/2506.05980",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05980v1 Announce Type: new \nAbstract: Skill-based reinforcement learning (SBRL) enables rapid adaptation in environments with sparse rewards by pretraining a skill-conditioned policy. Effective skill learning requires jointly maximizing both exploration and skill diversity. However, existing methods often face challenges in simultaneously optimizing for these two conflicting objectives. In this work, we propose a new method, Adaptive Multi-objective Projection for balancing Exploration and skill Diversification (AMPED), which explicitly addresses both exploration and skill diversification. We begin by conducting extensive ablation studies to identify and define a set of objectives that effectively capture the aspects of exploration and skill diversity, respectively. During the skill pretraining phase, AMPED introduces a gradient surgery technique to balance the objectives of exploration and skill diversity, mitigating conflicts and reducing reliance on heuristic tuning. In the subsequent fine-tuning phase, AMPED incorporates a skill selector module that dynamically selects suitable skills for downstream tasks, based on task-specific performance signals. Our approach achieves performance that surpasses SBRL baselines across various benchmarks. These results highlight the importance of explicitly harmonizing exploration and diversity and demonstrate the effectiveness of AMPED in enabling robust and generalizable skill learning. Project Page: https://geonwoo.me/amped/",
    "authors": [
      "Geonwoo Cho, Jaemoon Lee, Jaegyun Im, Subi Lee, Jihwan Lee, Sundong Kim"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.837281"
  },
  {
    "id": "oai:arXiv.org:2506.05981v1",
    "journal": "arXiv_CS",
    "title": "CrimeMind: Simulating Urban Crime with Multi-Modal LLM Agents",
    "link": "https://arxiv.org/abs/2506.05981",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05981v1 Announce Type: new \nAbstract: Modeling urban crime is an important yet challenging task that requires understanding the subtle visual, social, and cultural cues embedded in urban environments. Previous work has predominantly focused on rule-based agent-based modeling (ABM) and deep learning methods. ABMs offer interpretability of internal mechanisms but exhibit limited predictive accuracy.In contrast, deep learning methods are often effective in prediction but are less interpretable and require extensive training data. Moreover, both lines of work lack the cognitive flexibility to adapt to changing environments. Leveraging the capabilities of large language models (LLMs), we propose CrimeMind, a novel LLM-driven ABM framework for simulating urban crime within a multi-modal urban context.A key innovation of our design is the integration of the Routine Activity Theory (RAT) into the agentic workflow of CrimeMind, enabling it to process rich multi-modal urban features and reason about criminal behavior.However, RAT requires LLM agents to infer subtle cues in evaluating environmental safety as part of assessing guardianship, which can be challenging for LLMs. To address this, we collect a small-scale human-annotated dataset and align CrimeMind's perception with human judgment via a training-free textual gradient method.Experiments across four major U.S. cities demonstrate that CrimeMind outperforms both traditional ABMs and deep learning baselines in crime hotspot prediction and spatial distribution accuracy, achieving up to a 24% improvement over the strongest baseline.Furthermore, we conduct counterfactual simulations of external incidents and policy interventions and it successfully captures the expected changes in crime patterns, demonstrating its ability to reflect counterfactual scenarios.Overall, CrimeMind enables fine-grained modeling of individual behaviors and facilitates evaluation of real-world interventions.",
    "authors": [
      "Qingbin Zeng, Ruotong Zhao, Jinzhu Mao, Haoyang Li, Fengli Xu, Yong Li"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.837290"
  },
  {
    "id": "oai:arXiv.org:2506.05985v1",
    "journal": "arXiv_CS",
    "title": "Dynamic Mixture of Progressive Parameter-Efficient Expert Library for Lifelong Robot Learning",
    "link": "https://arxiv.org/abs/2506.05985",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05985v1 Announce Type: new \nAbstract: A generalist agent must continuously learn and adapt throughout its lifetime, achieving efficient forward transfer while minimizing catastrophic forgetting. Previous work within the dominant pretrain-then-finetune paradigm has explored parameter-efficient fine-tuning for single-task adaptation, effectively steering a frozen pretrained model with a small number of parameters. However, in the context of lifelong learning, these methods rely on the impractical assumption of a test-time task identifier and restrict knowledge sharing among isolated adapters. To address these limitations, we propose Dynamic Mixture of Progressive Parameter-Efficient Expert Library (DMPEL) for lifelong robot learning. DMPEL progressively learn a low-rank expert library and employs a lightweight router to dynamically combine experts into an end-to-end policy, facilitating flexible behavior during lifelong adaptation. Moreover, by leveraging the modular structure of the fine-tuned parameters, we introduce coefficient replay to guide the router in accurately retrieving frozen experts for previously encountered tasks, thereby mitigating catastrophic forgetting. This method is significantly more storage- and computationally-efficient than applying demonstration replay to the entire policy. Extensive experiments on the lifelong manipulation benchmark LIBERO demonstrate that our framework outperforms state-of-the-art lifelong learning methods in success rates across continual adaptation, while utilizing minimal trainable parameters and storage.",
    "authors": [
      "Yuheng Lei, Sitong Mao, Shunbo Zhou, Hongyuan Zhang, Xuelong Li, Ping Luo"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.837313"
  },
  {
    "id": "oai:arXiv.org:2506.05987v1",
    "journal": "arXiv_CS",
    "title": "The JPEG XL Image Coding System: History, Features, Coding Tools, Design Rationale, and Future",
    "link": "https://arxiv.org/abs/2506.05987",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05987v1 Announce Type: new \nAbstract: JPEG XL is a new image coding system offering state-of-the-art compression performance, lossless JPEG recompression, and advanced features. It aims to replace JPEG, PNG, GIF, and other formats with a single universal codec. This article provides an overview of JPEG XL, including its history, design rationale, coding tools, and future potential. It can be used as a companion document to the standard (ISO/IEC 18181), or as a standalone article to better understand JPEG XL, either at a high level or in considerable technical detail.",
    "authors": [
      "Jon Sneyers, Jyrki Alakuijala, Luca Versari, Zolt\\'an Szabadka, Sami Boukortt, Amnon Cohen-Tidhar, Moritz Firsching, Evgenii Kliuchnikov, Tal Lev-Ami, Eric Portis, Thomas Richter, Osamu Watanabe"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.837322"
  },
  {
    "id": "oai:arXiv.org:2506.05994v1",
    "journal": "arXiv_CS",
    "title": "RETENTION: Resource-Efficient Tree-Based Ensemble Model Acceleration with Content-Addressable Memory",
    "link": "https://arxiv.org/abs/2506.05994",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05994v1 Announce Type: new \nAbstract: Although deep learning has demonstrated remarkable capabilities in learning from unstructured data, modern tree-based ensemble models remain superior in extracting relevant information and learning from structured datasets. While several efforts have been made to accelerate tree-based models, the inherent characteristics of the models pose significant challenges for conventional accelerators. Recent research leveraging content-addressable memory (CAM) offers a promising solution for accelerating tree-based models, yet existing designs suffer from excessive memory consumption and low utilization. This work addresses these challenges by introducing RETENTION, an end-to-end framework that significantly reduces CAM capacity requirement for tree-based model inference. We propose an iterative pruning algorithm with a novel pruning criterion tailored for bagging-based models (e.g., Random Forest), which minimizes model complexity while ensuring controlled accuracy degradation. Additionally, we present a tree mapping scheme that incorporates two innovative data placement strategies to alleviate the memory redundancy caused by the widespread use of don't care states in CAM. Experimental results show that implementing the tree mapping scheme alone achieves $1.46\\times$ to $21.30 \\times$ better space efficiency, while the full RETENTION framework yields $4.35\\times$ to $207.12\\times$ improvement with less than 3% accuracy loss. These results demonstrate that RETENTION is highly effective in reducing CAM capacity requirement, providing a resource-efficient direction for tree-based model acceleration.",
    "authors": [
      "Yi-Chun Liao, Chieh-Lin Tsai, Yuan-Hao Chang, Cam\\'elia Slimani, Jalil Boukhobza, Tei-Wei Kuo"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.837347"
  },
  {
    "id": "oai:arXiv.org:2506.05997v1",
    "journal": "arXiv_CS",
    "title": "Improving Long-Range Navigation with Spatially-Enhanced Recurrent Memory via End-to-End Reinforcement Learning",
    "link": "https://arxiv.org/abs/2506.05997",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05997v1 Announce Type: new \nAbstract: Recent advancements in robot navigation, especially with end-to-end learning approaches like reinforcement learning (RL), have shown remarkable efficiency and effectiveness. Yet, successful navigation still relies on two key capabilities: mapping and planning, whether explicit or implicit. Classical approaches use explicit mapping pipelines to register ego-centric observations into a coherent map frame for the planner. In contrast, end-to-end learning achieves this implicitly, often through recurrent neural networks (RNNs) that fuse current and past observations into a latent space for planning. While architectures such as LSTM and GRU capture temporal dependencies, our findings reveal a key limitation: their inability to perform effective spatial memorization. This skill is essential for transforming and integrating sequential observations from varying perspectives to build spatial representations that support downstream planning. To address this, we propose Spatially-Enhanced Recurrent Units (SRUs), a simple yet effective modification to existing RNNs, designed to enhance spatial memorization capabilities. We introduce an attention-based architecture with SRUs, enabling long-range navigation using a single forward-facing stereo camera. Regularization techniques are employed to ensure robust end-to-end recurrent training via RL. Experimental results show our approach improves long-range navigation by 23.5% compared to existing RNNs. Furthermore, with SRU memory, our method outperforms the RL baseline with explicit mapping and memory modules, achieving a 29.6% improvement in diverse environments requiring long-horizon mapping and memorization. Finally, we address the sim-to-real gap by leveraging large-scale pretraining on synthetic depth data, enabling zero-shot transfer to diverse and complex real-world environments.",
    "authors": [
      "Fan Yang, Per Frivik, David Hoeller, Chen Wang, Cesar Cadena, Marco Hutter"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.837356"
  },
  {
    "id": "oai:arXiv.org:2506.06001v1",
    "journal": "arXiv_CS",
    "title": "LaDEEP: A Deep Learning-based Surrogate Model for Large Deformation of Elastic-Plastic Solids",
    "link": "https://arxiv.org/abs/2506.06001",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06001v1 Announce Type: new \nAbstract: Scientific computing for large deformation of elastic-plastic solids is critical for numerous real-world applications. Classical numerical solvers rely primarily on local discrete linear approximation and are constrained by an inherent trade-off between accuracy and efficiency. Recently, deep learning models have achieved impressive progress in solving the continuum mechanism. While previous models have explored various architectures and constructed coefficient-solution mappings, they are designed for general instances without considering specific problem properties and hard to accurately handle with complex elastic-plastic solids involving contact, loading and unloading. In this work, we take stretch bending, a popular metal fabrication technique, as our case study and introduce LaDEEP, a deep learning-based surrogate model for \\textbf{La}rge \\textbf{De}formation of \\textbf{E}lastic-\\textbf{P}lastic Solids. We encode the partitioned regions of the involved slender solids into a token sequence to maintain their essential order property. To characterize the physical process of the solid deformation, a two-stage Transformer-based module is designed to predict the deformation with the sequence of tokens as input. Empirically, LaDEEP achieves five magnitudes faster speed than finite element methods with a comparable accuracy, and gains 20.47\\% relative improvement on average compared to other deep learning baselines. We have also deployed our model into a real-world industrial production system, and it has shown remarkable performance in both accuracy and efficiency.",
    "authors": [
      "Shilong Tao, Zhe Feng, Haonan Sun, Zhanxing Zhu, Yunhuai Liu"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.837373"
  },
  {
    "id": "oai:arXiv.org:2506.06003v1",
    "journal": "arXiv_CS",
    "title": "What Really is a Member? Discrediting Membership Inference via Poisoning",
    "link": "https://arxiv.org/abs/2506.06003",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06003v1 Announce Type: new \nAbstract: Membership inference tests aim to determine whether a particular data point was included in a language model's training set. However, recent works have shown that such tests often fail under the strict definition of membership based on exact matching, and have suggested relaxing this definition to include semantic neighbors as members as well. In this work, we show that membership inference tests are still unreliable under this relaxation - it is possible to poison the training dataset in a way that causes the test to produce incorrect predictions for a target point. We theoretically reveal a trade-off between a test's accuracy and its robustness to poisoning. We also present a concrete instantiation of this poisoning attack and empirically validate its effectiveness. Our results show that it can degrade the performance of existing tests to well below random.",
    "authors": [
      "Neal Mangaokar, Ashish Hooda, Zhuohang Li, Bradley A. Malin, Kassem Fawaz, Somesh Jha, Atul Prakash, Amrita Roy Chowdhury"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.837382"
  },
  {
    "id": "oai:arXiv.org:2506.06005v1",
    "journal": "arXiv_CS",
    "title": "LightGTS: A Lightweight General Time Series Forecasting Model",
    "link": "https://arxiv.org/abs/2506.06005",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06005v1 Announce Type: new \nAbstract: Existing works on general time series forecasting build foundation models with heavy model parameters through large-scale multi-source pre-training. These models achieve superior generalization ability across various datasets at the cost of significant computational burdens and limitations in resource-constrained scenarios. This paper introduces LightGTS, a lightweight general time series forecasting model designed from the perspective of consistent periodical modeling. To handle diverse scales and intrinsic periods in multi-source pre-training, we introduce Periodical Tokenization, which extracts consistent periodic patterns across different datasets with varying scales. To better utilize the periodicity in the decoding process, we further introduce Periodical Parallel Decoding, which leverages historical tokens to improve forecasting. Based on the two techniques above which fully leverage the inductive bias of periods inherent in time series, LightGTS uses a lightweight model to achieve outstanding performance on general time series forecasting. It achieves state-of-the-art forecasting performance on 9 real-world benchmarks in both zero-shot and full-shot settings with much better efficiency compared with existing time series foundation models.",
    "authors": [
      "Yihang Wang, Yuying Qiu, Peng Chen, Yang Shu, Zhongwen Rao, Lujia Pan, Bin Yang, Chenjuan Guo"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.837390"
  },
  {
    "id": "oai:arXiv.org:2506.06006v1",
    "journal": "arXiv_CS",
    "title": "Bootstrapping World Models from Dynamics Models in Multimodal Foundation Models",
    "link": "https://arxiv.org/abs/2506.06006",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06006v1 Announce Type: new \nAbstract: To what extent do vision-and-language foundation models possess a realistic world model (observation $\\times$ action $\\rightarrow$ observation) and a dynamics model (observation $\\times$ observation $\\rightarrow$ action), when actions are expressed through language? While open-source foundation models struggle with both, we find that fine-tuning them to acquire a dynamics model through supervision is significantly easier than acquiring a world model. In turn, dynamics models can be used to bootstrap world models through two main strategies: 1) weakly supervised learning from synthetic data and 2) inference time verification. Firstly, the dynamics model can annotate actions for unlabelled pairs of video frame observations to expand the training data. We further propose a new objective, where image tokens in observation pairs are weighted by their importance, as predicted by a recognition model. Secondly, the dynamics models can assign rewards to multiple samples of the world model to score them, effectively guiding search at inference time. We evaluate the world models resulting from both strategies through the task of action-centric image editing on Aurora-Bench. Our best model achieves a performance competitive with state-of-the-art image editing models, improving on them by a margin of $15\\%$ on real-world subsets according to GPT4o-as-judge, and achieving the best average human evaluation across all subsets of Aurora-Bench.",
    "authors": [
      "Yifu Qiu, Yftah Ziser, Anna Korhonen, Shay B. Cohen, Edoardo M. Ponti"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.837399"
  },
  {
    "id": "oai:arXiv.org:2506.06009v1",
    "journal": "arXiv_CS",
    "title": "Unlocking Recursive Thinking of LLMs: Alignment via Refinement",
    "link": "https://arxiv.org/abs/2506.06009",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06009v1 Announce Type: new \nAbstract: The OpenAI o1-series models have demonstrated that leveraging long-form Chain of Thought (CoT) can substantially enhance performance. However, the recursive thinking capabilities of Large Language Models (LLMs) remain limited, particularly in the absence of expert-curated data for distillation. In this paper, we propose \\textbf{AvR}: \\textbf{Alignment via Refinement}, a novel method aimed at unlocking the potential of LLMs for recursive reasoning through long-form CoT. AvR introduces a refinement process that integrates criticism and improvement actions, guided by differentiable learning techniques to optimize \\textbf{refinement-aware rewards}. As a result, the synthesized multi-round data can be organized as a long refinement thought, further enabling test-time scaling. Experimental results show that AvR significantly outperforms conventional preference optimization methods. Notably, with only 3k synthetic samples, our method boosts the performance of the LLaMA-3-8B-Instruct model by over 20\\% in win rate on AlpacaEval 2.0. Our code is available at Github (https://github.com/Banner-Z/AvR.git).",
    "authors": [
      "Haoke Zhang, Xiaobo Liang, Cunxiang Wang, Juntao Li, Min Zhang"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.837424"
  },
  {
    "id": "oai:arXiv.org:2506.06011v1",
    "journal": "arXiv_CS",
    "title": "London Blue Light Collaboration Evaluation: A Comparative Analysis of Spatio temporal Patterns on Emergency Services by London Ambulance Service and London Fire Brigade",
    "link": "https://arxiv.org/abs/2506.06011",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06011v1 Announce Type: new \nAbstract: With rising demand for emergency services, the London Ambulance Service, LAS, and the London Fire Brigade, LFB, face growing challenges in resource coordination. This study investigates the temporal and spatial similarities in their service demands to assess potential for routine cross-agency collaboration. Time series analysis revealed aligned demand peaks in summer, on Fridays, during daytime hours, and were highly sensitive to high temperature weather conditions. Bivariate mapping and Moran I indicated significant spatial overlaps in central London and Hillingdon. Geographically Weighted Regression, GWR, examined the influence of socioeconomic factors, while Comap analysis uncovered spatiotemporal heterogeneity across fire service types. The findings highlight opportunities for targeted collaboration in high-overlap areas and peak periods, offering practical insights to enhance emergency service resilience and efficiency.",
    "authors": [
      "Fangyuan Li, Yijing Li, Luke Edward Rogerson"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.837434"
  },
  {
    "id": "oai:arXiv.org:2506.06012v1",
    "journal": "arXiv_CS",
    "title": "Enhanced Trust Region Sequential Convex Optimization for Multi-Drone Thermal Screening Trajectory Planning in Urban Environments",
    "link": "https://arxiv.org/abs/2506.06012",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06012v1 Announce Type: new \nAbstract: The rapid detection of abnormal body temperatures in urban populations is essential for managing public health risks, especially during outbreaks of infectious diseases. Multi-drone thermal screening systems offer promising solutions for fast, large-scale, and non-intrusive human temperature monitoring. However, trajectory planning for multiple drones in complex urban environments poses significant challenges, including collision avoidance, coverage efficiency, and constrained flight environments. In this study, we propose an enhanced trust region sequential convex optimization (TR-SCO) algorithm for optimal trajectory planning of multiple drones performing thermal screening tasks. Our improved algorithm integrates a refined convex optimization formulation within a trust region framework, effectively balancing trajectory smoothness, obstacle avoidance, altitude constraints, and maximum screening coverage. Simulation results demonstrate that our approach significantly improves trajectory optimality and computational efficiency compared to conventional convex optimization methods. This research provides critical insights and practical contributions toward deploying efficient multi-drone systems for real-time thermal screening in urban areas. For reader who are interested in our research, we release our source code at https://github.com/Cherry0302/Enhanced-TR-SCO.",
    "authors": [
      "Kaiyuan Chen, Zhengjie Hu, Shaolin Zhang, Yuanqing Xia, Wannian Liang, Shuo Wang"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.837444"
  },
  {
    "id": "oai:arXiv.org:2506.06013v1",
    "journal": "arXiv_CS",
    "title": "Scalable Counting of Minimal Trap Spaces and Fixed Points in Boolean Networks",
    "link": "https://arxiv.org/abs/2506.06013",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06013v1 Announce Type: new \nAbstract: Boolean Networks (BNs) serve as a fundamental modeling framework for capturing complex dynamical systems across various domains, including systems biology, computational logic, and artificial intelligence. A crucial property of BNs is the presence of trap spaces -- subspaces of the state space that, once entered, cannot be exited. Minimal trap spaces, in particular, play a significant role in analyzing the long-term behavior of BNs, making their efficient enumeration and counting essential. The fixed points in BNs are a special case of minimal trap spaces. In this work, we formulate several meaningful counting problems related to minimal trap spaces and fixed points in BNs. These problems provide valuable insights both within BN theory (e.g., in probabilistic reasoning and dynamical analysis) and in broader application areas, including systems biology, abstract argumentation, and logic programming. To address these computational challenges, we propose novel methods based on {\\em approximate answer set counting}, leveraging techniques from answer set programming. Our approach efficiently approximates the number of minimal trap spaces and the number of fixed points without requiring exhaustive enumeration, making it particularly well-suited for large-scale BNs. Our experimental evaluation on an extensive and diverse set of benchmark instances shows that our methods significantly improve the feasibility of counting minimal trap spaces and fixed points, paving the way for new applications in BN analysis and beyond.",
    "authors": [
      "Mohimenul Kabir, Van-Giang Trinh, Samuel Pastva, Kuldeep S Meel"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.837452"
  },
  {
    "id": "oai:arXiv.org:2506.06015v1",
    "journal": "arXiv_CS",
    "title": "On the Merits of LLM-Based Corpus Enrichment",
    "link": "https://arxiv.org/abs/2506.06015",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06015v1 Announce Type: new \nAbstract: Generative AI (genAI) technologies -- specifically, large language models (LLMs) -- and search have evolving relations. We argue for a novel perspective: using genAI to enrich a document corpus so as to improve query-based retrieval effectiveness. The enrichment is based on modifying existing documents or generating new ones. As an empirical proof of concept, we use LLMs to generate documents relevant to a topic which are more retrievable than existing ones. In addition, we demonstrate the potential merits of using corpus enrichment for retrieval augmented generation (RAG) and answer attribution in question answering.",
    "authors": [
      "Gal Zur, Tommy Mordo, Moshe Tennenholtz, Oren Kurland"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.837460"
  },
  {
    "id": "oai:arXiv.org:2506.06016v1",
    "journal": "arXiv_CS",
    "title": "Equivariant Filter for Relative Attitude and Target Angular Velocity Estimation",
    "link": "https://arxiv.org/abs/2506.06016",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06016v1 Announce Type: new \nAbstract: Accurate estimation of the relative attitude and angular velocity between two rigid bodies is fundamental in aerospace applications such as spacecraft rendezvous and docking. In these scenarios, a chaser vehicle must determine the orientation and angular velocity of a target object using onboard sensors. This work addresses the challenge of designing an Equivariant Filter (EqF) that can reliably estimate both the relative attitude and the target angular velocity using noisy observations of two known, non-collinear vectors fixed in the target frame. To derive the EqF, a symmetry for the system is proposed and an equivariant lift onto the symmetry group is calculated. Observability and convergence properties are analyzed. Simulations demonstrate the filter's performance, with Monte Carlo runs yielding statistically significant results. The impact of low-rate measurements is also examined and a strategy to mitigate this effect is proposed. Experimental results, using fiducial markers and both conventional and event cameras for measurement acquisition, further validate the approach, confirming its effectiveness in a realistic setting.",
    "authors": [
      "Gil Serrano, Bruno J. Guerreiro, Pedro Louren\\c{c}o, Rita Cunha"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.837469"
  },
  {
    "id": "oai:arXiv.org:2506.06017v1",
    "journal": "arXiv_CS",
    "title": "AgentSwift: Efficient LLM Agent Design via Value-guided Hierarchical Search",
    "link": "https://arxiv.org/abs/2506.06017",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06017v1 Announce Type: new \nAbstract: Large language model (LLM) agents have demonstrated strong capabilities across diverse domains. However, designing high-performing agentic systems remains challenging. Existing agent search methods suffer from three major limitations: (1) an emphasis on optimizing agentic workflows while under-utilizing proven human-designed components such as memory, planning, and tool use; (2) high evaluation costs, as each newly generated agent must be fully evaluated on benchmarks; and (3) inefficient search in large search space. In this work, we introduce a comprehensive framework to address these challenges. First, We propose a hierarchical search space that jointly models agentic workflow and composable functional components, enabling richer agentic system designs. Building on this structured design space, we introduce a predictive value model that estimates agent performance given agentic system and task description, allowing for efficient, low-cost evaluation during the search process. Finally, we present a hierarchical Monte Carlo Tree Search (MCTS) strategy informed by uncertainty to guide the search. Experiments on seven benchmarks, covering embodied, math, web, tool, and game, show that our method achieves an average performance gain of 8.34\\% over state-of-the-art baselines and exhibits faster search progress with steeper improvement trajectories. Code repo is available at https://github.com/Ericccc02/AgentSwift.",
    "authors": [
      "Yu Li, Lehui Li, Zhihao Wu, Qingmin Liao, Jianye Hao, Kun Shao, Fengli Xu, Yong Li"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.837478"
  },
  {
    "id": "oai:arXiv.org:2506.06018v1",
    "journal": "arXiv_CS",
    "title": "Optimization-Free Universal Watermark Forgery with Regenerative Diffusion Models",
    "link": "https://arxiv.org/abs/2506.06018",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06018v1 Announce Type: new \nAbstract: Watermarking becomes one of the pivotal solutions to trace and verify the origin of synthetic images generated by artificial intelligence models, but it is not free of risks. Recent studies demonstrate the capability to forge watermarks from a target image onto cover images via adversarial optimization without knowledge of the target generative model and watermark schemes. In this paper, we uncover a greater risk of an optimization-free and universal watermark forgery that harnesses existing regenerative diffusion models. Our proposed forgery attack, PnP (Plug-and-Plant), seamlessly extracts and integrates the target watermark via regenerating the image, without needing any additional optimization routine. It allows for universal watermark forgery that works independently of the target image's origin or the watermarking model used. We explore the watermarked latent extracted from the target image and visual-textual context of cover images as priors to guide sampling of the regenerative process. Extensive evaluation on 24 scenarios of model-data-watermark combinations demonstrates that PnP can successfully forge the watermark (up to 100% detectability and user attribution), and maintain the best visual perception. By bypassing model retraining and enabling adaptability to any image, our approach significantly broadens the scope of forgery attacks, presenting a greater challenge to the security of current watermarking techniques for diffusion models and the authority of watermarking schemes in synthetic data generation and governance.",
    "authors": [
      "Chaoyi Zhu, Zaitang Li, Renyi Yang, Robert Birke, Pin-Yu Chen, Tsung-Yi Ho, Lydia Y. Chen"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.837487"
  },
  {
    "id": "oai:arXiv.org:2506.06019v1",
    "journal": "arXiv_CS",
    "title": "Runtime Analysis of Evolutionary NAS for Multiclass Classification",
    "link": "https://arxiv.org/abs/2506.06019",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06019v1 Announce Type: new \nAbstract: Evolutionary neural architecture search (ENAS) is a key part of evolutionary machine learning, which commonly utilizes evolutionary algorithms (EAs) to automatically design high-performing deep neural architectures. During past years, various ENAS methods have been proposed with exceptional performance. However, the theory research of ENAS is still in the infant. In this work, we step for the runtime analysis, which is an essential theory aspect of EAs, of ENAS upon multiclass classification problems. Specifically, we first propose a benchmark to lay the groundwork for the analysis. Furthermore, we design a two-level search space, making it suitable for multiclass classification problems and consistent with the common settings of ENAS. Based on both designs, we consider (1+1)-ENAS algorithms with one-bit and bit-wise mutations, and analyze their upper and lower bounds on the expected runtime. We prove that the algorithm using both mutations can find the optimum with the expected runtime upper bound of $O(rM\\ln{rM})$ and lower bound of $\\Omega(rM\\ln{M})$. This suggests that a simple one-bit mutation may be greatly considered, given that most state-of-the-art ENAS methods are laboriously designed with the bit-wise mutation. Empirical studies also support our theoretical proof.",
    "authors": [
      "Zeqiong Lv, Chao Qian, Yun Liu, Jiahao Fan, Yanan Sun"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.837495"
  },
  {
    "id": "oai:arXiv.org:2506.06020v1",
    "journal": "arXiv_CS",
    "title": "When to Trust Context: Self-Reflective Debates for Context Reliability",
    "link": "https://arxiv.org/abs/2506.06020",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06020v1 Announce Type: new \nAbstract: Large language models frequently encounter conflicts between their parametric knowledge and contextual input, often resulting in factual inconsistencies or hallucinations. We propose Self-Reflective Debate for Contextual Reliability (SR-DCR), a lightweight framework that integrates token-level self-confidence with an asymmetric multi-agent debate to adjudicate such conflicts. A critic, deprived of context, challenges a defender who argues from the given passage; a judge model evaluates the debate and determines the context's reliability. The final answer is selected by combining the verdict with model confidence. Experiments on the ClashEval benchmark demonstrate that SR-DCR consistently enhances robustness to misleading context while maintaining accuracy on trustworthy inputs, outperforming both classical debate and confidence-only baselines with minimal computational overhead. The code is available at https://github.com/smiles724/Self-Reflective-Debates.",
    "authors": [
      "Zeqi Zhou, Fang Wu, Shayan Talaei, Haokai Zhao, Cheng Meixin, Tinson Xu, Amin Saberi, Yejin Choi"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.837503"
  },
  {
    "id": "oai:arXiv.org:2506.06021v1",
    "journal": "arXiv_CS",
    "title": "Unisoma: A Unified Transformer-based Solver for Multi-Solid Systems",
    "link": "https://arxiv.org/abs/2506.06021",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06021v1 Announce Type: new \nAbstract: Multi-solid systems are foundational to a wide range of real-world applications, yet modeling their complex interactions remains challenging. Existing deep learning methods predominantly rely on implicit modeling, where the factors influencing solid deformation are not explicitly represented but are instead indirectly learned. However, as the number of solids increases, these methods struggle to accurately capture intricate physical interactions. In this paper, we introduce a novel explicit modeling paradigm that incorporates factors influencing solid deformation through structured modules. Specifically, we present Unisoma, a unified and flexible Transformer-based model capable of handling variable numbers of solids. Unisoma directly captures physical interactions using contact modules and adaptive interaction allocation mechanism, and learns the deformation through a triplet relationship. Compared to implicit modeling techniques, explicit modeling is more well-suited for multi-solid systems with diverse coupling patterns, as it enables detailed treatment of each solid while preventing information blending and confusion. Experimentally, Unisoma achieves consistent state-of-the-art performance across seven well-established datasets and two complex multi-solid tasks. Code is avaiable at \\href{this link}{https://github.com/therontau0054/Unisoma}.",
    "authors": [
      "Shilong Tao, Zhe Feng, Haonan Sun, Zhanxing Zhu, Yunhuai Liu"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.837512"
  },
  {
    "id": "oai:arXiv.org:2506.06023v1",
    "journal": "arXiv_CS",
    "title": "Restereo: Diffusion stereo video generation and restoration",
    "link": "https://arxiv.org/abs/2506.06023",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06023v1 Announce Type: new \nAbstract: Stereo video generation has been gaining increasing attention with recent advancements in video diffusion models. However, most existing methods focus on generating 3D stereoscopic videos from monocular 2D videos. These approaches typically assume that the input monocular video is of high quality, making the task primarily about inpainting occluded regions in the warped video while preserving disoccluded areas. In this paper, we introduce a new pipeline that not only generates stereo videos but also enhances both left-view and right-view videos consistently with a single model. Our approach achieves this by fine-tuning the model on degraded data for restoration, as well as conditioning the model on warped masks for consistent stereo generation. As a result, our method can be fine-tuned on a relatively small synthetic stereo video datasets and applied to low-quality real-world videos, performing both stereo video generation and restoration. Experiments demonstrate that our method outperforms existing approaches both qualitatively and quantitatively in stereo video generation from low-resolution inputs.",
    "authors": [
      "Xingchang Huang, Ashish Kumar Singh, Florian Dubost, Cristina Nader Vasconcelos, Sakar Khattar, Liang Shi, Christian Theobalt, Cengiz Oztireli, Gurprit Singh"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.837520"
  },
  {
    "id": "oai:arXiv.org:2506.06026v1",
    "journal": "arXiv_CS",
    "title": "O-MaMa @ EgoExo4D Correspondence Challenge: Learning Object Mask Matching between Egocentric and Exocentric Views",
    "link": "https://arxiv.org/abs/2506.06026",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06026v1 Announce Type: new \nAbstract: The goal of the correspondence task is to segment specific objects across different views. This technical report re-defines cross-image segmentation by treating it as a mask matching task. Our method consists of: (1) A Mask-Context Encoder that pools dense DINOv2 semantic features to obtain discriminative object-level representations from FastSAM mask candidates, (2) an Ego$\\leftrightarrow$Exo Cross-Attention that fuses multi-perspective observations, (3) a Mask Matching contrastive loss that aligns cross-view features in a shared latent space, and (4) a Hard Negative Adjacent Mining strategy to encourage the model to better differentiate between nearby objects.",
    "authors": [
      "Lorenzo Mur-Labadia, Maria Santos-Villafranca, Alejandro Perez-Yus, Jesus Bermudez-Cameo, Ruben Martinez-Cantin, Jose J. Guerrero"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.837536"
  },
  {
    "id": "oai:arXiv.org:2506.06027v1",
    "journal": "arXiv_CS",
    "title": "Sample-Specific Noise Injection For Diffusion-Based Adversarial Purification",
    "link": "https://arxiv.org/abs/2506.06027",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06027v1 Announce Type: new \nAbstract: Diffusion-based purification (DBP) methods aim to remove adversarial noise from the input sample by first injecting Gaussian noise through a forward diffusion process, and then recovering the clean example through a reverse generative process. In the above process, how much Gaussian noise is injected to the input sample is key to the success of DBP methods, which is controlled by a constant noise level $t^*$ for all samples in existing methods. In this paper, we discover that an optimal $t^*$ for each sample indeed could be different. Intuitively, the cleaner a sample is, the less the noise it should be injected, and vice versa. Motivated by this finding, we propose a new framework, called Sample-specific Score-aware Noise Injection (SSNI). Specifically, SSNI uses a pre-trained score network to estimate how much a data point deviates from the clean data distribution (i.e., score norms). Then, based on the magnitude of score norms, SSNI applies a reweighting function to adaptively adjust $t^*$ for each sample, achieving sample-specific noise injections. Empirically, incorporating our framework with existing DBP methods results in a notable improvement in both accuracy and robustness on CIFAR-10 and ImageNet-1K, highlighting the necessity to allocate distinct noise levels to different samples in DBP methods. Our code is available at: https://github.com/tmlr-group/SSNI.",
    "authors": [
      "Yuhao Sun, Jiacheng Zhang, Zesheng Ye, Chaowei Xiao, Feng Liu"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.837545"
  },
  {
    "id": "oai:arXiv.org:2506.06028v1",
    "journal": "arXiv_CS",
    "title": "End-to-End Framework for Robot Lawnmower Coverage Path Planning using Cellular Decomposition",
    "link": "https://arxiv.org/abs/2506.06028",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06028v1 Announce Type: new \nAbstract: Efficient Coverage Path Planning (CPP) is necessary for autonomous robotic lawnmowers to effectively navigate and maintain lawns with diverse and irregular shapes. This paper introduces a comprehensive end-to-end pipeline for CPP, designed to convert user-defined boundaries on an aerial map into optimized coverage paths seamlessly. The pipeline includes user input extraction, coordinate transformation, area decomposition and path generation using our novel AdaptiveDecompositionCPP algorithm, preview and customization through an interactive coverage path visualizer, and conversion to actionable GPS waypoints. The AdaptiveDecompositionCPP algorithm combines cellular decomposition with an adaptive merging strategy to reduce non-mowing travel thereby enhancing operational efficiency. Experimental evaluations, encompassing both simulations and real-world lawnmower tests, demonstrate the effectiveness of the framework in coverage completeness and mowing efficiency.",
    "authors": [
      "Nikunj Shah, Utsav Dey, Kenji Nishimiya"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.837554"
  },
  {
    "id": "oai:arXiv.org:2506.06032v1",
    "journal": "arXiv_CS",
    "title": "Modeling human reputation-seeking behavior in a spatio-temporally complex public good provision game",
    "link": "https://arxiv.org/abs/2506.06032",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06032v1 Announce Type: new \nAbstract: Multi-agent reinforcement learning algorithms are useful for simulating social behavior in settings that are too complex for other theoretical approaches like game theory. However, they have not yet been empirically supported by laboratory experiments with real human participants. In this work we demonstrate how multi-agent reinforcement learning can model group behavior in a spatially and temporally complex public good provision game called Clean Up. We show that human groups succeed in Clean Up when they can see who is who and track reputations over time but fail under conditions of anonymity. A new multi-agent reinforcement learning model of reputation-based cooperation demonstrates the same difference between identifiable and anonymous conditions. Furthermore, both human groups and artificial agent groups solve the problem via turn-taking despite other options being available. Our results highlight the benefits of using multi-agent reinforcement learning to model human social behavior in complex environments.",
    "authors": [
      "Edward Hughes, Tina O. Zhu, Martin J. Chadwick, Raphael Koster, Antonio Garc\\'ia Casta\\~neda, Charles Beattie, Thore Graepel, Matthew M. Botvinick, Joel Z. Leibo"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.837562"
  },
  {
    "id": "oai:arXiv.org:2506.06033v1",
    "journal": "arXiv_CS",
    "title": "Large Language Models are Demonstration Pre-Selectors for Themselves",
    "link": "https://arxiv.org/abs/2506.06033",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06033v1 Announce Type: new \nAbstract: In-context learning (ICL) with large language models (LLMs) delivers strong few-shot performance by choosing few-shot demonstrations from the entire training data. However, existing ICL methods, which rely on similarity or diversity scores to choose demonstrations, incur high computational costs due to repeatedly retrieval from large-scale datasets for each query. To this end, we propose FEEDER (FEw yet Essential Demonstration prE-selectoR), a novel pre-selection framework that identifies a representative subset of demonstrations containing the most representative examples in the training data, tailored to specific LLMs. To construct this subset, we introduce the \"sufficiency\" and \"necessity\" metrics in the pre-selection stage and design a tree-based algorithm to identify representative examples efficiently. Once pre-selected, this representative subset can effectively replace the full training data, improving efficiency while maintaining comparable performance in ICL. Additionally, our pre-selected subset also benefits fine-tuning LLMs, where we introduce a bi-level optimization method that enhances training efficiency without sacrificing performance. Experiments with LLMs ranging from 300M to 8B parameters show that FEEDER can reduce training data size by over 20% while maintaining performance and seamlessly integrating with various downstream demonstration selection strategies in ICL.",
    "authors": [
      "Jiarui Jin, Yuwei Wu, Haoxuan Li, Xiaoting He, Weinan Zhang, Yiming Yang, Yong Yu, Jun Wang, Mengyue Yang"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.837571"
  },
  {
    "id": "oai:arXiv.org:2506.06034v1",
    "journal": "arXiv_CS",
    "title": "MATP-BENCH: Can MLLM Be a Good Automated Theorem Prover for Multimodal Problems?",
    "link": "https://arxiv.org/abs/2506.06034",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06034v1 Announce Type: new \nAbstract: Numerous theorems, such as those in geometry, are often presented in multimodal forms (e.g., diagrams). Humans benefit from visual reasoning in such settings, using diagrams to gain intuition and guide the proof process. Modern Multimodal Large Language Models (MLLMs) have demonstrated remarkable capabilities in solving a wide range of mathematical problems. However, the potential of MLLMs as Automated Theorem Provers (ATPs), specifically in the multimodal domain, remains underexplored. In this paper, we introduce the Multimodal Automated Theorem Proving benchmark (MATP-BENCH), a new Multimodal, Multi-level, and Multi-language benchmark designed to evaluate MLLMs in this role as multimodal automated theorem provers. MATP-BENCH consists of 1056 multimodal theorems drawn from high school, university, and competition-level mathematics. All these multimodal problems are accompanied by formalizations in Lean 4, Coq and Isabelle, thus making the benchmark compatible with a wide range of theorem-proving frameworks. MATP-BENCH requires models to integrate sophisticated visual understanding with mastery of a broad spectrum of mathematical knowledge and rigorous symbolic reasoning to generate formal proofs. We use MATP-BENCH to evaluate a variety of advanced multimodal language models. Existing methods can only solve a limited number of the MATP-BENCH problems, indicating that this benchmark poses an open challenge for research on automated theorem proving.",
    "authors": [
      "Zhitao He, Zongwei Lyu, Dazhong Chen, Dadi Guo, Yi R. Fung"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.837580"
  },
  {
    "id": "oai:arXiv.org:2506.06035v1",
    "journal": "arXiv_CS",
    "title": "HAVIR: HierArchical Vision to Image Reconstruction using CLIP-Guided Versatile Diffusion",
    "link": "https://arxiv.org/abs/2506.06035",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06035v1 Announce Type: new \nAbstract: Reconstructing visual information from brain activity bridges the gap between neuroscience and computer vision. Even though progress has been made in decoding images from fMRI using generative models, a challenge remains in accurately recovering highly complex visual stimuli. This difficulty stems from their elemental density and diversity, sophisticated spatial structures, and multifaceted semantic information.\n  To address these challenges, we propose HAVIR that contains two adapters: (1) The AutoKL Adapter transforms fMRI voxels into a latent diffusion prior, capturing topological structures; (2) The CLIP Adapter converts the voxels to CLIP text and image embeddings, containing semantic information. These complementary representations are fused by Versatile Diffusion to generate the final reconstructed image. To extract the most essential semantic information from complex scenarios, the CLIP Adapter is trained with text captions describing the visual stimuli and their corresponding semantic images synthesized from these captions. The experimental results demonstrate that HAVIR effectively reconstructs both structural features and semantic information of visual stimuli even in complex scenarios, outperforming existing models.",
    "authors": [
      "Shiyi Zhang, Dong Liang, Hairong Zheng, Yihang Zhou"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.837588"
  },
  {
    "id": "oai:arXiv.org:2506.06037v1",
    "journal": "arXiv_CS",
    "title": "SVD: Spatial Video Dataset",
    "link": "https://arxiv.org/abs/2506.06037",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06037v1 Announce Type: new \nAbstract: Stereoscopic video has long been the subject of research due to its capacity to deliver immersive three-dimensional content across a wide range of applications, from virtual and augmented reality to advanced human-computer interaction. The dual-view format inherently provides binocular disparity cues that enhance depth perception and realism, making it indispensable for fields such as telepresence, 3D mapping, and robotic vision. Until recently, however, end-to-end pipelines for capturing, encoding, and viewing high-quality 3D video were neither widely accessible nor optimized for consumer-grade devices. Today's smartphones, such as the iPhone Pro, and modern Head-Mounted Displays (HMDs), like the Apple Vision Pro (AVP), offer built-in support for stereoscopic video capture, hardware-accelerated encoding, and seamless playback on devices like the Apple Vision Pro and Meta Quest 3, requiring minimal user intervention. Apple refers to this streamlined workflow as spatial video. Making the full stereoscopic video process available to everyone has made new applications possible. Despite these advances, there remains a notable absence of publicly available datasets that include the complete spatial video pipeline.\n  In this paper, we introduce SVD, a spatial video dataset comprising 300 five-second video sequences, 150 captured using an iPhone Pro and 150 with an AVP. Additionally, 10 longer videos with a minimum duration of 2 minutes have been recorded. The SVD dataset is publicly released under an open-access license to facilitate research in codec performance evaluation, subjective and objective quality of experience (QoE) assessment, depth-based computer vision, stereoscopic video streaming, and other emerging 3D applications such as neural rendering and volumetric capture. Link to the dataset: https://cd-athena.github.io/SVD/",
    "authors": [
      "M. H. Izadimehr, Milad Ghanbari, Guodong Chen, Wei Zhou, Xiaoshuai Hao, Mallesham Dasari, Christian Timmerer, Hadi Amirpour"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.837596"
  },
  {
    "id": "oai:arXiv.org:2506.06039v1",
    "journal": "arXiv_CS",
    "title": "Do-PFN: In-Context Learning for Causal Effect Estimation",
    "link": "https://arxiv.org/abs/2506.06039",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06039v1 Announce Type: new \nAbstract: Estimation of causal effects is critical to a range of scientific disciplines. Existing methods for this task either require interventional data, knowledge about the ground truth causal graph, or rely on assumptions such as unconfoundedness, restricting their applicability in real-world settings. In the domain of tabular machine learning, Prior-data fitted networks (PFNs) have achieved state-of-the-art predictive performance, having been pre-trained on synthetic data to solve tabular prediction problems via in-context learning. To assess whether this can be transferred to the harder problem of causal effect estimation, we pre-train PFNs on synthetic data drawn from a wide variety of causal structures, including interventions, to predict interventional outcomes given observational data. Through extensive experiments on synthetic case studies, we show that our approach allows for the accurate estimation of causal effects without knowledge of the underlying causal graph. We also perform ablation studies that elucidate Do-PFN's scalability and robustness across datasets with a variety of causal characteristics.",
    "authors": [
      "Jake Robertson, Arik Reuter, Siyuan Guo, Noah Hollmann, Frank Hutter, Bernhard Sch\\\"olkopf"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.837612"
  },
  {
    "id": "oai:arXiv.org:2506.06040v1",
    "journal": "arXiv_CS",
    "title": "Hardware Accelerated Neural Block Texture Compression with Cooperative Vectors",
    "link": "https://arxiv.org/abs/2506.06040",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06040v1 Announce Type: new \nAbstract: In this work, we present an extension to the neural texture compression method of Weinreich and colleagues [2024]. Like them, we leverage existing block compression methods which permit to use hardware texture filtering to store a neural representation of physically-based rendering (PBR) texture sets (including albedo, normal maps, roughness, etc.). However, we show that low dynamic range block compression formats still make the solution viable. Thanks to this, we show that we can achieve higher compression ratio or higher quality at fixed compression ratio. We improve performance at runtime using a tile based rendering architecture that leverage hardware matrix multiplication engine. Thanks to all this, we render 4k textures sets (9 channels per asset) with anisotropic filtering at 1080p using only 28MB of VRAM per texture set at 0.55ms on an Intel B580.",
    "authors": [
      "Belcour Laurent, Benyoub Anis"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.837621"
  },
  {
    "id": "oai:arXiv.org:2506.06041v1",
    "journal": "arXiv_CS",
    "title": "Tensor-to-Tensor Models with Fast Iterated Sum Features",
    "link": "https://arxiv.org/abs/2506.06041",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06041v1 Announce Type: new \nAbstract: Data in the form of images or higher-order tensors is ubiquitous in modern deep learning applications. Owing to their inherent high dimensionality, the need for subquadratic layers processing such data is even more pressing than for sequence data. We propose a novel tensor-to-tensor layer with linear cost in the input size, utilizing the mathematical gadget of ``corner trees'' from the field of permutation counting. In particular, for order-two tensors, we provide an image-to-image layer that can be plugged into image processing pipelines. On the one hand, our method can be seen as a higher-order generalization of state-space models. On the other hand, it is based on a multiparameter generalization of the signature of iterated integrals (or sums). The proposed tensor-to-tensor concept is used to build a neural network layer called the Fast Iterated Sums (FIS) layer which integrates seamlessly with other layer types. We demonstrate the usability of the FIS layer with both classification and anomaly detection tasks. By replacing some layers of a smaller ResNet architecture with FIS, a similar accuracy (with a difference of only 0.1\\%) was achieved in comparison to a larger ResNet while reducing the number of trainable parameters and multi-add operations. The FIS layer was also used to build an anomaly detection model that achieved an average AUROC of 97.3\\% on the texture images of the popular MVTec AD dataset. The processing and modelling codes are publicly available at https://github.com/diehlj/fast-iterated-sums.",
    "authors": [
      "Joscha Diehl, Rasheed Ibraheem, Leonard Schmitz, Yue Wu"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.837629"
  },
  {
    "id": "oai:arXiv.org:2506.06042v1",
    "journal": "arXiv_CS",
    "title": "SDS-Net: Shallow-Deep Synergism-detection Network for infrared small target detection",
    "link": "https://arxiv.org/abs/2506.06042",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06042v1 Announce Type: new \nAbstract: Current CNN-based infrared small target detection(IRSTD) methods generally overlook the heterogeneity between shallow and deep features, leading to inefficient collaboration between shallow fine grained structural information and deep high-level semantic representations. Additionally, the dependency relationships and fusion mechanisms across different feature hierarchies lack systematic modeling, which fails to fully exploit the complementarity of multilevel features. These limitations hinder IRSTD performance while incurring substantial computational costs. To address these challenges, this paper proposes a shallow-deep synergistic detection network (SDS-Net) that efficiently models multilevel feature representations to increase both the detection accuracy and computational efficiency in IRSTD tasks. SDS-Net introduces a dual-branch architecture that separately models the structural characteristics and semantic properties of features, effectively preserving shallow spatial details while capturing deep semantic representations, thereby achieving high-precision detection with significantly improved inference speed. Furthermore, the network incorporates an adaptive feature fusion module to dynamically model cross-layer feature correlations, enhancing overall feature collaboration and representation capability. Comprehensive experiments on three public datasets (NUAA-SIRST, NUDT-SIRST, and IRSTD-1K) demonstrate that SDS-Net outperforms state-of-the-art IRSTD methods while maintaining low computational complexity and high inference efficiency, showing superior detection performance and broad application prospects. Our code will be made public at https://github.com/PhysiLearn/SDS-Net.",
    "authors": [
      "Taoran Yue, Xiaojin Lu, Jiaxi Cai, Yuanping Chen, Shibing Chu"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.837638"
  },
  {
    "id": "oai:arXiv.org:2506.06044v1",
    "journal": "arXiv_CS",
    "title": "On the Complexity of Claw-Free Vertex Splitting",
    "link": "https://arxiv.org/abs/2506.06044",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06044v1 Announce Type: new \nAbstract: Vertex splitting consists of taking a vertex v in a graph and replacing it with two vertices whose combined neighborhoods is the neighborhood of v. The split is said to be exclusive when these neighborhoods are disjoint. In the (Exclusive) Claw-Free Vertex Splitting problem, we are given a graph G and an integer k, and we are asked if we can find a subset of at most k vertices whose (exclusive) splitting can make G claw-free. We consider the complexity of Exclusive Claw-Free Vertex Splitting and prove it to be NP-complete in general, while admitting a polynomial-time algorithm when the input graph has maximum degree four. This result settles an open problem posed in [Firbas \\& Sorge, ISAAC 2024]. On the positive side, we show that Claw-Free Vertex Splitting is fixed-parameter tractable by providing a cubic-order kernel. We also show that our results can be generalized to $K_{1,c}$-Free Vertex Splitting for all $c \\geq 3$.",
    "authors": [
      "Faisal N. Abu-Khzam, Sergio Thoumi"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.837646"
  },
  {
    "id": "oai:arXiv.org:2506.06045v1",
    "journal": "arXiv_CS",
    "title": "Diffusion-Based Hierarchical Graph Neural Networks for Simulating Nonlinear Solid Mechanics",
    "link": "https://arxiv.org/abs/2506.06045",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06045v1 Announce Type: new \nAbstract: Graph-based learned simulators have emerged as a promising approach for simulating physical systems on unstructured meshes, offering speed and generalization across diverse geometries. However, they often struggle with capturing global phenomena, such as bending or long-range correlations, and suffer from error accumulation over long rollouts due to their reliance on local message passing and direct next-step prediction. We address these limitations by introducing the Rolling Diffusion-Batched Inference Network (ROBIN), a novel learned simulator that integrates two key innovations: (i) Rolling Diffusion, a parallelized inference scheme that amortizes the cost of diffusion-based refinement across physical time steps by overlapping denoising steps across a temporal window. (ii) A Hierarchical Graph Neural Network built on algebraic multigrid coarsening, enabling multiscale message passing across different mesh resolutions. This architecture, implemented via Algebraic-hierarchical Message Passing Networks, captures both fine-scale local dynamics and global structural effects critical for phenomena like beam bending or multi-body contact. We validate ROBIN on challenging 2D and 3D solid mechanics benchmarks involving geometric, material, and contact nonlinearities. ROBIN achieves state-of-the-art accuracy on all tasks, substantially outperforming existing next-step learned simulators while reducing inference time by up to an order of magnitude compared to standard diffusion simulators.",
    "authors": [
      "Tobias W\\\"urth, Niklas Freymuth, Gerhard Neumann, Luise K\\\"arger"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.837655"
  },
  {
    "id": "oai:arXiv.org:2506.06048v1",
    "journal": "arXiv_CS",
    "title": "TRUST: Test-time Resource Utilization for Superior Trustworthiness",
    "link": "https://arxiv.org/abs/2506.06048",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06048v1 Announce Type: new \nAbstract: Standard uncertainty estimation techniques, such as dropout, often struggle to clearly distinguish reliable predictions from unreliable ones. We attribute this limitation to noisy classifier weights, which, while not impairing overall class-level predictions, render finer-level statistics less informative. To address this, we propose a novel test-time optimization method that accounts for the impact of such noise to produce more reliable confidence estimates. This score defines a monotonic subset-selection function, where population accuracy consistently increases as samples with lower scores are removed, and it demonstrates superior performance in standard risk-based metrics such as AUSE and AURC. Additionally, our method effectively identifies discrepancies between training and test distributions, reliably differentiates in-distribution from out-of-distribution samples, and elucidates key differences between CNN and ViT classifiers across various vision datasets.",
    "authors": [
      "Haripriya Harikumar, Santu Rana"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.837663"
  },
  {
    "id": "oai:arXiv.org:2506.06055v1",
    "journal": "arXiv_CS",
    "title": "The Turn to Practice in Design Ethics: Characteristics and Future Research Directions for HCI Research",
    "link": "https://arxiv.org/abs/2506.06055",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06055v1 Announce Type: new \nAbstract: As emerging technologies continue to shape society, there is a growing emphasis on the need to engage with design ethics as it unfolds in practice to better capture the complexities of ethical considerations embedded in day-to-day work. Positioned within the broader \"turn to practice\" in HCI, the review characterizes this body of work in terms of its motivations, conceptual frameworks, methodologies, and contributions across a range of design disciplines and academic databases. The findings reveal a shift away from static and abstract ethical frameworks toward an understanding of ethics as an evolving, situated, and inherent aspect of design activities, one that can be cultivated and fostered collaboratively. This review proposes six future directions for establishing common research priorities and fostering the field's growth. While the review promotes cross-disciplinary dialogue, we argue that HCI research, given its cumulative experience with practice-oriented research, is well-equipped to guide this emerging strand of work on design ethics.",
    "authors": [
      "Gizem \\\"Oz, Christian Dindler, Sharon Lindberg"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.837680"
  },
  {
    "id": "oai:arXiv.org:2506.06057v1",
    "journal": "arXiv_CS",
    "title": "Hey, That's My Data! Label-Only Dataset Inference in Large Language Models",
    "link": "https://arxiv.org/abs/2506.06057",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06057v1 Announce Type: new \nAbstract: Large Language Models (LLMs) have revolutionized Natural Language Processing by excelling at interpreting, reasoning about, and generating human language. However, their reliance on large-scale, often proprietary datasets poses a critical challenge: unauthorized usage of such data can lead to copyright infringement and significant financial harm. Existing dataset-inference methods typically depend on log probabilities to detect suspicious training material, yet many leading LLMs have begun withholding or obfuscating these signals. This reality underscores the pressing need for label-only approaches capable of identifying dataset membership without relying on internal model logits.\n  We address this gap by introducing CatShift, a label-only dataset-inference framework that capitalizes on catastrophic forgetting: the tendency of an LLM to overwrite previously learned knowledge when exposed to new data. If a suspicious dataset was previously seen by the model, fine-tuning on a portion of it triggers a pronounced post-tuning shift in the model's outputs; conversely, truly novel data elicits more modest changes. By comparing the model's output shifts for a suspicious dataset against those for a known non-member validation set, we statistically determine whether the suspicious set is likely to have been part of the model's original training corpus. Extensive experiments on both open-source and API-based LLMs validate CatShift's effectiveness in logit-inaccessible settings, offering a robust and practical solution for safeguarding proprietary data.",
    "authors": [
      "Chen Xiong, Zihao Wang, Rui Zhu, Tsung-Yi Ho, Pin-Yu Chen, Jingwei Xiong, Haixu Tang, Lucila Ohno-Machado"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.837688"
  },
  {
    "id": "oai:arXiv.org:2506.06058v1",
    "journal": "arXiv_CS",
    "title": "Microgrids Coalitions for Energy Market Balancing",
    "link": "https://arxiv.org/abs/2506.06058",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06058v1 Announce Type: new \nAbstract: With the integration of renewable sources in electricity distribution networks, the need to develop intelligent mechanisms for balancing the energy market has arisen. In the absence of such mechanisms, the energy market may face imbalances that can lead to power outages, financial losses or instability at the grid level. In this context, the grouping of microgrids into optimal coalitions that can absorb energy from the market during periods of surplus or supply energy to the market during periods of is a key aspect in the efficient management of distribution networks. In this article, we propose a method that identify an optimal microgrids coalition capable of addressing the dynamics of the energy market. The proposed method models the problem of identifying the optimal coalition as an optimization problem that it solves by combining a strategy inspired by cooperative game theory with a memetic algorithm. An individual is represented as a coalition of microgrids and the evolution of population of individuals over generations is assured by recombination and mutation. The fitness function is defined as the difference between the total value generated by the coalition and a penalty applied to the coalition when the energy traded by coalition exceeds the energy available/demanded on/by the energy market. The value generated by the coalition is calculated based on the profit obtained by the collation if it sells energy on the market during periods of deficit or the savings obtained by the coalition if it buys energy on the market during periods of surplus and the costs associated with the trading process. This value is divided equitably among the coalition members, according to the Shapley value, which considers the contribution of each one to the formation of collective value.",
    "authors": [
      "Viorica Chifu, Cristina Bianca Pop, Tudor Cioara, Ionut Anghel"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.837696"
  },
  {
    "id": "oai:arXiv.org:2506.06060v1",
    "journal": "arXiv_CS",
    "title": "Simple Yet Effective: Extracting Private Data Across Clients in Federated Fine-Tuning of Large Language Models",
    "link": "https://arxiv.org/abs/2506.06060",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06060v1 Announce Type: new \nAbstract: Federated fine-tuning of large language models (FedLLMs) presents a promising approach for achieving strong model performance while preserving data privacy in sensitive domains. However, the inherent memorization ability of LLMs makes them vulnerable to training data extraction attacks. To investigate this risk, we introduce simple yet effective extraction attack algorithms specifically designed for FedLLMs. In contrast to prior \"verbatim\" extraction attacks, which assume access to fragments from all training data, our approach operates under a more realistic threat model, where the attacker only has access to a single client's data and aims to extract previously unseen personally identifiable information (PII) from other clients. This requires leveraging contextual prefixes held by the attacker to generalize across clients. To evaluate the effectiveness of our approaches, we propose two rigorous metrics-coverage rate and efficiency-and extend a real-world legal dataset with PII annotations aligned with CPIS, GDPR, and CCPA standards, achieving 89.9% human-verified precision. Experimental results show that our method can extract up to 56.57% of victim-exclusive PII, with \"Address,\" \"Birthday,\" and \"Name\" being the most vulnerable categories. Our findings underscore the pressing need for robust defense strategies and contribute a new benchmark and evaluation framework for future research in privacy-preserving federated learning.",
    "authors": [
      "Yingqi Hu, Zhuo Zhang, Jingyuan Zhang, Lizhen Qu, Zenglin Xu"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.837706"
  },
  {
    "id": "oai:arXiv.org:2506.06062v1",
    "journal": "arXiv_CS",
    "title": "Minoritised Ethnic People's Security and Privacy Concerns and Responses towards Essential Online Services",
    "link": "https://arxiv.org/abs/2506.06062",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06062v1 Announce Type: new \nAbstract: Minoritised ethnic people are marginalised in society, and therefore at a higher risk of adverse online harms, including those arising from the loss of security and privacy of personal data. Despite this, there has been very little research focused on minoritised ethnic people's security and privacy concerns, attitudes, and behaviours. In this work, we provide the results of one of the first studies in this regard. We explore minoritised ethnic people's experiences of using essential online services across three sectors: health, social housing, and energy, their security and privacy-related concerns, and responses towards these services. We conducted a thematic analysis of 44 semi-structured interviews with people of various reported minoritised ethnicities in the UK. Privacy concerns and lack of control over personal data emerged as a major theme, with many interviewees considering privacy as their most significant concern when using online services. Several creative tactics to exercise some agency were reported, including selective and inconsistent disclosure of personal data. A core concern about how data may be used was driven by a fear of repercussions, including penalisation and discrimination, influenced by prior experiences of institutional and online racism. The increased concern and potential for harm resulted in minoritised ethnic people grappling with a higher-stakes dilemma of whether to disclose personal information online or not. Furthermore, trust in institutions, or lack thereof, was found to be embedded throughout as a basis for adapting behaviour. We draw on our results to provide lessons learned for the design of more inclusive, marginalisation-aware, and privacy-preserving online services.",
    "authors": [
      "Aunam Quyoum, Mark Wong, Sebati Ghosh, Siamak F. Shahandashti"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.837714"
  },
  {
    "id": "oai:arXiv.org:2506.06065v1",
    "journal": "arXiv_CS",
    "title": "Direct Integration of Recursive Gaussian Process Regression Into Extended Kalman Filters With Application to Vapor Compression Cycle Control",
    "link": "https://arxiv.org/abs/2506.06065",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06065v1 Announce Type: new \nAbstract: This paper presents a real-time capable algorithm for the learning of Gaussian Processes (GP) for submodels. It extends an existing recursive Gaussian Process (RGP) algorithm which requires a measurable output. In many applications, however, an envisaged GP output is not directly measurable. Therefore, we present the integration of an RGP into an Extended Kalman Filter (EKF) for the combined state estimation and GP learning. The algorithm is successfully tested in simulation studies and outperforms two alternative implementations -- especially if high measurement noise is present. We conclude the paper with an experimental validation within the control structure of a Vapor Compression Cycle typically used in refrigeration and heat pumps. In this application, the algorithm is used to learn a GP model for the heat-transfer values in dependency of several process parameters. The GP model significantly improves the tracking performance of a previously published model-based controller.",
    "authors": [
      "Ricus Husmann, Sven Weishaupt, Harald Aschemann"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.837724"
  },
  {
    "id": "oai:arXiv.org:2506.06066v1",
    "journal": "arXiv_CS",
    "title": "Conversational Interfaces for Parametric Conceptual Architectural Design: Integrating Mixed Reality with LLM-driven Interaction",
    "link": "https://arxiv.org/abs/2506.06066",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06066v1 Announce Type: new \nAbstract: Mixed reality (MR) environments offer embodied spatial interaction, providing intuitive 3D manipulation capabilities that enhance the conceptual design process. Parametric modeling, a powerful and advanced architectural design method, enables the generation of complex, optimized geometries. However, its integration into MR environments remains limited due to precision constraints and unsuitable input modalities. Existing MR tools prioritize spatial interaction but lack the control and expressiveness required for parametric workflows, particularly for designers without formal programming backgrounds. We address this gap by introducing a novel conversational MR interface that combines speech input, gesture recognition, and a multi-agent large language model (LLM) system to support intuitive parametric modeling. Our system dynamically manages parameter states, resolves ambiguous commands through conversation and contextual prompting, and enables real-time model manipulation within immersive environments. We demonstrate how this approach reduces cognitive and operational barriers in early-stage design tasks, allowing users to refine and explore their design space. This work expands the role of MR to a generative design platform, supporting programmatic thinking in design tasks through natural, embodied interaction.",
    "authors": [
      "Ruochen Ji, Lyu Tiangang"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.837734"
  },
  {
    "id": "oai:arXiv.org:2506.06067v1",
    "journal": "arXiv_CS",
    "title": "Efficient Memory Tiering in a Virtual Machine",
    "link": "https://arxiv.org/abs/2506.06067",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06067v1 Announce Type: new \nAbstract: Memory tiering is the norm to effectively tackle the increasing server memory total cost of ownership (TCO) and the growing data demands of modern data center workloads. However, the host-based state-of-the-art memory tiering solutions can be inefficient for a virtualized environment when (i) the frequently accessed data are scattered across the guest physical address space or (ii) the accesses to a huge page inside the guest are skewed due to a small number of subpages being hot. Scattered or skewed accesses make the whole huge page look hot in the host address space. This results in host selecting and placing sparsely accessed huge pages in near memory, wasting costly near memory resources.\n  We propose a host-agnostic technique employed inside the guest that exploits the two-level address translation in a virtualized environment to consolidate the scattered and skewed accesses to a set of guest physical address ranges. Consolidation transforms sparsely hot huge pages to densely hot huge pages in the host address space context. As a consequence, host-based tiering solutions can place densely hot huge pages in near memory, improving near memory utilization. Our evaluation of our technique on standalone real-world benchmarks with state-of-the-art host-based tiering show 50-70% reduction in near memory consumption at similar performance levels, while evaluation at scale improves performance by 10-13% with similar memory TCO.",
    "authors": [
      "Chandra Prakash, Aravinda Prasad, Sandeep Kumar, Sreenivas Subramoney"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.837742"
  },
  {
    "id": "oai:arXiv.org:2506.06069v1",
    "journal": "arXiv_CS",
    "title": "Zero-Shot Detection of LLM-Generated Code via Approximated Task Conditioning",
    "link": "https://arxiv.org/abs/2506.06069",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06069v1 Announce Type: new \nAbstract: Detecting Large Language Model (LLM)-generated code is a growing challenge with implications for security, intellectual property, and academic integrity. We investigate the role of conditional probability distributions in improving zero-shot LLM-generated code detection, when considering both the code and the corresponding task prompt that generated it. Our key insight is that when evaluating the probability distribution of code tokens using an LLM, there is little difference between LLM-generated and human-written code. However, conditioning on the task reveals notable differences. This contrasts with natural language text, where differences exist even in the unconditional distributions. Leveraging this, we propose a novel zero-shot detection approach that approximates the original task used to generate a given code snippet and then evaluates token-level entropy under the approximated task conditioning (ATC). We further provide a mathematical intuition, contextualizing our method relative to previous approaches. ATC requires neither access to the generator LLM nor the original task prompts, making it practical for real-world applications. To the best of our knowledge, it achieves state-of-the-art results across benchmarks and generalizes across programming languages, including Python, CPP, and Java. Our findings highlight the importance of task-level conditioning for LLM-generated code detection. The supplementary materials and code are available at https://github.com/maorash/ATC, including the dataset gathering implementation, to foster further research in this area.",
    "authors": [
      "Maor Ashkenazi, Ofir Brenner, Tal Furman Shohet, Eran Treister"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.837751"
  },
  {
    "id": "oai:arXiv.org:2506.06072v1",
    "journal": "arXiv_CS",
    "title": "BEAST: Efficient Tokenization of B-Splines Encoded Action Sequences for Imitation Learning",
    "link": "https://arxiv.org/abs/2506.06072",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06072v1 Announce Type: new \nAbstract: We present the B-spline Encoded Action Sequence Tokenizer (BEAST), a novel action tokenizer that encodes action sequences into compact discrete or continuous tokens using B-splines. In contrast to existing action tokenizers based on vector quantization or byte pair encoding, BEAST requires no separate tokenizer training and consistently produces tokens of uniform length, enabling fast action sequence generation via parallel decoding. Leveraging our B-spline formulation, BEAST inherently ensures generating smooth trajectories without discontinuities between adjacent segments. We extensively evaluate BEAST by integrating it with three distinct model architectures: a Variational Autoencoder (VAE) with continuous tokens, a decoder-only Transformer with discrete tokens, and Florence-2, a pretrained Vision-Language Model with an encoder-decoder architecture, demonstrating BEAST's compatibility and scalability with large pretrained models. We evaluate BEAST across three established benchmarks consisting of 166 simulated tasks and on three distinct robot settings with a total of 8 real-world tasks. Experimental results demonstrate that BEAST (i) significantly reduces both training and inference computational costs, and (ii) consistently generates smooth, high-frequency control signals suitable for continuous control tasks while (iii) reliably achieves competitive task success rates compared to state-of-the-art methods.",
    "authors": [
      "Hongyi Zhou, Weiran Liao, Xi Huang, Yucheng Tang, Fabian Otto, Xiaogang Jia, Xinkai Jiang, Simon Hilber, Ge Li, Qian Wang, \\\"Omer Erdin\\c{c} Ya\\u{g}murlu, Nils Blank, Moritz Reuss, Rudolf Lioutikov"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.837760"
  },
  {
    "id": "oai:arXiv.org:2506.06073v1",
    "journal": "arXiv_CS",
    "title": "System-Aware Unlearning Algorithms: Use Lesser, Forget Faster",
    "link": "https://arxiv.org/abs/2506.06073",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06073v1 Announce Type: new \nAbstract: Machine unlearning addresses the problem of updating a machine learning model/system trained on a dataset $S$ so that the influence of a set of deletion requests $U \\subseteq S$ on the unlearned model is minimized. The gold standard definition of unlearning demands that the updated model, after deletion, be nearly identical to the model obtained by retraining. This definition is designed for a worst-case attacker (one who can recover not only the unlearned model but also the remaining data samples, i.e., $S \\setminus U$). Such a stringent definition has made developing efficient unlearning algorithms challenging. However, such strong attackers are also unrealistic. In this work, we propose a new definition, system-aware unlearning, which aims to provide unlearning guarantees against an attacker that can at best only gain access to the data stored in the system for learning/unlearning requests and not all of $S\\setminus U$. With this new definition, we use the simple intuition that if a system can store less to make its learning/unlearning updates, it can be more secure and update more efficiently against a system-aware attacker. Towards that end, we present an exact system-aware unlearning algorithm for linear classification using a selective sampling-based approach, and we generalize the method for classification with general function classes. We theoretically analyze the tradeoffs between deletion capacity, accuracy, memory, and computation time.",
    "authors": [
      "Linda Lu, Ayush Sekhari, Karthik Sridharan"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.837768"
  },
  {
    "id": "oai:arXiv.org:2506.06074v1",
    "journal": "arXiv_CS",
    "title": "On the Suitability of Wi-Fi for Interconnecting Moving Equipment in Industrial Environments",
    "link": "https://arxiv.org/abs/2506.06074",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06074v1 Announce Type: new \nAbstract: To ensure an unprecedented degree of flexibility, next-generation Industry 4.0/5.0 production plants increasingly rely on mobile devices, e.g., autonomous mobile robots and wearables. In these cases, a major requirement is getting rid of cables through the adoption of wireless networks. To this purpose, Wi-Fi is currently deemed one of the most promising solutions. Achieving reliable communications over the air for distributed real-time control applications is, however, not devoid of troubles. In fact, bounded transmission latency must be ensured for most of the exchanged packets. Moreover, for devices powered on batteries, energy consumption also needs to be taken into account. In this paper, a joint simulated analysis of these aspects is carried out to quantitatively evaluate what we can practically expect from Wi-Fi technology.",
    "authors": [
      "Pietro Chiavassa, Stefano Scanzio, Gianluca Cena"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.837777"
  },
  {
    "id": "oai:arXiv.org:2506.06076v1",
    "journal": "arXiv_CS",
    "title": "Full Conformal Adaptation of Medical Vision-Language Models",
    "link": "https://arxiv.org/abs/2506.06076",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06076v1 Announce Type: new \nAbstract: Vision-language models (VLMs) pre-trained at large scale have shown unprecedented transferability capabilities and are being progressively integrated into medical image analysis. Although its discriminative potential has been widely explored, its reliability aspect remains overlooked. This work investigates their behavior under the increasingly popular split conformal prediction (SCP) framework, which theoretically guarantees a given error level on output sets by leveraging a labeled calibration set. However, the zero-shot performance of VLMs is inherently limited, and common practice involves few-shot transfer learning pipelines, which cannot absorb the rigid exchangeability assumptions of SCP. To alleviate this issue, we propose full conformal adaptation, a novel setting for jointly adapting and conformalizing pre-trained foundation models, which operates transductively over each test data point using a few-shot adaptation set. Moreover, we complement this framework with SS-Text, a novel training-free linear probe solver for VLMs that alleviates the computational cost of such a transductive approach. We provide comprehensive experiments using 3 different modality-specialized medical VLMs and 9 adaptation tasks. Our framework requires exactly the same data as SCP, and provides consistent relative improvements of up to 27% on set efficiency while maintaining the same coverage guarantees.",
    "authors": [
      "Julio Silva-Rodr\\'iguez, Leo Fillioux, Paul-Henry Courn\\`ede, Maria Vakalopoulou, Stergios Christodoulidis, Ismail Ben Ayed, Jose Dolz"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.837785"
  },
  {
    "id": "oai:arXiv.org:2506.06077v1",
    "journal": "arXiv_CS",
    "title": "Self driving algorithm for an active four wheel drive racecar",
    "link": "https://arxiv.org/abs/2506.06077",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06077v1 Announce Type: new \nAbstract: Controlling autonomous vehicles at their handling limits is a significant challenge, particularly for electric vehicles with active four wheel drive (A4WD) systems offering independent wheel torque control. While traditional Vehicle Dynamics Control (VDC) methods use complex physics-based models, this study explores Deep Reinforcement Learning (DRL) to develop a unified, high-performance controller. We employ the Proximal Policy Optimization (PPO) algorithm to train an agent for optimal lap times in a simulated racecar (TORCS) at the tire grip limit. Critically, the agent learns an end-to-end policy that directly maps vehicle states, like velocities, accelerations, and yaw rate, to a steering angle command and independent torque commands for each of the four wheels. This formulation bypasses conventional pedal inputs and explicit torque vectoring algorithms, allowing the agent to implicitly learn the A4WD control logic needed for maximizing performance and stability. Simulation results demonstrate the RL agent learns sophisticated strategies, dynamically optimizing wheel torque distribution corner-by-corner to enhance handling and mitigate the vehicle's inherent understeer. The learned behaviors mimic and, in aspects of grip utilization, potentially surpass traditional physics-based A4WD controllers while achieving competitive lap times. This research underscores DRL's potential to create adaptive control systems for complex vehicle dynamics, suggesting RL is a potent alternative for advancing autonomous driving in demanding, grip-limited scenarios for racing and road safety.",
    "authors": [
      "Gergely Bari, Laszlo Palkovics"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.837794"
  },
  {
    "id": "oai:arXiv.org:2506.06079v1",
    "journal": "arXiv_CS",
    "title": "Data-driven nonlinear output regulation via data-enforced incremental passivity",
    "link": "https://arxiv.org/abs/2506.06079",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06079v1 Announce Type: new \nAbstract: This work proposes a data-driven regulator design that drives the output of a nonlinear system asymptotically to a time-varying reference and rejects time-varying disturbances. The key idea is to design a data-driven feedback controller such that the closed-loop system is incrementally passive with respect to the regulation error and a virtual input. By carefully designing the virtual input, we solve the data-driven nonlinear output regulation problem where the reference and disturbances are generated by a linear exosystem. The designed regulator is composed of an internal model and a passivation feedback controller characterized by a set of data-dependent linear matrix inequalities. The proposed data-driven method is also applied to stabilizing the non-zero equilibrium of a class of nonlinear systems with unknown equilibrium input. Numerical examples are presented to illustrate the effectiveness of the proposed designs.",
    "authors": [
      "Yixuan Liu, Meichen Guo"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.837811"
  },
  {
    "id": "oai:arXiv.org:2506.06083v1",
    "journal": "arXiv_CS",
    "title": "A Novel, Human-in-the-Loop Computational Grounded Theory Framework for Big Social Data",
    "link": "https://arxiv.org/abs/2506.06083",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06083v1 Announce Type: new \nAbstract: The availability of big data has significantly influenced the possibilities and methodological choices for conducting large-scale behavioural and social science research. In the context of qualitative data analysis, a major challenge is that conventional methods require intensive manual labour and are often impractical to apply to large datasets. One effective way to address this issue is by integrating emerging computational methods to overcome scalability limitations. However, a critical concern for researchers is the trustworthiness of results when Machine Learning (ML) and Natural Language Processing (NLP) tools are used to analyse such data. We argue that confidence in the credibility and robustness of results depends on adopting a 'human-in-the-loop' methodology that is able to provide researchers with control over the analytical process, while retaining the benefits of using ML and NLP. With this in mind, we propose a novel methodological framework for Computational Grounded Theory (CGT) that supports the analysis of large qualitative datasets, while maintaining the rigour of established Grounded Theory (GT) methodologies. To illustrate the framework's value, we present the results of testing it on a dataset collected from Reddit in a study aimed at understanding tutors' experiences in the gig economy.",
    "authors": [
      "Lama Alqazlan, Zheng Fang, Michael Castelle, Rob Procter"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.837819"
  },
  {
    "id": "oai:arXiv.org:2506.06084v1",
    "journal": "arXiv_CS",
    "title": "WisWheat: A Three-Tiered Vision-Language Dataset for Wheat Management",
    "link": "https://arxiv.org/abs/2506.06084",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06084v1 Announce Type: new \nAbstract: Wheat management strategies play a critical role in determining yield. Traditional management decisions often rely on labour-intensive expert inspections, which are expensive, subjective and difficult to scale. Recently, Vision-Language Models (VLMs) have emerged as a promising solution to enable scalable, data-driven management support. However, due to a lack of domain-specific knowledge, directly applying VLMs to wheat management tasks results in poor quantification and reasoning capabilities, ultimately producing vague or even misleading management recommendations. In response, we propose WisWheat, a wheat-specific dataset with a three-layered design to enhance VLM performance on wheat management tasks: (1) a foundational pretraining dataset of 47,871 image-caption pairs for coarsely adapting VLMs to wheat morphology; (2) a quantitative dataset comprising 7,263 VQA-style image-question-answer triplets for quantitative trait measuring tasks; and (3) an Instruction Fine-tuning dataset with 4,888 samples targeting biotic and abiotic stress diagnosis and management plan for different phenological stages. Extensive experimental results demonstrate that fine-tuning open-source VLMs (e.g., Qwen2.5 7B) on our dataset leads to significant performance improvements. Specifically, the Qwen2.5 VL 7B fine-tuned on our wheat instruction dataset achieves accuracy scores of 79.2% and 84.6% on wheat stress and growth stage conversation tasks respectively, surpassing even general-purpose commercial models such as GPT-4o by a margin of 11.9% and 34.6%.",
    "authors": [
      "Bowen Yuan, Selena Song, Javier Fernandez, Yadan Luo, Mahsa Baktashmotlagh, Zijian Wang"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.837828"
  },
  {
    "id": "oai:arXiv.org:2506.06085v1",
    "journal": "arXiv_CS",
    "title": "Feedback Guidance of Diffusion Models",
    "link": "https://arxiv.org/abs/2506.06085",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06085v1 Announce Type: new \nAbstract: While Classifier-Free Guidance (CFG) has become standard for improving sample fidelity in conditional diffusion models, it can harm diversity and induce memorization by applying constant guidance regardless of whether a particular sample needs correction. We propose FeedBack Guidance (FBG), which uses a state-dependent coefficient to self-regulate guidance amounts based on need. Our approach is derived from first principles by assuming the learned conditional distribution is linearly corrupted by the unconditional distribution, contrasting with CFG's implicit multiplicative assumption. Our scheme relies on feedback of its own predictions about the conditional signal informativeness to adapt guidance dynamically during inference, challenging the view of guidance as a fixed hyperparameter. The approach is benchmarked on ImageNet512x512, where it significantly outperforms Classifier-Free Guidance and is competitive to Limited Interval Guidance (LIG) while benefitting from a strong mathematical framework. On Text-To-Image generation, we demonstrate that, as anticipated, our approach automatically applies higher guidance scales for complex prompts than for simpler ones and that it can be easily combined with existing guidance schemes such as CFG or LIG.",
    "authors": [
      "Koulischer Felix, Handke Florian, Deleu Johannes, Demeester Thomas, Ambrogioni Luca"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.837836"
  },
  {
    "id": "oai:arXiv.org:2506.06093v1",
    "journal": "arXiv_CS",
    "title": "Reinforcing Code Generation: Improving Text-to-SQL with Execution-Based Learning",
    "link": "https://arxiv.org/abs/2506.06093",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06093v1 Announce Type: new \nAbstract: In this work, we study the problem of code generation with a large language model (LLM), with a focus on generating SQL queries from natural language questions. We ask: Instead of using supervised fine tuning with text-code pairs, can we tune a model by having it interact with a database engine? We frame this problem as a reinforcement learning problem where the model receives execution-based feedback from the environment in the form of scalar rewards. These rewards penalize execution failures and assign positive values when a query returns a correct answer. We use the rewards within the Group Relative Policy Optimization (GRPO) framework. We use a tabular reasoning benchmark to test and evaluate our findings. We find that with only weak supervision in the form of question-answer pairs, RL-tuning improves the accuracy of model generated SQL code from 31.49 to 49.83 while reducing error percentage from 25.43% to 14.71%. This improvement allowed the model nearly match the performance performance to the larger SQLCoder-70B model. Our work demonstrates the potential of using execution-based feedback to improve symbolic reasoning capabilities of LLMs.",
    "authors": [
      "Atharv Kulkarni, Vivek Srikumar"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.837852"
  },
  {
    "id": "oai:arXiv.org:2506.06094v1",
    "journal": "arXiv_CS",
    "title": "On-board Mission Replanning for Adaptive Cooperative Multi-Robot Systems",
    "link": "https://arxiv.org/abs/2506.06094",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06094v1 Announce Type: new \nAbstract: Cooperative autonomous robotic systems have significant potential for executing complex multi-task missions across space, air, ground, and maritime domains. But they commonly operate in remote, dynamic and hazardous environments, requiring rapid in-mission adaptation without reliance on fragile or slow communication links to centralised compute. Fast, on-board replanning algorithms are therefore needed to enhance resilience. Reinforcement Learning shows strong promise for efficiently solving mission planning tasks when formulated as Travelling Salesperson Problems (TSPs), but existing methods: 1) are unsuitable for replanning, where agents do not start at a single location; 2) do not allow cooperation between agents; 3) are unable to model tasks with variable durations; or 4) lack practical considerations for on-board deployment. Here we define the Cooperative Mission Replanning Problem as a novel variant of multiple TSP with adaptations to overcome these issues, and develop a new encoder/decoder-based model using Graph Attention Networks and Attention Models to solve it effectively and efficiently. Using a simple example of cooperative drones, we show our replanner consistently (90% of the time) maintains performance within 10% of the state-of-the-art LKH3 heuristic solver, whilst running 85-370 times faster on a Raspberry Pi. This work paves the way for increased resilience in autonomous multi-agent systems.",
    "authors": [
      "Elim Kwan, Rehman Qureshi, Liam Fletcher, Colin Laganier, Victoria Nockles, Richard Walters"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.837861"
  },
  {
    "id": "oai:arXiv.org:2506.06095v1",
    "journal": "arXiv_CS",
    "title": "Flexible Operator Fusion for Fast Sparse Transformer with Diverse Masking on GPU",
    "link": "https://arxiv.org/abs/2506.06095",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06095v1 Announce Type: new \nAbstract: Large language models are popular around the world due to their powerful understanding capabilities. As the core component of LLMs, accelerating Transformer through parallelization has gradually become a hot research topic. Mask layers introduce sparsity into Transformer to reduce calculations. However, previous works rarely focus on the performance optimization of sparse Transformer. Moreover, rule-based mechanisms ignore the fusion opportunities of mixed-type operators and fail to adapt to various sequence lengths. To address the above problems, we propose STOF, a framework that incorporates optimizations for Sparse Transformer via flexible masking and operator fusion on GPU. We firstly unify the storage format and kernel implementation for the multi-head attention. Then, we map fusion schemes to compilation templates and determine the optimal parameter setting through a two-stage search engine. The experimental results show that compared to the state-of-the-art work, STOF achieves maximum speedups of 1.7x in MHA computation and 1.5x in end-to-end inference.",
    "authors": [
      "Wenhao Dai, Haodong Deng, Mengfei Rong, Xinyu Yang, Hongyu Liu, Fangxin Liu, Hailong Yang, Weifeng Liu, Qingxiao Sun"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.837869"
  },
  {
    "id": "oai:arXiv.org:2506.06096v1",
    "journal": "arXiv_CS",
    "title": "Label-Context-Dependent Internal Language Model Estimation for CTC",
    "link": "https://arxiv.org/abs/2506.06096",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06096v1 Announce Type: new \nAbstract: Although connectionist temporal classification (CTC) has the label context independence assumption, it can still implicitly learn a context-dependent internal language model (ILM) due to modern powerful encoders. In this work, we investigate the implicit context dependency modeled in the ILM of CTC. To this end, we propose novel context-dependent ILM estimation methods for CTC based on knowledge distillation (KD) with theoretical justifications. Furthermore, we introduce two regularization methods for KD. We conduct experiments on Librispeech and TED-LIUM Release 2 datasets for in-domain and cross-domain evaluation, respectively. Experimental results show that context-dependent ILMs outperform the context-independent priors in cross-domain evaluation, indicating that CTC learns a context-dependent ILM. The proposed label-level KD with smoothing method surpasses other ILM estimation approaches, with more than 13% relative improvement in word error rate compared to shallow fusion.",
    "authors": [
      "Zijian Yang, Minh-Nghia Phan, Ralf Schl\\\"uter, Hermann Ney"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.837878"
  },
  {
    "id": "oai:arXiv.org:2506.06100v1",
    "journal": "arXiv_CS",
    "title": "Compression of executable QR codes or sQRy for Industry: an example for Wi-Fi access points",
    "link": "https://arxiv.org/abs/2506.06100",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06100v1 Announce Type: new \nAbstract: Executable QR codes, or sQRy, is a technology dated 2022 that permits to include a runnable program inside a QR code, enabling interaction with the user even in the absence of an Internet connection. sQRy are enablers for different practical applications, including network equipment configuration, diagnostics, and enhanced smart manuals in industrial contexts. Many other non-industry-related fields can also benefit from this technology. Regardless of where sQRy are used, text strings are among the most commonly embedded data. However, due to strict limitations on the available payload, the occupancy of strings limits the length of the programs that can be embedded. In this work, we propose a simple yet effective strategy that can reduce the space taken by strings, hence broadening sQRy applicability.",
    "authors": [
      "Stefano Scanzio, Gabriele Formis, Pietro Chiavassa, Lukasz Wisniewski, Gianluca Cena"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.837895"
  },
  {
    "id": "oai:arXiv.org:2506.06102v1",
    "journal": "arXiv_CS",
    "title": "Perfect Matching with Few Link Activations",
    "link": "https://arxiv.org/abs/2506.06102",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06102v1 Announce Type: new \nAbstract: We consider the problem of computing a perfect matching problem in a synchronous distributed network, where the network topology corresponds to a complete bipartite graph. The communication between nodes is restricted to activating communication links, which means that instead of sending messages containing a number of bits, each node can only send a pulse over some of its incident links in each round. In the port numbering model, where nodes are unaware of their neighbor's IDs, we give a randomized algorithm that terminates in $O( \\log n )$ rounds and has a pulse complexity of $O( n\\log n )$, which corresponds to the number of pulses sent over all links. We also show that randomness is crucial in the port numbering model, as any deterministic algorithm must send at least $\\Omega( n^2 )$ messages in the standard LOCAL model, where the messages can be of unbounded size. Then, we turn our attention to the KT_1 assumption, where each node starts out knowing its neighbors' IDs. We show that this additional knowledge enables significantly improved bounds even for deterministic algorithms. First, we give an $O( \\log n )$ time deterministic algorithm that sends only $O( n )$ pulses. Finally, we apply this algorithm recursively to obtain an exponential reduction in the time complexity to $O( \\log^*n\\log\\log n )$, while slightly increasing the pulse complexity to $O( n\\log^*n )$. All our bounds also hold in the standard CONGEST model with single-bit messages.",
    "authors": [
      "Hugo Mirault, Peter Robinson, Ming Ming Tan, Xianbin Zhu"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.837903"
  },
  {
    "id": "oai:arXiv.org:2506.06105v1",
    "journal": "arXiv_CS",
    "title": "Text-to-LoRA: Instant Transformer Adaption",
    "link": "https://arxiv.org/abs/2506.06105",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06105v1 Announce Type: new \nAbstract: While Foundation Models provide a general tool for rapid content creation, they regularly require task-specific adaptation. Traditionally, this exercise involves careful curation of datasets and repeated fine-tuning of the underlying model. Fine-tuning techniques enable practitioners to adapt foundation models for many new applications but require expensive and lengthy training while being notably sensitive to hyper-parameter choices. To overcome these limitations, we introduce Text-to-LoRA (T2L), a model capable of adapting Large Language Models on the fly solely based on a natural language description of the target task. T2L is a hypernetwork trained to construct LoRAs in a single inexpensive forward pass. After training T2L on a suite of 9 pre-trained LoRA adapters (GSM8K, Arc, etc.), we show that the ad-hoc reconstructed LoRA instances match the performance of task-specific adapters across the corresponding test sets. Furthermore, T2L can compress hundreds of LoRA instances and zero-shot generalize to entirely unseen tasks. This approach provides a significant step towards democratizing the specialization of foundation models and enables language-based adaptation with minimal compute requirements. Our code is available at https://github.com/SakanaAI/text-to-lora",
    "authors": [
      "Rujikorn Charakorn, Edoardo Cetin, Yujin Tang, Robert Tjarko Lange"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.837918"
  },
  {
    "id": "oai:arXiv.org:2506.06106v1",
    "journal": "arXiv_CS",
    "title": "Measuring the co-evolution of online engagement with (mis)information and its visibility at scale",
    "link": "https://arxiv.org/abs/2506.06106",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06106v1 Announce Type: new \nAbstract: Online attention is an increasingly valuable resource in the digital age, with extraordinary events such as the COVID-19 pandemic fuelling fierce competition around it. As misinformation pervades online platforms, users seek credible sources, while news outlets compete to attract and retain their attention. Here we measure the co-evolution of online \"engagement\" with (mis)information and its \"visibility\", where engagement corresponds to user interactions on social media, and visibility to fluctuations in user follower counts. Using a scalable temporal network modelling framework applied to over 100 million COVID-related retweets spanning 3 years, we find that highly engaged sources experience sharp spikes in follower growth during major events (e.g., vaccine rollouts, epidemic severity), whereas sources with more questionable credibility tend to sustain faster growth outside of these periods. Our framework lends itself to studying other large-scale events where online attention is at stake, such as climate and political debates.",
    "authors": [
      "Yueting Han, Paolo Turrini, Marya Bazzi, Giulia Andrighetto, Eugenia Polizzi, Manlio De Domenico"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.837927"
  },
  {
    "id": "oai:arXiv.org:2506.06108v1",
    "journal": "arXiv_CS",
    "title": "Synthetic Tabular Data: Methods, Attacks and Defenses",
    "link": "https://arxiv.org/abs/2506.06108",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06108v1 Announce Type: new \nAbstract: Synthetic data is often positioned as a solution to replace sensitive fixed-size datasets with a source of unlimited matching data, freed from privacy concerns. There has been much progress in synthetic data generation over the last decade, leveraging corresponding advances in machine learning and data analytics. In this survey, we cover the key developments and the main concepts in tabular synthetic data generation, including paradigms based on probabilistic graphical models and on deep learning. We provide background and motivation, before giving a technical deep-dive into the methodologies. We also address the limitations of synthetic data, by studying attacks that seek to retrieve information about the original sensitive data. Finally, we present extensions and open problems in this area.",
    "authors": [
      "Graham Cormode, Samuel Maddock, Enayat Ullah, Shripad Gade"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.837936"
  },
  {
    "id": "oai:arXiv.org:2506.06112v1",
    "journal": "arXiv_CS",
    "title": "Towards Lifecycle Unlearning Commitment Management: Measuring Sample-level Unlearning Completeness",
    "link": "https://arxiv.org/abs/2506.06112",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06112v1 Announce Type: new \nAbstract: Growing concerns over data privacy and security highlight the importance of machine unlearning--removing specific data influences from trained models without full retraining. Techniques like Membership Inference Attacks (MIAs) are widely used to externally assess successful unlearning. However, existing methods face two key limitations: (1) maximizing MIA effectiveness (e.g., via online attacks) requires prohibitive computational resources, often exceeding retraining costs; (2) MIAs, designed for binary inclusion tests, struggle to capture granular changes in approximate unlearning. To address these challenges, we propose the Interpolated Approximate Measurement (IAM), a framework natively designed for unlearning inference. IAM quantifies sample-level unlearning completeness by interpolating the model's generalization-fitting behavior gap on queried samples. IAM achieves strong performance in binary inclusion tests for exact unlearning and high correlation for approximate unlearning--scalable to LLMs using just one pre-trained shadow model. We theoretically analyze how IAM's scoring mechanism maintains performance efficiently. We then apply IAM to recent approximate unlearning algorithms, revealing general risks of both over-unlearning and under-unlearning, underscoring the need for stronger safeguards in approximate unlearning systems. The code is available at https://github.com/Happy2Git/Unlearning_Inference_IAM.",
    "authors": [
      "Cheng-Long Wang, Qi Li, Zihang Xiang, Yinzhi Cao, Di Wang"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.837945"
  },
  {
    "id": "oai:arXiv.org:2506.06113v1",
    "journal": "arXiv_CS",
    "title": "Bridging the Gap: In-Context Learning for Modeling Human Disagreement",
    "link": "https://arxiv.org/abs/2506.06113",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06113v1 Announce Type: new \nAbstract: Large Language Models (LLMs) have shown strong performance on NLP classification tasks. However, they typically rely on aggregated labels-often via majority voting-which can obscure the human disagreement inherent in subjective annotations. This study examines whether LLMs can capture multiple perspectives and reflect annotator disagreement in subjective tasks such as hate speech and offensive language detection. We use in-context learning (ICL) in zero-shot and few-shot settings, evaluating four open-source LLMs across three label modeling strategies: aggregated hard labels, and disaggregated hard and soft labels. In few-shot prompting, we assess demonstration selection methods based on textual similarity (BM25, PLM-based), annotation disagreement (entropy), a combined ranking, and example ordering strategies (random vs. curriculum-based). Results show that multi-perspective generation is viable in zero-shot settings, while few-shot setups often fail to capture the full spectrum of human judgments. Prompt design and demonstration selection notably affect performance, though example ordering has limited impact. These findings highlight the challenges of modeling subjectivity with LLMs and the importance of building more perspective-aware, socially intelligent models.",
    "authors": [
      "Benedetta Muscato, Yue Li, Gizem Gezici, Zhixue Zhao, Fosca Giannotti"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.837953"
  },
  {
    "id": "oai:arXiv.org:2506.06114v1",
    "journal": "arXiv_CS",
    "title": "Scalable unsupervised feature selection via weight stability",
    "link": "https://arxiv.org/abs/2506.06114",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06114v1 Announce Type: new \nAbstract: Unsupervised feature selection is critical for improving clustering performance in high-dimensional data, where irrelevant features can obscure meaningful structure. In this work, we introduce the Minkowski weighted $k$-means++, a novel initialisation strategy for the Minkowski Weighted $k$-means. Our initialisation selects centroids probabilistically using feature relevance estimates derived from the data itself. Building on this, we propose two new feature selection algorithms, FS-MWK++, which aggregates feature weights across a range of Minkowski exponents to identify stable and informative features, and SFS-MWK++, a scalable variant based on subsampling. We support our approach with a theoretical guarantee under mild assumptions and extensive experiments showing that our methods consistently outperform existing alternatives.",
    "authors": [
      "Xudong Zhang, Renato Cordeiro de Amorim"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.837962"
  },
  {
    "id": "oai:arXiv.org:2506.06117v1",
    "journal": "arXiv_CS",
    "title": "Phonetically-Augmented Discriminative Rescoring for Voice Search Error Correction",
    "link": "https://arxiv.org/abs/2506.06117",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06117v1 Announce Type: new \nAbstract: End-to-end (E2E) Automatic Speech Recognition (ASR) models are trained using paired audio-text samples that are expensive to obtain, since high-quality ground-truth data requires human annotators. Voice search applications, such as digital media players, leverage ASR to allow users to search by voice as opposed to an on-screen keyboard. However, recent or infrequent movie titles may not be sufficiently represented in the E2E ASR system's training data, and hence, may suffer poor recognition.\n  In this paper, we propose a phonetic correction system that consists of (a) a phonetic search based on the ASR model's output that generates phonetic alternatives that may not be considered by the E2E system, and (b) a rescorer component that combines the ASR model recognition and the phonetic alternatives, and select a final system output.\n  We find that our approach improves word error rate between 4.4 and 7.6% relative on benchmarks of popular movie titles over a series of competitive baselines.",
    "authors": [
      "Christophe Van Gysel, Maggie Wu, Lyan Verwimp, Caglar Tirkaz, Marco Bertola, Zhihong Lei, Youssef Oualil"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.837972"
  },
  {
    "id": "oai:arXiv.org:2506.06119v1",
    "journal": "arXiv_CS",
    "title": "SATversary: Adversarial Attacks on Satellite Fingerprinting",
    "link": "https://arxiv.org/abs/2506.06119",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06119v1 Announce Type: new \nAbstract: As satellite systems become increasingly vulnerable to physical layer attacks via SDRs, novel countermeasures are being developed to protect critical systems, particularly those lacking cryptographic protection, or those which cannot be upgraded to support modern cryptography. Among these is transmitter fingerprinting, which provides mechanisms by which communication can be authenticated by looking at characteristics of the transmitter, expressed as impairments on the signal.\n  Previous works show that fingerprinting can be used to classify satellite transmitters, or authenticate them against SDR-equipped attackers under simple replay scenarios. In this paper we build upon this by looking at attacks directly targeting the fingerprinting system, with an attacker optimizing for maximum impact in jamming, spoofing, and dataset poisoning attacks, and demonstrate these attacks on the SatIQ system designed to authenticate Iridium transmitters. We show that an optimized jamming signal can cause a 50% error rate with attacker-to-victim ratios as low as -30dB (far less power than traditional jamming) and demonstrate successful identity forgery during spoofing attacks, with an attacker successfully removing their own transmitter's fingerprint from messages. We also present a data poisoning attack, enabling persistent message spoofing by altering the data used to authenticate incoming messages to include the fingerprint of the attacker's transmitter.\n  Finally, we show that our model trained to optimize spoofing attacks can also be used to detect spoofing and replay attacks, even when it has never seen the attacker's transmitter before. Furthermore, this technique works even when the training dataset includes only a single transmitter, enabling fingerprinting to be used to protect small constellations and even individual satellites, providing additional protection where it is needed the most.",
    "authors": [
      "Joshua Smailes, Sebastian K\\\"ohler, Simon Birnbach, Martin Strohmeier, Ivan Martinovic"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.837980"
  },
  {
    "id": "oai:arXiv.org:2506.06120v1",
    "journal": "arXiv_CS",
    "title": "Bidirectional Image-Event Guided Low-Light Image Enhancement",
    "link": "https://arxiv.org/abs/2506.06120",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06120v1 Announce Type: new \nAbstract: Under extreme low-light conditions, traditional frame-based cameras, due to their limited dynamic range and temporal resolution, face detail loss and motion blur in captured images. To overcome this bottleneck, researchers have introduced event cameras and proposed event-guided low-light image enhancement algorithms. However, these methods neglect the influence of global low-frequency noise caused by dynamic lighting conditions and local structural discontinuities in sparse event data. To address these issues, we propose an innovative Bidirectional guided Low-light Image Enhancement framework (BiLIE). Specifically, to mitigate the significant low-frequency noise introduced by global illumination step changes, we introduce the frequency high-pass filtering-based Event Feature Enhancement (EFE) module at the event representation level to suppress the interference of low-frequency information, and preserve and highlight the high-frequency edges.Furthermore, we design a Bidirectional Cross Attention Fusion (BCAF) mechanism to acquire high-frequency structures and edges while suppressing structural discontinuities and local noise introduced by sparse event guidance, thereby generating smoother fused representations.Additionally, considering the poor visual quality and color bias in existing datasets, we provide a new dataset (RELIE), with high-quality ground truth through a reliable enhancement scheme. Extensive experimental results demonstrate that our proposed BiLIE outperforms state-of-the-art methods by 0.96dB in PSNR and 0.03 in LPIPS.",
    "authors": [
      "Zhanwen Liu, Huanna Song, Yang Wang, Nan Yang, Shangyu Xie, Yisheng An, Xiangmo Zhao"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.837989"
  },
  {
    "id": "oai:arXiv.org:2506.06121v1",
    "journal": "arXiv_CS",
    "title": "Decomposability-Guaranteed Cooperative Coevolution for Large-Scale Itinerary Planning",
    "link": "https://arxiv.org/abs/2506.06121",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06121v1 Announce Type: new \nAbstract: Large-scale itinerary planning is a variant of the traveling salesman problem, aiming to determine an optimal path that maximizes the collected points of interest (POIs) scores while minimizing travel time and cost, subject to travel duration constraints. This paper analyzes the decomposability of large-scale itinerary planning, proving that strict decomposability is difficult to satisfy, and introduces a weak decomposability definition based on a necessary condition, deriving the corresponding graph structures that fulfill this property. With decomposability guaranteed, we propose a novel multi-objective cooperative coevolutionary algorithm for large-scale itinerary planning, addressing the challenges of component imbalance and interactions. Specifically, we design a dynamic decomposition strategy based on the normalized fitness within each component, define optimization potential considering component scale and contribution, and develop a computational resource allocation strategy. Finally, we evaluate the proposed algorithm on a set of real-world datasets. Comparative experiments with state-of-the-art multi-objective itinerary planning algorithms demonstrate the superiority of our approach, with performance advantages increasing as the problem scale grows.",
    "authors": [
      "Ziyu Zhang, Peilan Xu, Yuetong Sun, Yuhui Shi, Wenjian Luo"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.837997"
  },
  {
    "id": "oai:arXiv.org:2506.06122v1",
    "journal": "arXiv_CS",
    "title": "Reinforcement Learning Optimization for Large-Scale Learning: An Efficient and User-Friendly Scaling Library",
    "link": "https://arxiv.org/abs/2506.06122",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06122v1 Announce Type: new \nAbstract: We introduce ROLL, an efficient, scalable, and user-friendly library designed for Reinforcement Learning Optimization for Large-scale Learning. ROLL caters to three primary user groups: tech pioneers aiming for cost-effective, fault-tolerant large-scale training, developers requiring flexible control over training workflows, and researchers seeking agile experimentation. ROLL is built upon several key modules to serve these user groups effectively. First, a single-controller architecture combined with an abstraction of the parallel worker simplifies the development of the training pipeline. Second, the parallel strategy and data transfer modules enable efficient and scalable training. Third, the rollout scheduler offers fine-grained management of each sample's lifecycle during the rollout stage. Fourth, the environment worker and reward worker support rapid and flexible experimentation with agentic RL algorithms and reward designs. Finally, AutoDeviceMapping allows users to assign resources to different models flexibly across various stages.",
    "authors": [
      "Weixun Wang, Shaopan Xiong, Gengru Chen, Wei Gao, Sheng Guo, Yancheng He, Ju Huang, Jiaheng Liu, Zhendong Li, Xiaoyang Li, Zichen Liu, Haizhou Zhao, Dakai An, Lunxi Cao, Qiyang Cao, Wanxi Deng, Feilei Du, Yiliang Gu, Jiahe Li, Xiang Li, Mingjie Liu, Yijia Luo, Zihe Liu, Yadao Wang, Pei Wang, Tianyuan Wu, Yanan Wu, Yuheng Zhao, Shuaibing Zhao, Jin Yang, Siran Yang, Yingshui Tan, Huimin Yi, Yuchi Xu, Yujin Yuan, Xingyao Zhang, Lin Qu, Wenbo Su, Wei Wang, Jiamang Wang, Bo Zheng"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.838007"
  },
  {
    "id": "oai:arXiv.org:2506.06124v1",
    "journal": "arXiv_CS",
    "title": "PrivTru: A Privacy-by-Design Data Trustee Minimizing Information Leakage",
    "link": "https://arxiv.org/abs/2506.06124",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06124v1 Announce Type: new \nAbstract: Data trustees serve as intermediaries that facilitate secure data sharing between independent parties. This paper offers a technical perspective on Data trustees, guided by privacy-by-design principles. We introduce PrivTru, an instantiation of a data trustee that provably achieves optimal privacy properties. Therefore, PrivTru calculates the minimal amount of information the data trustee needs to request from data sources to respond to a given query. Our analysis shows that PrivTru minimizes information leakage to the data trustee, regardless of the trustee's prior knowledge, while preserving the utility of the data.",
    "authors": [
      "Lukas Gehring, Florian Tschorsch"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.838016"
  },
  {
    "id": "oai:arXiv.org:2506.06127v1",
    "journal": "arXiv_CS",
    "title": "Flow-Attentional Graph Neural Networks",
    "link": "https://arxiv.org/abs/2506.06127",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06127v1 Announce Type: new \nAbstract: Graph Neural Networks (GNNs) have become essential for learning from graph-structured data. However, existing GNNs do not consider the conservation law inherent in graphs associated with a flow of physical resources, such as electrical current in power grids or traffic in transportation networks, which can lead to reduced model performance. To address this, we propose flow attention, which adapts existing graph attention mechanisms to satisfy Kirchhoff\\'s first law. Furthermore, we discuss how this modification influences the expressivity and identify sets of non-isomorphic graphs that can be discriminated by flow attention but not by standard attention. Through extensive experiments on two flow graph datasets (electronic circuits and power grids), we demonstrate that flow attention enhances the performance of attention-based GNNs on both graph-level classification and regression tasks.",
    "authors": [
      "Pascal Plettenberg, Dominik K\\\"ohler, Bernhard Sick, Josephine M. Thomas"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.838025"
  },
  {
    "id": "oai:arXiv.org:2506.06128v1",
    "journal": "arXiv_CS",
    "title": "CCLSTM: Coupled Convolutional Long-Short Term Memory Network for Occupancy Flow Forecasting",
    "link": "https://arxiv.org/abs/2506.06128",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06128v1 Announce Type: new \nAbstract: Predicting future states of dynamic agents is a fundamental task in autonomous driving. An expressive representation for this purpose is Occupancy Flow Fields, which provide a scalable and unified format for modeling motion, spatial extent, and multi-modal future distributions. While recent methods have achieved strong results using this representation, they often depend on high-quality vectorized inputs, which are unavailable or difficult to generate in practice, and the use of transformer-based architectures, which are computationally intensive and costly to deploy. To address these issues, we propose \\textbf{Coupled Convolutional LSTM (CCLSTM)}, a lightweight, end-to-end trainable architecture based solely on convolutional operations. Without relying on vectorized inputs or self-attention mechanisms, CCLSTM effectively captures temporal dynamics and spatial occupancy-flow correlations using a compact recurrent convolutional structure. Despite its simplicity, CCLSTM achieves state-of-the-art performance on occupancy flow metrics and, as of this submission, ranks \\(1^{\\text{st}}\\) in all metrics on the 2024 Waymo Occupancy and Flow Prediction Challenge leaderboard.",
    "authors": [
      "Peter Lengyel"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.838034"
  },
  {
    "id": "oai:arXiv.org:2506.06130v1",
    "journal": "arXiv_CS",
    "title": "Gradient Similarity Surgery in Multi-Task Deep Learning",
    "link": "https://arxiv.org/abs/2506.06130",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06130v1 Announce Type: new \nAbstract: The multi-task learning ($MTL$) paradigm aims to simultaneously learn multiple tasks within a single model capturing higher-level, more general hidden patterns that are shared by the tasks. In deep learning, a significant challenge in the backpropagation training process is the design of advanced optimisers to improve the convergence speed and stability of the gradient descent learning rule. In particular, in multi-task deep learning ($MTDL$) the multitude of tasks may generate potentially conflicting gradients that would hinder the concurrent convergence of the diverse loss functions. This challenge arises when the gradients of the task objectives have either different magnitudes or opposite directions, causing one or a few to dominate or to interfere with each other, thus degrading the training process. Gradient surgery methods address the problem explicitly dealing with conflicting gradients by adjusting the overall gradient trajectory. This work introduces a novel gradient surgery method, the Similarity-Aware Momentum Gradient Surgery (SAM-GS), which provides an effective and scalable approach based on a gradient magnitude similarity measure to guide the optimisation process. The SAM-GS surgery adopts gradient equalisation and modulation of the first-order momentum. A series of experimental tests have shown the effectiveness of SAM-GS on synthetic problems and $MTL$ benchmarks. Gradient magnitude similarity plays a crucial role in regularising gradient aggregation in $MTDL$ for the optimisation of the learning process.",
    "authors": [
      "Thomas Borsani, Andrea Rosani, Giuseppe Nicosia, Giuseppe Di Fatta"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.838042"
  },
  {
    "id": "oai:arXiv.org:2506.06133v1",
    "journal": "arXiv_CS",
    "title": "Let's CONFER: A Dataset for Evaluating Natural Language Inference Models on CONditional InFERence and Presupposition",
    "link": "https://arxiv.org/abs/2506.06133",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06133v1 Announce Type: new \nAbstract: Natural Language Inference (NLI) is the task of determining whether a sentence pair represents entailment, contradiction, or a neutral relationship. While NLI models perform well on many inference tasks, their ability to handle fine-grained pragmatic inferences, particularly presupposition in conditionals, remains underexplored. In this study, we introduce CONFER, a novel dataset designed to evaluate how NLI models process inference in conditional sentences. We assess the performance of four NLI models, including two pre-trained models, to examine their generalization to conditional reasoning. Additionally, we evaluate Large Language Models (LLMs), including GPT-4o, LLaMA, Gemma, and DeepSeek-R1, in zero-shot and few-shot prompting settings to analyze their ability to infer presuppositions with and without prior context. Our findings indicate that NLI models struggle with presuppositional reasoning in conditionals, and fine-tuning on existing NLI datasets does not necessarily improve their performance.",
    "authors": [
      "Tara Azin, Daniel Dumitrescu, Diana Inkpen, Raj Singh"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.838052"
  },
  {
    "id": "oai:arXiv.org:2506.06136v1",
    "journal": "arXiv_CS",
    "title": "UAV-UGV Cooperative Trajectory Optimization and Task Allocation for Medical Rescue Tasks in Post-Disaster Environments",
    "link": "https://arxiv.org/abs/2506.06136",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06136v1 Announce Type: new \nAbstract: In post-disaster scenarios, rapid and efficient delivery of medical resources is critical and challenging due to severe damage to infrastructure. To provide an optimized solution, we propose a cooperative trajectory optimization and task allocation framework leveraging unmanned aerial vehicles (UAVs) and unmanned ground vehicles (UGVs). This study integrates a Genetic Algorithm (GA) for efficient task allocation among multiple UAVs and UGVs, and employs an informed-RRT* (Rapidly-exploring Random Tree Star) algorithm for collision-free trajectory generation. Further optimization of task sequencing and path efficiency is conducted using Covariance Matrix Adaptation Evolution Strategy (CMA-ES). Simulation experiments conducted in a realistic post-disaster environment demonstrate that our proposed approach significantly improves the overall efficiency of medical rescue operations compared to traditional strategies, showing substantial reductions in total mission completion time and traveled distance. Additionally, the cooperative utilization of UAVs and UGVs effectively balances their complementary advantages, highlighting the system' s scalability and practicality for real-world deployment.",
    "authors": [
      "Kaiyuan Chen, Wanpeng Zhao, Yongxi Liu, Yuanqing Xia, Wannian Liang, Shuo Wang"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.838061"
  },
  {
    "id": "oai:arXiv.org:2506.06137v1",
    "journal": "arXiv_CS",
    "title": "Table-r1: Self-supervised and Reinforcement Learning for Program-based Table Reasoning in Small Language Models",
    "link": "https://arxiv.org/abs/2506.06137",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06137v1 Announce Type: new \nAbstract: Table reasoning (TR) requires structured reasoning over semi-structured tabular data and remains challenging, particularly for small language models (SLMs, e.g., LLaMA-8B) due to their limited capacity compared to large LMs (LLMs, e.g., GPT-4o). To narrow this gap, we explore program-based TR (P-TR), which circumvents key limitations of text-based TR (T-TR), notably in numerical reasoning, by generating executable programs. However, applying P-TR to SLMs introduces two challenges: (i) vulnerability to heterogeneity in table layouts, and (ii) inconsistency in reasoning due to limited code generation capability. We propose Table-r1, a two-stage P-TR method designed for SLMs. Stage 1 introduces an innovative self-supervised learning task, Layout Transformation Inference, to improve tabular layout generalization from a programmatic view. Stage 2 adopts a mix-paradigm variant of Group Relative Policy Optimization, enhancing P-TR consistency while allowing dynamic fallback to T-TR when needed. Experiments on four TR benchmarks demonstrate that Table-r1 outperforms all SLM-based methods, achieving at least a 15% accuracy improvement over the base model (LLaMA-8B) across all datasets and reaching performance competitive with LLMs.",
    "authors": [
      "Rihui Jin, Zheyu Xin, Xing Xie, Zuoyi Li, Guilin Qi, Yongrui Chen, Xinbang Dai, Tongtong Wu, Gholamreza Haffari"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.838080"
  },
  {
    "id": "oai:arXiv.org:2506.06138v1",
    "journal": "arXiv_CS",
    "title": "An extension of Dembo-Hammer's reduction algorithm for the 0-1 knapsack problem",
    "link": "https://arxiv.org/abs/2506.06138",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06138v1 Announce Type: new \nAbstract: Dembo-Hammer's Reduction Algorithm (DHR) is one of the classical algorithms for the 0-1 Knapsack Problem (0-1 KP) and its variants, which reduces an instance of the 0-1 KP to a sub-instance of smaller size with reduction time complexity $O(n)$. We present an extension of DHR (abbreviated as EDHR), which reduces an instance of 0-1 KP to at most $n^i$ sub-instances for any positive integer $i$. In practice, $i$ can be set as needed. In particular, if we choose $i=1$ then EDHR is exactly DHR. Finally, computational experiments on randomly generated data instances demonstrate that EDHR substantially reduces the search tree size compared to CPLEX.",
    "authors": [
      "Yang Yang"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.838089"
  },
  {
    "id": "oai:arXiv.org:2506.06143v1",
    "journal": "arXiv_CS",
    "title": "carps: A Framework for Comparing N Hyperparameter Optimizers on M Benchmarks",
    "link": "https://arxiv.org/abs/2506.06143",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06143v1 Announce Type: new \nAbstract: Hyperparameter Optimization (HPO) is crucial to develop well-performing machine learning models. In order to ease prototyping and benchmarking of HPO methods, we propose carps, a benchmark framework for Comprehensive Automated Research Performance Studies allowing to evaluate N optimizers on M benchmark tasks. In this first release of carps, we focus on the four most important types of HPO task types: blackbox, multi-fidelity, multi-objective and multi-fidelity-multi-objective. With 3 336 tasks from 5 community benchmark collections and 28 variants of 9 optimizer families, we offer the biggest go-to library to date to evaluate and compare HPO methods. The carps framework relies on a purpose-built, lightweight interface, gluing together optimizers and benchmark tasks. It also features an analysis pipeline, facilitating the evaluation of optimizers on benchmarks. However, navigating a huge number of tasks while developing and comparing methods can be computationally infeasible. To address this, we obtain a subset of representative tasks by minimizing the star discrepancy of the subset, in the space spanned by the full set. As a result, we propose an initial subset of 10 to 30 diverse tasks for each task type, and include functionality to re-compute subsets as more benchmarks become available, enabling efficient evaluations. We also establish a first set of baseline results on these tasks as a measure for future comparisons. With carps (https://www.github.com/automl/CARP-S), we make an important step in the standardization of HPO evaluation.",
    "authors": [
      "Carolin Benjamins, Helena Graf, Sarah Segel, Difan Deng, Tim Ruhkopf, Leona Hennig, Soham Basu, Neeratyoy Mallik, Edward Bergman, Deyao Chen, Fran\\c{c}ois Cl\\'ement, Matthias Feurer, Katharina Eggensperger, Frank Hutter, Carola Doerr, Marius Lindauer"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.838097"
  },
  {
    "id": "oai:arXiv.org:2506.06144v1",
    "journal": "arXiv_CS",
    "title": "CLaMR: Contextualized Late-Interaction for Multimodal Content Retrieval",
    "link": "https://arxiv.org/abs/2506.06144",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06144v1 Announce Type: new \nAbstract: Online video web content is richly multimodal: a single video blends vision, speech, ambient audio, and on-screen text. Retrieval systems typically treat these modalities as independent retrieval sources, which can lead to noisy and subpar retrieval. We explore multimodal video content retrieval, where relevance can be scored from one particular modality or jointly across multiple modalities simultaneously. Consequently, an effective retriever must dynamically choose which modality (or set of modalities) best addresses the query. We introduce CLaMR, a multimodal, late-interaction retriever that jointly indexes 4 modalities: video frames, transcribed speech, on-screen text, and metadata. CLaMR jointly encodes all modalities with a unified multimodal backbone for improved contextualization and is trained to enhance dynamic modality selection via two key innovations. First, given the lack of training data for multimodal retrieval, we introduce MultiVENT 2.0++, a large-scale synthetic training dataset built on MultiVENT 2.0 (event-centric videos in various languages paired with queries) with modality-targeted queries. Next, we propose a modality-aware loss that jointly trains according to a standard contrastive objective alongside an objective for learning correct modality usage. On the test sets of MultiVENT 2.0++ and MSRVTT, conventional aggregation strategies, such as averaging similarities for baseline retrievers, degrade performance by introducing noise from irrelevant modalities. In contrast, CLaMR consistently outperforms existing retrievers: on MultiVENT 2.0++, CLaMR improves nDCG@10 by 25.6 over the best single-modality retriever and by 35.4 over the best multi-modality retriever. We illustrate CLaMR's downstream utility on long-video QA, retrieving relevant frames and obtaining a 3.50% boost over LanguageBind on Video-MME and 1.42% over dense sampling on LongVideoBench.",
    "authors": [
      "David Wan, Han Wang, Elias Stengel-Eskin, Jaemin Cho, Mohit Bansal"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.838106"
  },
  {
    "id": "oai:arXiv.org:2506.06147v1",
    "journal": "arXiv_CS",
    "title": "Stream DaQ: Stream-First Data Quality Monitoring",
    "link": "https://arxiv.org/abs/2506.06147",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06147v1 Announce Type: new \nAbstract: Data quality is fundamental to modern data science workflows, where data continuously flows as unbounded streams feeding critical downstream tasks, from elementary analytics to advanced artificial intelligence models. Existing data quality approaches either focus exclusively on static data or treat streaming as an extension of batch processing, lacking the temporal granularity and contextual awareness required for true streaming applications. In this paper, we present a novel data quality monitoring model specifically designed for unbounded data streams. Our model introduces stream-first concepts, such as configurable windowing mechanisms, dynamic constraint adaptation, and continuous assessment that produces quality meta-streams for real-time pipeline awareness. To demonstrate practical applicability, we developed Stream DaQ, an open-source Python framework that implements our theoretical model. Stream DaQ unifies and adapts over 30 quality checks fragmented across existing static tools into a comprehensive streaming suite, enabling practitioners to define sophisticated, context-aware quality constraints through compositional expressiveness. Our evaluation demonstrates that the model's implementation significantly outperforms a production-grade alternative in both execution time and throughput while offering richer functionality via native streaming capabilities compared to other choices. Through its Python-native design, Stream DaQ seamlessly integrates with modern data science workflows, making continuous quality monitoring accessible to the broader data science community.",
    "authors": [
      "Vasileios Papastergios, Anastasios Gounaris"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.838114"
  },
  {
    "id": "oai:arXiv.org:2506.06151v1",
    "journal": "arXiv_CS",
    "title": "Joint-GCG: Unified Gradient-Based Poisoning Attacks on Retrieval-Augmented Generation Systems",
    "link": "https://arxiv.org/abs/2506.06151",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06151v1 Announce Type: new \nAbstract: Retrieval-Augmented Generation (RAG) systems enhance Large Language Models (LLMs) by retrieving relevant documents from external corpora before generating responses. This approach significantly expands LLM capabilities by leveraging vast, up-to-date external knowledge. However, this reliance on external knowledge makes RAG systems vulnerable to corpus poisoning attacks that manipulate generated outputs via poisoned document injection. Existing poisoning attack strategies typically treat the retrieval and generation stages as disjointed, limiting their effectiveness. We propose Joint-GCG, the first framework to unify gradient-based attacks across both retriever and generator models through three innovations: (1) Cross-Vocabulary Projection for aligning embedding spaces, (2) Gradient Tokenization Alignment for synchronizing token-level gradient signals, and (3) Adaptive Weighted Fusion for dynamically balancing attacking objectives. Evaluations demonstrate that Joint-GCG achieves at most 25% and an average of 5% higher attack success rate than previous methods across multiple retrievers and generators. While optimized under a white-box assumption, the generated poisons show unprecedented transferability to unseen models. Joint-GCG's innovative unification of gradient-based attacks across retrieval and generation stages fundamentally reshapes our understanding of vulnerabilities within RAG systems. Our code is available at https://github.com/NicerWang/Joint-GCG.",
    "authors": [
      "Haowei Wang, Rupeng Zhang, Junjie Wang, Mingyang Li, Yuekai Huang, Dandan Wang, Qing Wang"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.838123"
  },
  {
    "id": "oai:arXiv.org:2506.06153v1",
    "journal": "arXiv_CS",
    "title": "Personalized Large Language Models Can Increase the Belief Accuracy of Social Networks",
    "link": "https://arxiv.org/abs/2506.06153",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06153v1 Announce Type: new \nAbstract: Large language models (LLMs) are increasingly involved in shaping public understanding on contested issues. This has led to substantial discussion about the potential of LLMs to reinforce or correct misperceptions. While existing literature documents the impact of LLMs on individuals' beliefs, limited work explores how LLMs affect social networks. We address this gap with a pre-registered experiment (N = 1265) around the 2024 US presidential election, where we empirically explore the impact of personalized LLMs on belief accuracy in the context of social networks. The LLMs are constructed to be personalized, offering messages tailored to individuals' profiles, and to have guardrails for accurate information retrieval. We find that the presence of a personalized LLM leads individuals to update their beliefs towards the truth. More importantly, individuals with a personalized LLM in their social network not only choose to follow it, indicating they would like to obtain information from it in subsequent interactions, but also construct subsequent social networks to include other individuals with beliefs similar to the LLM -- in this case, more accurate beliefs. Therefore, our results show that LLMs have the capacity to influence individual beliefs and the social networks in which people exist, and highlight the potential of LLMs to act as corrective agents in online environments. Our findings can inform future strategies for responsible AI-mediated communication.",
    "authors": [
      "Adiba Mahbub Proma, Neeley Pate, Sean Kelty, Gourab Ghoshal, James N. Druckman, Ehsan Hoque"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.838132"
  },
  {
    "id": "oai:arXiv.org:2506.06156v1",
    "journal": "arXiv_CS",
    "title": "Resource Allocation for Pinching-Antenna Systems: State-of-the-Art, Key Techniques and Open Issues",
    "link": "https://arxiv.org/abs/2506.06156",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06156v1 Announce Type: new \nAbstract: Pinching antennas have emerged as a promising technology for reconfiguring wireless propagation environments, particularly in high-frequency communication systems operating in the millimeter-wave and terahertz bands. By enabling dynamic activation at arbitrary positions along a dielectric waveguide, pinching antennas offer unprecedented channel reconfigurability and the ability to provide line-of-sight (LoS) links in scenarios with severe LoS blockages. The performance of pinching-antenna systems is highly dependent on the optimized placement of the pinching antennas, which must be jointly considered with traditional resource allocation (RA) variables -- including transmission power, time slots, and subcarriers. The resulting joint RA problems are typically non-convex with complex variable coupling, necessitating sophisticated optimization techniques. This article provides a comprehensive survey of existing RA algorithms designed for pinching-antenna systems, supported by numerical case studies that demonstrate their potential performance gains. Key challenges and open research problems are also identified to guide future developments in this emerging field.",
    "authors": [
      "Ming Zeng, Ji Wang, Octavia A. Dobre, Zhiguo Ding, George K. Karagiannidis, Robert Schober, H. Vincent Poor"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.838150"
  },
  {
    "id": "oai:arXiv.org:2506.06157v1",
    "journal": "arXiv_CS",
    "title": "Masked Language Models are Good Heterogeneous Graph Generalizers",
    "link": "https://arxiv.org/abs/2506.06157",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06157v1 Announce Type: new \nAbstract: Heterogeneous graph neural networks (HGNNs) excel at capturing structural and semantic information in heterogeneous graphs (HGs), while struggling to generalize across domains and tasks. Recently, some researchers have turned to integrating HGNNs with large language models (LLMs) for more generalizable heterogeneous graph learning. However, these approaches typically extract structural information via HGNNs as HG tokens, and disparities in embedding spaces between HGNNs and LLMs have been shown to bias the LLM's comprehension of HGs. Moreover, as these HG tokens are often derived from node-level tasks, the model's ability to generalize across tasks remains limited. To this end, we propose a simple yet effective Masked Language Modeling-based method, called MLM4HG. MLM4HG introduces metapath-based textual sequences instead of HG tokens to extract structural and semantic information inherent in HGs, and designs customized textual templates to unify different graph tasks into a coherent cloze-style \"mask\" token prediction paradigm. Specifically, MLM4HG first converts HGs from various domains to texts based on metapaths, and subsequently combines them with the unified task texts to form a HG-based corpus. Moreover, the corpus is fed into a pretrained LM for fine-tuning with a constrained target vocabulary, enabling the fine-tuned LM to generalize to unseen target HGs. Extensive cross-domain and multi-task experiments on four real-world datasets demonstrate the superior generalization performance of MLM4HG over state-of-the-art methods in both few-shot and zero-shot scenarios. Our code is available at https://github.com/BUPT-GAMMA/MLM4HG.",
    "authors": [
      "Jinyu Yang, Cheng Yang, Shanyuan Cui, Zeyuan Guo, Liangwei Yang, Muhan Zhang, Chuan Shi"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.838159"
  },
  {
    "id": "oai:arXiv.org:2506.06158v1",
    "journal": "arXiv_CS",
    "title": "ENMA: Tokenwise Autoregression for Generative Neural PDE Operators",
    "link": "https://arxiv.org/abs/2506.06158",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06158v1 Announce Type: new \nAbstract: Solving time-dependent parametric partial differential equations (PDEs) remains a fundamental challenge for neural solvers, particularly when generalizing across a wide range of physical parameters and dynamics. When data is uncertain or incomplete-as is often the case-a natural approach is to turn to generative models. We introduce ENMA, a generative neural operator designed to model spatio-temporal dynamics arising from physical phenomena. ENMA predicts future dynamics in a compressed latent space using a generative masked autoregressive transformer trained with flow matching loss, enabling tokenwise generation. Irregularly sampled spatial observations are encoded into uniform latent representations via attention mechanisms and further compressed through a spatio-temporal convolutional encoder. This allows ENMA to perform in-context learning at inference time by conditioning on either past states of the target trajectory or auxiliary context trajectories with similar dynamics. The result is a robust and adaptable framework that generalizes to new PDE regimes and supports one-shot surrogate modeling of time-dependent parametric PDEs.",
    "authors": [
      "Armand Kassa\\\"i Koupa\\\"i, Lise Le Boudec, Louis Serrano, Patrick Gallinari"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.838167"
  },
  {
    "id": "oai:arXiv.org:2506.06161v1",
    "journal": "arXiv_CS",
    "title": "Obfuscation-Resilient Binary Code Similarity Analysis using Dominance Enhanced Semantic Graph",
    "link": "https://arxiv.org/abs/2506.06161",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06161v1 Announce Type: new \nAbstract: Binary code similarity analysis (BCSA) serves as a core technique for binary analysis tasks such as vulnerability detection. While current graph-based BCSA approaches capture substantial semantics and show strong performance, their performance suffers under code obfuscation due to the unstable control flow. To address this issue, we develop ORCAS, an Obfuscation-Resilient BCSA model based on Dominance Enhanced Semantic Graph (DESG). The DESG is an original binary code representation, capturing more binaries' implicit semantics without control flow structure, including inter-instruction relations, inter-basic block relations, and instruction-basic block relations. ORCAS robustly scores semantic similarity across binary functions from different obfuscation options, optimization levels, and instruction set architectures. Extensive evaluation on the BinKit dataset shows ORCAS significantly outperforms eight baselines, achieving an average 12.1% PR-AUC gain when using combined three obfuscation options compared to the state-of-the-art approaches. Furthermore, ORCAS improves recall by up to 43% on an original obfuscated real-world vulnerability dataset, which we released to facilitate future research.",
    "authors": [
      "Yufeng Wang, Yuhong Feng, Yixuan Cao, Haoran Li, Haiyue Feng, Yifeng Wang"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.838176"
  },
  {
    "id": "oai:arXiv.org:2506.06162v1",
    "journal": "arXiv_CS",
    "title": "Recommender systems, stigmergy, and the tyranny of popularity",
    "link": "https://arxiv.org/abs/2506.06162",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06162v1 Announce Type: new \nAbstract: Scientific recommender systems, such as Google Scholar and Web of Science, are essential tools for discovery. Search algorithms that power work through stigmergy, a collective intelligence mechanism that surfaces useful paths through repeated engagement. While generally effective, this ``rich-get-richer'' dynamic results in a small number of high-profile papers that dominate visibility. This essay argues argue that these algorithm over-reliance on popularity fosters intellectual homogeneity and exacerbates structural inequities, stifling innovative and diverse perspectives critical for scientific progress. We propose an overhaul of search platforms to incorporate user-specific calibration, allowing researchers to manually adjust the weights of factors like popularity, recency, and relevance. We also advise platform developers on how word embeddings and LLMs could be implemented in ways that increase user autonomy. While our suggestions are particularly pertinent to aligning recommender systems with scientific values, these ideas are broadly applicable to information access systems in general. Designing platforms that increase user autonomy is an important step toward more robust and dynamic information",
    "authors": [
      "Zackary Okun Dunivin, Paul E. Smaldino"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.838184"
  },
  {
    "id": "oai:arXiv.org:2506.06166v1",
    "journal": "arXiv_CS",
    "title": "The Lock-in Hypothesis: Stagnation by Algorithm",
    "link": "https://arxiv.org/abs/2506.06166",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06166v1 Announce Type: new \nAbstract: The training and deployment of large language models (LLMs) create a feedback loop with human users: models learn human beliefs from data, reinforce these beliefs with generated content, reabsorb the reinforced beliefs, and feed them back to users again and again. This dynamic resembles an echo chamber. We hypothesize that this feedback loop entrenches the existing values and beliefs of users, leading to a loss of diversity and potentially the lock-in of false beliefs. We formalize this hypothesis and test it empirically with agent-based LLM simulations and real-world GPT usage data. Analysis reveals sudden but sustained drops in diversity after the release of new GPT iterations, consistent with the hypothesized human-AI feedback loop. Code and data available at https://thelockinhypothesis.com",
    "authors": [
      "Tianyi Alex Qiu, Zhonghao He, Tejasveer Chugh, Max Kleiman-Weiner"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.838200"
  },
  {
    "id": "oai:arXiv.org:2506.06169v1",
    "journal": "arXiv_CS",
    "title": "semantic-features: A User-Friendly Tool for Studying Contextual Word Embeddings in Interpretable Semantic Spaces",
    "link": "https://arxiv.org/abs/2506.06169",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06169v1 Announce Type: new \nAbstract: We introduce semantic-features, an extensible, easy-to-use library based on Chronis et al. (2023) for studying contextualized word embeddings of LMs by projecting them into interpretable spaces. We apply this tool in an experiment where we measure the contextual effect of the choice of dative construction (prepositional or double object) on the semantic interpretation of utterances (Bresnan, 2007). Specifically, we test whether \"London\" in \"I sent London the letter.\" is more likely to be interpreted as an animate referent (e.g., as the name of a person) than in \"I sent the letter to London.\" To this end, we devise a dataset of 450 sentence pairs, one in each dative construction, with recipients being ambiguous with respect to person-hood vs. place-hood. By applying semantic-features, we show that the contextualized word embeddings of three masked language models show the expected sensitivities. This leaves us optimistic about the usefulness of our tool.",
    "authors": [
      "Jwalanthi Ranganathan, Rohan Jha, Kanishka Misra, Kyle Mahowald"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.838210"
  },
  {
    "id": "oai:arXiv.org:2506.06172v1",
    "journal": "arXiv_CS",
    "title": "Monitorability for the Modal mu-Calculus over Systems with Data: From Practice to Theory",
    "link": "https://arxiv.org/abs/2506.06172",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06172v1 Announce Type: new \nAbstract: Runtime verification, also known as runtime monitoring, consists of checking whether a system satisfies a given specification by observing the trace it produces during its execution. It is used as a lightweight verification technique to complement or substitute costlier methods such as model-checking.\n  In the regular setting, Hennessy-Milner logic with recursion, a variant of the modal mu-calculus, provides a versatile formalism for expressing linear- and branching-time specifications of the control flow of the system.\n  In this paper, we shift the focus from control to data and study the monitorability of an extension of this logic that allows one to express properties of the data flow. Data values are modelled as values from an infinite domain. They are stored using data variables and manipulated using predicates and first-order quantification.\n  The resulting logic is closely related to register automata with guessing. This correspondence yields a monitor synthesis algorithm, and allows us to derive a strict monitorability hierarchy between the different fragments of the logic, in stark contrast to the regular setting. In particular, restricting to deterministic monitors strictly reduces the set of monitorable properties.\n  Last, we exhibit a fragment of the logic that can express all monitorable formulae in the logic without greatest fixed-points but not in the full logic. We finally show that this is unavoidable because, in fact, there is no decidable fragment of the logic that captures all monitorable properties.",
    "authors": [
      "Luca Aceto, Antonis Achilleos, Duncan Paul Attard, L\\'eo Exibard, Adrian Francalanza, Anna Ing\\'olfsd\\'ottir, Karoliina Lehtinen"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.838219"
  },
  {
    "id": "oai:arXiv.org:2506.06174v1",
    "journal": "arXiv_CS",
    "title": "Technical Report for Egocentric Mistake Detection for the HoloAssist Challenge",
    "link": "https://arxiv.org/abs/2506.06174",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06174v1 Announce Type: new \nAbstract: In this report, we address the task of online mistake detection, which is vital in domains like industrial automation and education, where real-time video analysis allows human operators to correct errors as they occur. While previous work focuses on procedural errors involving action order, broader error types must be addressed for real-world use. We introduce an online mistake detection framework that handles both procedural and execution errors (e.g., motor slips or tool misuse). Upon detecting an error, we use a large language model (LLM) to generate explanatory feedback. Experiments on the HoloAssist benchmark confirm the effectiveness of our approach, where our approach is placed second on the mistake detection task.",
    "authors": [
      "Constantin Patsch, Marsil Zakour, Yuankai Wu, Eckehard Steinbach"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.838228"
  },
  {
    "id": "oai:arXiv.org:2506.06175v1",
    "journal": "arXiv_CS",
    "title": "Does It Run and Is That Enough? Revisiting Text-to-Chart Generation with a Multi-Agent Approach",
    "link": "https://arxiv.org/abs/2506.06175",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06175v1 Announce Type: new \nAbstract: Large language models can translate natural-language chart descriptions into runnable code, yet approximately 15\\% of the generated scripts still fail to execute, even after supervised fine-tuning and reinforcement learning. We investigate whether this persistent error rate stems from model limitations or from reliance on a single-prompt design. To explore this, we propose a lightweight multi-agent pipeline that separates drafting, execution, repair, and judgment, using only an off-the-shelf GPT-4o-mini model. On the \\textsc{Text2Chart31} benchmark, our system reduces execution errors to 4.5\\% within three repair iterations, outperforming the strongest fine-tuned baseline by nearly 5 percentage points while requiring significantly less compute. Similar performance is observed on the \\textsc{ChartX} benchmark, with an error rate of 4.6\\%, demonstrating strong generalization. Under current benchmarks, execution success appears largely solved. However, manual review reveals that 6 out of 100 sampled charts contain hallucinations, and an LLM-based accessibility audit shows that only 33.3\\% (\\textsc{Text2Chart31}) and 7.2\\% (\\textsc{ChartX}) of generated charts satisfy basic colorblindness guidelines. These findings suggest that future work should shift focus from execution reliability toward improving chart aesthetics, semantic fidelity, and accessibility.",
    "authors": [
      "James Ford, Anthony Rios"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.838237"
  },
  {
    "id": "oai:arXiv.org:2506.06176v1",
    "journal": "arXiv_CS",
    "title": "SatelliteFormula: Multi-Modal Symbolic Regression from Remote Sensing Imagery for Physics Discovery",
    "link": "https://arxiv.org/abs/2506.06176",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06176v1 Announce Type: new \nAbstract: We propose SatelliteFormula, a novel symbolic regression framework that derives physically interpretable expressions directly from multi-spectral remote sensing imagery. Unlike traditional empirical indices or black-box learning models, SatelliteFormula combines a Vision Transformer-based encoder for spatial-spectral feature extraction with physics-guided constraints to ensure consistency and interpretability. Existing symbolic regression methods struggle with the high-dimensional complexity of multi-spectral data; our method addresses this by integrating transformer representations into a symbolic optimizer that balances accuracy and physical plausibility. Extensive experiments on benchmark datasets and remote sensing tasks demonstrate superior performance, stability, and generalization compared to state-of-the-art baselines. SatelliteFormula enables interpretable modeling of complex environmental variables, bridging the gap between data-driven learning and physical understanding.",
    "authors": [
      "Zhenyu Yu, Mohd. Yamani Idna Idris, Pei Wang, Yuelong Xia, Fei Ma, Rizwan Qureshi"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.838246"
  },
  {
    "id": "oai:arXiv.org:2506.06178v1",
    "journal": "arXiv_CS",
    "title": "Reusing Trajectories in Policy Gradients Enables Fast Convergence",
    "link": "https://arxiv.org/abs/2506.06178",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06178v1 Announce Type: new \nAbstract: Policy gradient (PG) methods are a class of effective reinforcement learning algorithms, particularly when dealing with continuous control problems. These methods learn the parameters of parametric policies via stochastic gradient ascent, typically using on-policy trajectory data to estimate the policy gradient. However, such reliance on fresh data makes them sample-inefficient. Indeed, vanilla PG methods require $O(\\epsilon^{-2})$ trajectories to reach an $\\epsilon$-approximate stationary point. A common strategy to improve efficiency is to reuse off-policy information from past iterations, such as previous gradients or trajectories. While gradient reuse has received substantial theoretical attention, leading to improved rates of $O(\\epsilon^{-3/2})$, the reuse of past trajectories remains largely unexplored from a theoretical perspective. In this work, we provide the first rigorous theoretical evidence that extensive reuse of past off-policy trajectories can significantly accelerate convergence in PG methods. We introduce a power mean correction to the multiple importance weighting estimator and propose RPG (Retrospective Policy Gradient), a PG algorithm that combines old and new trajectories for policy updates. Through a novel analysis, we show that, under established assumptions, RPG achieves a sample complexity of $\\widetilde{O}(\\epsilon^{-1})$, the best known rate in the literature. We further validate empirically our approach against PG methods with state-of-the-art rates.",
    "authors": [
      "Alessandro Montenegro, Federico Mansutti, Marco Mussi, Matteo Papini, Alberto Maria Metelli"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.838255"
  },
  {
    "id": "oai:arXiv.org:2506.06180v1",
    "journal": "arXiv_CS",
    "title": "Detecting Voice Phishing with Precision: Fine-Tuning Small Language Models",
    "link": "https://arxiv.org/abs/2506.06180",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06180v1 Announce Type: new \nAbstract: We develop a voice phishing (VP) detector by fine-tuning Llama3, a representative open-source, small language model (LM). In the prompt, we provide carefully-designed VP evaluation criteria and apply the Chain-of-Thought (CoT) technique. To evaluate the robustness of LMs and highlight differences in their performance, we construct an adversarial test dataset that places the models under challenging conditions. Moreover, to address the lack of VP transcripts, we create transcripts by referencing existing or new types of VP techniques. We compare cases where evaluation criteria are included, the CoT technique is applied, or both are used together. In the experiment, our results show that the Llama3-8B model, fine-tuned with a dataset that includes a prompt with VP evaluation criteria, yields the best performance among small LMs and is comparable to that of a GPT-4-based VP detector. These findings indicate that incorporating human expert knowledge into the prompt is more effective than using the CoT technique for small LMs in VP detection.",
    "authors": [
      "Ju Yong Sim, Seong Hwan Kim"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.838271"
  },
  {
    "id": "oai:arXiv.org:2506.06181v1",
    "journal": "arXiv_CS",
    "title": "Swap Kripke models for deontic LFIs",
    "link": "https://arxiv.org/abs/2506.06181",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06181v1 Announce Type: new \nAbstract: We present a construction of nondeterministic semantics for some deontic logics based on the class of paraconsistent logics known as Logics of Formal Inconsistency (LFIs), for the first time combining swap structures and Kripke models through the novel notion of swap Kripe models. We start by making use of Nmatrices to characterize systems based on LFIs that do not satisfy axiom (cl), while turning to RNmatrices when the latter is considered in the underlying LFIs. This paper also presents, for the first time, a full axiomatization and a semantics for the $C^{D}_n$ hierarchy, by use of the aforementioned mixed semantics with RNmatrices. This includes the historical system $C^{D}_1$ of da Costa-Carnielli (1986), the first deontic paraconsistent system proposed in the literature.",
    "authors": [
      "Mahan Vaz, Marcelo E. Coniglio"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.838279"
  },
  {
    "id": "oai:arXiv.org:2506.06185v1",
    "journal": "arXiv_CS",
    "title": "Antithetic Noise in Diffusion Models",
    "link": "https://arxiv.org/abs/2506.06185",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06185v1 Announce Type: new \nAbstract: We initiate a systematic study of antithetic initial noise in diffusion models. Across unconditional models trained on diverse datasets, text-conditioned latent-diffusion models, and diffusion-posterior samplers, we find that pairing each initial noise with its negation consistently yields strongly negatively correlated samples. To explain this phenomenon, we combine experiments and theoretical analysis, leading to a symmetry conjecture that the learned score function is approximately affine antisymmetric (odd symmetry up to a constant shift), and provide evidence supporting it. Leveraging this negative correlation, we enable two applications: (1) enhancing image diversity in models like Stable Diffusion without quality loss, and (2) sharpening uncertainty quantification (e.g., up to 90% narrower confidence intervals) when estimating downstream statistics. Building on these gains, we extend the two-point pairing to a randomized quasi-Monte Carlo estimator, which further improves estimation accuracy. Our framework is training-free, model-agnostic, and adds no runtime overhead.",
    "authors": [
      "Jing Jia, Sifan Liu, Bowen Song, Wei Yuan, Liyue Shen, Guanyang Wang"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.838287"
  },
  {
    "id": "oai:arXiv.org:2506.06188v1",
    "journal": "arXiv_CS",
    "title": "Physics-Informed Neural Networks for Control of Single-Phase Flow Systems Governed by Partial Differential Equations",
    "link": "https://arxiv.org/abs/2506.06188",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06188v1 Announce Type: new \nAbstract: The modeling and control of single-phase flow systems governed by Partial Differential Equations (PDEs) present challenges, especially under transient conditions. In this work, we extend the Physics-Informed Neural Nets for Control (PINC) framework, originally proposed to modeling and control of Ordinary Differential Equations (ODE) without the need of any labeled data, to the PDE case, particularly to single-phase incompressible and compressible flows, integrating neural networks with physical conservation laws. The PINC model for PDEs is structured into two stages: a steady-state network, which learns equilibrium solutions for a wide range of control inputs, and a transient network, which captures dynamic responses under time-varying boundary conditions. We propose a simplifying assumption that reduces the dimensionality of the spatial coordinate regarding the initial condition, allowing the efficient training of the PINC network. This simplification enables the derivation of optimal control policies using Model Predictive Control (MPC). We validate our approach through numerical experiments, demonstrating that the PINC model, which is trained exclusively using physical laws, i.e., without labeled data, accurately represents flow dynamics and enables real-time control applications. The results highlight the PINC's capability to efficiently approximate PDE solutions without requiring iterative solvers, making it a promising alternative for fluid flow monitoring and optimization in engineering applications.",
    "authors": [
      "Luis Kin Miyatake, Eduardo Camponogara, Eric Aislan Antonelo, Alexey Pavlov"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.838297"
  },
  {
    "id": "oai:arXiv.org:2506.06190v1",
    "journal": "arXiv_CS",
    "title": "NAT: Neural Acoustic Transfer for Interactive Scenes in Real Time",
    "link": "https://arxiv.org/abs/2506.06190",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06190v1 Announce Type: new \nAbstract: Previous acoustic transfer methods rely on extensive precomputation and storage of data to enable real-time interaction and auditory feedback. However, these methods struggle with complex scenes, especially when dynamic changes in object position, material, and size significantly alter sound effects. These continuous variations lead to fluctuating acoustic transfer distributions, making it challenging to represent with basic data structures and render efficiently in real time. To address this challenge, we present Neural Acoustic Transfer, a novel approach that utilizes an implicit neural representation to encode precomputed acoustic transfer and its variations, allowing for real-time prediction of sound fields under varying conditions. To efficiently generate the training data required for the neural acoustic field, we developed a fast Monte-Carlo-based boundary element method (BEM) approximation for general scenarios with smooth Neumann conditions. Additionally, we implemented a GPU-accelerated version of standard BEM for scenarios requiring higher precision. These methods provide the necessary training data, enabling our neural network to accurately model the sound radiation space. We demonstrate our method's numerical accuracy and runtime efficiency (within several milliseconds for 30s audio) through comprehensive validation and comparisons in diverse acoustic transfer scenarios. Our approach allows for efficient and accurate modeling of sound behavior in dynamically changing environments, which can benefit a wide range of interactive applications such as virtual reality, augmented reality, and advanced audio production.",
    "authors": [
      "Xutong Jin, Bo Pang, Chenxi Xu, Xinyun Hou, Guoping Wang, Sheng Li"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.838305"
  },
  {
    "id": "oai:arXiv.org:2506.06192v1",
    "journal": "arXiv_CS",
    "title": "ICU-TSB: A Benchmark for Temporal Patient Representation Learning for Unsupervised Stratification into Patient Cohorts",
    "link": "https://arxiv.org/abs/2506.06192",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06192v1 Announce Type: new \nAbstract: Patient stratification identifying clinically meaningful subgroups is essential for advancing personalized medicine through improved diagnostics and treatment strategies. Electronic health records (EHRs), particularly those from intensive care units (ICUs), contain rich temporal clinical data that can be leveraged for this purpose. In this work, we introduce ICU-TSB (Temporal Stratification Benchmark), the first comprehensive benchmark for evaluating patient stratification based on temporal patient representation learning using three publicly available ICU EHR datasets. A key contribution of our benchmark is a novel hierarchical evaluation framework utilizing disease taxonomies to measure the alignment of discovered clusters with clinically validated disease groupings. In our experiments with ICU-TSB, we compared statistical methods and several recurrent neural networks, including LSTM and GRU, for their ability to generate effective patient representations for subsequent clustering of patient trajectories. Our results demonstrate that temporal representation learning can rediscover clinically meaningful patient cohorts; nevertheless, it remains a challenging task, with v-measuring varying from up to 0.46 at the top level of the taxonomy to up to 0.40 at the lowest level. To further enhance the practical utility of our findings, we also evaluate multiple strategies for assigning interpretable labels to the identified clusters. The experiments and benchmark are fully reproducible and available at https://github.com/ds4dh/CBMS2025stratification.",
    "authors": [
      "Dimitrios Proios, Alban Bornet, Anthony Yazdani, Jose F Rodrigues Jr, Douglas Teodoro"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.838314"
  },
  {
    "id": "oai:arXiv.org:2506.06193v1",
    "journal": "arXiv_CS",
    "title": "Validation of the Critical Reflection and Agency in Computing Index: Do Computing Ethics Courses Make a Difference?",
    "link": "https://arxiv.org/abs/2506.06193",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06193v1 Announce Type: new \nAbstract: Computing ethics education aims to develop students' critical reflection and agency. We need validated ways to measure whether our efforts succeed. Through two survey administrations (N=474, N=464) with computing students and professionals, we provide evidence for the validity of the Critical Reflection and Agency in Computing Index. Our psychometric analyses demonstrate distinct dimensions of ethical development and show strong reliability and construct validity. Participants who completed computing ethics courses showed higher scores in some dimensions of ethical reflection and agency, but they also exhibited stronger techno-solutionist beliefs, highlighting a challenge in current pedagogy. This validated instrument enables systematic measurement of how computing students develop critical consciousness, allowing educators to better understand how to prepare computing professionals to tackle ethical challenges in their work.",
    "authors": [
      "Aadarsh Padiyath, Casey Fiesler, Mark Guzdial, Barbara Ericson"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.838323"
  },
  {
    "id": "oai:arXiv.org:2506.06194v1",
    "journal": "arXiv_CS",
    "title": "Transformative or Conservative? Conservation laws for ResNets and Transformers",
    "link": "https://arxiv.org/abs/2506.06194",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06194v1 Announce Type: new \nAbstract: While conservation laws in gradient flow training dynamics are well understood for (mostly shallow) ReLU and linear networks, their study remains largely unexplored for more practical architectures. This paper bridges this gap by deriving and analyzing conservation laws for modern architectures, with a focus on convolutional ResNets and Transformer networks. For this, we first show that basic building blocks such as ReLU (or linear) shallow networks, with or without convolution, have easily expressed conservation laws, and no more than the known ones. In the case of a single attention layer, we also completely describe all conservation laws, and we show that residual blocks have the same conservation laws as the same block without a skip connection. We then introduce the notion of conservation laws that depend only on a subset of parameters (corresponding e.g. to a pair of consecutive layers, to a residual block, or to an attention layer). We demonstrate that the characterization of such laws can be reduced to the analysis of the corresponding building block in isolation. Finally, we examine how these newly discovered conservation principles, initially established in the continuous gradient flow regime, persist under discrete optimization dynamics, particularly in the context of Stochastic Gradient Descent (SGD).",
    "authors": [
      "Sibylle Marcotte, R\\'emi Gribonval, Gabriel Peyr\\'e"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.838332"
  },
  {
    "id": "oai:arXiv.org:2506.06196v1",
    "journal": "arXiv_CS",
    "title": "Bridging Perception and Action: Spatially-Grounded Mid-Level Representations for Robot Generalization",
    "link": "https://arxiv.org/abs/2506.06196",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06196v1 Announce Type: new \nAbstract: In this work, we investigate how spatially grounded auxiliary representations can provide both broad, high-level grounding as well as direct, actionable information to improve policy learning performance and generalization for dexterous tasks. We study these mid-level representations across three critical dimensions: object-centricity, pose-awareness, and depth-awareness. We use these interpretable mid-level representations to train specialist encoders via supervised learning, then feed them as inputs to a diffusion policy to solve dexterous bimanual manipulation tasks in the real world. We propose a novel mixture-of-experts policy architecture that combines multiple specialized expert models, each trained on a distinct mid-level representation, to improve policy generalization. This method achieves an average success rate that is 11% higher than a language-grounded baseline and 24 percent higher than a standard diffusion policy baseline on our evaluation tasks. Furthermore, we find that leveraging mid-level representations as supervision signals for policy actions within a weighted imitation learning algorithm improves the precision with which the policy follows these representations, yielding an additional performance increase of 10%. Our findings highlight the importance of grounding robot policies not only with broad perceptual tasks but also with more granular, actionable representations. For further information and videos, please visit https://mid-level-moe.github.io.",
    "authors": [
      "Jonathan Yang, Chuyuan Kelly Fu, Dhruv Shah, Dorsa Sadigh, Fei Xia, Tingnan Zhang"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.838341"
  },
  {
    "id": "oai:arXiv.org:2506.06199v1",
    "journal": "arXiv_CS",
    "title": "3DFlowAction: Learning Cross-Embodiment Manipulation from 3D Flow World Model",
    "link": "https://arxiv.org/abs/2506.06199",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06199v1 Announce Type: new \nAbstract: Manipulation has long been a challenging task for robots, while humans can effortlessly perform complex interactions with objects, such as hanging a cup on the mug rack. A key reason is the lack of a large and uniform dataset for teaching robots manipulation skills. Current robot datasets often record robot action in different action spaces within a simple scene. This hinders the robot to learn a unified and robust action representation for different robots within diverse scenes. Observing how humans understand a manipulation task, we find that understanding how the objects should move in the 3D space is a critical clue for guiding actions. This clue is embodiment-agnostic and suitable for both humans and different robots. Motivated by this, we aim to learn a 3D flow world model from both human and robot manipulation data. This model predicts the future movement of the interacting objects in 3D space, guiding action planning for manipulation. Specifically, we synthesize a large-scale 3D optical flow dataset, named ManiFlow-110k, through a moving object auto-detect pipeline. A video diffusion-based world model then learns manipulation physics from these data, generating 3D optical flow trajectories conditioned on language instructions. With the generated 3D object optical flow, we propose a flow-guided rendering mechanism, which renders the predicted final state and leverages GPT-4o to assess whether the predicted flow aligns with the task description. This equips the robot with a closed-loop planning ability. Finally, we consider the predicted 3D optical flow as constraints for an optimization policy to determine a chunk of robot actions for manipulation. Extensive experiments demonstrate strong generalization across diverse robotic manipulation tasks and reliable cross-embodiment adaptation without hardware-specific training.",
    "authors": [
      "Hongyan Zhi, Peihao Chen, Siyuan Zhou, Yubo Dong, Quanxi Wu, Lei Han, Mingkui Tan"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.838349"
  },
  {
    "id": "oai:arXiv.org:2506.06204v1",
    "journal": "arXiv_CS",
    "title": "How to craft a deep reinforcement learning policy for wind farm flow control",
    "link": "https://arxiv.org/abs/2506.06204",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06204v1 Announce Type: new \nAbstract: Within wind farms, wake effects between turbines can significantly reduce overall energy production. Wind farm flow control encompasses methods designed to mitigate these effects through coordinated turbine control. Wake steering, for example, consists in intentionally misaligning certain turbines with the wind to optimize airflow and increase power output. However, designing a robust wake steering controller remains challenging, and existing machine learning approaches are limited to quasi-static wind conditions or small wind farms. This work presents a new deep reinforcement learning methodology to develop a wake steering policy that overcomes these limitations. Our approach introduces a novel architecture that combines graph attention networks and multi-head self-attention blocks, alongside a novel reward function and training strategy. The resulting model computes the yaw angles of each turbine, optimizing energy production in time-varying wind conditions. An empirical study conducted on steady-state, low-fidelity simulation, shows that our model requires approximately 10 times fewer training steps than a fully connected neural network and achieves more robust performance compared to a strong optimization baseline, increasing energy production by up to 14 %. To the best of our knowledge, this is the first deep reinforcement learning-based wake steering controller to generalize effectively across any time-varying wind conditions in a low-fidelity, steady-state numerical simulation setting.",
    "authors": [
      "Elie Kadoche, Pascal Bianchi, Florence Carton, Philippe Ciblat, Damien Ernst"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.838366"
  },
  {
    "id": "oai:arXiv.org:2506.06205v1",
    "journal": "arXiv_CS",
    "title": "Astra: Toward General-Purpose Mobile Robots via Hierarchical Multimodal Learning",
    "link": "https://arxiv.org/abs/2506.06205",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06205v1 Announce Type: new \nAbstract: Modern robot navigation systems encounter difficulties in diverse and complex indoor environments. Traditional approaches rely on multiple modules with small models or rule-based systems and thus lack adaptability to new environments. To address this, we developed Astra, a comprehensive dual-model architecture, Astra-Global and Astra-Local, for mobile robot navigation. Astra-Global, a multimodal LLM, processes vision and language inputs to perform self and goal localization using a hybrid topological-semantic graph as the global map, and outperforms traditional visual place recognition methods. Astra-Local, a multitask network, handles local path planning and odometry estimation. Its 4D spatial-temporal encoder, trained through self-supervised learning, generates robust 4D features for downstream tasks. The planning head utilizes flow matching and a novel masked ESDF loss to minimize collision risks for generating local trajectories, and the odometry head integrates multi-sensor inputs via a transformer encoder to predict the relative pose of the robot. Deployed on real in-house mobile robots, Astra achieves high end-to-end mission success rate across diverse indoor environments.",
    "authors": [
      "Sheng Chen, Peiyu He, Jiaxin Hu, Ziyang Liu, Yansheng Wang, Tao Xu, Chi Zhang, Chongchong Zhang, Chao An, Shiyu Cai, Duo Cao, Kangping Chen, Shuai Chu, Tianwei Chu, Mingdi Dan, Min Du, Weiwei Fang, Pengyou Fu, Junkai Hu, Xiaowei Jiang, Zhaodi Jiang, Fuxuan Li, Jun Li, Minghui Li, Mingyao Li, Yanchang Li, Zhibin Li, Guangming Liu, Kairui Liu, Lihao Liu, Weizhi Liu, Xiaoshun Liu, Yufei Liu, Yunfei Liu, Qiang Lu, Yuanfei Luo, Xiang Lv, Hongying Ma, Sai Ma, Lingxian Mi, Sha Sa, Hongxiang Shu, Lei Tian, Chengzhi Wang, Jiayu Wang, Kaijie Wang, Qingyi Wang, Renwen Wang, Tao Wang, Wei Wang, Xirui Wang, Chao Wei, Xuguang Wei, Zijun Xia, Zhaohao Xiao, Tingshuai Yan, Liyan Yang, Yifan Yang, Zhikai Yang, Zhong Yin, Li Yuan, Liuchun Yuan, Chi Zhang, Jinyang Zhang, Junhui Zhang, Linge Zhang, Zhenyi Zhang, Zheyu Zhang, Dongjie Zhu, Hang Li, Yangang Zhang"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.838375"
  },
  {
    "id": "oai:arXiv.org:2506.06208v1",
    "journal": "arXiv_CS",
    "title": "Building Models of Neurological Language",
    "link": "https://arxiv.org/abs/2506.06208",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06208v1 Announce Type: new \nAbstract: This report documents the development and evaluation of domain-specific language models for neurology. Initially focused on building a bespoke model, the project adapted to rapid advances in open-source and commercial medical LLMs, shifting toward leveraging retrieval-augmented generation (RAG) and representational models for secure, local deployment. Key contributions include the creation of neurology-specific datasets (case reports, QA sets, textbook-derived data), tools for multi-word expression extraction, and graph-based analyses of medical terminology. The project also produced scripts and Docker containers for local hosting. Performance metrics and graph community results are reported, with future possible work open for multimodal models using open-source architectures like phi-4.",
    "authors": [
      "Henry Watkins"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.838383"
  },
  {
    "id": "oai:arXiv.org:2506.06211v1",
    "journal": "arXiv_CS",
    "title": "PuzzleWorld: A Benchmark for Multimodal, Open-Ended Reasoning in Puzzlehunts",
    "link": "https://arxiv.org/abs/2506.06211",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06211v1 Announce Type: new \nAbstract: Puzzlehunts are a genre of complex, multi-step puzzles lacking well-defined problem definitions. In contrast to conventional reasoning benchmarks consisting of tasks with clear instructions, puzzlehunts require models to discover the underlying problem structure from multimodal evidence and iterative reasoning, mirroring real-world domains such as scientific discovery, exploratory data analysis, or investigative problem-solving. Despite recent progress in foundation models, their performance on such open-ended settings remains largely untested. In this paper, we introduce PuzzleWorld, a large-scale benchmark of 667 puzzlehunt-style problems designed to assess step-by-step, open-ended, and creative multimodal reasoning. Each puzzle is annotated with the final solution, detailed reasoning traces, and cognitive skill labels, enabling holistic benchmarking and fine-grained diagnostic analysis. Most state-of-the-art models achieve only 1-2% final answer accuracy, with the best model solving only 14% of puzzles and reaching 40% stepwise accuracy. To demonstrate the value of our reasoning annotations, we show that fine-tuning a small model on reasoning traces improves stepwise reasoning from 4% to 11%, while training on final answers alone degrades performance to near zero. Our error analysis reveals that current models exhibit myopic reasoning, are bottlenecked by the limitations of language-based inference, and lack sketching capabilities crucial for visual and spatial reasoning. We release PuzzleWorld at https://github.com/MIT-MI/PuzzleWorld to support future work on building more general, open-ended, and creative reasoning systems.",
    "authors": [
      "Hengzhi Li, Brendon Jiang, Alexander Naehu, Regan Song, Justin Zhang, Megan Tjandrasuwita, Chanakya Ekbote, Steven-Shine Chen, Adithya Balachandran, Wei Dai, Rebecca Chang, Paul Pu Liang"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.838392"
  },
  {
    "id": "oai:arXiv.org:2506.06212v1",
    "journal": "arXiv_CS",
    "title": "Model-Driven Graph Contrastive Learning",
    "link": "https://arxiv.org/abs/2506.06212",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06212v1 Announce Type: new \nAbstract: We propose $\\textbf{MGCL}$, a model-driven graph contrastive learning (GCL) framework that leverages graphons (probabilistic generative models for graphs) to guide contrastive learning by accounting for the data's underlying generative process. GCL has emerged as a powerful self-supervised framework for learning expressive node or graph representations without relying on annotated labels, which are often scarce in real-world data. By contrasting augmented views of graph data, GCL has demonstrated strong performance across various downstream tasks, such as node and graph classification. However, existing methods typically rely on manually designed or heuristic augmentation strategies that are not tailored to the underlying data distribution and operate at the individual graph level, ignoring similarities among graphs generated from the same model. Conversely, in our proposed approach, MGCL first estimates the graphon associated with the observed data and then defines a graphon-informed augmentation process, enabling data-adaptive and principled augmentations. Additionally, for graph-level tasks, MGCL clusters the dataset and estimates a graphon per group, enabling contrastive pairs to reflect shared semantics and structure. Extensive experiments on benchmark datasets demonstrate that MGCL achieves state-of-the-art performance, highlighting the advantages of incorporating generative models into GCL.",
    "authors": [
      "Ali Azizpour, Nicolas Zilberstein, Santiago Segarra"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.838401"
  },
  {
    "id": "oai:arXiv.org:2506.06214v1",
    "journal": "arXiv_CS",
    "title": "Can Theoretical Physics Research Benefit from Language Agents?",
    "link": "https://arxiv.org/abs/2506.06214",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06214v1 Announce Type: new \nAbstract: Large Language Models (LLMs) are rapidly advancing across diverse domains, yet their application in theoretical physics research is not yet mature. This position paper argues that LLM agents can potentially help accelerate theoretical, computational, and applied physics when properly integrated with domain knowledge and toolbox. We analyze current LLM capabilities for physics -- from mathematical reasoning to code generation -- identifying critical gaps in physical intuition, constraint satisfaction, and reliable reasoning. We envision future physics-specialized LLMs that could handle multimodal data, propose testable hypotheses, and design experiments. Realizing this vision requires addressing fundamental challenges: ensuring physical consistency, and developing robust verification methods. We call for collaborative efforts between physics and AI communities to help advance scientific discovery in physics.",
    "authors": [
      "Sirui Lu, Zhijing Jin, Terry Jingchen Zhang, Pavel Kos, J. Ignacio Cirac, Bernhard Sch\\\"olkopf"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.838409"
  },
  {
    "id": "oai:arXiv.org:2506.06215v1",
    "journal": "arXiv_CS",
    "title": "Corrector Sampling in Language Models",
    "link": "https://arxiv.org/abs/2506.06215",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06215v1 Announce Type: new \nAbstract: Autoregressive language models accumulate errors due to their fixed, irrevocable left-to-right token generation. To address this, we propose a new sampling method called Resample-Previous-Tokens (RPT). RPT mitigates error accumulation by iteratively revisiting and potentially replacing tokens in a window of previously generated text. This method can be integrated into existing autoregressive models, preserving their next-token-prediction quality and speed. Fine-tuning a pretrained 8B parameter model with RPT for only 100B resulted in ~10% relative improvements on reasoning and coding benchmarks compared to the standard sampling.",
    "authors": [
      "Itai Gat, Neta Shaul, Uriel Singer, Yaron Lipman"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.838417"
  },
  {
    "id": "oai:arXiv.org:2506.06216v1",
    "journal": "arXiv_CS",
    "title": "Integer Linear Programming Preprocessing for Maximum Satisfiability",
    "link": "https://arxiv.org/abs/2506.06216",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06216v1 Announce Type: new \nAbstract: The Maximum Satisfiability problem (MaxSAT) is a major optimization challenge with numerous practical applications. In recent MaxSAT evaluations, most MaxSAT solvers have adopted an ILP solver as part of their portfolios. This paper investigates the impact of Integer Linear Programming (ILP) preprocessing techniques on MaxSAT solving. Experimental results show that ILP preprocessing techniques help WMaxCDCL-OpenWbo1200, the winner of the MaxSAT evaluation 2024 in the unweighted track, solve 15 additional instances. Moreover, current state-of-the-art MaxSAT solvers heavily use an ILP solver in their portfolios, while our proposed approach reduces the need to call an ILP solver in a portfolio including WMaxCDCL or MaxCDCL.",
    "authors": [
      "Jialu Zhang, Chu-Min Li, Sami Cherif, Shuolin Li, Zhifei Zheng"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.838425"
  },
  {
    "id": "oai:arXiv.org:2506.06217v1",
    "journal": "arXiv_CS",
    "title": "Longer Lists Yield Better Matchings",
    "link": "https://arxiv.org/abs/2506.06217",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06217v1 Announce Type: new \nAbstract: Many centralized mechanisms for two-sided matching markets that enjoy strong theoretical properties assume that the planner solicits full information on the preferences of each participating agent. In particular, they expect that participants compile and communicate their complete preference lists over agents from the other side of the market. However, real-world markets are often very large and agents cannot always be expected to even produce a ranking of all options on the other side. It is therefore important to understand the impact of incomplete or truncated lists on the quality of the resultant matching.\n  In this paper, we focus on the Serial Dictatorship mechanism in a model where each agent of the proposing side (students) has a random preference list of length $d$, sampled independently and uniformly at random from $n$ schools, each of which has one seat. Our main result shows that if the students primarily care about being matched to any school of their list (as opposed to ending up unmatched), then all students in position $i\\leq n$ will prefer markets with longer lists, when $n$ is large enough. Schools on the other hand will always prefer longer lists in our model. We moreover investigate the impact of $d$ on the rank of the school that a student gets matched to.\n  Our main result suggests that markets that are well-approximated by our hypothesis and where the demand of schools does not exceed supply should be designed with preference lists as long as reasonable, since longer lists would favor all agents.",
    "authors": [
      "Yuri Faenza, Aapeli Vuorinen"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.838433"
  },
  {
    "id": "oai:arXiv.org:2506.06218v1",
    "journal": "arXiv_CS",
    "title": "STSBench: A Spatio-temporal Scenario Benchmark for Multi-modal Large Language Models in Autonomous Driving",
    "link": "https://arxiv.org/abs/2506.06218",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06218v1 Announce Type: new \nAbstract: We introduce STSBench, a scenario-based framework to benchmark the holistic understanding of vision-language models (VLMs) for autonomous driving. The framework automatically mines pre-defined traffic scenarios from any dataset using ground-truth annotations, provides an intuitive user interface for efficient human verification, and generates multiple-choice questions for model evaluation. Applied to the NuScenes dataset, we present STSnu, the first benchmark that evaluates the spatio-temporal reasoning capabilities of VLMs based on comprehensive 3D perception. Existing benchmarks typically target off-the-shelf or fine-tuned VLMs for images or videos from a single viewpoint and focus on semantic tasks such as object recognition, dense captioning, risk assessment, or scene understanding. In contrast, STSnu evaluates driving expert VLMs for end-to-end driving, operating on videos from multi-view cameras or LiDAR. It specifically assesses their ability to reason about both ego-vehicle actions and complex interactions among traffic participants, a crucial capability for autonomous vehicles. The benchmark features 43 diverse scenarios spanning multiple views and frames, resulting in 971 human-verified multiple-choice questions. A thorough evaluation uncovers critical shortcomings in existing models' ability to reason about fundamental traffic dynamics in complex environments. These findings highlight the urgent need for architectural advances that explicitly model spatio-temporal reasoning. By addressing a core gap in spatio-temporal evaluation, STSBench enables the development of more robust and explainable VLMs for autonomous driving.",
    "authors": [
      "Christian Fruhwirth-Reisinger, Du\\v{s}an Mali\\'c, Wei Lin, David Schinagl, Samuel Schulter, Horst Possegger"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.838442"
  },
  {
    "id": "oai:arXiv.org:2506.06220v1",
    "journal": "arXiv_CS",
    "title": "GenIR: Generative Visual Feedback for Mental Image Retrieval",
    "link": "https://arxiv.org/abs/2506.06220",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06220v1 Announce Type: new \nAbstract: Vision-language models (VLMs) have shown strong performance on text-to-image retrieval benchmarks. However, bridging this success to real-world applications remains a challenge. In practice, human search behavior is rarely a one-shot action. Instead, it is often a multi-round process guided by clues in mind, that is, a mental image ranging from vague recollections to vivid mental representations of the target image. Motivated by this gap, we study the task of Mental Image Retrieval (MIR), which targets the realistic yet underexplored setting where users refine their search for a mentally envisioned image through multi-round interactions with an image search engine. Central to successful interactive retrieval is the capability of machines to provide users with clear, actionable feedback; however, existing methods rely on indirect or abstract verbal feedback, which can be ambiguous, misleading, or ineffective for users to refine the query. To overcome this, we propose GenIR, a generative multi-round retrieval paradigm leveraging diffusion-based image generation to explicitly reify the AI system's understanding at each round. These synthetic visual representations provide clear, interpretable feedback, enabling users to refine their queries intuitively and effectively. We further introduce a fully automated pipeline to generate a high-quality multi-round MIR dataset. Experimental results demonstrate that GenIR significantly outperforms existing interactive methods in the MIR scenario. This work establishes a new task with a dataset and an effective generative retrieval method, providing a foundation for future research in this direction.",
    "authors": [
      "Diji Yang, Minghao Liu, Chung-Hsiang Lo, Yi Zhang, James Davis"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.838451"
  },
  {
    "id": "oai:arXiv.org:2506.06221v1",
    "journal": "arXiv_CS",
    "title": "BiAssemble: Learning Collaborative Affordance for Bimanual Geometric Assembly",
    "link": "https://arxiv.org/abs/2506.06221",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06221v1 Announce Type: new \nAbstract: Shape assembly, the process of combining parts into a complete whole, is a crucial robotic skill with broad real-world applications. Among various assembly tasks, geometric assembly--where broken parts are reassembled into their original form (e.g., reconstructing a shattered bowl)--is particularly challenging. This requires the robot to recognize geometric cues for grasping, assembly, and subsequent bimanual collaborative manipulation on varied fragments. In this paper, we exploit the geometric generalization of point-level affordance, learning affordance aware of bimanual collaboration in geometric assembly with long-horizon action sequences. To address the evaluation ambiguity caused by geometry diversity of broken parts, we introduce a real-world benchmark featuring geometric variety and global reproducibility. Extensive experiments demonstrate the superiority of our approach over both previous affordance-based and imitation-based methods. Project page: https://sites.google.com/view/biassembly/.",
    "authors": [
      "Yan Shen, Ruihai Wu, Yubin Ke, Xinyuan Song, Zeyi Li, Xiaoqi Li, Hongwei Fan, Haoran Lu, Hao dong"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.838460"
  },
  {
    "id": "oai:arXiv.org:2506.06223v1",
    "journal": "arXiv_CS",
    "title": "A Direct Reduction from Stochastic Parity Games to Simple Stochastic Games",
    "link": "https://arxiv.org/abs/2506.06223",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06223v1 Announce Type: new \nAbstract: Significant progress has been recently achieved in developing efficient solutions for simple stochastic games (SSGs), focusing on reachability objectives. While reductions from stochastic parity games (SPGs) to SSGs have been presented in the literature through the use of multiple intermediate game models, a direct and simple reduction has been notably absent. This paper introduces a novel and direct polynomial-time reduction from quantitative SPGs to quantitative SSGs. By leveraging a gadget-based transformation that effectively removes the priority function, we construct an SSG that simulates the behavior of a given SPG. We formally establish the correctness of our direct reduction. Furthermore, we demonstrate that under binary encoding this reduction is polynomial, thereby directly corroborating the known $\\textbf{NP}\\,\\mathbf{\\cap}\\,\\textbf{coNP}$ complexity of SPGs and providing new understanding in the relationship between parity and reachability objectives in turn-based stochastic games.",
    "authors": [
      "Rapha\\\"el Berthon, Joost-Pieter Katoen, Zihan Zhou"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.838468"
  },
  {
    "id": "oai:arXiv.org:2506.06226v1",
    "journal": "arXiv_CS",
    "title": "PROVSYN: Synthesizing Provenance Graphs for Data Augmentation in Intrusion Detection Systems",
    "link": "https://arxiv.org/abs/2506.06226",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06226v1 Announce Type: new \nAbstract: Provenance graph analysis plays a vital role in intrusion detection, particularly against Advanced Persistent Threats (APTs), by exposing complex attack patterns. While recent systems combine graph neural networks (GNNs) with natural language processing (NLP) to capture structural and semantic features, their effectiveness is limited by class imbalance in real-world data. To address this, we introduce PROVSYN, an automated framework that synthesizes provenance graphs through a three-phase pipeline: (1) heterogeneous graph structure synthesis with structural-semantic modeling, (2) rule-based topological refinement, and (3) context-aware textual attribute synthesis using large language models (LLMs). PROVSYN includes a comprehensive evaluation framework that integrates structural, textual, temporal, and embedding-based metrics, along with a semantic validation mechanism to assess the correctness of generated attack patterns and system behaviors. To demonstrate practical utility, we use the synthetic graphs to augment training datasets for downstream APT detection models. Experimental results show that PROVSYN produces high-fidelity graphs and improves detection performance through effective data augmentation.",
    "authors": [
      "Yi Huang, Wajih UI Hassan, Yao Guo, Xiangqun Chen, Ding Li"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.838485"
  },
  {
    "id": "oai:arXiv.org:2506.06227v1",
    "journal": "arXiv_CS",
    "title": "CompilerGPT: Leveraging Large Language Models for Analyzing and Acting on Compiler Optimization Reports",
    "link": "https://arxiv.org/abs/2506.06227",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06227v1 Announce Type: new \nAbstract: Current compiler optimization reports often present complex, technical information that is difficult for programmers to interpret and act upon effectively. This paper assesses the capability of large language models (LLM) to understand compiler optimization reports and automatically rewrite the code accordingly.\n  To this end, the paper introduces CompilerGPT, a novel framework that automates the interaction between compilers, LLMs, and user defined test and evaluation harness. CompilerGPT's workflow runs several iterations and reports on the obtained results.\n  Experiments with two leading LLM models (GPT-4o and Claude Sonnet), optimization reports from two compilers (Clang and GCC), and five benchmark codes demonstrate the potential of this approach. Speedups of up to 6.5x were obtained, though not consistently in every test. This method holds promise for improving compiler usability and streamlining the software optimization process.",
    "authors": [
      "Peter Pirkelbauer"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.838494"
  },
  {
    "id": "oai:arXiv.org:2506.06228v1",
    "journal": "arXiv_CS",
    "title": "Statistical Guarantees in Data-Driven Nonlinear Control: Conformal Robustness for Stability and Safety",
    "link": "https://arxiv.org/abs/2506.06228",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06228v1 Announce Type: new \nAbstract: We present a true-dynamics-agnostic, statistically rigorous framework for establishing exponential stability and safety guarantees of closed-loop, data-driven nonlinear control. Central to our approach is the novel concept of conformal robustness, which robustifies the Lyapunov and zeroing barrier certificates of data-driven dynamical systems against model prediction uncertainties using conformal prediction. It quantifies these uncertainties by leveraging rank statistics of prediction scores over system trajectories, without assuming any specific underlying structure of the prediction model or distribution of the uncertainties. With the quantified uncertainty information, we further construct the conformally robust control Lyapunov function (CR-CLF) and control barrier function (CR-CBF), data-driven counterparts of the CLF and CBF, for fully data-driven control with statistical guarantees of finite-horizon exponential stability and safety. The performance of the proposed concept is validated in numerical simulations with four benchmark nonlinear control problems.",
    "authors": [
      "Ting-Wei Hsu, Hiroyasu Tsukamoto"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.838504"
  },
  {
    "id": "oai:arXiv.org:2506.06232v1",
    "journal": "arXiv_CS",
    "title": "Challenging Vision-Language Models with Surgical Data: A New Dataset and Broad Benchmarking Study",
    "link": "https://arxiv.org/abs/2506.06232",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06232v1 Announce Type: new \nAbstract: While traditional computer vision models have historically struggled to generalize to endoscopic domains, the emergence of foundation models has shown promising cross-domain performance. In this work, we present the first large-scale study assessing the capabilities of Vision Language Models (VLMs) for endoscopic tasks with a specific focus on laparoscopic surgery. Using a diverse set of state-of-the-art models, multiple surgical datasets, and extensive human reference annotations, we address three key research questions: (1) Can current VLMs solve basic perception tasks on surgical images? (2) Can they handle advanced frame-based endoscopic scene understanding tasks? and (3) How do specialized medical VLMs compare to generalist models in this context? Our results reveal that VLMs can effectively perform basic surgical perception tasks, such as object counting and localization, with performance levels comparable to general domain tasks. However, their performance deteriorates significantly when the tasks require medical knowledge. Notably, we find that specialized medical VLMs currently underperform compared to generalist models across both basic and advanced surgical tasks, suggesting that they are not yet optimized for the complexity of surgical environments. These findings highlight the need for further advancements to enable VLMs to handle the unique challenges posed by surgery. Overall, our work provides important insights for the development of next-generation endoscopic AI systems and identifies key areas for improvement in medical visual language models.",
    "authors": [
      "Leon Mayer, Tim R\\\"adsch, Dominik Michael, Lucas Luttner, Amine Yamlahi, Evangelia Christodoulou, Patrick Godau, Marcel Knopp, Annika Reinke, Fiona Kolbinger, Lena Maier-Hein"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.838520"
  },
  {
    "id": "oai:arXiv.org:2506.06235v1",
    "journal": "arXiv_CS",
    "title": "Optimizing Cloud-to-GPU Throughput for Deep Learning With Earth Observation Data",
    "link": "https://arxiv.org/abs/2506.06235",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06235v1 Announce Type: new \nAbstract: Training deep learning models on petabyte-scale Earth observation (EO) data requires separating compute resources from data storage. However, standard PyTorch data loaders cannot keep modern GPUs utilized when streaming GeoTIFF files directly from cloud storage. In this work, we benchmark GeoTIFF loading throughput from both cloud object storage and local SSD, systematically testing different loader configurations and data parameters. We focus on tile-aligned reads and worker thread pools, using Bayesian optimization to find optimal settings for each storage type. Our optimized configurations increase remote data loading throughput by 20x and local throughput by 4x compared to default settings. On three public EO benchmarks, models trained with optimized remote loading achieve the same accuracy as local training within identical time budgets. We improve validation IoU by 6-15% and maintain 85-95% GPU utilization versus 0-30% with standard configurations. Code is publicly available at https://github.com/microsoft/pytorch-cloud-geotiff-optimization",
    "authors": [
      "Akram Zaytar, Caleb Robinson, Girmaw Abebe Tadesse, Tammy Glazer, Gilles Hacheme, Anthony Ortiz, Rahul M Dodhia, Juan M Lavista Ferres"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.838528"
  },
  {
    "id": "oai:arXiv.org:2506.06239v1",
    "journal": "arXiv_CS",
    "title": "Optimizing Recall or Relevance? A Multi-Task Multi-Head Approach for Item-to-Item Retrieval in Recommendation",
    "link": "https://arxiv.org/abs/2506.06239",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06239v1 Announce Type: new \nAbstract: The task of item-to-item (I2I) retrieval is to identify a set of relevant and highly engaging items based on a given trigger item. It is a crucial component in modern recommendation systems, where users' previously engaged items serve as trigger items to retrieve relevant content for future engagement. However, existing I2I retrieval models in industry are primarily built on co-engagement data and optimized using the recall measure, which overly emphasizes co-engagement patterns while failing to capture semantic relevance. This often leads to overfitting short-term co-engagement trends at the expense of long-term benefits such as discovering novel interests and promoting content diversity. To address this challenge, we propose MTMH, a Multi-Task and Multi-Head I2I retrieval model that achieves both high recall and semantic relevance. Our model consists of two key components: 1) a multi-task learning loss for formally optimizing the trade-off between recall and semantic relevance, and 2) a multi-head I2I retrieval architecture for retrieving both highly co-engaged and semantically relevant items. We evaluate MTMH using proprietary data from a commercial platform serving billions of users and demonstrate that it can improve recall by up to 14.4% and semantic relevance by up to 56.6% compared with prior state-of-the-art models. We also conduct live experiments to verify that MTMH can enhance both short-term consumption metrics and long-term user-experience-related metrics. Our work provides a principled approach for jointly optimizing I2I recall and semantic relevance, which has significant implications for improving the overall performance of recommendation systems.",
    "authors": [
      "Jiang Zhang, Sumit Kumar, Wei Chang, Yubo Wang, Feng Zhang, Weize Mao, Hanchao Yu, Aashu Singh, Min Li, Qifan Wang"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.838545"
  },
  {
    "id": "oai:arXiv.org:2506.06240v1",
    "journal": "arXiv_CS",
    "title": "Bridging External and Parametric Knowledge: Mitigating Hallucination of LLMs with Shared-Private Semantic Synergy in Dual-Stream Knowledge",
    "link": "https://arxiv.org/abs/2506.06240",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06240v1 Announce Type: new \nAbstract: Retrieval-augmented generation (RAG) is a cost-effective approach to mitigate the hallucination of Large Language Models (LLMs) by incorporating the retrieved external knowledge into the generation process. However, external knowledge may conflict with the parametric knowledge of LLMs. Furthermore, current LLMs lack inherent mechanisms for resolving such knowledge conflicts, making traditional RAG methods suffer from degraded performance and stability. Thus, we propose a Dual-Stream Knowledge-Augmented Framework for Shared-Private Semantic Synergy (DSSP-RAG). Central to the framework is a novel approach that refines self-attention into a mixed-attention, distinguishing shared and private semantics for a controlled internal-external knowledge integration. To effectively facilitate DSSP in RAG, we further introduce an unsupervised hallucination detection method based on cognitive uncertainty, ensuring the necessity of introducing knowledge, and an Energy Quotient (EQ) based on attention difference matrices to reduce noise in the retrieved external knowledge. Extensive experiments on benchmark datasets show that DSSP-RAG can effectively resolve conflicts and enhance the complementarity of dual-stream knowledge, leading to superior performance over strong baselines.",
    "authors": [
      "Yi Sui, Chaozhuo Li, Chen Zhang, Dawei song, Qiuchi Li"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.838555"
  },
  {
    "id": "oai:arXiv.org:2506.06242v1",
    "journal": "arXiv_CS",
    "title": "Visual Graph Arena: Evaluating Visual Conceptualization of Vision and Multimodal Large Language Models",
    "link": "https://arxiv.org/abs/2506.06242",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06242v1 Announce Type: new \nAbstract: Recent advancements in multimodal large language models have driven breakthroughs in visual question answering. Yet, a critical gap persists, `conceptualization'-the ability to recognize and reason about the same concept despite variations in visual form, a basic ability of human reasoning. To address this challenge, we introduce the Visual Graph Arena (VGA), a dataset featuring six graph-based tasks designed to evaluate and improve AI systems' capacity for visual abstraction. VGA uses diverse graph layouts (e.g., Kamada-Kawai vs. planar) to test reasoning independent of visual form. Experiments with state-of-the-art vision models and multimodal LLMs reveal a striking divide: humans achieved near-perfect accuracy across tasks, while models totally failed on isomorphism detection and showed limited success in path/cycle tasks. We further identify behavioral anomalies suggesting pseudo-intelligent pattern matching rather than genuine understanding. These findings underscore fundamental limitations in current AI models for visual understanding. By isolating the challenge of representation-invariant reasoning, the VGA provides a framework to drive progress toward human-like conceptualization in AI visual models. The Visual Graph Arena is available at: \\href{https://vga.csail.mit.edu/}{vga.csail.mit.edu}",
    "authors": [
      "Zahra Babaiee, Peyman M. Kiasari, Daniela Rus, Radu Grosu"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.838564"
  },
  {
    "id": "oai:arXiv.org:2506.06244v1",
    "journal": "arXiv_CS",
    "title": "Neural Responses to Affective Sentences Reveal Signatures of Depression",
    "link": "https://arxiv.org/abs/2506.06244",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06244v1 Announce Type: new \nAbstract: Major Depressive Disorder (MDD) is a highly prevalent mental health condition, and a deeper understanding of its neurocognitive foundations is essential for identifying how core functions such as emotional and self-referential processing are affected. We investigate how depression alters the temporal dynamics of emotional processing by measuring neural responses to self-referential affective sentences using surface electroencephalography (EEG) in healthy and depressed individuals. Our results reveal significant group-level differences in neural activity during sentence viewing, suggesting disrupted integration of emotional and self-referential information in depression. Deep learning model trained on these responses achieves an area under the receiver operating curve (AUC) of 0.707 in distinguishing healthy from depressed participants, and 0.624 in differentiating depressed subgroups with and without suicidal ideation. Spatial ablations highlight anterior electrodes associated with semantic and affective processing as key contributors. These findings suggest stable, stimulus-driven neural signatures of depression that may inform future diagnostic tools.",
    "authors": [
      "Aditya Kommineni, Woojae Jeong, Kleanthis Avramidis, Colin McDaniel, Myzelle Hughes, Thomas McGee, Elsi Kaiser, Kristina Lerman, Idan A. Blank, Dani Byrd, Assal Habibi, B. Rael Cahn, Sudarsana Kadiri, Takfarinas Medani, Richard M. Leahy, Shrikanth Narayanan"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.838573"
  },
  {
    "id": "oai:arXiv.org:2506.06248v1",
    "journal": "arXiv_CS",
    "title": "Lagrangian-based Equilibrium Propagation: generalisation to arbitrary boundary conditions & equivalence with Hamiltonian Echo Learning",
    "link": "https://arxiv.org/abs/2506.06248",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06248v1 Announce Type: new \nAbstract: Equilibrium Propagation (EP) is a learning algorithm for training Energy-based Models (EBMs) on static inputs which leverages the variational description of their fixed points. Extending EP to time-varying inputs is a challenging problem, as the variational description must apply to the entire system trajectory rather than just fixed points, and careful consideration of boundary conditions becomes essential. In this work, we present Generalized Lagrangian Equilibrium Propagation (GLEP), which extends the variational formulation of EP to time-varying inputs. We demonstrate that GLEP yields different learning algorithms depending on the boundary conditions of the system, many of which are impractical for implementation. We then show that Hamiltonian Echo Learning (HEL) -- which includes the recently proposed Recurrent HEL (RHEL) and the earlier known Hamiltonian Echo Backpropagation (HEB) algorithms -- can be derived as a special case of GLEP. Notably, HEL is the only instance of GLEP we found that inherits the properties that make EP a desirable alternative to backpropagation for hardware implementations: it operates in a \"forward-only\" manner (i.e. using the same system for both inference and learning), it scales efficiently (requiring only two or more passes through the system regardless of model size), and enables local learning.",
    "authors": [
      "Guillaume Pourcel, Debabrota Basu, Maxence Ernoult, Aditya Gilra"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.838590"
  },
  {
    "id": "oai:arXiv.org:2506.06251v1",
    "journal": "arXiv_CS",
    "title": "DesignBench: A Comprehensive Benchmark for MLLM-based Front-end Code Generation",
    "link": "https://arxiv.org/abs/2506.06251",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06251v1 Announce Type: new \nAbstract: Multimodal Large Language Models (MLLMs) have demonstrated remarkable capabilities in automated front-end engineering, e.g., generating UI code from visual designs. However, existing front-end UI code generation benchmarks have the following limitations: (1) While framework-based development becomes predominant in modern front-end programming, current benchmarks fail to incorporate mainstream development frameworks. (2) Existing evaluations focus solely on the UI code generation task, whereas practical UI development involves several iterations, including refining editing, and repairing issues. (3) Current benchmarks employ unidimensional evaluation, lacking investigation into influencing factors like task difficulty, input context variations, and in-depth code-level analysis. To bridge these gaps, we introduce DesignBench, a multi-framework, multi-task evaluation benchmark for assessing MLLMs' capabilities in automated front-end engineering. DesignBench encompasses three widely-used UI frameworks (React, Vue, and Angular) alongside vanilla HTML/CSS, and evaluates on three essential front-end tasks (generation, edit, and repair) in real-world development workflows. DesignBench contains 900 webpage samples spanning over 11 topics, 9 edit types, and 6 issue categories, enabling detailed analysis of MLLM performance across multiple dimensions. Our systematic evaluation reveals critical insights into MLLMs' framework-specific limitations, task-related bottlenecks, and performance variations under different conditions, providing guidance for future research in automated front-end development. Our code and data are available at https://github.com/WebPAI/DesignBench.",
    "authors": [
      "Jingyu Xiao, Ming Wang, Man Ho Lam, Yuxuan Wan, Junliang Liu, Yintong Huo, Michael R. Lyu"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.838599"
  },
  {
    "id": "oai:arXiv.org:2506.06253v1",
    "journal": "arXiv_CS",
    "title": "Bridging Perspectives: A Survey on Cross-view Collaborative Intelligence with Egocentric-Exocentric Vision",
    "link": "https://arxiv.org/abs/2506.06253",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06253v1 Announce Type: new \nAbstract: Perceiving the world from both egocentric (first-person) and exocentric (third-person) perspectives is fundamental to human cognition, enabling rich and complementary understanding of dynamic environments. In recent years, allowing the machines to leverage the synergistic potential of these dual perspectives has emerged as a compelling research direction in video understanding. In this survey, we provide a comprehensive review of video understanding from both exocentric and egocentric viewpoints. We begin by highlighting the practical applications of integrating egocentric and exocentric techniques, envisioning their potential collaboration across domains. We then identify key research tasks to realize these applications. Next, we systematically organize and review recent advancements into three main research directions: (1) leveraging egocentric data to enhance exocentric understanding, (2) utilizing exocentric data to improve egocentric analysis, and (3) joint learning frameworks that unify both perspectives. For each direction, we analyze a diverse set of tasks and relevant works. Additionally, we discuss benchmark datasets that support research in both perspectives, evaluating their scope, diversity, and applicability. Finally, we discuss limitations in current works and propose promising future research directions. By synthesizing insights from both perspectives, our goal is to inspire advancements in video understanding and artificial intelligence, bringing machines closer to perceiving the world in a human-like manner. A GitHub repo of related works can be found at https://github.com/ayiyayi/Awesome-Egocentric-and-Exocentric-Vision.",
    "authors": [
      "Yuping He, Yifei Huang, Guo Chen, Lidong Lu, Baoqi Pei, Jilan Xu, Tong Lu, Yoichi Sato"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.838608"
  },
  {
    "id": "oai:arXiv.org:2506.06254v1",
    "journal": "arXiv_CS",
    "title": "PersonaAgent: When Large Language Model Agents Meet Personalization at Test Time",
    "link": "https://arxiv.org/abs/2506.06254",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06254v1 Announce Type: new \nAbstract: Large Language Model (LLM) empowered agents have recently emerged as advanced paradigms that exhibit impressive capabilities in a wide range of domains and tasks. Despite their potential, current LLM agents often adopt a one-size-fits-all approach, lacking the flexibility to respond to users' varying needs and preferences. This limitation motivates us to develop PersonaAgent, the first personalized LLM agent framework designed to address versatile personalization tasks. Specifically, PersonaAgent integrates two complementary components - a personalized memory module that includes episodic and semantic memory mechanisms; a personalized action module that enables the agent to perform tool actions tailored to the user. At the core, the persona (defined as unique system prompt for each user) functions as an intermediary: it leverages insights from personalized memory to control agent actions, while the outcomes of these actions in turn refine the memory. Based on the framework, we propose a test-time user-preference alignment strategy that simulate the latest n interactions to optimize the persona prompt, ensuring real-time user preference alignment through textual loss feedback between simulated and ground-truth responses. Experimental evaluations demonstrate that PersonaAgent significantly outperforms other baseline methods by not only personalizing the action space effectively but also scaling during test-time real-world applications. These results underscore the feasibility and potential of our approach in delivering tailored, dynamic user experiences.",
    "authors": [
      "Weizhi Zhang, Xinyang Zhang, Chenwei Zhang, Liangwei Yang, Jingbo Shang, Zhepei Wei, Henry Peng Zou, Zijie Huang, Zhengyang Wang, Yifan Gao, Xiaoman Pan, Lian Xiong, Jingguo Liu, Philip S. Yu, Xian Li"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.838617"
  },
  {
    "id": "oai:arXiv.org:2506.06255v1",
    "journal": "arXiv_CS",
    "title": "From NLVO to NAO: Reactive Robot Navigation using Velocity and Acceleration Obstacles",
    "link": "https://arxiv.org/abs/2506.06255",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06255v1 Announce Type: new \nAbstract: This paper introduces a novel approach for robot navigation in challenging dynamic environments. The proposed method builds upon the concept of Velocity Obstacles (VO) that was later extended to Nonlinear Velocity Obstacles (NLVO) to account for obstacles moving along nonlinear trajectories. The NLVO is extended in this paper to Acceleration Obstacles (AO) and Nonlinear Acceleration Obstacles (NAO) that account for velocity and acceleration constraints. Multi-robot navigation is achieved by using the same avoidance algorithm by all robots. At each time step, the trajectories of all robots are predicted based on their current velocity and acceleration to allow the computation of their respective NLVO, AO and NAO.\n  The introduction of AO and NAO allows the generation of safe avoidance maneuvers that account for the robot dynamic constraints better than could be done with the NLVO alone. This paper demonstrates the use of AO and NAO for robot navigation in challenging environments. It is shown that using AO and NAO enables simultaneous real-time collision avoidance while accounting for robot kinematics and a direct consideration of its dynamic constraints. The presented approach enables reactive and efficient navigation, with potential application for autonomous vehicles operating in complex dynamic environments.",
    "authors": [
      "Asher Stern, Zvi Shiller"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.838626"
  },
  {
    "id": "oai:arXiv.org:2506.06256v1",
    "journal": "arXiv_CS",
    "title": "Quadratic Extended and Unscented Kalman Filter Updates",
    "link": "https://arxiv.org/abs/2506.06256",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06256v1 Announce Type: new \nAbstract: Common filters are usually based on the linear approximation of the optimal minimum mean square error estimator. The Extended and Unscented Kalman Filters handle nonlinearity through linearization and unscented transformation, respectively, but remain linear estimators, meaning that the state estimate is a linear function of the measurement. This paper proposes a quadratic approximation of the optimal estimator, creating the Quadratic Extended and Quadratic Unscented Kalman Filter. These retain the structure of their linear counterpart, but include information from the measurement square to obtain a more accurate estimate. Numerical results show the benefits in accuracy of the new technique, which can be generalized to upgrade other linear estimators to their quadratic versions.",
    "authors": [
      "Simone Servadio, Chiran Cherian"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.838634"
  },
  {
    "id": "oai:arXiv.org:2506.06261v1",
    "journal": "arXiv_CS",
    "title": "Reflect-then-Plan: Offline Model-Based Planning through a Doubly Bayesian Lens",
    "link": "https://arxiv.org/abs/2506.06261",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06261v1 Announce Type: new \nAbstract: Offline reinforcement learning (RL) is crucial when online exploration is costly or unsafe but often struggles with high epistemic uncertainty due to limited data. Existing methods rely on fixed conservative policies, restricting adaptivity and generalization. To address this, we propose Reflect-then-Plan (RefPlan), a novel doubly Bayesian offline model-based (MB) planning approach. RefPlan unifies uncertainty modeling and MB planning by recasting planning as Bayesian posterior estimation. At deployment, it updates a belief over environment dynamics using real-time observations, incorporating uncertainty into MB planning via marginalization. Empirical results on standard benchmarks show that RefPlan significantly improves the performance of conservative offline RL policies. In particular, RefPlan maintains robust performance under high epistemic uncertainty and limited data, while demonstrating resilience to changing environment dynamics, improving the flexibility, generalizability, and robustness of offline-learned policies.",
    "authors": [
      "Jihwan Jeong, Xiaoyu Wang, Jingmin Wang, Scott Sanner, Pascal Poupart"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.838643"
  },
  {
    "id": "oai:arXiv.org:2506.06262v1",
    "journal": "arXiv_CS",
    "title": "PyGemini: Unified Software Development towards Maritime Autonomy Systems",
    "link": "https://arxiv.org/abs/2506.06262",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06262v1 Announce Type: new \nAbstract: Ensuring the safety and certifiability of autonomous surface vessels (ASVs) requires robust decision-making systems, supported by extensive simulation, testing, and validation across a broad range of scenarios. However, the current landscape of maritime autonomy development is fragmented -- relying on disparate tools for communication, simulation, monitoring, and system integration -- which hampers interdisciplinary collaboration and inhibits the creation of compelling assurance cases, demanded by insurers and regulatory bodies. Furthermore, these disjointed tools often suffer from performance bottlenecks, vendor lock-in, and limited support for continuous integration workflows. To address these challenges, we introduce PyGemini, a permissively licensed, Python-native framework that builds on the legacy of Autoferry Gemini to unify maritime autonomy development. PyGemini introduces a novel Configuration-Driven Development (CDD) process that fuses Behavior-Driven Development (BDD), data-oriented design, and containerization to support modular, maintainable, and scalable software architectures. The framework functions as a stand-alone application, cloud-based service, or embedded library -- ensuring flexibility across research and operational contexts. We demonstrate its versatility through a suite of maritime tools -- including 3D content generation for simulation and monitoring, scenario generation for autonomy validation and training, and generative artificial intelligence pipelines for augmenting imagery -- thereby offering a scalable, maintainable, and performance-oriented foundation for future maritime robotics and autonomy research.",
    "authors": [
      "Kjetil Vasstein, Christian Le, Simon Lerv{\\aa}g Breivik, Trygve Maukon Myhr, Annette Stahl, Edmund F{\\o}rland Brekke"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.838652"
  },
  {
    "id": "oai:arXiv.org:2506.06266v1",
    "journal": "arXiv_CS",
    "title": "Cartridges: Lightweight and general-purpose long context representations via self-study",
    "link": "https://arxiv.org/abs/2506.06266",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06266v1 Announce Type: new \nAbstract: Large language models are often used to answer queries grounded in large text corpora (e.g. codebases, legal documents, or chat histories) by placing the entire corpus in the context window and leveraging in-context learning (ICL). Although current models support contexts of 100K-1M tokens, this setup is costly to serve because the memory consumption of the KV cache scales with input length. We explore an alternative: training a smaller KV cache offline on each corpus. At inference time, we load this trained KV cache, which we call a Cartridge, and decode a response. Critically, the cost of training a Cartridge can be amortized across all the queries referencing the same corpus. However, we find that the naive approach of training the Cartridge with next-token prediction on the corpus is not competitive with ICL. Instead, we propose self-study, a training recipe in which we generate synthetic conversations about the corpus and train the Cartridge with a context-distillation objective. We find that Cartridges trained with self-study replicate the functionality of ICL, while being significantly cheaper to serve. On challenging long-context benchmarks, Cartridges trained with self-study match ICL performance while using 38.6x less memory and enabling 26.4x higher throughput. Self-study also extends the model's effective context length (e.g. from 128k to 484k tokens on MTOB) and surprisingly, leads to Cartridges that can be composed at inference time without retraining.",
    "authors": [
      "Sabri Eyuboglu, Ryan Ehrlich, Simran Arora, Neel Guha, Dylan Zinsley, Emily Liu, Will Tennien, Atri Rudra, James Zou, Azalia Mirhoseini, Christopher Re"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.838660"
  },
  {
    "id": "oai:arXiv.org:2506.06270v1",
    "journal": "arXiv_CS",
    "title": "RecGPT: A Foundation Model for Sequential Recommendation",
    "link": "https://arxiv.org/abs/2506.06270",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06270v1 Announce Type: new \nAbstract: This work addresses a fundamental barrier in recommender systems: the inability to generalize across domains without extensive retraining. Traditional ID-based approaches fail entirely in cold-start and cross-domain scenarios where new users or items lack sufficient interaction history. Inspired by foundation models' cross-domain success, we develop a foundation model for sequential recommendation that achieves genuine zero-shot generalization capabilities. Our approach fundamentally departs from existing ID-based methods by deriving item representations exclusively from textual features. This enables immediate embedding of any new item without model retraining. We introduce unified item tokenization with Finite Scalar Quantization that transforms heterogeneous textual descriptions into standardized discrete tokens. This eliminates domain barriers that plague existing systems. Additionally, the framework features hybrid bidirectional-causal attention that captures both intra-item token coherence and inter-item sequential dependencies. An efficient catalog-aware beam search decoder enables real-time token-to-item mapping. Unlike conventional approaches confined to their training domains, RecGPT naturally bridges diverse recommendation contexts through its domain-invariant tokenization mechanism. Comprehensive evaluations across six datasets and industrial scenarios demonstrate consistent performance advantages.",
    "authors": [
      "Yangqin Jiang, Xubin Ren, Lianghao Xia, Da Luo, Kangyi Lin, Chao Huang"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.838669"
  },
  {
    "id": "oai:arXiv.org:2506.06271v1",
    "journal": "arXiv_CS",
    "title": "BecomingLit: Relightable Gaussian Avatars with Hybrid Neural Shading",
    "link": "https://arxiv.org/abs/2506.06271",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06271v1 Announce Type: new \nAbstract: We introduce BecomingLit, a novel method for reconstructing relightable, high-resolution head avatars that can be rendered from novel viewpoints at interactive rates. Therefore, we propose a new low-cost light stage capture setup, tailored specifically towards capturing faces. Using this setup, we collect a novel dataset consisting of diverse multi-view sequences of numerous subjects under varying illumination conditions and facial expressions. By leveraging our new dataset, we introduce a new relightable avatar representation based on 3D Gaussian primitives that we animate with a parametric head model and an expression-dependent dynamics module. We propose a new hybrid neural shading approach, combining a neural diffuse BRDF with an analytical specular term. Our method reconstructs disentangled materials from our dynamic light stage recordings and enables all-frequency relighting of our avatars with both point lights and environment maps. In addition, our avatars can easily be animated and controlled from monocular videos. We validate our approach in extensive experiments on our dataset, where we consistently outperform existing state-of-the-art methods in relighting and reenactment by a significant margin.",
    "authors": [
      "Jonathan Schmidt, Simon Giebenhain, Matthias Niessner"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.838677"
  },
  {
    "id": "oai:arXiv.org:2506.06275v1",
    "journal": "arXiv_CS",
    "title": "Movie Facts and Fibs (MF$^2$): A Benchmark for Long Movie Understanding",
    "link": "https://arxiv.org/abs/2506.06275",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06275v1 Announce Type: new \nAbstract: Despite recent progress in vision-language models (VLMs), holistic understanding of long-form video content remains a significant challenge, partly due to limitations in current benchmarks. Many focus on peripheral, ``needle-in-a-haystack'' details, encouraging context-insensitive retrieval over deep comprehension. Others rely on large-scale, semi-automatically generated questions (often produced by language models themselves) that are easier for models to answer but fail to reflect genuine understanding. In this paper, we introduce MF$^2$, a new benchmark for evaluating whether models can comprehend, consolidate, and recall key narrative information from full-length movies (50-170 minutes long). MF$^2$ includes over 50 full-length, open-licensed movies, each paired with manually constructed sets of claim pairs -- one true (fact) and one plausible but false (fib), totalling over 850 pairs. These claims target core narrative elements such as character motivations and emotions, causal chains, and event order, and refer to memorable moments that humans can recall without rewatching the movie. Instead of multiple-choice formats, we adopt a binary claim evaluation protocol: for each pair, models must correctly identify both the true and false claims. This reduces biases like answer ordering and enables a more precise assessment of reasoning. Our experiments demonstrate that both open-weight and closed state-of-the-art models fall well short of human performance, underscoring the relative ease of the task for humans and their superior ability to retain and reason over critical narrative information -- an ability current VLMs lack.",
    "authors": [
      "Emmanouil Zaranis, Ant\\'onio Farinhas, Saul Santos, Beatriz Canaverde, Miguel Moura Ramos, Aditya K Surikuchi, Andr\\'e Viveiros, Baohao Liao, Elena Bueno-Benito, Nithin Sivakumaran, Pavlo Vasylenko, Shoubin Yu, Sonal Sannigrahi, Wafaa Mohammed, Ben Peters, Danae S\\'anchez Villegas, Elias Stengel-Eskin, Giuseppe Attanasio, Jaehong Yoon, Stella Frank, Alessandro Suglia, Chrysoula Zerva, Desmond Elliott, Mariella Dimiccoli, Mohit Bansal, Oswald Lanz, Raffaella Bernardi, Raquel Fern\\'andez, Sandro Pezzelle, Vlad Niculae, Andr\\'e F. T. Martins"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.838693"
  },
  {
    "id": "oai:arXiv.org:2506.06276v1",
    "journal": "arXiv_CS",
    "title": "STARFlow: Scaling Latent Normalizing Flows for High-resolution Image Synthesis",
    "link": "https://arxiv.org/abs/2506.06276",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06276v1 Announce Type: new \nAbstract: We present STARFlow, a scalable generative model based on normalizing flows that achieves strong performance in high-resolution image synthesis. The core of STARFlow is Transformer Autoregressive Flow (TARFlow), which combines the expressive power of normalizing flows with the structured modeling capabilities of Autoregressive Transformers. We first establish the theoretical universality of TARFlow for modeling continuous distributions. Building on this foundation, we introduce several key architectural and algorithmic innovations to significantly enhance scalability: (1) a deep-shallow design, wherein a deep Transformer block captures most of the model representational capacity, complemented by a few shallow Transformer blocks that are computationally efficient yet substantially beneficial; (2) modeling in the latent space of pretrained autoencoders, which proves more effective than direct pixel-level modeling; and (3) a novel guidance algorithm that significantly boosts sample quality. Crucially, our model remains an end-to-end normalizing flow, enabling exact maximum likelihood training in continuous spaces without discretization. STARFlow achieves competitive performance in both class-conditional and text-conditional image generation tasks, approaching state-of-the-art diffusion models in sample quality. To our knowledge, this work is the first successful demonstration of normalizing flows operating effectively at this scale and resolution.",
    "authors": [
      "Jiatao Gu, Tianrong Chen, David Berthelot, Huangjie Zheng, Yuyang Wang, Ruixiang Zhang, Laurent Dinh, Miguel Angel Bautista, Josh Susskind, Shuangfei Zhai"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.838702"
  },
  {
    "id": "oai:arXiv.org:2506.06277v1",
    "journal": "arXiv_CS",
    "title": "ExAct: A Video-Language Benchmark for Expert Action Analysis",
    "link": "https://arxiv.org/abs/2506.06277",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06277v1 Announce Type: new \nAbstract: We present ExAct, a new video-language benchmark for expert-level understanding of skilled physical human activities. Our new benchmark contains 3521 expert-curated video question-answer pairs spanning 11 physical activities in 6 domains: Sports, Bike Repair, Cooking, Health, Music, and Dance. ExAct requires the correct answer to be selected from five carefully designed candidate options, thus necessitating a nuanced, fine-grained, expert-level understanding of physical human skills. Evaluating the recent state-of-the-art VLMs on ExAct reveals a substantial performance gap relative to human expert performance. Specifically, the best-performing GPT-4o model achieves only 44.70% accuracy, well below the 82.02% attained by trained human specialists/experts. We believe that ExAct will be beneficial for developing and evaluating VLMs capable of precise understanding of human skills in various physical and procedural domains. Dataset and code are available at https://texaser.github.io/exact_project_page/",
    "authors": [
      "Han Yi, Yulu Pan, Feihong He, Xinyu Liu, Benjamin Zhang, Oluwatumininu Oguntola, Gedas Bertasius"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.838711"
  },
  {
    "id": "oai:arXiv.org:2506.06278v1",
    "journal": "arXiv_CS",
    "title": "Distillation Robustifies Unlearning",
    "link": "https://arxiv.org/abs/2506.06278",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06278v1 Announce Type: new \nAbstract: Current LLM unlearning methods are not robust: they can be reverted easily with a few steps of finetuning. This is true even for the idealized unlearning method of training to imitate an oracle model that was never exposed to unwanted information, suggesting that output-based finetuning is insufficient to achieve robust unlearning. In a similar vein, we find that training a randomly initialized student to imitate an unlearned model transfers desired behaviors while leaving undesired capabilities behind. In other words, distillation robustifies unlearning. Building on this insight, we propose Unlearn-Noise-Distill-on-Outputs (UNDO), a scalable method that distills an unlearned model into a partially noised copy of itself. UNDO introduces a tunable tradeoff between compute cost and robustness, establishing a new Pareto frontier on synthetic language and arithmetic tasks. At its strongest setting, UNDO matches the robustness of a model retrained from scratch with perfect data filtering while using only 60-80% of the compute and requiring only 0.01% of the pretraining data to be labeled. We also show that UNDO robustifies unlearning on the more realistic Weapons of Mass Destruction Proxy (WMDP) benchmark. Since distillation is widely used in practice, incorporating an unlearning step beforehand offers a convenient path to robust capability removal.",
    "authors": [
      "Bruce W. Lee, Addie Foote, Alex Infanger, Leni Shor, Harish Kamath, Jacob Goldman-Wetzler, Bryce Woodworth, Alex Cloud, Alexander Matt Turner"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.838719"
  },
  {
    "id": "oai:arXiv.org:2506.06279v1",
    "journal": "arXiv_CS",
    "title": "CoMemo: LVLMs Need Image Context with Image Memory",
    "link": "https://arxiv.org/abs/2506.06279",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06279v1 Announce Type: new \nAbstract: Recent advancements in Large Vision-Language Models built upon Large Language Models have established aligning visual features with LLM representations as the dominant paradigm. However, inherited LLM architectural designs introduce suboptimal characteristics for multimodal processing. First, LVLMs exhibit a bimodal distribution in attention allocation, leading to the progressive neglect of middle visual content as context expands. Second, conventional positional encoding schemes fail to preserve vital 2D structural relationships when processing dynamic high-resolution images. To address these limitations, we propose CoMemo - a dual-path architecture that combines a Context image path with an image Memory path for visual processing, effectively alleviating visual information neglect. Additionally, we introduce RoPE-DHR, a novel positional encoding mechanism that employs thumbnail-based positional aggregation to maintain 2D spatial awareness while mitigating remote decay in extended sequences. Evaluations across seven benchmarks,including long-context comprehension, multi-image reasoning, and visual question answering, demonstrate CoMemo's superior performance compared to conventional LVLM architectures. Project page is available at https://lalbj.github.io/projects/CoMemo/.",
    "authors": [
      "Shi Liu, Weijie Su, Xizhou Zhu, Wenhai Wang, Jifeng Dai"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.838728"
  },
  {
    "id": "oai:arXiv.org:2506.06280v1",
    "journal": "arXiv_CS",
    "title": "Eigenspectrum Analysis of Neural Networks without Aspect Ratio Bias",
    "link": "https://arxiv.org/abs/2506.06280",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06280v1 Announce Type: new \nAbstract: Diagnosing deep neural networks (DNNs) through the eigenspectrum of weight matrices has been an active area of research in recent years. At a high level, eigenspectrum analysis of DNNs involves measuring the heavytailness of the empirical spectral densities (ESD) of weight matrices. It provides insight into how well a model is trained and can guide decisions on assigning better layer-wise training hyperparameters. In this paper, we address a challenge associated with such eigenspectrum methods: the impact of the aspect ratio of weight matrices on estimated heavytailness metrics. We demonstrate that matrices of varying sizes (and aspect ratios) introduce a non-negligible bias in estimating heavytailness metrics, leading to inaccurate model diagnosis and layer-wise hyperparameter assignment. To overcome this challenge, we propose FARMS (Fixed-Aspect-Ratio Matrix Subsampling), a method that normalizes the weight matrices by subsampling submatrices with a fixed aspect ratio. Instead of measuring the heavytailness of the original ESD, we measure the average ESD of these subsampled submatrices. We show that measuring the heavytailness of these submatrices with the fixed aspect ratio can effectively mitigate the aspect ratio bias. We validate our approach across various optimization techniques and application domains that involve eigenspectrum analysis of weights, including image classification in computer vision (CV) models, scientific machine learning (SciML) model training, and large language model (LLM) pruning. Our results show that despite its simplicity, FARMS uniformly improves the accuracy of eigenspectrum analysis while enabling more effective layer-wise hyperparameter assignment in these application domains. In one of the LLM pruning experiments, FARMS reduces the perplexity of the LLaMA-7B model by 17.3% when compared with the state-of-the-art method.",
    "authors": [
      "Yuanzhe Hu, Kinshuk Goel, Vlad Killiakov, Yaoqing Yang"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.838736"
  },
  {
    "id": "oai:arXiv.org:2506.06281v1",
    "journal": "arXiv_CS",
    "title": "TerraFM: A Scalable Foundation Model for Unified Multisensor Earth Observation",
    "link": "https://arxiv.org/abs/2506.06281",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06281v1 Announce Type: new \nAbstract: Modern Earth observation (EO) increasingly leverages deep learning to harness the scale and diversity of satellite imagery across sensors and regions. While recent foundation models have demonstrated promising generalization across EO tasks, many remain limited by the scale, geographical coverage, and spectral diversity of their training data, factors critical for learning globally transferable representations. In this work, we introduce TerraFM, a scalable self-supervised learning model that leverages globally distributed Sentinel-1 and Sentinel-2 imagery, combined with large spatial tiles and land-cover aware sampling to enrich spatial and semantic coverage. By treating sensing modalities as natural augmentations in our self-supervised approach, we unify radar and optical inputs via modality-specific patch embeddings and adaptive cross-attention fusion. Our training strategy integrates local-global contrastive learning and introduces a dual-centering mechanism that incorporates class-frequency-aware regularization to address long-tailed distributions in land cover.TerraFM achieves strong generalization on both classification and segmentation tasks, outperforming prior models on GEO-Bench and Copernicus-Bench. Our code and pretrained models are publicly available at: https://github.com/mbzuai-oryx/TerraFM .",
    "authors": [
      "Muhammad Sohail Danish, Muhammad Akhtar Munir, Syed Roshaan Ali Shah, Muhammad Haris Khan, Rao Muhammad Anwer, Jorma Laaksonen, Fahad Shahbaz Khan, Salman Khan"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.838745"
  },
  {
    "id": "oai:arXiv.org:2303.14005v1",
    "journal": "arXiv_CS",
    "title": "Category Query Learning for Human-Object Interaction Classification",
    "link": "https://arxiv.org/abs/2303.14005",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2303.14005v1 Announce Type: cross \nAbstract: Unlike most previous HOI methods that focus on learning better human-object features, we propose a novel and complementary approach called category query learning. Such queries are explicitly associated to interaction categories, converted to image specific category representation via a transformer decoder, and learnt via an auxiliary image-level classification task. This idea is motivated by an earlier multi-label image classification method, but is for the first time applied for the challenging human-object interaction classification task. Our method is simple, general and effective. It is validated on three representative HOI baselines and achieves new state-of-the-art results on two benchmarks.",
    "authors": [
      "Chi Xie, Fangao Zeng, Yue Hu, Shuang Liang, Yichen Wei"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.838754"
  },
  {
    "id": "oai:arXiv.org:2406.03674v2",
    "journal": "arXiv_CS",
    "title": "Learning Safe Strategies for Value Maximizing Buyers in Uniform Price Auctions",
    "link": "https://arxiv.org/abs/2406.03674",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2406.03674v2 Announce Type: cross \nAbstract: We study the bidding problem in repeated uniform price multi-unit auctions from the perspective of a single value-maximizing buyer who aims to maximize their cumulative value over $T$ rounds while adhering to return-on-investment (RoI) constraints in each round. Buyers adopt $m$-uniform bidding format, where they submit $m$ bid-quantity pairs $(b_i, q_i)$ to demand $q_i$ units at bid $b_i$. We introduce safe bidding strategies as those that satisfy RoI constraints in every auction, regardless of competing bids. We show that these strategies depend only on the valuation curve of the bidder, and the bidder can focus on a finite subset of this class without loss of generality. While the number of strategies in this subset is exponential in $m$, we develop a polynomial-time algorithm to learn the optimal safe strategy that achieves sublinear regret in the online setting, where regret is measured against a clairvoyant benchmark that knows the competing bids a priori and selects a fixed hindsight optimal safe strategy. We then evaluate the performance of safe strategies against a clairvoyant that selects the optimal strategy from a richer class of strategies in the online setting. In this scenario, we compute the richness ratio, $\\alpha\\in(0, 1]$ for the class of strategies chosen by the clairvoyant and show that our algorithm, designed to learn safe strategies, achieves $\\alpha$-approximate sublinear regret against these stronger benchmarks. Experiments on semi-synthetic data from real-world auctions show that safe strategies substantially outperform the derived theoretical bounds, making them quite appealing in practice.",
    "authors": [
      "Negin Golrezaei, Sourav Sahoo"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.838762"
  },
  {
    "id": "oai:arXiv.org:2506.02619v1",
    "journal": "arXiv_CS",
    "title": "HGOT: Self-supervised Heterogeneous Graph Neural Network with Optimal Transport",
    "link": "https://arxiv.org/abs/2506.02619",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.02619v1 Announce Type: cross \nAbstract: Heterogeneous Graph Neural Networks (HGNNs), have demonstrated excellent capabilities in processing heterogeneous information networks. Self-supervised learning on heterogeneous graphs, especially contrastive self-supervised strategy, shows great potential when there are no labels. However, this approach requires the use of carefully designed graph augmentation strategies and the selection of positive and negative samples. Determining the exact level of similarity between sample pairs is non-trivial.To solve this problem, we propose a novel self-supervised Heterogeneous graph neural network with Optimal Transport (HGOT) method which is designed to facilitate self-supervised learning for heterogeneous graphs without graph augmentation strategies. Different from traditional contrastive self-supervised learning, HGOT employs the optimal transport mechanism to relieve the laborious sampling process of positive and negative samples. Specifically, we design an aggregating view (central view) to integrate the semantic information contained in the views represented by different meta-paths (branch views). Then, we introduce an optimal transport plan to identify the transport relationship between the semantics contained in the branch view and the central view. This allows the optimal transport plan between graphs to align with the representations, forcing the encoder to learn node representations that are more similar to the graph space and of higher quality. Extensive experiments on four real-world datasets demonstrate that our proposed HGOT model can achieve state-of-the-art performance on various downstream tasks. In particular, in the node classification task, HGOT achieves an average of more than 6% improvement in accuracy compared with state-of-the-art methods.",
    "authors": [
      "Yanbei Liu, Chongxu Wang, Zhitao Xiao, Lei Geng, Yanwei Pang, Xiao Wang"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.838771"
  },
  {
    "id": "oai:arXiv.org:2506.04665v1",
    "journal": "arXiv_CS",
    "title": "An O(log log n)-approximate budget feasible mechanism for subadditive valuations",
    "link": "https://arxiv.org/abs/2506.04665",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.04665v1 Announce Type: cross \nAbstract: In budget-feasible mechanism design, there is a set of items $U$, each owned by a distinct seller. The seller of item $e$ incurs a private cost $\\overline{c}_e$ for supplying her item. A buyer wishes to procure a set of items from the sellers of maximum value, where the value of a set $S\\subseteq U$ of items is given by a valuation function $v:2^U\\to \\mathbb{R}_+$. The buyer has a budget of $B \\in \\mathbb{R}_+$ for the total payments made to the sellers. We wish to design a mechanism that is truthful, that is, sellers are incentivized to report their true costs, budget-feasible, that is, the sum of the payments made to the sellers is at most the budget $B$, and that outputs a set whose value is large compared to $\\text{OPT}:=\\max\\{v(S):\\overline{c}(S)\\le B,S\\subseteq U\\}$.\n  Budget-feasible mechanism design has been extensively studied, with the literature focussing on (classes of) subadditive valuation functions, and various polytime, budget-feasible mechanisms, achieving constant-factor approximation, have been devised for the special cases of additive, submodular, and XOS valuations. However, for general subadditive valuations, the best-known approximation factor achievable by a polytime budget-feasible mechanism (given access to demand oracles) was only $O(\\log n / \\log \\log n)$, where $n$ is the number of items.\n  We improve this state-of-the-art significantly by designing a budget-feasible mechanism for subadditive valuations that \\emph{achieves a substantially-improved approximation factor of $O(\\log\\log n)$ and runs in polynomial time, given access to demand oracles.}",
    "authors": [
      "Rian Neogi, Kanstantsin Pashkovich, Chaitanya Swamy"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.838780"
  },
  {
    "id": "oai:arXiv.org:2506.05354v1",
    "journal": "arXiv_CS",
    "title": "Adaptive stable distribution and Hurst exponent by method of moments moving estimator for nonstationary time series",
    "link": "https://arxiv.org/abs/2506.05354",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05354v1 Announce Type: cross \nAbstract: Nonstationarity of real-life time series requires model adaptation. In classical approaches like ARMA-ARCH there is assumed some arbitrarily chosen dependence type. To avoid their bias, we will focus on novel more agnostic approach: moving estimator, which estimates parameters separately for every time $t$: optimizing $F_t=\\sum_{\\tau<t} (1-\\eta)^{t-\\tau} \\ln(\\rho_\\theta (x_\\tau))$ local log-likelihood with exponentially weakening weights of the old values. In practice such moving estimates can be found by EMA (exponential moving average) of some parameters, like $m_p=E[|x-\\mu|^p]$ absolute central moments, updated by $m_{p,t+1} = m_{p,t} + \\eta (|x_t-\\mu_t|^p-m_{p,t})$. We will focus here on its applications for alpha-Stable distribution, which also influences Hurst exponent, hence can be used for its adaptive estimation. Its application will be shown on financial data as DJIA time series - beside standard estimation of evolution of center $\\mu$ and scale parameter $\\sigma$, there is also estimated evolution of $\\alpha$ parameter allowing to continuously evaluate market stability - tails having $\\rho(x) \\sim 1/|x|^{\\alpha+1}$ behavior, controlling probability of potentially dangerous extreme events.",
    "authors": [
      "Jarek Duda"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.838797"
  },
  {
    "id": "oai:arXiv.org:2506.05359v1",
    "journal": "arXiv_CS",
    "title": "Enhancing Meme Token Market Transparency: A Multi-Dimensional Entity-Linked Address Analysis for Liquidity Risk Evaluation",
    "link": "https://arxiv.org/abs/2506.05359",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05359v1 Announce Type: cross \nAbstract: Meme tokens represent a distinctive asset class within the cryptocurrency ecosystem, characterized by high community engagement, significant market volatility, and heightened vulnerability to market manipulation. This paper introduces an innovative approach to assessing liquidity risk in meme token markets using entity-linked address identification techniques. We propose a multi-dimensional method integrating fund flow analysis, behavioral similarity, and anomalous transaction detection to identify related addresses. We develop a comprehensive set of liquidity risk indicators tailored for meme tokens, covering token distribution, trading activity, and liquidity metrics. Empirical analysis of tokens like BabyBonk, NMT, and BonkFork validates our approach, revealing significant disparities between apparent and actual liquidity in meme token markets. The findings of this study provide significant empirical evidence for market participants and regulatory authorities, laying a theoretical foundation for building a more transparent and robust meme token ecosystem.",
    "authors": [
      "Qiangqiang Liu, Qian Huang, Frank Fan, Haishan Wu, Xueyan Tang"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.838806"
  },
  {
    "id": "oai:arXiv.org:2506.05391v1",
    "journal": "arXiv_CS",
    "title": "Enhancing Neural Autoregressive Distribution Estimators for Image Reconstruction",
    "link": "https://arxiv.org/abs/2506.05391",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05391v1 Announce Type: cross \nAbstract: Autoregressive models are often employed to learn distributions of image data by decomposing the $D$-dimensional density function into a product of one-dimensional conditional distributions. Each conditional depends on preceding variables (pixels, in the case of image data), making the order in which variables are processed fundamental to the model performance. In this paper, we study the problem of observing a small subset of image pixels (referred to as a pixel patch) to predict the unobserved parts of the image. As our prediction mechanism, we propose a generalized and computationally efficient version of the convolutional neural autoregressive distribution estimator (ConvNADE) model adapted for real-valued and color images. Moreover, we investigate the quality of image reconstruction when observing both random pixel patches and low-discrepancy pixel patches inspired by quasi-Monte Carlo theory. Experiments on benchmark datasets demonstrate that choosing the pixels akin to a low-discrepancy sequence reduces test loss and produces more realistic reconstructed images.",
    "authors": [
      "Ambrose Emmett-Iwaniw, Nathan Kirk"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.838815"
  },
  {
    "id": "oai:arXiv.org:2506.05441v1",
    "journal": "arXiv_CS",
    "title": "Deep histological synthesis from mass spectrometry imaging for multimodal registration",
    "link": "https://arxiv.org/abs/2506.05441",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05441v1 Announce Type: cross \nAbstract: Registration of histological and mass spectrometry imaging (MSI) allows for more precise identification of structural changes and chemical interactions in tissue. With histology and MSI having entirely different image formation processes and dimensionalities, registration of the two modalities remains an ongoing challenge. This work proposes a solution that synthesises histological images from MSI, using a pix2pix model, to effectively enable unimodal registration. Preliminary results show promising synthetic histology images with limited artifacts, achieving increases in mutual information (MI) and structural similarity index measures (SSIM) of +0.924 and +0.419, respectively, compared to a baseline U-Net model. Our source code is available on GitHub: https://github.com/kimberley/MIUA2025.",
    "authors": [
      "Kimberley M. Bird, Xujiong Ye, Alan M. Race, James M. Brown"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.838823"
  },
  {
    "id": "oai:arXiv.org:2506.05544v1",
    "journal": "arXiv_CS",
    "title": "Online Conformal Model Selection for Nonstationary Time Series",
    "link": "https://arxiv.org/abs/2506.05544",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05544v1 Announce Type: cross \nAbstract: This paper introduces the MPS (Model Prediction Set), a novel framework for online model selection for nonstationary time series. Classical model selection methods, such as information criteria and cross-validation, rely heavily on the stationarity assumption and often fail in dynamic environments which undergo gradual or abrupt changes over time. Yet real-world data are rarely stationary, and model selection under nonstationarity remains a largely open problem. To tackle this challenge, we combine conformal inference with model confidence sets to develop a procedure that adaptively selects models best suited to the evolving dynamics at any given time. Concretely, the MPS updates in real time a confidence set of candidate models that covers the best model for the next time period with a specified long-run probability, while adapting to nonstationarity of unknown forms. Through simulations and real-world data analysis, we demonstrate that MPS reliably and efficiently identifies optimal models under nonstationarity, an essential capability lacking in offline methods. Moreover, MPS frequently produces high-quality sets with small cardinality, whose evolution offers deeper insights into changing dynamics. As a generic framework, MPS accommodates any data-generating process, data structure, model class, training method, and evaluation metric, making it broadly applicable across diverse problem settings.",
    "authors": [
      "Shibo Li, Yao Zheng"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.838832"
  },
  {
    "id": "oai:arXiv.org:2506.05556v1",
    "journal": "arXiv_CS",
    "title": "DART-Vetter: A Deep LeARning Tool for automatic triage of exoplanet candidates",
    "link": "https://arxiv.org/abs/2506.05556",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05556v1 Announce Type: cross \nAbstract: In the identification of new planetary candidates in transit surveys, the employment of Deep Learning models proved to be essential to efficiently analyse a continuously growing volume of photometric observations. To further improve the robustness of these models, it is necessary to exploit the complementarity of data collected from different transit surveys such as NASA's Kepler, Transiting Exoplanet Survey Satellite (TESS), and, in the near future, the ESA PLAnetary Transits and Oscillation of stars (PLATO) mission. In this work, we present a Deep Learning model, named DART-Vetter, able to distinguish planetary candidates (PC) from false positives signals (NPC) detected by any potential transiting survey. DART-Vetter is a Convolutional Neural Network that processes only the light curves folded on the period of the relative signal, featuring a simpler and more compact architecture with respect to other triaging and/or vetting models available in the literature. We trained and tested DART-Vetter on several dataset of publicly available and homogeneously labelled TESS and Kepler light curves in order to prove the effectiveness of our model. Despite its simplicity, DART-Vetter achieves highly competitive triaging performance, with a recall rate of 91% on an ensemble of TESS and Kepler data, when compared to Exominer and Astronet-Triage. Its compact, open source and easy to replicate architecture makes DART-Vetter a particularly useful tool for automatizing triaging procedures or assisting human vetters, showing a discrete generalization on TCEs with Multiple Event Statistic (MES) > 20 and orbital period < 50 days.",
    "authors": [
      "Stefano Fiscale (UNESCO Chair \"Environment, Resources and Sustainable Development\", Department of Science and Technology, Parthenope University of Naples, Italy, Department of Science and Technology, Parthenope University of Naples, Centro Direzionale di Napoli, Naples, I-80143, Italy, INAF, Osservatorio Astronomico di Capodimonte, Salita Moiariello, 16, Naples, I-80131, Italy), Laura Inno (Department of Science and Technology, Parthenope University of Naples, Centro Direzionale di Napoli, Naples, I-80143, Italy, INAF, Osservatorio Astronomico di Capodimonte, Salita Moiariello, 16, Naples, I-80131, Italy), Alessandra Rotundi (UNESCO Chair \"Environment, Resources and Sustainable Development\", Department of Science and Technology, Parthenope University of Naples, Italy, Department of Science and Technology, Parthenope University of Naples, Centro Direzionale di Napoli, Naples, I-80143, Italy), Angelo Ciaramella (Department of Science and Technology, Parthenope University of Naples, Centro Direzionale di Napoli, Naples, I-80143, Italy), Alessio Ferone (Department of Science and Technology, Parthenope University of Naples, Centro Direzionale di Napoli, Naples, I-80143, Italy), Christian Magliano (INAF, Osservatorio Astronomico di Capodimonte, Salita Moiariello, 16, Naples, I-80131, Italy, Department of Physics \"Ettore Pancini\", University of Naples Federico II, Naples, Italy), Luca Cacciapuoti (European Southern Observatory, Karl-Schwarzschild-Strasse 2 D-85748 Garching bei Munchen, Germany), Veselin Kostov (NASA Goddard Space Flight Center, 8800 Greenbelt Road, Greenbelt, MD 20771, USA, Citizen Scientist, Planet Patrol Collaboration, Greenbelt, MD, 20771, USA), Elisa Quintana (NASA Goddard Space Flight Center, 8800 Greenbelt Road, Greenbelt, MD 20771, USA), Giovanni Covone (INAF, Osservatorio Astronomico di Capodimonte, Salita Moiariello, 16, Naples, I-80131, Italy, Department of Physics \"Ettore Pancini\", University of Naples Federico II, Naples, Italy, INFN section of Naples, Via Cinthia 6, 80126, Napoli, Italy), Maria Teresa Muscari Tomajoli (UNESCO Chair \"Environment, Resources and Sustainable Development\", Department of Science and Technology, Parthenope University of Naples, Italy, Department of Science and Technology, Parthenope University of Naples, Centro Direzionale di Napoli, Naples, I-80143, Italy), Vito Saggese (Department of Physics \"Ettore Pancini\", University of Naples Federico II, Naples, Italy), Luca Tonietti (UNESCO Chair \"Environment, Resources and Sustainable Development\", Department of Science and Technology, Parthenope University of Naples, Italy, Department of Science and Technology, Parthenope University of Naples, Centro Direzionale di Napoli, Naples, I-80143, Italy, INAF, Osservatorio Astronomico di Capodimonte, Salita Moiariello, 16, Naples, I-80131, Italy, Department of Biology, Federico II University of Naples, Naples, Italy), Antonio Vanzanella (National centre for Nuclear Research, Pasteura 7, 02-093, Warsaw, Poland), Vincenzo Della Corte (INAF, Osservatorio Astronomico di Capodimonte, Salita Moiariello, 16, Naples, I-80131, Italy)"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.838841"
  },
  {
    "id": "oai:arXiv.org:2506.05567v1",
    "journal": "arXiv_CS",
    "title": "Partially-Supervised Neural Network Model For Quadratic Multiparametric Programming",
    "link": "https://arxiv.org/abs/2506.05567",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05567v1 Announce Type: cross \nAbstract: Neural Networks (NN) with ReLU activation functions are used to model multiparametric quadratic optimization problems (mp-QP) in diverse engineering applications. Researchers have suggested leveraging the piecewise affine property of deep NN models to solve mp-QP with linear constraints, which also exhibit piecewise affine behaviour. However, traditional deep NN applications to mp-QP fall short of providing optimal and feasible predictions, even when trained on large datasets. This study proposes a partially-supervised NN (PSNN) architecture that directly represents the mathematical structure of the global solution function. In contrast to generic NN training approaches, the proposed PSNN method derives a large proportion of model weights directly from the mathematical properties of the optimization problem, producing more accurate solutions despite significantly smaller training data sets. Many energy management problems are formulated as QP, so we apply the proposed approach to energy systems (specifically DC optimal power flow) to demonstrate proof of concept. Model performance in terms of solution accuracy and speed of predictions was compared against a commercial solver and a generic Deep NN model based on classical training. Results show KKT sufficient conditions for PSNN consistently outperform generic NN architectures with classical training using far less data, including when tested on extreme, out-of-training distribution test data. Given its speed advantages over traditional solvers, the PSNN model can quickly produce optimal and feasible solutions within a second for millions of input parameters sampled from a distribution of stochastic demands and renewable generator dispatches, which can be used for simulations and long term planning.",
    "authors": [
      "Fuat Can Beylunioglu, Mehrdad Pirnia, P. Robert Duimering"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.838850"
  },
  {
    "id": "oai:arXiv.org:2506.05590v1",
    "journal": "arXiv_CS",
    "title": "Nonlinear Causal Discovery through a Sequential Edge Orientation Approach",
    "link": "https://arxiv.org/abs/2506.05590",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05590v1 Announce Type: cross \nAbstract: Recent advances have established the identifiability of a directed acyclic graph (DAG) under additive noise models (ANMs), spurring the development of various causal discovery methods. However, most existing methods make restrictive model assumptions, rely heavily on general independence tests, or require substantial computational time. To address these limitations, we propose a sequential procedure to orient undirected edges in a completed partial DAG (CPDAG), representing an equivalence class of DAGs, by leveraging the pairwise additive noise model (PANM) to identify their causal directions. We prove that this procedure can recover the true causal DAG assuming a restricted ANM. Building on this result, we develop a novel constraint-based algorithm for learning causal DAGs under nonlinear ANMs. Given an estimated CPDAG, we develop a ranking procedure that sorts undirected edges by their adherence to the PANM, which defines an evaluation order of the edges. To determine the edge direction, we devise a statistical test that compares the log-likelihood values, evaluated with respect to the competing directions, of a sub-graph comprising just the candidate nodes and their identified parents in the partial DAG. We further establish the structural learning consistency of our algorithm in the large-sample limit. Extensive experiments on synthetic and real-world datasets demonstrate that our method is computationally efficient, robust to model misspecification, and consistently outperforms many existing nonlinear DAG learning methods.",
    "authors": [
      "Stella Huang, Qing Zhou"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.838859"
  },
  {
    "id": "oai:arXiv.org:2506.05758v1",
    "journal": "arXiv_CS",
    "title": "Mapping correlations and coherence: adjacency-based approach to data visualization and regularity discovery",
    "link": "https://arxiv.org/abs/2506.05758",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05758v1 Announce Type: cross \nAbstract: The development of science has been transforming man's view towards nature for centuries. Observing structures and patterns in an effective approach to discover regularities from data is a key step toward theory-building. With increasingly complex data being obtained, revealing regularities systematically has become a challenge. Correlation is a most commonly-used and effective approach to describe regularities in data, yet for complex patterns, spatial inhomogeneity and complexity can often undermine the correlations. We present an algorithm to derive maps representing the type and degree of correlations, by taking the two-fold symmetry of the correlation vector into full account using the Stokes parameter. The method allows for a spatially resolved view of the nature and strength of correlations between physical quantities. In the correlation view, a region can often be separated into different subregions with different types of correlations. Subregions correspond to physical regimes for physical systems, or climate zones for climate maps. The simplicity of the method makes it widely applicable to a variety of data, where the correlation-based approach makes the map particularly useful in revealing regularities in physical systems and alike. As a new and efficient approach to represent data, the method should facilitate the development of new computational approaches to regularity discovery.",
    "authors": [
      "Guang-Xing Li"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.838893"
  },
  {
    "id": "oai:arXiv.org:2506.05759v1",
    "journal": "arXiv_CS",
    "title": "Revealing hidden correlations from complex spatial distributions: Adjacent Correlation Analysis",
    "link": "https://arxiv.org/abs/2506.05759",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05759v1 Announce Type: cross \nAbstract: Physics has been transforming our view of nature for centuries. While combining physical knowledge with computational approaches has enabled detailed modeling of physical systems' evolution, understanding the emergence of patterns and structures remains limited. Correlations between quantities are the most reliable approach to describe relationships between different variables. However, for complex patterns, directly searching for correlations is often impractical, as complexity and spatial inhomogeneity can obscure correlations. We discovered that the key is to search for correlations in local regions and developed a new method, adjacent correlation analysis, to extract such correlations and represent them in phase space. When multiple observations are available, a useful way to study a system is to analyze distributions in phase space using the Probability Density Function (PDF). Adjacent correlation analysis evaluates vectors representing local correlations, which can be overlaid on the PDF plot to form the adjacent correlation plot. These correlation vectors often exhibit remarkably regular patterns and may lead to the discovery of new laws. The vectors we derive are equivalent to the vector field in dynamical systems on the attracting manifold. By efficiently representing spatial patterns as correlation vectors in phase space, our approach opens avenues for classification, prediction, parameter fitting, and forecasting.",
    "authors": [
      "Guang-Xing Li"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.838902"
  },
  {
    "id": "oai:arXiv.org:2506.05894v1",
    "journal": "arXiv_CS",
    "title": "Policy Optimization for Continuous-time Linear-Quadratic Graphon Mean Field Games",
    "link": "https://arxiv.org/abs/2506.05894",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05894v1 Announce Type: cross \nAbstract: Multi-agent reinforcement learning, despite its popularity and empirical success, faces significant scalability challenges in large-population dynamic games. Graphon mean field games (GMFGs) offer a principled framework for approximating such games while capturing heterogeneity among players. In this paper, we propose and analyze a policy optimization framework for continuous-time, finite-horizon linear-quadratic GMFGs. Exploiting the structural properties of GMFGs, we design an efficient policy parameterization in which each player's policy is represented as an affine function of their private state, with a shared slope function and player-specific intercepts. We develop a bilevel optimization algorithm that alternates between policy gradient updates for best-response computation under a fixed population distribution, and distribution updates using the resulting policies. We prove linear convergence of the policy gradient steps to best-response policies and establish global convergence of the overall algorithm to the Nash equilibrium. The analysis relies on novel landscape characterizations over infinite-dimensional policy spaces. Numerical experiments demonstrate the convergence and robustness of the proposed algorithm under varying graphon structures, noise levels, and action frequencies.",
    "authors": [
      "Philipp Plank, Yufei Zhang"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.838918"
  },
  {
    "id": "oai:arXiv.org:2506.05905v1",
    "journal": "arXiv_CS",
    "title": "Sequential Monte Carlo approximations of Wasserstein--Fisher--Rao gradient flows",
    "link": "https://arxiv.org/abs/2506.05905",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05905v1 Announce Type: cross \nAbstract: We consider the problem of sampling from a probability distribution $\\pi$. It is well known that this can be written as an optimisation problem over the space of probability distribution in which we aim to minimise the Kullback--Leibler divergence from $\\pi$. We consider several partial differential equations (PDEs) whose solution is a minimiser of the Kullback--Leibler divergence from $\\pi$ and connect them to well-known Monte Carlo algorithms. We focus in particular on PDEs obtained by considering the Wasserstein--Fisher--Rao geometry over the space of probabilities and show that these lead to a natural implementation using importance sampling and sequential Monte Carlo. We propose a novel algorithm to approximate the Wasserstein--Fisher--Rao flow of the Kullback--Leibler divergence which empirically outperforms the current state-of-the-art.\n  We study tempered versions of these PDEs obtained by replacing the target distribution with a geometric mixture of initial and target distribution and show that these do not lead to a convergence speed up.",
    "authors": [
      "Francesca R. Crucinio, Sahani Pathiraja"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.838927"
  },
  {
    "id": "oai:arXiv.org:2506.05955v1",
    "journal": "arXiv_CS",
    "title": "Dual Approach to Inverse Covariance Intersection Fusion",
    "link": "https://arxiv.org/abs/2506.05955",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05955v1 Announce Type: cross \nAbstract: Linear fusion of estimates under the condition of no knowledge of correlation of estimation errors has reached maturity. On the other hand, various cases of partial knowledge are still active research areas. A frequent motivation is to deal with \"common information\" or \"common noise\", whatever it means. A fusion rule for a strict meaning of the former expression has already been elaborated. Despite the dual relationship, a strict meaning of the latter one has not been considered so far. The paper focuses on this area. The assumption of unknown \"common noise\" is formulated first, analysis of theoretical properties and illustrations follow. Although the results are disappointing from the perspective of a single upper bound of mean square error matrices, the partial knowledge demonstrates improvement over no knowledge in suboptimal cases and from the perspective of families of upper bounds.",
    "authors": [
      "Ji\\v{r}\\'i Ajgl, Ond\\v{r}ej Straka"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.838935"
  },
  {
    "id": "oai:arXiv.org:2506.05984v1",
    "journal": "arXiv_CS",
    "title": "Audio-Aware Large Language Models as Judges for Speaking Styles",
    "link": "https://arxiv.org/abs/2506.05984",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05984v1 Announce Type: cross \nAbstract: Audio-aware large language models (ALLMs) can understand the textual and non-textual information in the audio input. In this paper, we explore using ALLMs as an automatic judge to assess the speaking styles of speeches. We use ALLM judges to evaluate the speeches generated by SLMs on two tasks: voice style instruction following and role-playing. The speaking style we consider includes emotion, volume, speaking pace, word emphasis, pitch control, and non-verbal elements. We use four spoken language models (SLMs) to complete the two tasks and use humans and ALLMs to judge the SLMs' responses. We compare two ALLM judges, GPT-4o-audio and Gemini-2.5-pro, with human evaluation results and show that the agreement between Gemini and human judges is comparable to the agreement between human evaluators. These promising results show that ALLMs can be used as a judge to evaluate SLMs. Our results also reveal that current SLMs, even GPT-4o-audio, still have room for improvement in controlling the speaking style and generating natural dialogues.",
    "authors": [
      "Cheng-Han Chiang, Xiaofei Wang, Chung-Ching Lin, Kevin Lin, Linjie Li, Radu Kopetz, Yao Qian, Zhendong Wang, Zhengyuan Yang, Hung-yi Lee, Lijuan Wang"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.838944"
  },
  {
    "id": "oai:arXiv.org:2506.06053v1",
    "journal": "arXiv_CS",
    "title": "Some remarks on stochastic converse Lyapunov theorems",
    "link": "https://arxiv.org/abs/2506.06053",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06053v1 Announce Type: cross \nAbstract: In this brief note, we investigate some constructions of Lyapunov functions for stochastic discrete-time stabilizable dynamical systems, in other words, controlled Markov chains. The main question here is whether a Lyapunov function in some statistical sense exists if the respective controlled Markov chain admits a stabilizing policy. We demonstrate some constructions extending on the classical results for deterministic systems. Some limitations of the constructed Lyapunov functions for stabilization are discussed, particularly for stabilization in mean. Although results for deterministic systems are well known, the stochastic case was addressed in less detail, which the current paper remarks on. A distinguishable feature of this work is the study of stabilizers that possess computationally tractable convergence certificates.",
    "authors": [
      "Pavel Osinenko, Grigory Yaremenko"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.838953"
  },
  {
    "id": "oai:arXiv.org:2506.06054v1",
    "journal": "arXiv_CS",
    "title": "FPDANet: A Multi-Section Classification Model for Intelligent Screening of Fetal Ultrasound",
    "link": "https://arxiv.org/abs/2506.06054",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06054v1 Announce Type: cross \nAbstract: ResNet has been widely used in image classification tasks due to its ability to model the residual dependence of constant mappings for linear computation. However, the ResNet method adopts a unidirectional transfer of features and lacks an effective method to correlate contextual information, which is not effective in classifying fetal ultrasound images in the classification task, and fetal ultrasound images have problems such as low contrast, high similarity, and high noise. Therefore, we propose a bilateral multi-scale information fusion network-based FPDANet to address the above challenges. Specifically, we design the positional attention mechanism (DAN) module, which utilizes the similarity of features to establish the dependency of different spatial positional features and enhance the feature representation. In addition, we design a bilateral multi-scale (FPAN) information fusion module to capture contextual and global feature dependencies at different feature scales, thereby further improving the model representation. FPDANet classification results obtained 91.05\\% and 100\\% in Top-1 and Top-5 metrics, respectively, and the experimental results proved the effectiveness and robustness of FPDANet.",
    "authors": [
      "Minglang Chen, Jie He, Caixu Xu, Bocheng Liang, Shengli Li, Guannan He, Xiongjie Tao"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.838961"
  },
  {
    "id": "oai:arXiv.org:2506.06087v1",
    "journal": "arXiv_CS",
    "title": "Multilevel neural simulation-based inference",
    "link": "https://arxiv.org/abs/2506.06087",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06087v1 Announce Type: cross \nAbstract: Neural simulation-based inference (SBI) is a popular set of methods for Bayesian inference when models are only available in the form of a simulator. These methods are widely used in the sciences and engineering, where writing down a likelihood can be significantly more challenging than constructing a simulator. However, the performance of neural SBI can suffer when simulators are computationally expensive, thereby limiting the number of simulations that can be performed. In this paper, we propose a novel approach to neural SBI which leverages multilevel Monte Carlo techniques for settings where several simulators of varying cost and fidelity are available. We demonstrate through both theoretical analysis and extensive experiments that our method can significantly enhance the accuracy of SBI methods given a fixed computational budget.",
    "authors": [
      "Yuga Hikida, Ayush Bharti, Niall Jeffrey, Fran\\c{c}ois-Xavier Briol"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.838977"
  },
  {
    "id": "oai:arXiv.org:2506.06092v1",
    "journal": "arXiv_CS",
    "title": "LinGuinE: Longitudinal Guidance Estimation for Volumetric Lung Tumour Segmentation",
    "link": "https://arxiv.org/abs/2506.06092",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06092v1 Announce Type: cross \nAbstract: Segmentation of lung gross tumour volumes is an important first step in radiotherapy and surgical intervention, and is starting to play a role in assessing chemotherapy response. Response to a drug is measured by tracking the tumour volumes over a series of CT scans over a time period i.e. a longitudinal study. However, there currently exist few solutions for automated or semi-automated longitudinal tumour segmentation. This paper introduces LinGuinE, an automated method to segment a longitudinal series of lung tumours. A radiologist must provide an initial input, indicating the location of the tumour in a CT scan at an arbitrary time point. LinGuinE samples points inside this tumour and propagates them to another time point using rigid registration. A click validity classifier selects points which still fall within the tumour; these are used to automatically create a segmentation in the new time point. We test LinGuinE on a dataset acquired from a phase 3 clinical trial for lung tumours and the publicly available 4-D lung CBCT dataset. We find that LinGuinE improves the Dice on both test sets by over 20% (p< 0.05) across 63 longitudinal studies. We show that any time point can be used as a starting point, conduct ablation experiments, and find that our LinGuinE setup yields the best results on both test datasets.",
    "authors": [
      "Nadine Garibli, Mayank Patwari, Bence Csiba, Yi Wei, Kostas Sidiropoulos"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.838986"
  },
  {
    "id": "oai:arXiv.org:2506.06125v1",
    "journal": "arXiv_CS",
    "title": "Convergence of linear programming hierarchies for Gibbs states of spin systems",
    "link": "https://arxiv.org/abs/2506.06125",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06125v1 Announce Type: cross \nAbstract: We consider the problem of computing expectation values of local functions under the Gibbs distribution of a spin system. In particular, we study two families of linear programming hierarchies for this problem. The first hierarchy imposes local spin flip equalities and has been considered in the bootstrap literature in high energy physics. For this hierarchy, we prove fast convergence under a spatial mixing (decay of correlations) condition. This condition is satisfied for example above the critical temperature for Ising models on a $d$-dimensional grid. The second hierarchy is based on a Markov chain having the Gibbs state as a fixed point and has been studied in the optimization literature and more recently in the bootstrap literature. For this hierarchy, we prove fast convergence provided the Markov chain mixes rapidly. Both hierarchies lead to an $\\varepsilon$-approximation for local expectation values using a linear program of size quasi-polynomial in $n/\\varepsilon$, where $n$ is the total number of sites, provided the interactions can be embedded in a $d$-dimensional grid with constant $d$. Compared to standard Monte Carlo methods, an advantage of this approach is that it always (i.e., for any system) outputs rigorous upper and lower bounds on the expectation value of interest, without needing an a priori analysis of the convergence speed.",
    "authors": [
      "Hamza Fawzi, Omar Fawzi"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.839004"
  },
  {
    "id": "oai:arXiv.org:2506.06259v1",
    "journal": "arXiv_CS",
    "title": "An Optimized Franz-Parisi Criterion and its Equivalence with SQ Lower Bounds",
    "link": "https://arxiv.org/abs/2506.06259",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.06259v1 Announce Type: cross \nAbstract: Bandeira et al. (2022) introduced the Franz-Parisi (FP) criterion for characterizing the computational hard phases in statistical detection problems. The FP criterion, based on an annealed version of the celebrated Franz-Parisi potential from statistical physics, was shown to be equivalent to low-degree polynomial (LDP) lower bounds for Gaussian additive models, thereby connecting two distinct approaches to understanding the computational hardness in statistical inference. In this paper, we propose a refined FP criterion that aims to better capture the geometric ``overlap\" structure of statistical models. Our main result establishes that this optimized FP criterion is equivalent to Statistical Query (SQ) lower bounds -- another foundational framework in computational complexity of statistical inference. Crucially, this equivalence holds under a mild, verifiable assumption satisfied by a broad class of statistical models, including Gaussian additive models, planted sparse models, as well as non-Gaussian component analysis (NGCA), single-index (SI) models, and convex truncation detection settings. For instance, in the case of convex truncation tasks, the assumption is equivalent with the Gaussian correlation inequality (Royen, 2014) from convex geometry.\n  In addition to the above, our equivalence not only unifies and simplifies the derivation of several known SQ lower bounds -- such as for the NGCA model (Diakonikolas et al., 2017) and the SI model (Damian et al., 2024) -- but also yields new SQ lower bounds of independent interest, including for the computational gaps in mixed sparse linear regression (Arpino et al., 2023) and convex truncation (De et al., 2023).",
    "authors": [
      "Siyu Chen, Theodor Misiakiewicz, Ilias Zadik, Peiyuan Zhang"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.839020"
  },
  {
    "id": "oai:arXiv.org:2205.06628v3",
    "journal": "arXiv_CS",
    "title": "Computing well-balanced spanning trees of unweighted networks",
    "link": "https://arxiv.org/abs/2205.06628",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2205.06628v3 Announce Type: replace \nAbstract: A spanning tree of a network or graph is a subgraph that connects all nodes with the least number or weight of edges. The spanning tree is one of the most straightforward techniques for network simplification and sampling, and for discovering its backbone or skeleton. Prim's algorithm and Kruskal's algorithm are well-known algorithms for computing a spanning tree of a weighted network, and are therefore also the default procedure for unweighted networks in the most popular network libraries. In this paper, we empirically study the performance of these algorithms on unweighted networks and compare them with different priority-first search algorithms. We show that the structure of a network, such as the distances between the nodes, is better preserved by a simpler algorithm based on breadth-first search. The spanning trees are also most compact and well-balanced as measured by classical graph indices. We support our findings with experiments on synthetic graphs and more than a thousand real networks, and demonstrate practical applications of the computed spanning trees. We conclude that if a spanning tree is to maintain the structure of an unweighted network, the breadth-first search algorithm should be the preferred choice, and it should be implemented as such in network libraries.",
    "authors": [
      "Lovro \\v{S}ubelj"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.839035"
  },
  {
    "id": "oai:arXiv.org:2210.00229v3",
    "journal": "arXiv_CS",
    "title": "On the stability analysis of perfectly matched layer for the elastic wave equation in layered media",
    "link": "https://arxiv.org/abs/2210.00229",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2210.00229v3 Announce Type: replace \nAbstract: In this paper, we present the stability analysis of the perfectly matched layer (PML) in two-space dimensional layered elastic media. Using normal mode analysis we prove that all interface wave modes present at a planar interface of bi-material elastic solids are dissipated by the PML. Our analysis builds upon the ideas presented in [SIAM Journal on Numerical Analysis 52 (2014) 2883-2904] and extends the stability results of boundary waves (such as Rayleigh waves) on a half-plane elastic solid to interface wave modes (such as Stoneley waves) transmitted into the PML at a planar interface separating two half-plane elastic solids. Numerical experiments in two-layer and multi-layer elastic solids corroborate the theoretical analysis, and generalise the results to complex elastic media. Numerical examples using the Marmousi model demonstrates the utility of the PML and our numerical method for seismological applications.",
    "authors": [
      "Kenneth Duru, Balaje Kalyanaraman, Siyang Wang"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.839045"
  },
  {
    "id": "oai:arXiv.org:2301.04612v2",
    "journal": "arXiv_CS",
    "title": "Self-Supervised Generative-Contrastive Learning of Multi-Modal Euclidean Input for 3D Shape Latent Representations: A Dynamic Switching Approach",
    "link": "https://arxiv.org/abs/2301.04612",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2301.04612v2 Announce Type: replace \nAbstract: We propose a combined generative and contrastive neural architecture for learning latent representations of 3D volumetric shapes. The architecture uses two encoder branches for voxel grids and multi-view images from the same underlying shape. The main idea is to combine a contrastive loss between the resulting latent representations with an additional reconstruction loss. That helps to avoid collapsing the latent representations as a trivial solution for minimizing the contrastive loss. A novel dynamic switching approach is used to cross-train two encoders with a shared decoder. The switching approach also enables the stop gradient operation on a random branch. Further classification experiments show that the latent representations learned with our self-supervised method integrate more useful information from the additional input data implicitly, thus leading to better reconstruction and classification performance.",
    "authors": [
      "Chengzhi Wu, Julius Pfrommer, Mingyuan Zhou, J\\\"urgen Beyerer"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.839055"
  },
  {
    "id": "oai:arXiv.org:2301.08789v3",
    "journal": "arXiv_CS",
    "title": "Active Learning of Piecewise Gaussian Process Surrogates",
    "link": "https://arxiv.org/abs/2301.08789",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2301.08789v3 Announce Type: replace \nAbstract: Active learning of Gaussian process (GP) surrogates has been useful for optimizing experimental designs for physical/computer simulation experiments, and for steering data acquisition schemes in machine learning. In this paper, we develop a method for active learning of piecewise, Jump GP surrogates. Jump GPs are continuous within, but discontinuous across, regions of a design space, as required for applications spanning autonomous materials design, configuration of smart factory systems, and many others. Although our active learning heuristics are appropriated from strategies originally designed for ordinary GPs, we demonstrate that additionally accounting for model bias, as opposed to the usual model uncertainty, is essential in the Jump GP context. Toward that end, we develop an estimator for bias and variance of Jump GP models. Illustrations, and evidence of the advantage of our proposed methods, are provided on a suite of synthetic benchmarks, and real-simulation experiments of varying complexity.",
    "authors": [
      "Chiwoo Park, Robert Waelder, Bonggwon Kang, Benji Maruyama, Soondo Hong, Robert Gramacy"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.839063"
  },
  {
    "id": "oai:arXiv.org:2302.09913v4",
    "journal": "arXiv_CS",
    "title": "ByzSecAgg: A Byzantine-Resistant Secure Aggregation Scheme for Federated Learning Based on Coded Computing and Vector Commitment",
    "link": "https://arxiv.org/abs/2302.09913",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2302.09913v4 Announce Type: replace \nAbstract: In this paper, we propose ByzSecAgg, an efficient secure aggregation scheme for federated learning that is resistant to Byzantine attacks and privacy leakages. Processing individual updates to manage adversarial behavior, while preserving the privacy of the data against colluding nodes, requires some sort of secure secret sharing. However, the communication load for secret sharing of long vectors of updates can be very high. In federated settings, where users are often edge devices with potential bandwidth constraints, excessive communication overhead is undesirable. ByzSecAgg solves this problem by partitioning local updates into smaller sub-vectors and sharing them using ramp secret sharing. However, this sharing method does not admit bilinear computations, such as pairwise distances calculations, which are needed for distance-based outlier-detection algorithms, and effective methods for mitigating Byzantine attacks. To overcome this issue, each user runs another round of ramp sharing, with a different embedding of the data in the sharing polynomial. This technique, motivated by ideas from coded computing, enables secure computation of pairwise distance. In addition, to maintain the integrity and privacy of the local update, ByzSecAgg also uses a vector commitment method, in which the commitment size remains constant (i.e., does not increase with the length of the local update), while simultaneously allowing verification of the secret sharing process. In terms of communication load, ByzSecAgg significantly outperforms the related baseline scheme, known as BREA.",
    "authors": [
      "Tayyebeh Jahani-Nezhad, Mohammad Ali Maddah-Ali, Giuseppe Caire"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.839082"
  },
  {
    "id": "oai:arXiv.org:2305.16800v2",
    "journal": "arXiv_CS",
    "title": "Joint Optimization of Triangle Mesh, Material, and Light from Neural Fields with Neural Radiance Cache",
    "link": "https://arxiv.org/abs/2305.16800",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2305.16800v2 Announce Type: replace \nAbstract: Traditional inverse rendering techniques are based on textured meshes, which naturally adapts to modern graphics pipelines, but costly differentiable multi-bounce Monte Carlo (MC) ray tracing poses challenges for modeling global illumination. Recently, neural fields has demonstrated impressive reconstruction quality but falls short in modeling indirect illumination. In this paper, we introduce a simple yet efficient inverse rendering framework that combines the strengths of both methods. Specifically, given pre-trained neural field representing the scene, we can obtain an initial estimate of the signed distance field (SDF) and create a Neural Radiance Cache (NRC), an enhancement over the traditional radiance cache used in real-time rendering. By using the former to initialize differentiable marching tetrahedrons (DMTet) and the latter to model indirect illumination, we can compute the global illumination via single-bounce differentiable MC ray tracing and jointly optimize the geometry, material, and light through back propagation. Experiments demonstrate that, compared to previous methods, our approach effectively prevents indirect illumination effects from being baked into materials, thus obtaining the high-quality reconstruction of triangle mesh, Physically-Based (PBR) materials, and High Dynamic Range (HDR) light probe.",
    "authors": [
      "Jiakai Sun, Weijing Zhang, Zhanjie Zhang, Tianyi Chu, Guangyuan Li, Lei Zhao, Wei Xing"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.839091"
  },
  {
    "id": "oai:arXiv.org:2306.02194v3",
    "journal": "arXiv_CS",
    "title": "PathFinder: A unified approach for handling paths in graph query languages",
    "link": "https://arxiv.org/abs/2306.02194",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2306.02194v3 Announce Type: replace \nAbstract: Path queries are a core feature of modern graph query languages such as Cypher, SQL/PGQ, and GQL. These languages provide a rich set of features for matching paths, such as restricting to certain path modes (shortest, simple, trail) and constraining the edge labels along the path by a regular expression. In this paper we present PathFinder, a unifying approach for dealing with path queries in all these query languages. PathFinder leverages a compact representation of the (potentially exponential number of) paths that can match a given query, extends it with pipelined execution, and supports all commonly used path modes. In the paper we describe the algorithmic backbone of PathFinder, provide a reference implementation, and test it over a large set of real-world queries and datasets. Our results show that PathFinder exhibits very stable behavior, even on large data and complex queries, and its performance is an order of magnitude better than that of many modern graph engines.",
    "authors": [
      "Benjam\\'in Far\\'ias, Wim Martens, Carlos Rojas, Domagoj Vrgo\\v{c}"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.839100"
  },
  {
    "id": "oai:arXiv.org:2306.13926v3",
    "journal": "arXiv_CS",
    "title": "Quantifying the Optimization and Generalization Advantages of Graph Neural Networks Over Multilayer Perceptrons",
    "link": "https://arxiv.org/abs/2306.13926",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2306.13926v3 Announce Type: replace \nAbstract: Graph neural networks (GNNs) have demonstrated remarkable capabilities in learning from graph-structured data, often outperforming traditional Multilayer Perceptrons (MLPs) in numerous graph-based tasks. Although existing works have demonstrated the benefits of graph convolution through Laplacian smoothing, expressivity or separability, there remains a lack of quantitative analysis comparing GNNs and MLPs from an optimization and generalization perspective. This study aims to address this gap by examining the role of graph convolution through feature learning theory. Using a signal-noise data model, we conduct a comparative analysis of the optimization and generalization between two-layer graph convolutional networks (GCNs) and their MLP counterparts. Our approach tracks the trajectory of signal learning and noise memorization in GNNs, characterizing their post-training generalization. We reveal that GNNs significantly prioritize signal learning, thus enhancing the regime of {low test error} over MLPs by $D^{q-2}$ times, where $D$ denotes a node's expected degree and $q$ is the power of ReLU activation function with $q>2$. This finding highlights a substantial and quantitative discrepancy between GNNs and MLPs in terms of optimization and generalization, a conclusion further supported by our empirical simulations on both synthetic and real-world datasets.",
    "authors": [
      "Wei Huang, Yuan Cao, Haonan Wang, Xin Cao, Taiji Suzuki"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.839110"
  },
  {
    "id": "oai:arXiv.org:2307.04726v4",
    "journal": "arXiv_CS",
    "title": "Diffusion Policies for Out-of-Distribution Generalization in Offline Reinforcement Learning",
    "link": "https://arxiv.org/abs/2307.04726",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2307.04726v4 Announce Type: replace \nAbstract: Offline Reinforcement Learning (RL) methods leverage previous experiences to learn better policies than the behavior policy used for data collection. However, they face challenges handling distribution shifts due to the lack of online interaction during training. To this end, we propose a novel method named State Reconstruction for Diffusion Policies (SRDP) that incorporates state reconstruction feature learning in the recent class of diffusion policies to address the problem of out-of-distribution (OOD) generalization. Our method promotes learning of generalizable state representation to alleviate the distribution shift caused by OOD states. To illustrate the OOD generalization and faster convergence of SRDP, we design a novel 2D Multimodal Contextual Bandit environment and realize it on a 6-DoF real-world UR10 robot, as well as in simulation, and compare its performance with prior algorithms. In particular, we show the importance of the proposed state reconstruction via ablation studies. In addition, we assess the performance of our model on standard continuous control benchmarks (D4RL), namely the navigation of an 8-DoF ant and forward locomotion of half-cheetah, hopper, and walker2d, achieving state-of-the-art results. Finally, we demonstrate that our method can achieve 167% improvement over the competing baseline on a sparse continuous control navigation task where various regions of the state space are removed from the offline RL dataset, including the region encapsulating the goal.",
    "authors": [
      "Suzan Ece Ada, Erhan Oztop, Emre Ugur"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.839119"
  },
  {
    "id": "oai:arXiv.org:2310.15978v2",
    "journal": "arXiv_CS",
    "title": "Graph Deep Learning for Time Series Forecasting",
    "link": "https://arxiv.org/abs/2310.15978",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2310.15978v2 Announce Type: replace \nAbstract: Graph deep learning methods have become popular tools to process collections of correlated time series. Unlike traditional multivariate forecasting methods, graph-based predictors leverage pairwise relationships by conditioning forecasts on graphs spanning the time series collection. The conditioning takes the form of architectural inductive biases on the forecasting architecture, resulting in a family of models called spatiotemporal graph neural networks. These biases allow for training global forecasting models on large collections of time series while localizing predictions w.r.t. each element in the set (nodes) by accounting for correlations among them (edges). Recent advances in graph neural networks and deep learning for time series forecasting make the adoption of such processing framework appealing and timely. However, most studies focus on refining existing architectures by exploiting modern deep-learning practices. Conversely, foundational and methodological aspects have not been subject to systematic investigation. To fill this void, this tutorial paper aims to introduce a comprehensive methodological framework formalizing the forecasting problem and providing design principles for graph-based predictors, as well as methods to assess their performance. In addition, together with an overview of the field, we provide design guidelines and best practices, as well as an in-depth discussion of open challenges and future directions.",
    "authors": [
      "Andrea Cini, Ivan Marisca, Daniele Zambon, Cesare Alippi"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.839135"
  },
  {
    "id": "oai:arXiv.org:2401.05707v2",
    "journal": "arXiv_CS",
    "title": "CAT-LLM: Style-enhanced Large Language Models with Text Style Definition for Chinese Article-style Transfer",
    "link": "https://arxiv.org/abs/2401.05707",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2401.05707v2 Announce Type: replace \nAbstract: Text style transfer plays a vital role in online entertainment and social media. However, existing models struggle to handle the complexity of Chinese long texts, such as rhetoric, structure, and culture, which restricts their broader application. To bridge this gap, we propose a Chinese Article-style Transfer (CAT-LLM) framework, which addresses the challenges of style transfer in complex Chinese long texts. At its core, CAT-LLM features a bespoke pluggable Text Style Definition (TSD) module that integrates machine learning algorithms to analyze and model article styles at both word and sentence levels. This module acts as a bridge, enabling LLMs to better understand and adapt to the complexities of Chinese article styles. Furthermore, it supports the dynamic expansion of internal style trees, enabling the framework to seamlessly incorporate new and diverse style definitions, enhancing adaptability and scalability for future research and applications. Additionally, to facilitate robust evaluation, we created ten parallel datasets using a combination of ChatGPT and various Chinese texts, each corresponding to distinct writing styles, significantly improving the accuracy of the model evaluation and establishing a novel paradigm for text style transfer research. Extensive experimental results demonstrate that CAT-LLM, combined with GPT-3.5-Turbo, achieves state-of-the-art performance, with a transfer accuracy F1 score of 79.36% and a content preservation F1 score of 96.47% on the \"Fortress Besieged\" dataset. These results highlight CAT-LLM's innovative contributions to style transfer research, including its ability to preserve content integrity while achieving precise and flexible style transfer across diverse Chinese text domains. Building on these contributions, CAT-LLM presents significant potential for advancing Chinese digital media and facilitating automated content creation.",
    "authors": [
      "Zhen Tao, Dinghao Xi, Zhiyu Li, Liumin Tang, Wei Xu"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.839152"
  },
  {
    "id": "oai:arXiv.org:2401.06379v2",
    "journal": "arXiv_CS",
    "title": "Vehicle: Bridging the Embedding Gap in the Verification of Neuro-Symbolic Programs",
    "link": "https://arxiv.org/abs/2401.06379",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2401.06379v2 Announce Type: replace \nAbstract: Neuro-symbolic programs, i.e. programs containing both machine learning components and traditional symbolic code, are becoming increasingly widespread. Finding a general methodology for verifying such programs is challenging due to both the number of different tools involved and the intricate interface between the ``neural'' and ``symbolic'' program components. In this paper we present a general decomposition of the neuro-symbolic verification problem into parts, and examine the problem of the embedding gap that occurs when one tries to combine proofs about the neural and symbolic components. To address this problem we then introduce Vehicle -- standing as an abbreviation for a ``verification condition language'' -- an intermediate programming language interface between machine learning frameworks, automated theorem provers, and dependently-typed formalisations of neuro-symbolic programs. Vehicle allows users to specify the properties of the neural components of neuro-symbolic programs once, and then safely compile the specification to each interface using a tailored typing and compilation procedure. We give a high-level overview of Vehicle's overall design, its interfaces and compilation & type-checking procedures, and then demonstrate its utility by formally verifying the safety of a simple autonomous car controlled by a neural network, operating in a stochastic environment with imperfect information.",
    "authors": [
      "Matthew L. Daggitt, Wen Kokke, Robert Atkey, Ekaterina Komendantskaya, Natalia Slusarz, Luca Arnaboldi"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.839160"
  },
  {
    "id": "oai:arXiv.org:2402.04835v3",
    "journal": "arXiv_CS",
    "title": "Pseudo-labelling meets Label Smoothing for Noisy Partial Label Learning",
    "link": "https://arxiv.org/abs/2402.04835",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2402.04835v3 Announce Type: replace \nAbstract: We motivate weakly supervised learning as an effective learning paradigm for problems where curating perfectly annotated datasets is expensive and may require domain expertise such as fine-grained classification. We focus on Partial Label Learning (PLL), a weakly-supervised learning paradigm where each training instance is paired with a set of candidate labels (partial label), one of which is the true label. Noisy PLL (NPLL) relaxes this constraint by allowing some partial labels to not contain the true label, enhancing the practicality of the problem. Our work centres on NPLL and presents a framework that initially assigns pseudo-labels to images by exploiting the noisy partial labels through a weighted nearest neighbour algorithm. These pseudo-label and image pairs are then used to train a deep neural network classifier with label smoothing. The classifier's features and predictions are subsequently employed to refine and enhance the accuracy of pseudo-labels. We perform thorough experiments on seven datasets and compare against nine NPLL and PLL methods. We achieve state-of-the-art results in all studied settings from the prior literature, obtaining substantial gains in the simulated fine-grained benchmarks. Further, we show the promising generalisation capability of our framework in realistic, fine-grained, crowd-sourced datasets.",
    "authors": [
      "Darshana Saravanan, Naresh Manwani, Vineet Gandhi"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.839169"
  },
  {
    "id": "oai:arXiv.org:2402.13284v3",
    "journal": "arXiv_CS",
    "title": "Structure Guided Large Language Model for SQL Generation",
    "link": "https://arxiv.org/abs/2402.13284",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2402.13284v3 Announce Type: replace \nAbstract: Recent advancements in large language models (LLMs) have shown promise in bridging the gap between natural language queries and database management systems, enabling users to interact with databases without the background of SQL. However, LLMs often struggle to comprehend complex database structures and accurately interpret user intentions. Decomposition-based methods have been proposed to enhance the performance of LLMs on complex tasks, but decomposing SQL generation into subtasks is non-trivial due to the declarative structure of SQL syntax and the intricate connections between query concepts and database elements. In this paper, we propose a novel Structure GUided text-to-SQL framework~(SGU-SQL) that incorporates syntax-based prompting to enhance the SQL generation capabilities of LLMs. Specifically, SGU-SQL establishes structure-aware links between user queries and database schema and decomposes the complex generation task using syntax-based prompting to enable more accurate LLM-based SQL generation. Extensive experiments on two benchmark datasets demonstrate that SGU-SQL consistently outperforms state-of-the-art text-to-SQL models.",
    "authors": [
      "Qinggang Zhang, Hao Chen, Junnan Dong, Shengyuan Chen, Feiran Huang, Xiao Huang"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.839177"
  },
  {
    "id": "oai:arXiv.org:2402.16021v2",
    "journal": "arXiv_CS",
    "title": "TMT: Tri-Modal Translation between Speech, Image, and Text by Processing Different Modalities as Different Languages",
    "link": "https://arxiv.org/abs/2402.16021",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2402.16021v2 Announce Type: replace \nAbstract: The capability to jointly process multi-modal information is becoming an essential task. However, the limited number of paired multi-modal data and the large computational requirements in multi-modal learning hinder the development. We propose a novel Tri-Modal Translation (TMT) model that translates between arbitrary modalities spanning speech, image, and text. We introduce a novel viewpoint, where we interpret different modalities as different languages, and treat multi-modal translation as a well-established machine translation problem. To this end, we tokenize speech and image data into discrete tokens, which provide a unified interface across modalities and significantly decrease the computational cost. In the proposed TMT, a multi-modal encoder-decoder conducts the core translation, whereas modality-specific processing is conducted only within the tokenization and detokenization stages. We evaluate the proposed TMT on all six modality translation tasks. TMT outperforms single model counterparts consistently, demonstrating that unifying tasks is beneficial not only for practicality but also for performance.",
    "authors": [
      "Minsu Kim, Jee-weon Jung, Hyeongseop Rha, Soumi Maiti, Siddhant Arora, Xuankai Chang, Shinji Watanabe, Yong Man Ro"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.839186"
  },
  {
    "id": "oai:arXiv.org:2403.07200v2",
    "journal": "arXiv_CS",
    "title": "Computing $p$-presentation distances is hard",
    "link": "https://arxiv.org/abs/2403.07200",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2403.07200v2 Announce Type: replace \nAbstract: Recently, $p$-presentation distances for $p\\in [1,\\infty]$ were introduced for merge trees and multiparameter persistence modules as more sensitive variations of the respective interleaving distances ($p=\\infty)$. It is well-known that computing the interleaving distance is NP-hard in both cases. We extend this result by showing that computing the $p$-presentation distance is NP-hard for all $p\\in [1,\\infty)$ for both merge trees and $t$-parameter persistence modules for any $t\\geq 2$. Though the details differ, both proofs follow the same novel strategy, suggesting that our approach can be adapted to proving the NP-hardness of other distances based on sums or $p$-norms.",
    "authors": [
      "H{\\aa}vard Bakke Bjerkevik, Magnus Bakke Botnan"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.839194"
  },
  {
    "id": "oai:arXiv.org:2404.14161v3",
    "journal": "arXiv_CS",
    "title": "Multidimensional Adaptive Coefficient for Inference Trajectory Optimization in Flow and Diffusion",
    "link": "https://arxiv.org/abs/2404.14161",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2404.14161v3 Announce Type: replace \nAbstract: Flow and diffusion models have demonstrated strong performance and training stability across various tasks but lack two critical properties of simulation-based methods: freedom of dimensionality and adaptability to different inference trajectories. To address this limitation, we propose the Multidimensional Adaptive Coefficient (MAC), a plug-in module for flow and diffusion models that extends conventional unidimensional coefficients to multidimensional ones and enables inference trajectory-wise adaptation. MAC is trained via simulation-based feedback through adversarial refinement. Empirical results across diverse frameworks and datasets demonstrate that MAC enhances generative quality with high training efficiency. Consequently, our work offers a new perspective on inference trajectory optimality, encouraging future research to move beyond vector field design and to leverage training-efficient, simulation-based optimization.",
    "authors": [
      "Dohoon Lee, Jaehyun Park, Hyunwoo J. Kim, Kyogu Lee"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.839204"
  },
  {
    "id": "oai:arXiv.org:2405.03234v3",
    "journal": "arXiv_CS",
    "title": "A Reliable Framework for Human-in-the-Loop Anomaly Detection in Time Series",
    "link": "https://arxiv.org/abs/2405.03234",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2405.03234v3 Announce Type: replace \nAbstract: Time series anomaly detection is a critical machine learning task for numerous applications, such as finance, healthcare, and industrial systems. However, even high-performing models may exhibit potential issues such as biases, leading to unreliable outcomes and misplaced confidence. While model explanation techniques, particularly visual explanations, offer valuable insights by elucidating model attributions of their decision, many limitations still exist -- They are primarily instance-based and not scalable across the dataset, and they provide one-directional information from the model to the human side, lacking a mechanism for users to address detected issues. To fulfill these gaps, we introduce HILAD, a novel framework designed to foster a dynamic and bidirectional collaboration between humans and AI for enhancing anomaly detection models in time series. Through our visual interface, HILAD empowers domain experts to detect, interpret, and correct unexpected model behaviors at scale. Our evaluation through user studies with two models and three time series datasets demonstrates the effectiveness of HILAD, which fosters a deeper model understanding, immediate corrective actions, and model reliability enhancement.",
    "authors": [
      "Ziquan Deng, Xiwei Xuan, Kwan-Liu Ma, Zhaodan Kong"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.839213"
  },
  {
    "id": "oai:arXiv.org:2405.05751v3",
    "journal": "arXiv_CS",
    "title": "Mirage: A Multi-Level Superoptimizer for Tensor Programs",
    "link": "https://arxiv.org/abs/2405.05751",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2405.05751v3 Announce Type: replace \nAbstract: We introduce Mirage, the first multi-level superoptimizer for tensor programs. A key idea in Mirage is $\\mu$Graphs, a uniform representation of tensor programs at the kernel, thread block, and thread levels of the GPU compute hierarchy. $\\mu$Graphs enable Mirage to discover novel optimizations that combine algebraic transformations, schedule transformations, and generation of new custom kernels. To navigate the large search space, Mirage introduces a pruning technique based on abstraction that significantly reduces the search space and provides a certain optimality guarantee. To ensure that the optimized $\\mu$Graph is equivalent to the input program, Mirage introduces a probabilistic equivalence verification procedure with strong theoretical guarantees. Our evaluation shows that Mirage outperforms existing approaches by up to 3.3$\\times$ even for DNNs that are widely used and heavily optimized. Mirage is publicly available at https://github.com/mirage-project/mirage.",
    "authors": [
      "Mengdi Wu, Xinhao Cheng, Shengyu Liu, Chunan Shi, Jianan Ji, Kit Ao, Praveen Velliengiri, Xupeng Miao, Oded Padon, Zhihao Jia"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.839221"
  },
  {
    "id": "oai:arXiv.org:2405.12493v2",
    "journal": "arXiv_CS",
    "title": "Visualizing, Rethinking, and Mining the Loss Landscape of Deep Neural Networks",
    "link": "https://arxiv.org/abs/2405.12493",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2405.12493v2 Announce Type: replace \nAbstract: The loss landscape of deep neural networks (DNNs) is commonly considered complex and wildly fluctuated. However, an interesting observation is that the loss surfaces plotted along Gaussian noise directions are almost v-basin ones with the perturbed model lying on the basin. This motivates us to rethink whether the 1D or 2D subspace could cover more complex local geometry structures, and how to mine the corresponding perturbation directions. This paper systematically and gradually categorizes the 1D curves from simple to complex, including v-basin, v-side, w-basin, w-peak, and vvv-basin curves. Notably, the latter two types are already hard to obtain via the intuitive construction of specific perturbation directions, and we need to propose proper mining algorithms to plot the corresponding 1D curves. Combining these 1D directions, various types of 2D surfaces are visualized such as the saddle surfaces and the bottom of a bottle of wine that are only shown by demo functions in previous works. Finally, we propose theoretical insights from the lens of the Hessian matrix to explain the observed several interesting phenomena.",
    "authors": [
      "Yichu Xu, Xin-Chun Li, Lan Li, De-Chuan Zhan"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.839230"
  },
  {
    "id": "oai:arXiv.org:2405.13078v2",
    "journal": "arXiv_CS",
    "title": "Exploring Dark Knowledge under Various Teacher Capacities and Addressing Capacity Mismatch",
    "link": "https://arxiv.org/abs/2405.13078",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2405.13078v2 Announce Type: replace \nAbstract: Knowledge Distillation (KD) could transfer the ``dark knowledge\" of a well-performed yet large neural network to a weaker but lightweight one. From the view of output logits and softened probabilities, this paper goes deeper into the dark knowledge provided by teachers with different capacities. Two fundamental observations are: (1) a larger teacher tends to produce probability vectors with lower distinction among non-ground-truth classes; (2) teachers with different capacities are basically consistent in their cognition of relative class affinity. Through abundant experimental studies we verify these observations and provide in-depth empirical explanations to them. We argue that the distinctness among incorrect classes embodies the essence of dark knowledge. A larger and more accurate teacher lacks this distinctness, which hampers its teaching ability compared to a smaller teacher, ultimately leading to the peculiar phenomenon named \"capacity mismatch\". Building on this insight, this paper explores multiple simple yet effective ways to address capacity mismatch, achieving superior experimental results compared to previous approaches.",
    "authors": [
      "Wen-Shu Fan, Xin-Chun Li, De-Chuan Zhan"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.839239"
  },
  {
    "id": "oai:arXiv.org:2406.03136v2",
    "journal": "arXiv_CS",
    "title": "Computational Limits of Low-Rank Adaptation (LoRA) Fine-Tuning for Transformer Models",
    "link": "https://arxiv.org/abs/2406.03136",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2406.03136v2 Announce Type: replace \nAbstract: We study the computational limits of Low-Rank Adaptation (LoRA) for finetuning transformer-based models using fine-grained complexity theory. Our key observation is that the existence of low-rank decompositions within the gradient computation of LoRA adaptation leads to possible algorithmic speedup. This allows us to (i) identify a phase transition behavior of efficiency assuming the Strong Exponential Time Hypothesis (SETH), and (ii) prove the existence of almost linear algorithms by controlling the LoRA update computation term by term. For the former, we identify a sharp transition in the efficiency of all possible rank-$r$ LoRA update algorithms for transformers, based on specific norms resulting from the multiplications of the input sequence $X$, pretrained weights ${W^\\star}$, and adapter matrices $\\alpha B A/r$. Specifically, we derive a shared upper bound threshold for such norms, and show that efficient (sub-quadratic) approximation algorithms of LoRA exist only below this threshold. For the latter, we prove the existence of almost linear approximation algorithms for LoRA adaptation by utilizing the hierarchical low-rank structures of LoRA gradients and approximating the gradients with a series of chained low-rank approximations. To showcase our theory, we consider two practical scenarios: partial (e.g., only $W_V$ and $W_Q$) and full adaptations (e.g., $W_Q$, $W_V$, and $W_K$) of weights in attention heads.",
    "authors": [
      "Jerry Yao-Chieh Hu, Maojiang Su, En-Jui Kuo, Zhao Song, Han Liu"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.839254"
  },
  {
    "id": "oai:arXiv.org:2406.05113v3",
    "journal": "arXiv_CS",
    "title": "LlavaGuard: An Open VLM-based Framework for Safeguarding Vision Datasets and Models",
    "link": "https://arxiv.org/abs/2406.05113",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2406.05113v3 Announce Type: replace \nAbstract: This paper introduces LlavaGuard, a suite of VLM-based vision safeguards that address the critical need for reliable guardrails in the era of large-scale data and models. To this end, we establish a novel open framework, describing a customizable safety taxonomy, data preprocessing, augmentation, and training setup. For teaching a VLM safeguard on safety, we further create a multimodal safety dataset with high-quality human expert annotations, where each image is labeled with a safety rating, category, and rationale. We also employ advanced augmentations to support context-specific assessments. The resulting LlavaGuard models, ranging from 0.5B to 7B, serve as a versatile tool for evaluating the safety compliance of visual content against flexible policies. In comprehensive experiments, LlavaGuard outperforms both state-of-the-art safeguards and VLMs in accuracy and in flexibly handling different policies. Additionally, we demonstrate LlavaGuard's performance in two real-world applications: large-scale dataset annotation and moderation of text-to-image models. We make our entire framework, including the dataset, model weights, and training code.",
    "authors": [
      "Lukas Helff, Felix Friedrich, Manuel Brack, Kristian Kersting, Patrick Schramowski"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.839263"
  },
  {
    "id": "oai:arXiv.org:2406.08979v2",
    "journal": "arXiv_CS",
    "title": "Multi-Agent Collaboration via Cross-Team Orchestration",
    "link": "https://arxiv.org/abs/2406.08979",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2406.08979v2 Announce Type: replace \nAbstract: Large Language Models (LLMs) have significantly impacted various domains, especially through organized LLM-driven autonomous agents. A representative scenario is in software development, where agents can collaborate in a team like humans, following predefined phases to complete sub-tasks sequentially. However, for an agent team, each phase yields only one possible outcome. This results in the completion of only one development chain, thereby losing the opportunity to explore multiple potential decision paths within the solution space. Consequently leading to suboptimal results or extensive trial and error. To address this, we introduce Cross-Team Orchestration (Croto), a scalable multi-team framework that enables orchestrated teams to jointly propose various task-oriented solutions and interact with their insights in a self-independence while cross-team collaboration environment for superior solutions generation. Experiments reveal a notable increase in software quality compared to state-of-the-art baselines. We further tested our framework on story generation tasks, which demonstrated a promising generalization ability of our framework in other domains. The code and data is available at https://github.com/OpenBMB/ChatDev/tree/macnet",
    "authors": [
      "Zhuoyun Du, Chen Qian, Wei Liu, Zihao Xie, YiFei Wang, Rennai Qiu, Yufan Dang, Weize Chen, Cheng Yang, Ye Tian, Xuantang Xiong, Lei Han"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.839271"
  },
  {
    "id": "oai:arXiv.org:2406.10737v4",
    "journal": "arXiv_CS",
    "title": "DPCore: Dynamic Prompt Coreset for Continual Test-Time Adaptation",
    "link": "https://arxiv.org/abs/2406.10737",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2406.10737v4 Announce Type: replace \nAbstract: Continual Test-Time Adaptation (CTTA) seeks to adapt source pre-trained models to continually changing, unseen target domains. While existing CTTA methods assume structured domain changes with uniform durations, real-world environments often exhibit dynamic patterns where domains recur with varying frequencies and durations. Current approaches, which adapt the same parameters across different domains, struggle in such dynamic conditions-they face convergence issues with brief domain exposures, risk forgetting previously learned knowledge, or misapplying it to irrelevant domains. To remedy this, we propose DPCore, a method designed for robust performance across diverse domain change patterns while ensuring computational efficiency. DPCore integrates three key components: Visual Prompt Adaptation for efficient domain alignment, a Prompt Coreset for knowledge preservation, and a Dynamic Update mechanism that intelligently adjusts existing prompts for similar domains while creating new ones for substantially different domains. Extensive experiments on four benchmarks demonstrate that DPCore consistently outperforms various CTTA methods, achieving state-of-the-art performance in both structured and dynamic settings while reducing trainable parameters by 99% and computation time by 64% compared to previous approaches.",
    "authors": [
      "Yunbei Zhang, Akshay Mehra, Shuaicheng Niu, Jihun Hamm"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.839279"
  },
  {
    "id": "oai:arXiv.org:2406.12329v3",
    "journal": "arXiv_CS",
    "title": "Opt-Out: Investigating Entity-Level Unlearning for Large Language Models via Optimal Transport",
    "link": "https://arxiv.org/abs/2406.12329",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2406.12329v3 Announce Type: replace \nAbstract: Instruction-following large language models (LLMs), such as ChatGPT, have become widely popular among everyday users. However, these models inadvertently disclose private, sensitive information to their users, underscoring the need for machine unlearning techniques to remove selective information from the models. While prior work has focused on forgetting small, random subsets of training data at the instance-level, we argue that real-world scenarios often require the removal of an entire user data, which may require a more careful maneuver. In this study, we explore entity-level unlearning, which aims to erase all knowledge related to a target entity while preserving the remaining model capabilities. To address this, we introduce Opt-Out, an optimal transport-based unlearning method that utilizes the Wasserstein distance from the model's initial parameters to achieve more effective and fine-grained unlearning. We also present the first Entity-Level Unlearning Dataset (ELUDe) designed to evaluate entity-level unlearning. Our empirical results demonstrate that Opt-Out surpasses existing methods, establishing a new standard for secure and adaptable LLMs that can accommodate user data removal requests without the need for full retraining.",
    "authors": [
      "Minseok Choi, Daniel Rim, Dohyun Lee, Jaegul Choo"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.839288"
  },
  {
    "id": "oai:arXiv.org:2406.18383v2",
    "journal": "arXiv_CS",
    "title": "Rauzy dimension and finite-state dimension",
    "link": "https://arxiv.org/abs/2406.18383",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2406.18383v2 Announce Type: replace \nAbstract: In 1976, Rauzy studied two complexity functions, $\\underline{\\beta}$ and $\\overline{\\beta}$, for infinite sequences over a finite alphabet. The function $\\underline{\\beta}$ achieves its maximum precisely for Borel normal sequences, while $\\overline{\\beta}$ reaches its minimum for sequences that, when added to any Borel normal sequence, result in another Borel normal sequence. We establish a connection between Rauzy's complexity functions, $\\underline{\\beta}$ and $\\overline{\\beta}$, and the notions of non-aligned block entropy, $\\underline{h}$ and $\\overline{h}$, by providing sharp upper and lower bounds for $\\underline{h}$ in terms of $\\underline{\\beta}$, and sharp upper and lower bounds for $\\overline{h}$ in terms of $\\overline{\\beta}$. We adopt a probabilistic approach by considering an infinite sequence of random variables over a finite alphabet. The proof relies on a new characterization of non-aligned block entropies, $\\overline{h}$ and $\\underline{h}$, in terms of Shannon's conditional entropy. The bounds imply that sequences with $\\overline{h} = 0$ coincide with those for which $\\overline{\\beta} = 0$. We also show that the non-aligned block entropies, $\\underline{h}$ and $\\overline{h}$, are essentially subadditive.",
    "authors": [
      "Ver\\'onica Becher, Olivier Carton, Santiago Figueira"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.839311"
  },
  {
    "id": "oai:arXiv.org:2407.00397v4",
    "journal": "arXiv_CS",
    "title": "Learning Time-Varying Multi-Region Communications via Scalable Markovian Gaussian Processes",
    "link": "https://arxiv.org/abs/2407.00397",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2407.00397v4 Announce Type: replace \nAbstract: Understanding and constructing brain communications that capture dynamic communications across multiple regions is fundamental to modern system neuroscience, yet current methods struggle to find time-varying region-level communications or scale to large neural datasets with long recording durations. We present a novel framework using Markovian Gaussian Processes to learn brain communications with time-varying temporal delays from multi-region neural recordings, named Adaptive Delay Model (ADM). Our method combines Gaussian Processes with State Space Models and employs parallel scan inference algorithms, enabling efficient scaling to large datasets while identifying concurrent communication patterns that evolve over time. This time-varying approach captures how brain region interactions shift dynamically during cognitive processes. Validated on synthetic and multi-region neural recordings datasets, our approach discovers both the directionality and temporal dynamics of neural communication. This work advances our understanding of distributed neural computation and provides a scalable tool for analyzing dynamic brain networks.",
    "authors": [
      "Weihan Li, Yule Wang, Chengrui Li, Anqi Wu"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.839320"
  },
  {
    "id": "oai:arXiv.org:2407.02814v3",
    "journal": "arXiv_CS",
    "title": "Images Speak Louder than Words: Understanding and Mitigating Bias in Vision-Language Model from a Causal Mediation Perspective",
    "link": "https://arxiv.org/abs/2407.02814",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2407.02814v3 Announce Type: replace \nAbstract: Vision-language models (VLMs) pre-trained on extensive datasets can inadvertently learn biases by correlating gender information with specific objects or scenarios. Current methods, which focus on modifying inputs and monitoring changes in the model's output probability scores, often struggle to comprehensively understand bias from the perspective of model components. We propose a framework that incorporates causal mediation analysis to measure and map the pathways of bias generation and propagation within VLMs. This approach allows us to identify the direct effects of interventions on model bias and the indirect effects of interventions on bias mediated through different model components. Our results show that image features are the primary contributors to bias, with significantly higher impacts than text features, specifically accounting for 32.57% and 12.63% of the bias in the MSCOCO and PASCAL-SENTENCE datasets, respectively. Notably, the image encoder's contribution surpasses that of the text encoder and the deep fusion encoder. Further experimentation confirms that contributions from both language and vision modalities are aligned and non-conflicting. Consequently, focusing on blurring gender representations within the image encoder, which contributes most to the model bias, reduces bias efficiently by 22.03% and 9.04% in the MSCOCO and PASCAL-SENTENCE datasets, respectively, with minimal performance loss or increased computational demands.",
    "authors": [
      "Zhaotian Weng, Zijun Gao, Jerone Andrews, Jieyu Zhao"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.839336"
  },
  {
    "id": "oai:arXiv.org:2407.02883v3",
    "journal": "arXiv_CS",
    "title": "CoIR: A Comprehensive Benchmark for Code Information Retrieval Models",
    "link": "https://arxiv.org/abs/2407.02883",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2407.02883v3 Announce Type: replace \nAbstract: Despite the substantial success of Information Retrieval (IR) in various NLP tasks, most IR systems predominantly handle queries and corpora in natural language, neglecting the domain of code retrieval. Code retrieval is critically important yet remains under-explored, with existing methods and benchmarks inadequately representing the diversity of code in various domains and tasks. Addressing this gap, we present COIR (Code Information Retrieval Benchmark), a robust and comprehensive benchmark specifically designed to assess code retrieval capabilities. COIR comprises ten meticulously curated code datasets, spanning eight distinctive retrieval tasks across seven diverse domains. We first discuss the construction of COIR and its diverse dataset composition. Further, we evaluate nine widely used retrieval models using COIR, uncovering significant difficulties in performing code retrieval tasks even with state-of-the-art systems. To facilitate easy adoption and integration within existing research workflows, COIR has been developed as a user-friendly Python framework, readily installable via pip. It shares same data schema as other popular benchmarks like MTEB and BEIR, enabling seamless cross-benchmark evaluations. Through COIR, we aim to invigorate research in the code retrieval domain, providing a versatile benchmarking tool that encourages further development and exploration of code retrieval systems. https://github.com/CoIR-team/coir.",
    "authors": [
      "Xiangyang Li, Kuicai Dong, Yi Quan Lee, Wei Xia, Hao Zhang, Xinyi Dai, Yasheng Wang, Ruiming Tang"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.839344"
  },
  {
    "id": "oai:arXiv.org:2407.05703v2",
    "journal": "arXiv_CS",
    "title": "HilbertMamba: Local-Global Reciprocal Network for Uterine Fibroid Segmentation in Ultrasound Videos",
    "link": "https://arxiv.org/abs/2407.05703",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2407.05703v2 Announce Type: replace \nAbstract: Regular screening and early discovery of uterine fibroid are crucial for preventing potential malignant transformations and ensuring timely, life-saving interventions. To this end, we collect and annotate the first ultrasound video dataset with 100 videos for uterine fibroid segmentation (UFUV). We also present Local-Global Reciprocal Network (LGRNet) to efficiently and effectively propagate the long-term temporal context which is crucial to help distinguish between uninformative noisy surrounding tissues and target lesion regions. Specifically, the Cyclic Neighborhood Propagation (CNP) is introduced to propagate the inter-frame local temporal context in a cyclic manner. Moreover, to aggregate global temporal context, we first condense each frame into a set of frame bottleneck queries and devise Hilbert Selective Scan (HilbertSS) to both efficiently path connect each frame and preserve the locality bias. A distribute layer is then utilized to disseminate back the global context for reciprocal refinement. Extensive experiments on UFUV and three public Video Polyp Segmentation (VPS) datasets demonstrate consistent improvements compared to state-of-the-art segmentation methods, indicating the effectiveness and versatility of LGRNet. Code, checkpoints, and dataset are available at https://github.com/bio-mlhui/LGRNet",
    "authors": [
      "Huihui Xu, Yijun Yang, Angelica I Aviles-Rivero, Guang Yang, Jing Qin, Lei Zhu"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.839353"
  },
  {
    "id": "oai:arXiv.org:2407.08806v2",
    "journal": "arXiv_CS",
    "title": "HO-FMN: Hyperparameter Optimization for Fast Minimum-Norm Attacks",
    "link": "https://arxiv.org/abs/2407.08806",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2407.08806v2 Announce Type: replace \nAbstract: Gradient-based attacks are a primary tool to evaluate robustness of machine-learning models. However, many attacks tend to provide overly-optimistic evaluations as they use fixed loss functions, optimizers, step-size schedulers, and default hyperparameters. In this work, we tackle these limitations by proposing a parametric variation of the well-known fast minimum-norm attack algorithm, whose loss, optimizer, step-size scheduler, and hyperparameters can be dynamically adjusted. We re-evaluate 12 robust models, showing that our attack finds smaller adversarial perturbations without requiring any additional tuning. This also enables reporting adversarial robustness as a function of the perturbation budget, providing a more complete evaluation than that offered by fixed-budget attacks, while remaining efficient. We release our open-source code at https://github.com/pralab/HO-FMN.",
    "authors": [
      "Raffaele Mura, Giuseppe Floris, Luca Scionis, Giorgio Piras, Maura Pintor, Ambra Demontis, Giorgio Giacinto, Battista Biggio, Fabio Roli"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.839361"
  },
  {
    "id": "oai:arXiv.org:2407.15134v2",
    "journal": "arXiv_CS",
    "title": "Proximal Policy Distillation",
    "link": "https://arxiv.org/abs/2407.15134",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2407.15134v2 Announce Type: replace \nAbstract: We introduce Proximal Policy Distillation (PPD), a novel policy distillation method that integrates student-driven distillation and Proximal Policy Optimization (PPO) to increase sample efficiency and to leverage the additional rewards that the student policy collects during distillation. To assess the efficacy of our method, we compare PPD with two common alternatives, student-distill and teacher-distill, over a wide range of reinforcement learning environments that include discrete actions and continuous control (ATARI, Mujoco, and Procgen). For each environment and method, we perform distillation to a set of target student neural networks that are smaller, identical (self-distillation), or larger than the teacher network. Our findings indicate that PPD improves sample efficiency and produces better student policies compared to typical policy distillation approaches. Moreover, PPD demonstrates greater robustness than alternative methods when distilling policies from imperfect demonstrations. The code for the paper is released as part of a new Python library built on top of stable-baselines3 to facilitate policy distillation: `sb3-distill'.",
    "authors": [
      "Giacomo Spigler"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.839377"
  },
  {
    "id": "oai:arXiv.org:2407.16401v2",
    "journal": "arXiv_CS",
    "title": "Some remarks on regularized Shannon sampling formulas",
    "link": "https://arxiv.org/abs/2407.16401",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2407.16401v2 Announce Type: replace \nAbstract: The fast reconstruction of a bandlimited function from its sample data is an essential problem in signal processing. In this paper, we consider the widely used Gaussian regularized Shannon sampling formula in comparison to regularized Shannon sampling formulas employing alternative window functions, such as the sinh-type window function and the continuous Kaiser-Bessel window function. It is shown that the approximation errors of these regularized Shannon sampling formulas possess an exponential decay with respect to the truncation parameter. The main focus of this work is to address minor gaps in preceding papers and rigorously prove assumptions that were previously based solely on numerical tests. In doing so, we demonstrate that the sinh-type regularized Shannon sampling formula has the same exponential decay as the continuous Kaiser-Bessel regularized Shannon sampling formula, but both have twice the exponential decay of the Gaussian regularized Shannon sampling formula. Additionally, numerical experiments illustrate the theoretical results.",
    "authors": [
      "Melanie Kircheis, Daniel Potts, Manfred Tasche"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.839385"
  },
  {
    "id": "oai:arXiv.org:2407.17771v4",
    "journal": "arXiv_CS",
    "title": "Banyan: Improved Representation Learning with Explicit Structure",
    "link": "https://arxiv.org/abs/2407.17771",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2407.17771v4 Announce Type: replace \nAbstract: We present Banyan, a model that efficiently learns semantic representations by leveraging explicit hierarchical structure. While transformers excel at scale, they struggle in low-resource settings. Conversely recent structured models have shown promise as efficient learners, but lack performance. Banyan bridges this gap with two key innovations: an entangled hierarchical tree structure and diagonalized message passing, enabling it to outperform larger transformer models with just 14 non-embedding parameters. It excels in low-resource settings, offering a viable alternative for under-represented languages and highlighting its potential for efficient, interpretable NLP in resource-constrained environments.",
    "authors": [
      "Mattia Opper, N. Siddharth"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.839394"
  },
  {
    "id": "oai:arXiv.org:2407.18327v2",
    "journal": "arXiv_CS",
    "title": "The Structure of Financial Equity Research Reports -- Identification of the Most Frequently Asked Questions in Financial Analyst Reports to Automate Equity Research Using Llama 3 and GPT-4",
    "link": "https://arxiv.org/abs/2407.18327",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2407.18327v2 Announce Type: replace \nAbstract: This research dissects financial equity research reports (ERRs) by mapping their content into categories. There is insufficient empirical analysis of the questions answered in ERRs. In particular, it is not understood how frequently certain information appears, what information is considered essential, and what information requires human judgment to distill into an ERR. The study analyzes 72 ERRs sentence-by-sentence, classifying their 4940 sentences into 169 unique question archetypes. We did not predefine the questions but derived them solely from the statements in the ERRs. This approach provides an unbiased view of the content of the observed ERRs. Subsequently, we used public corporate reports to classify the questions' potential for automation. Answers were labeled \"text-extractable\" if the answers to the question were accessible in corporate reports. 78.7% of the questions in ERRs can be automated. Those automatable question consist of 48.2% text-extractable (suited to processing by large language models, LLMs) and 30.5% database-extractable questions. Only 21.3% of questions require human judgment to answer. We empirically validate using Llama-3-70B and GPT-4-turbo-2024-04-09 that recent advances in language generation and information extraction enable the automation of approximately 80% of the statements in ERRs. Surprisingly, the models complement each other's strengths and weaknesses well. The research confirms that the current writing process of ERRs can likely benefit from additional automation, improving quality and efficiency. The research thus allows us to quantify the potential impacts of introducing large language models in the ERR writing process. The full question list, including the archetypes and their frequency, will be made available online after peer review.",
    "authors": [
      "Adria Pop, Jan Sp\\\"orer"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.839405"
  },
  {
    "id": "oai:arXiv.org:2407.19652v3",
    "journal": "arXiv_CS",
    "title": "SALVE: A 3D Reconstruction Benchmark of Wounds from Consumer-grade Videos",
    "link": "https://arxiv.org/abs/2407.19652",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2407.19652v3 Announce Type: replace \nAbstract: Managing chronic wounds is a global challenge that can be alleviated by the adoption of automatic systems for clinical wound assessment from consumer-grade videos. While 2D image analysis approaches are insufficient for handling the 3D features of wounds, existing approaches utilizing 3D reconstruction methods have not been thoroughly evaluated. To address this gap, this paper presents a comprehensive study on 3D wound reconstruction from consumer-grade videos. Specifically, we introduce the SALVE dataset, comprising video recordings of realistic wound phantoms captured with different cameras. Using this dataset, we assess the accuracy and precision of state-of-the-art methods for 3D reconstruction, ranging from traditional photogrammetry pipelines to advanced neural rendering approaches. In our experiments, we observe that photogrammetry approaches do not provide smooth surfaces suitable for precise clinical measurements of wounds. Neural rendering approaches show promise in addressing this issue, advancing the use of this technology in wound care practices. We encourage the readers to visit the project page: https://remichierchia.github.io/SALVE/.",
    "authors": [
      "Remi Chierchia, Leo Lebrat, David Ahmedt-Aristizabal, Olivier Salvado, Clinton Fookes, Rodrigo Santa Cruz"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.839413"
  },
  {
    "id": "oai:arXiv.org:2407.20279v2",
    "journal": "arXiv_CS",
    "title": "Robust and Efficient Transfer Learning via Supernet Transfer in Warm-started Neural Architecture Search",
    "link": "https://arxiv.org/abs/2407.20279",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2407.20279v2 Announce Type: replace \nAbstract: Hand-designing Neural Networks is a tedious process that requires significant expertise. Neural Architecture Search (NAS) frameworks offer a very useful and popular solution that helps to democratize AI. However, these NAS frameworks are often computationally expensive to run, which limits their applicability and accessibility. In this paper, we propose a novel transfer learning approach, capable of effectively transferring pretrained supernets based on Optimal Transport or multi-dataset pretaining. This method can be generally applied to NAS methods based on Differentiable Architecture Search (DARTS). Through extensive experiments across dozens of image classification tasks, we demonstrate that transferring pretrained supernets in this way can not only drastically speed up the supernet training which then finds optimal models (3 to 5 times faster on average), but even yield that outperform those found when running DARTS methods from scratch. We also observe positive transfer to almost all target datasets, making it very robust. Besides drastically improving the applicability of NAS methods, this also opens up new applications for continual learning and related fields.",
    "authors": [
      "Prabhant Singh, Joaquin Vanschoren"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.839423"
  },
  {
    "id": "oai:arXiv.org:2408.01127v3",
    "journal": "arXiv_CS",
    "title": "Relax, Estimate, and Track: a Simple Battery State-of-charge and State-of-health Estimation Method",
    "link": "https://arxiv.org/abs/2408.01127",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2408.01127v3 Announce Type: replace \nAbstract: Battery management is a critical component of ubiquitous battery-powered energy systems, in which battery state-of-charge (SOC) and state-of-health (SOH) estimations are of crucial importance. Conventional SOC and SOH estimation methods, especially model-based methods, often lack accurate modeling of the open circuit voltage (OCV), have relatively high computational complexity, and lack theoretical analysis. This study introduces a simple SOC and SOH estimation method that overcomes all these weaknesses. The key idea of the proposed method is to momentarily set the cell's current to zero for a few minutes during the charging, perform SOC and SOH estimation based on the measured data, and continue tracking the cell's SOC afterward. The method is based on rigorous theoretical analysis, requires no hyperparameter fine-tuning, and is hundreds of times faster than conventional model-based methods. The method is validated on six batteries charged at different C rates and temperatures, realizing fast and accurate estimations under various conditions, with a SOH root mean square error (RMSE) of around 3% and a SOC RMSE of around 1.5%. The data and codes are available at https://berkeley.box.com/s/jz1w6po2iqzzfy7irxd9ok47ku3tr86j.",
    "authors": [
      "Shida Jiang, Junzhe Shi, Scott Moura"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.839432"
  },
  {
    "id": "oai:arXiv.org:2408.04713v4",
    "journal": "arXiv_CS",
    "title": "DyGMamba: Efficiently Modeling Long-Term Temporal Dependency on Continuous-Time Dynamic Graphs with State Space Models",
    "link": "https://arxiv.org/abs/2408.04713",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2408.04713v4 Announce Type: replace \nAbstract: Learning useful representations for continuous-time dynamic graphs (CTDGs) is challenging, due to the concurrent need to span long node interaction histories and grasp nuanced temporal details. In particular, two problems emerge: (1) Encoding longer histories requires more computational resources, making it crucial for CTDG models to maintain low computational complexity to ensure efficiency; (2) Meanwhile, more powerful models are needed to identify and select the most critical temporal information within the extended context provided by longer histories. To address these problems, we propose a CTDG representation learning model named DyGMamba, originating from the popular Mamba state space model (SSM). DyGMamba first leverages a node-level SSM to encode the sequence of historical node interactions. Another time-level SSM is then employed to exploit the temporal patterns hidden in the historical graph, where its output is used to dynamically select the critical information from the interaction history. We validate DyGMamba experimentally on the dynamic link prediction task. The results show that our model achieves state-of-the-art in most cases. DyGMamba also maintains high efficiency in terms of computational resources, making it possible to capture long temporal dependencies with a limited computation budget.",
    "authors": [
      "Zifeng Ding, Yifeng Li, Yuan He, Antonio Norelli, Jingcheng Wu, Volker Tresp, Michael Bronstein, Yunpu Ma"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.839441"
  },
  {
    "id": "oai:arXiv.org:2408.07237v3",
    "journal": "arXiv_CS",
    "title": "A semantic embedding space based on large language models for modelling human beliefs",
    "link": "https://arxiv.org/abs/2408.07237",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2408.07237v3 Announce Type: replace \nAbstract: Beliefs form the foundation of human cognition and decision-making, guiding our actions and social connections. A model encapsulating beliefs and their interrelationships is crucial for understanding their influence on our actions. However, research on belief interplay has often been limited to beliefs related to specific issues and relied heavily on surveys. We propose a method to study the nuanced interplay between thousands of beliefs by leveraging an online user debate data and mapping beliefs onto a neural embedding space constructed using a fine-tuned large language model (LLM). This belief space captures the interconnectedness and polarization of diverse beliefs across social issues. Our findings show that positions within this belief space predict new beliefs of individuals and estimate cognitive dissonance based on the distance between existing and new beliefs. This study demonstrates how LLMs, combined with collective online records of human beliefs, can offer insights into the fundamental principles that govern human belief formation.",
    "authors": [
      "Byunghwee Lee, Rachith Aiyappa, Yong-Yeol Ahn, Haewoon Kwak, Jisun An"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.839450"
  },
  {
    "id": "oai:arXiv.org:2408.08540v3",
    "journal": "arXiv_CS",
    "title": "A Hybrid Iterative Neural Solver Based on Spectral Analysis for Parametric PDEs",
    "link": "https://arxiv.org/abs/2408.08540",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2408.08540v3 Announce Type: replace \nAbstract: Deep learning-based hybrid iterative methods (DL-HIM) have emerged as a promising approach for designing fast neural solvers to tackle large-scale sparse linear systems. DL-HIM combine the smoothing effect of simple iterative methods with the spectral bias of neural networks, which allows them to effectively eliminate both high-frequency and low-frequency error components. However, their efficiency may decrease if simple iterative methods can not provide effective smoothing, making it difficult for the neural network to learn mid-frequency and high-frequency components. This paper first conducts a convergence analysis for general DL-HIM from a spectral viewpoint, concluding that under reasonable assumptions, DL-HIM exhibit a convergence rate independent of grid size $h$ and physical parameters $\\boldsymbol{\\mu}$. To meet these assumptions, we design a neural network from an eigen perspective, focusing on learning the eigenvalues and eigenvectors corresponding to error components that simple iterative methods struggle to eliminate. Specifically, the eigenvalues are learned by a meta subnet, while the eigenvectors are approximated using Fourier modes with a transition matrix provided by another meta subnet. The resulting DL-HIM, termed the Fourier Neural Solver (FNS), can be trained to achieve a convergence rate independent of PDE parameters and grid size within a local neighborhood of the training scale by designing a loss function that ensures the neural network complements the smoothing effect of the damped Jacobi iterative methods. We verify the performance of FNS on five types of linear parametric PDEs.",
    "authors": [
      "Chen Cui, Kai Jiang, Yun Liu, Shi Shu"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.839459"
  },
  {
    "id": "oai:arXiv.org:2408.08541v2",
    "journal": "arXiv_CS",
    "title": "Where is the signal in tokenization space?",
    "link": "https://arxiv.org/abs/2408.08541",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2408.08541v2 Announce Type: replace \nAbstract: Large Language Models (LLMs) are typically shipped with tokenizers that deterministically encode text into so-called canonical token sequences, to which the LLMs assign probability values. One common assumption is that the probability of a piece of text is the probability of its canonical token sequence. However, the tokenization of a string is not unique: e.g., the Llama2 tokenizer encodes Tokens as [Tok,ens], but [Tok,en,s] also represents the same text. In this paper, we study non-canonical tokenizations. We prove that, given a string, it is computationally hard to find the most likely tokenization for an autoregressive LLM, as well as to compute the marginal probability over all possible tokenizations. We then show how the marginal is, in most cases, indistinguishable from the canonical probability. Surprisingly, we then empirically demonstrate the existence of a significant amount of signal hidden within tokenization space. Notably, by simply aggregating the probabilities of non-canonical tokenizations, we achieve improvements across a range of LLM evaluation benchmarks for a variety of architectures, including transformers and state space models.",
    "authors": [
      "Renato Lui Geh, Honghua Zhang, Kareem Ahmed, Benjie Wang, Guy Van den Broeck"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.839468"
  },
  {
    "id": "oai:arXiv.org:2408.13369v3",
    "journal": "arXiv_CS",
    "title": "Beyond Winning Strategies: Admissible and Admissible Winning Strategies for Quantitative Reachability Games",
    "link": "https://arxiv.org/abs/2408.13369",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2408.13369v3 Announce Type: replace \nAbstract: Classical reactive synthesis approaches aim to synthesize a reactive system that always satisfies a given specifications. These approaches often reduce to playing a two-player zero-sum game where the goal is to synthesize a winning strategy. However, in many pragmatic domains, such as robotics, a winning strategy does not always exist, yet it is desirable for the system to make an effort to satisfy its requirements instead of \"giving up\". To this end, this paper investigates the notion of admissible strategies, which formalize \"doing-your-best\", in quantitative reachability games. We show that, unlike the qualitative case, quantitative admissible strategies are history-dependent even for finite payoff functions, making synthesis a challenging task. In addition, we prove that admissible strategies always exist but may produce undesirable optimistic behaviors. To mitigate this, we propose admissible winning strategies, which enforce the best possible outcome while being admissible. We show that both strategies always exist but are not memoryless. We provide necessary and sufficient conditions for the existence of both strategies and propose synthesis algorithms. Finally, we illustrate the strategies on gridworld and robot manipulator domains.",
    "authors": [
      "Karan Muvvala, Qi Heng Ho, Morteza Lahijanian"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.839477"
  },
  {
    "id": "oai:arXiv.org:2408.17253v4",
    "journal": "arXiv_CS",
    "title": "VisionTS: Visual Masked Autoencoders Are Free-Lunch Zero-Shot Time Series Forecasters",
    "link": "https://arxiv.org/abs/2408.17253",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2408.17253v4 Announce Type: replace \nAbstract: Foundation models have emerged as a promising approach in time series forecasting (TSF). Existing approaches either repurpose large language models (LLMs) or build large-scale time series datasets to develop TSF foundation models for universal forecasting. However, these methods face challenges due to the severe cross-domain gap or in-domain heterogeneity. This paper explores a new road to building a TSF foundation model from rich, high-quality natural images. Our key insight is that a visual masked autoencoder, pre-trained on the ImageNet dataset, can naturally be a numeric series forecaster. By reformulating TSF as an image reconstruction task, we bridge the gap between image pre-training and TSF downstream tasks. Surprisingly, without further adaptation in the time series domain, the proposed VisionTS could achieve better zero-shot forecast performance than existing TSF foundation models. With fine-tuning for one epoch, VisionTS could further improve the forecasting and achieve state-of-the-art performance in most cases. Extensive experiments reveal intrinsic similarities between images and real-world time series, suggesting that visual models may offer a \"free lunch\" for TSF and highlight the potential for future cross-modality research. Our code is publicly available at https://github.com/Keytoyze/VisionTS.",
    "authors": [
      "Mouxiang Chen, Lefei Shen, Zhuo Li, Xiaoyun Joy Wang, Jianling Sun, Chenghao Liu"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.839494"
  },
  {
    "id": "oai:arXiv.org:2409.02289v2",
    "journal": "arXiv_CS",
    "title": "Query Answering in Lattice-based Description Logic",
    "link": "https://arxiv.org/abs/2409.02289",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2409.02289v2 Announce Type: replace \nAbstract: Recently, the description logic LE-ALC was introduced for reasoning in the semantic environment of the enriched formal contexts, and a tableaux algorithm was developed for checking the consistency of ABoxes in this logic. In this paper, we study the ontology-mediated query answering in LE-ALC . In particular, we show that several different types of queries can be answered efficiently for LE-ALC knowledge bases with acyclic TBoxes using our tableaux algorithm directly or by extending it with some additional rules.",
    "authors": [
      "Krishna Manoorkar, Ruoding Wang"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.839503"
  },
  {
    "id": "oai:arXiv.org:2409.09871v3",
    "journal": "arXiv_CS",
    "title": "Marginalizing and Conditioning Gaussians onto Linear Approximations of Smooth Manifolds with Applications in Robotics",
    "link": "https://arxiv.org/abs/2409.09871",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2409.09871v3 Announce Type: replace \nAbstract: We present closed-form expressions for marginalizing and conditioning Gaussians onto linear manifolds, and demonstrate how to apply these expressions to smooth nonlinear manifolds through linearization. Although marginalization and conditioning onto axis-aligned manifolds are well-established procedures, doing so onto non-axis-aligned manifolds is not as well understood. We demonstrate the utility of our expressions through three applications: 1) approximation of the projected normal distribution, where the quality of our linearized approximation increases as problem nonlinearity decreases; 2) covariance extraction in Koopman SLAM, where our covariances are shown to be consistent on a real-world dataset; and 3) covariance extraction in constrained GTSAM, where our covariances are shown to be consistent in simulation.",
    "authors": [
      "Zi Cong Guo, James R. Forbes, Timothy D. Barfoot"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.839512"
  },
  {
    "id": "oai:arXiv.org:2409.11252v3",
    "journal": "arXiv_CS",
    "title": "WER We Stand: Benchmarking Urdu ASR Models",
    "link": "https://arxiv.org/abs/2409.11252",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2409.11252v3 Announce Type: replace \nAbstract: This paper presents a comprehensive evaluation of Urdu Automatic Speech Recognition (ASR) models. We analyze the performance of three ASR model families: Whisper, MMS, and Seamless-M4T using Word Error Rate (WER), along with a detailed examination of the most frequent wrong words and error types including insertions, deletions, and substitutions. Our analysis is conducted using two types of datasets, read speech and conversational speech. Notably, we present the first conversational speech dataset designed for benchmarking Urdu ASR models. We find that seamless-large outperforms other ASR models on the read speech dataset, while whisper-large performs best on the conversational speech dataset. Furthermore, this evaluation highlights the complexities of assessing ASR models for low-resource languages like Urdu using quantitative metrics alone and emphasizes the need for a robust Urdu text normalization system. Our findings contribute valuable insights for developing robust ASR systems for low-resource languages like Urdu.",
    "authors": [
      "Samee Arif, Sualeha Farid, Aamina Jamal Khan, Mustafa Abbas, Agha Ali Raza, Awais Athar"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.839520"
  },
  {
    "id": "oai:arXiv.org:2409.12915v5",
    "journal": "arXiv_CS",
    "title": "Exploring Representations and Interventions in Time Series Foundation Models",
    "link": "https://arxiv.org/abs/2409.12915",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2409.12915v5 Announce Type: replace \nAbstract: Time series foundation models (TSFMs) promise to be powerful tools for a wide range of applications. However, their internal representations and learned concepts are still not well understood. In this study, we investigate the structure and redundancy of representations across various TSFMs, examining the self-similarity of model layers within and across different model sizes. This analysis reveals block-like redundancy in the representations, which can be utilized for informed pruning to improve inference speed and efficiency. Additionally, we explore the concepts learned by these models - such as periodicity and trends - and how these can be manipulated through latent space steering to influence model behavior. Our experiments show that steering interventions can introduce new features, e.g., adding periodicity or trends to signals that initially lacked them. These findings underscore the value of representational analysis for optimizing models and demonstrate how conceptual steering offers new possibilities for more controlled and efficient time series analysis with TSFMs.",
    "authors": [
      "Micha{\\l} Wili\\'nski, Mononito Goswami, Willa Potosnak, Nina \\.Zukowska, Artur Dubrawski"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.839529"
  },
  {
    "id": "oai:arXiv.org:2409.14700v2",
    "journal": "arXiv_CS",
    "title": "Adaptive and Robust Watermark for Generative Tabular Data",
    "link": "https://arxiv.org/abs/2409.14700",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2409.14700v2 Announce Type: replace \nAbstract: Recent development in generative models has demonstrated its ability to create high-quality synthetic data. However, the pervasiveness of synthetic content online also brings forth growing concerns that it can be used for malicious purpose. To ensure the authenticity of the data, watermarking techniques have recently emerged as a promising solution due to their strong statistical guarantees. In this paper, we propose a flexible and robust watermarking mechanism for generative tabular data. Specifically, a data provider with knowledge of the downstream tasks can partition the feature space into pairs of (key, value) columns. Within each pair, the data provider first uses elements in the key column to generate a randomized set of ``green'' intervals, then encourages elements of the value column to be in one of these ``green'' intervals. We show theoretically and empirically that the watermarked datasets (i) have negligible impact on the data quality and downstream utility, (ii) can be efficiently detected, (iii) are robust against multiple attacks commonly observed in data science, and (iv) maintain strong security against adversary attempting to learn the underlying watermark scheme.",
    "authors": [
      "Dung Daniel Ngo, Daniel Scott, Saheed Obitayo, Archan Ray, Akshay Seshadri, Niraj Kumar, Vamsi K. Potluru, Marco Pistoia, Manuela Veloso"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.839537"
  },
  {
    "id": "oai:arXiv.org:2409.17566v2",
    "journal": "arXiv_CS",
    "title": "Flexiffusion: Segment-wise Neural Architecture Search for Flexible Denoising Schedule",
    "link": "https://arxiv.org/abs/2409.17566",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2409.17566v2 Announce Type: replace \nAbstract: Diffusion models are cutting-edge generative models adept at producing diverse, high-quality images. Despite their effectiveness, these models often require significant computational resources owing to their numerous sequential denoising steps and the significant inference cost of each step. Recently, Neural Architecture Search (NAS) techniques have been employed to automatically search for faster generation processes. However, NAS for diffusion is inherently time-consuming as it requires estimating thousands of diffusion models to search for the optimal one. In this paper, we introduce Flexiffusion, a novel training-free NAS paradigm designed to accelerate diffusion models by concurrently optimizing generation steps and network structures. Specifically, we partition the generation process into isometric step segments, each sequentially composed of a full step, multiple partial steps, and several null steps. The full step computes all network blocks, while the partial step involves part of the blocks, and the null step entails no computation. Flexiffusion autonomously explores flexible step combinations for each segment, substantially reducing search costs and enabling greater acceleration compared to the state-of-the-art (SOTA) method for diffusion models. Our searched models reported speedup factors of $2.6\\times$ and $1.5\\times$ for the original LDM-4-G and the SOTA, respectively. The factors for Stable Diffusion V1.5 and the SOTA are $5.1\\times$ and $2.0\\times$. We also verified the performance of Flexiffusion on multiple datasets, and positive experiment results indicate that Flexiffusion can effectively reduce redundancy in diffusion models.",
    "authors": [
      "Hongtao Huang, Xiaojun Chang, Lina Yao"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.839546"
  },
  {
    "id": "oai:arXiv.org:2410.00568v3",
    "journal": "arXiv_CS",
    "title": "Approximation of Spanning Tree Congestion using Hereditary Bisection",
    "link": "https://arxiv.org/abs/2410.00568",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2410.00568v3 Announce Type: replace \nAbstract: The Spanning Tree Congestion (STC) problem is the following NP-hard problem: given a graph $G$, construct a spanning tree $T$ of $G$ minimizing its maximum edge congestion where the congestion of an edge $e\\in T$ is the number of edges $uv$ in $G$ such that the unique path between $u$ and $v$ in $T$ passes through $e$; the optimal value for a given graph $G$ is denoted $STC(G)$.\n  It is known that every spanning tree is an $n/2$-approximation for the STP problem. A long-standing problem is to design a better approximation algorithm. Our contribution towards this goal is an $O(\\Delta\\cdot\\log^{3/2}n)$-approximation algorithm where $\\Delta$ is the maximum degree in $G$ and $n$ the number of vertices. For graphs with a maximum degree bounded by a polylog of the number of vertices, this is an exponential improvement over the previous best approximation.\n  Our main tool for the algorithm is a new lower bound on the spanning tree congestion which is of independent interest. Denoting by $hb(G)$ the hereditary bisection of $G$ which is the maximum bisection width over all subgraphs of $G$, we prove that for every graph $G$, $STC(G)\\geq \\Omega(hb(G)/\\Delta)$.",
    "authors": [
      "Petr Kolman"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.839562"
  },
  {
    "id": "oai:arXiv.org:2410.01744v3",
    "journal": "arXiv_CS",
    "title": "Leopard: A Vision Language Model For Text-Rich Multi-Image Tasks",
    "link": "https://arxiv.org/abs/2410.01744",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2410.01744v3 Announce Type: replace \nAbstract: Text-rich images, where text serves as the central visual element guiding the overall understanding, are prevalent in real-world applications, such as presentation slides, scanned documents, and webpage snapshots. Tasks involving multiple text-rich images are especially challenging, as they require not only understanding the content of individual images but reasoning about inter-relationships and logical flows across multiple visual inputs. Despite the importance of these scenarios, current multimodal large language models (MLLMs) struggle to handle such tasks due to two key challenges: (1) the scarcity of high-quality instruction tuning datasets for text-rich multi-image scenarios, and (2) the difficulty in balancing image resolution with visual feature sequence length. To address these challenges, we propose Leopard, an MLLM tailored for handling vision-language tasks involving multiple text-rich images. First, we curated about one million high-quality multimodal instruction-tuning data, tailored to text-rich, multi-image scenarios. Second, we proposed an adaptive high-resolution multi-image encoding module to dynamically optimize the allocation of visual sequence length based on the original aspect ratios and resolutions of images. Experiments on a diverse set of benchmarks reveal that our model consistently outperforms state-of-the-art systems, such as Llama-3.2 and Qwen2-VL, in challenging text-rich, multi-image evaluations. Remarkably, our approach achieves outstanding performance using only 1.2M training instances, all of which are fully open-sourced, demonstrating both high efficiency and effectiveness compared to models trained on large-scale in-house data. Our code and data are available at https://github.com/tencent-ailab/Leopard.",
    "authors": [
      "Mengzhao Jia, Wenhao Yu, Kaixin Ma, Tianqing Fang, Zhihan Zhang, Siru Ouyang, Hongming Zhang, Dong Yu, Meng Jiang"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.839570"
  },
  {
    "id": "oai:arXiv.org:2410.02701v2",
    "journal": "arXiv_CS",
    "title": "Impact of a reclassification of Web of Science articles on bibliometric indicators",
    "link": "https://arxiv.org/abs/2410.02701",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2410.02701v2 Announce Type: replace \nAbstract: This work aims at evaluating a reclassification of Web of Science articles implemented at OST. Articles from the 254 scientific categories of the Web of Science were reclassified at article level in 242 modified categories and 11 disciplines using the method of S. Milojevi\\'c (2020). The reclassification is based on paper references categories and it no longer assigns papers to multiple or to multidisciplinary categories. It improves the accuracy and the modularity of the WoS classification. As there are important changes in document assignment at the lowest level, usual indicators such as disciplinary profiles or field normalized indicators are significantly modified. This study examines some of these modifications to provide explanations for the recipients of OST reports. Changes in specialization indexes reveal specific journal choices by scientists. In a sample of 25 countries, Brazil and China offer examples of facilities or constraints for selecting journals to publish certain research works.",
    "authors": [
      "Ag\\'enor Lahatte, \\'Elisabeth de Turckheim"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.839579"
  },
  {
    "id": "oai:arXiv.org:2410.02958v2",
    "journal": "arXiv_CS",
    "title": "AutoML-Agent: A Multi-Agent LLM Framework for Full-Pipeline AutoML",
    "link": "https://arxiv.org/abs/2410.02958",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2410.02958v2 Announce Type: replace \nAbstract: Automated machine learning (AutoML) accelerates AI development by automating tasks in the development pipeline, such as optimal model search and hyperparameter tuning. Existing AutoML systems often require technical expertise to set up complex tools, which is in general time-consuming and requires a large amount of human effort. Therefore, recent works have started exploiting large language models (LLM) to lessen such burden and increase the usability of AutoML frameworks via a natural language interface, allowing non-expert users to build their data-driven solutions. These methods, however, are usually designed only for a particular process in the AI development pipeline and do not efficiently use the inherent capacity of the LLMs. This paper proposes AutoML-Agent, a novel multi-agent framework tailored for full-pipeline AutoML, i.e., from data retrieval to model deployment. AutoML-Agent takes user's task descriptions, facilitates collaboration between specialized LLM agents, and delivers deployment-ready models. Unlike existing work, instead of devising a single plan, we introduce a retrieval-augmented planning strategy to enhance exploration to search for more optimal plans. We also decompose each plan into sub-tasks (e.g., data preprocessing and neural network design) each of which is solved by a specialized agent we build via prompting executing in parallel, making the search process more efficient. Moreover, we propose a multi-stage verification to verify executed results and guide the code generation LLM in implementing successful solutions. Extensive experiments on seven downstream tasks using fourteen datasets show that AutoML-Agent achieves a higher success rate in automating the full AutoML process, yielding systems with good performance throughout the diverse domains.",
    "authors": [
      "Patara Trirat, Wonyong Jeong, Sung Ju Hwang"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.839588"
  },
  {
    "id": "oai:arXiv.org:2410.07642v2",
    "journal": "arXiv_CS",
    "title": "Improving Numerical Stability of Normalized Mutual Information Estimator on High Dimensions",
    "link": "https://arxiv.org/abs/2410.07642",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2410.07642v2 Announce Type: replace \nAbstract: Mutual information provides a powerful, general-purpose metric for quantifying the amount of shared information between variables. Estimating normalized mutual information using a k-Nearest Neighbor (k-NN) based approach involves the calculation of the scaling-invariant k-NN radius. Calculation of the radius suffers from numerical overflow when the joint dimensionality of the data becomes high, typically in the range of several hundred dimensions. To address this issue, we propose a logarithmic transformation technique that improves the numerical stability of the radius calculation in high-dimensional spaces. By applying the proposed transformation during the calculation of the radius, numerical overflow is avoided, and precision is maintained. Proposed transformation is validated through both theoretical analysis and empirical evaluation, demonstrating its ability to stabilize the calculation without compromising precision, increasing bias, or adding significant computational overhead, while also helping to maintain estimator variance.",
    "authors": [
      "Marko Tuononen, Ville Hautam\\\"aki"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.839606"
  },
  {
    "id": "oai:arXiv.org:2410.08811v2",
    "journal": "arXiv_CS",
    "title": "PoisonBench: Assessing Large Language Model Vulnerability to Data Poisoning",
    "link": "https://arxiv.org/abs/2410.08811",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2410.08811v2 Announce Type: replace \nAbstract: Preference learning is a central component for aligning current LLMs, but this process can be vulnerable to data poisoning attacks. To address this concern, we introduce PoisonBench, a benchmark for evaluating large language models' susceptibility to data poisoning during preference learning. Data poisoning attacks can manipulate large language model responses to include hidden malicious content or biases, potentially causing the model to generate harmful or unintended outputs while appearing to function normally. We deploy two distinct attack types across eight realistic scenarios, assessing 21 widely-used models. Our findings reveal concerning trends: (1) Scaling up parameter size does not inherently enhance resilience against poisoning attacks; (2) There exists a log-linear relationship between the effects of the attack and the data poison ratio; (3) The effect of data poisoning can generalize to extrapolated triggers that are not included in the poisoned data. These results expose weaknesses in current preference learning techniques, highlighting the urgent need for more robust defenses against malicious models and data manipulation.",
    "authors": [
      "Tingchen Fu, Mrinank Sharma, Philip Torr, Shay B. Cohen, David Krueger, Fazl Barez"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.839629"
  },
  {
    "id": "oai:arXiv.org:2410.11165v4",
    "journal": "arXiv_CS",
    "title": "Toward Efficient Kernel-Based Solvers for Nonlinear PDEs",
    "link": "https://arxiv.org/abs/2410.11165",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2410.11165v4 Announce Type: replace \nAbstract: We introduce a novel kernel learning framework toward efficiently solving nonlinear partial differential equations (PDEs). In contrast to the state-of-the-art kernel solver that embeds differential operators within kernels, posing challenges with a large number of collocation points, our approach eliminates these operators from the kernel. We model the solution using a standard kernel interpolation form and differentiate the interpolant to compute the derivatives. Our framework obviates the need for complex Gram matrix construction between solutions and their derivatives, allowing for a straightforward implementation and scalable computation. As an instance, we allocate the collocation points on a grid and adopt a product kernel, which yields a Kronecker product structure in the interpolation. This structure enables us to avoid computing the full Gram matrix, reducing costs and scaling efficiently to a large number of collocation points. We provide a proof of the convergence and rate analysis of our method under appropriate regularity assumptions. In numerical experiments, we demonstrate the advantages of our method in solving several benchmark PDEs.",
    "authors": [
      "Zhitong Xu, Da Long, Yiming Xu, Guang Yang, Shandian Zhe, Houman Owhadi"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.839638"
  },
  {
    "id": "oai:arXiv.org:2410.13392v3",
    "journal": "arXiv_CS",
    "title": "Judgment of Learning: A Human Ability Beyond Generative Artificial Intelligence",
    "link": "https://arxiv.org/abs/2410.13392",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2410.13392v3 Announce Type: replace \nAbstract: Large language models (LLMs) increasingly mimic human cognition in various language-based tasks. However, their capacity for metacognition - particularly in predicting memory performance - remains unexplored. Here, we introduce a cross-agent prediction model to assess whether ChatGPT-based LLMs align with human judgments of learning (JOL), a metacognitive measure where individuals predict their own future memory performance. We tested humans and LLMs on pairs of sentences, one of which was a garden-path sentence - a sentence that initially misleads the reader toward an incorrect interpretation before requiring reanalysis. By manipulating contextual fit (fitting vs. unfitting sentences), we probed how intrinsic cues (i.e., relatedness) affect both LLM and human JOL. Our results revealed that while human JOL reliably predicted actual memory performance, none of the tested LLMs (GPT-3.5-turbo, GPT-4-turbo, and GPT-4o) demonstrated comparable predictive accuracy. This discrepancy emerged regardless of whether sentences appeared in fitting or unfitting contexts. These findings indicate that, despite LLMs' demonstrated capacity to model human cognition at the object-level, they struggle at the meta-level, failing to capture the variability in individual memory predictions. By identifying this shortcoming, our study underscores the need for further refinements in LLMs' self-monitoring abilities, which could enhance their utility in educational settings, personalized learning, and human-AI interactions. Strengthening LLMs' metacognitive performance may reduce the reliance on human oversight, paving the way for more autonomous and seamless integration of AI into tasks requiring deeper cognitive awareness.",
    "authors": [
      "Markus Huff, Elanur Ulak\\c{c}{\\i}"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.839647"
  },
  {
    "id": "oai:arXiv.org:2410.14477v2",
    "journal": "arXiv_CS",
    "title": "Laplace Transform Based Low-Complexity Learning of Continuous Markov Semigroups",
    "link": "https://arxiv.org/abs/2410.14477",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2410.14477v2 Announce Type: replace \nAbstract: Markov processes serve as a universal model for many real-world random processes. This paper presents a data-driven approach for learning these models through the spectral decomposition of the infinitesimal generator (IG) of the Markov semigroup. The unbounded nature of IGs complicates traditional methods such as vector-valued regression and Hilbert-Schmidt operator analysis. Existing techniques, including physics-informed kernel regression, are computationally expensive and limited in scope, with no recovery guarantees for transfer operator methods when the time-lag is small. We propose a novel method that leverages the IG's resolvent, characterized by the Laplace transform of transfer operators. This approach is robust to time-lag variations, ensuring accurate eigenvalue learning even for small time-lags. Our statistical analysis applies to a broader class of Markov processes than current methods while reducing computational complexity from quadratic to linear in the state dimension. Finally, we illustrate the behaviour of our method in two experiments.",
    "authors": [
      "Vladimir R. Kostic, Karim Lounici, H\\'el\\`ene Halconruy, Timoth\\'ee Devergne, Pietro Novelli, Massimiliano Pontil"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.839656"
  },
  {
    "id": "oai:arXiv.org:2410.22118v3",
    "journal": "arXiv_CS",
    "title": "The Impact of Inference Acceleration on Bias of LLMs",
    "link": "https://arxiv.org/abs/2410.22118",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2410.22118v3 Announce Type: replace \nAbstract: Last few years have seen unprecedented advances in capabilities of Large Language Models (LLMs). These advancements promise to benefit a vast array of application domains. However, due to their immense size, performing inference with LLMs is both costly and slow. Consequently, a plethora of recent work has proposed strategies to enhance inference efficiency, e.g., quantization, pruning, and caching. These acceleration strategies reduce the inference cost and latency, often by several factors, while maintaining much of the predictive performance measured via common benchmarks. In this work, we explore another critical aspect of LLM performance: demographic bias in model generations due to inference acceleration optimizations. Using a wide range of metrics, we probe bias in model outputs from a number of angles. Analysis of outputs before and after inference acceleration shows significant change in bias. Worryingly, these bias effects are complex and unpredictable. A combination of an acceleration strategy and bias type may show little bias change in one model but may lead to a large effect in another. Our results highlight a need for in-depth and case-by-case evaluation of model bias after it has been modified to accelerate inference.",
    "authors": [
      "Elisabeth Kirsten, Ivan Habernal, Vedant Nanda, Muhammad Bilal Zafar"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.839695"
  },
  {
    "id": "oai:arXiv.org:2410.22318v3",
    "journal": "arXiv_CS",
    "title": "Online Detection of LLM-Generated Texts via Sequential Hypothesis Testing by Betting",
    "link": "https://arxiv.org/abs/2410.22318",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2410.22318v3 Announce Type: replace \nAbstract: Developing algorithms to differentiate between machine-generated texts and human-written texts has garnered substantial attention in recent years. Existing methods in this direction typically concern an offline setting where a dataset containing a mix of real and machine-generated texts is given upfront, and the task is to determine whether each sample in the dataset is from a large language model (LLM) or a human. However, in many practical scenarios, sources such as news websites, social media accounts, and online forums publish content in a streaming fashion. Therefore, in this online scenario, how to quickly and accurately determine whether the source is an LLM with strong statistical guarantees is crucial for these media or platforms to function effectively and prevent the spread of misinformation and other potential misuse of LLMs. To tackle the problem of online detection, we develop an algorithm based on the techniques of sequential hypothesis testing by betting that not only builds upon and complements existing offline detection techniques but also enjoys statistical guarantees, which include a controlled false positive rate and the expected time to correctly identify a source as an LLM. Experiments were conducted to demonstrate the effectiveness of our method.",
    "authors": [
      "Can Chen, Jun-Kun Wang"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.839703"
  },
  {
    "id": "oai:arXiv.org:2410.23330v2",
    "journal": "arXiv_CS",
    "title": "CLIPErase: Efficient Unlearning of Visual-Textual Associations in CLIP",
    "link": "https://arxiv.org/abs/2410.23330",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2410.23330v2 Announce Type: replace \nAbstract: Machine unlearning (MU) has gained significant attention as a means to remove specific data from trained models without requiring a full retraining process. While progress has been made in unimodal domains like text and image classification, unlearning in multimodal models remains relatively underexplored. In this work, we address the unique challenges of unlearning in CLIP, a prominent multimodal model that aligns visual and textual representations. We introduce CLIPErase, a novel approach that disentangles and selectively forgets both visual and textual associations, ensuring that unlearning does not compromise model performance. CLIPErase consists of three key modules: a Forgetting Module that disrupts the associations in the forget set, a Retention Module that preserves performance on the retain set, and a Consistency Module that maintains consistency with the original model. Extensive experiments on the CIFAR-100 and Flickr30K datasets across four CLIP downstream tasks demonstrate that CLIPErase effectively forgets designated associations in zero-shot tasks for multimodal samples, while preserving the model's performance on the retain set after unlearning.",
    "authors": [
      "Tianyu Yang, Lisen Dai, Xiangqi Wang, Minhao Cheng, Yapeng Tian, Xiangliang Zhang"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.839712"
  },
  {
    "id": "oai:arXiv.org:2411.07722v2",
    "journal": "arXiv_CS",
    "title": "Is Cognition Consistent with Perception? Assessing and Mitigating Multimodal Knowledge Conflicts in Document Understanding",
    "link": "https://arxiv.org/abs/2411.07722",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2411.07722v2 Announce Type: replace \nAbstract: Multimodal large language models (MLLMs) have shown impressive capabilities in document understanding, a rapidly growing research area with significant industrial demand. As a multimodal task, document understanding requires models to possess both perceptual and cognitive abilities. However, due to different types of annotation noise in training, current MLLMs often face conflicts between perception and cognition. Taking a document VQA task (cognition) as an example, an MLLM might generate answers that do not match the corresponding visual content identified by its OCR (perception). This conflict suggests that the MLLM might struggle to establish an intrinsic connection between the information it \"sees\" and what it \"understands\". Such conflicts challenge the intuitive notion that cognition is consistent with perception, hindering the performance and explainability of MLLMs. In this paper, we define the conflicts between cognition and perception as Cognition and Perception (C&amp;P) knowledge conflicts, a form of multimodal knowledge conflict, and systematically assess them with a focus on document understanding. Our analysis reveals that even GPT-4o, a leading MLLM, achieves only 75.26% C&amp;P consistency. To mitigate the C&amp;P knowledge conflicts, we propose a novel method called Multimodal Knowledge Consistency Fine-tuning. Our method reduces C&amp;P knowledge conflicts across all tested MLLMs and enhances their performance in both cognitive and perceptual tasks. All data we construct will be publicly available.",
    "authors": [
      "Zirui Shao, Feiyu Gao, Zhaoqing Zhu, Chuwei Luo, Hangdi Xing, Zhi Yu, Qi Zheng, Ming Yan, Jiajun Bu"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.839721"
  },
  {
    "id": "oai:arXiv.org:2411.08638v3",
    "journal": "arXiv_CS",
    "title": "Graph Neural Network Generalization with Gaussian Mixture Model Based Augmentation",
    "link": "https://arxiv.org/abs/2411.08638",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2411.08638v3 Announce Type: replace \nAbstract: Graph Neural Networks (GNNs) have shown great promise in tasks like node and graph classification, but they often struggle to generalize, particularly to unseen or out-of-distribution (OOD) data. These challenges are exacerbated when training data is limited in size or diversity. To address these issues, we introduce a theoretical framework using Rademacher complexity to compute a regret bound on the generalization error and then characterize the effect of data augmentation. This framework informs the design of GRATIN, an efficient graph data augmentation algorithm leveraging the capability of Gaussian Mixture Models (GMMs) to approximate any distribution. Our approach not only outperforms existing augmentation techniques in terms of generalization but also offers improved time complexity, making it highly suitable for real-world applications.",
    "authors": [
      "Yassine Abbahaddou, Fragkiskos D. Malliaros, Johannes F. Lutzeyer, Amine Mohamed Aboussalah, Michalis Vazirgiannis"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.839730"
  },
  {
    "id": "oai:arXiv.org:2411.10298v3",
    "journal": "arXiv_CS",
    "title": "Unveiling Topological Structures from Language: A Comprehensive Survey of Topological Data Analysis Applications in NLP",
    "link": "https://arxiv.org/abs/2411.10298",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2411.10298v3 Announce Type: replace \nAbstract: The surge of data available on the internet has led to the adoption of various computational methods to analyze and extract valuable insights from this wealth of information. Among these, the field of Machine Learning (ML) has thrived by leveraging data to extract meaningful insights. However, ML techniques face notable challenges when dealing with real-world data, often due to issues of imbalance, noise, insufficient labeling, and high dimensionality. To address these limitations, some researchers advocate for the adoption of Topological Data Analysis (TDA), a statistical approach that discerningly captures the intrinsic shape of data despite noise. Despite its potential, TDA has not gained as much traction within the Natural Language Processing (NLP) domain compared to structurally distinct areas like computer vision. Nevertheless, a dedicated community of researchers has been exploring the application of TDA in NLP, yielding 95 papers we comprehensively survey in this paper. Our findings categorize these efforts into theoretical and non-theoretical approaches. Theoretical approaches aim to explain linguistic phenomena from a topological viewpoint, while non-theoretical approaches merge TDA with ML features, utilizing diverse numerical representation techniques. We conclude by exploring the challenges and unresolved questions that persist in this niche field. Resources and a list of papers on this topic can be found at: https://github.com/AdaUchendu/AwesomeTDA4NLP.",
    "authors": [
      "Adaku Uchendu, Thai Le"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.839747"
  },
  {
    "id": "oai:arXiv.org:2411.10685v2",
    "journal": "arXiv_CS",
    "title": "From Prototypes to General Distributions: An Efficient Curriculum for Masked Image Modeling",
    "link": "https://arxiv.org/abs/2411.10685",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2411.10685v2 Announce Type: replace \nAbstract: Masked Image Modeling (MIM) has emerged as a powerful self-supervised learning paradigm for visual representation learning, enabling models to acquire rich visual representations by predicting masked portions of images from their visible regions. While this approach has shown promising results, we hypothesize that its effectiveness may be limited by optimization challenges during early training stages, where models are expected to learn complex image distributions from partial observations before developing basic visual processing capabilities. To address this limitation, we propose a prototype-driven curriculum leagrning framework that structures the learning process to progress from prototypical examples to more complex variations in the dataset. Our approach introduces a temperature-based annealing scheme that gradually expands the training distribution, enabling more stable and efficient learning trajectories. Through extensive experiments on ImageNet-1K, we demonstrate that our curriculum learning strategy significantly improves both training efficiency and representation quality while requiring substantially fewer training epochs compared to standard Masked Auto-Encoding. Our findings suggest that carefully controlling the order of training examples plays a crucial role in self-supervised visual learning, providing a practical solution to the early-stage optimization challenges in MIM.",
    "authors": [
      "Jinhong Lin, Cheng-En Wu, Huanran Li, Jifan Zhang, Yu Hen Hu, Pedro Morgado"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.839756"
  },
  {
    "id": "oai:arXiv.org:2411.11428v2",
    "journal": "arXiv_CS",
    "title": "Weak Simplicial Bisimilarity and Minimisation for Polyhedral Model Checking",
    "link": "https://arxiv.org/abs/2411.11428",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2411.11428v2 Announce Type: replace \nAbstract: The work described in this paper builds on the polyhedral semantics of the Spatial Logic for Closure Spaces (SLCS) and the geometric spatial model checker PolyLogicA. Polyhedral models are central in domains that exploit mesh processing, such as 3D computer graphics. A discrete representation of polyhedral models is given by cell poset models, which are amenable to geometric spatial model checking on polyhedral models using the logical language SLCS$\\eta$, a weaker version of SLCS, where by ``weak'' we mean that the relevant equivalence is coarser than the corresponding one for SLCS, leading to a greater reduction of the size of models and thus to more efficient model checking. We show that the proposed bisimilarities enjoy the Hennessy-Milner property, i.e. two points are weakly simplicial bisimilar if and only if they are logically equivalent for SLCS$\\eta$. Similarly, two cells are weakly $\\pm$-bisimilar if and only if they are logically equivalent in the poset-model interpretation of SLCS$\\eta$. Furthermore we present a model minimisation procedure, and prove that it correctly computes the minimal model with respect to weak $\\pm$-bisimilarity, i.e. with respect to logical equivalence of SLCS$\\eta$. The procedure works via an encoding into LTSs and then exploits branching bisimilarity on those LTSs, exploiting the minimisation capabilities as included in the mCRL2 toolset. Various examples show the effectiveness of the approach.",
    "authors": [
      "Nick Bezhanishvili, Laura Bussi, Vincenzo Ciancia, David Gabelaia, Mamuka Jibladze, Diego Latella, Mieke Massink, Erik P. de Vink"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.839765"
  },
  {
    "id": "oai:arXiv.org:2411.12019v2",
    "journal": "arXiv_CS",
    "title": "Regret-Free Reinforcement Learning for LTL Specifications",
    "link": "https://arxiv.org/abs/2411.12019",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2411.12019v2 Announce Type: replace \nAbstract: Learning to control an unknown dynamical system with respect to high-level temporal specifications is an important problem in control theory. We present the first regret-free online algorithm for learning a controller for linear temporal logic (LTL) specifications for systems with unknown dynamics. We assume that the underlying (unknown) dynamics is modeled by a finite-state and action Markov decision process (MDP). Our core technical result is a regret-free learning algorithm for infinite-horizon reach-avoid problems on MDPs. For general LTL specifications, we show that the synthesis problem can be reduced to a reach-avoid problem once the graph structure is known. Additionally, we provide an algorithm for learning the graph structure, assuming knowledge of a minimum transition probability, which operates independently of the main regret-free algorithm. Our LTL controller synthesis algorithm provides sharp bounds on how close we are to achieving optimal behavior after a finite number of learning episodes. In contrast, previous algorithms for LTL synthesis only provide asymptotic guarantees, which give no insight into the transient performance during the learning phase.",
    "authors": [
      "Rupak Majumdar, Mahmoud Salamati, Sadegh Soudjani"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.839773"
  },
  {
    "id": "oai:arXiv.org:2411.12882v3",
    "journal": "arXiv_CS",
    "title": "ProSec: Fortifying Code LLMs with Proactive Security Alignment",
    "link": "https://arxiv.org/abs/2411.12882",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2411.12882v3 Announce Type: replace \nAbstract: While recent code-specific large language models (LLMs) have greatly enhanced their code generation capabilities, the safety of these models remains under-explored, posing potential risks as insecure code generated by these models may introduce vulnerabilities into real-world systems. Existing methods collect security-focused datasets from real-world vulnerabilities for instruction tuning in order to mitigate such issues. However, they are largely constrained by the data sparsity of vulnerable code, and have limited applicability in the multi-stage post-training workflows of modern LLMs. In this paper, we propose ProSec, a novel proactive security alignment approach designed to align code LLMs with secure coding practices. ProSec systematically exposes the vulnerabilities in a code LLM by synthesizing vulnerability-inducing coding scenarios from Common Weakness Enumerations (CWEs) and generates fixes to vulnerable code snippets, allowing the model to learn secure practices through preference learning objectives. The scenarios synthesized by ProSec trigger 25x more vulnerable code than a normal instruction-tuning dataset, resulting in a security-focused alignment dataset 7x larger than the previous work. Experiments show that models trained with ProSec are 25.2% to 35.4% more secure compared to previous work without degrading models' utility.",
    "authors": [
      "Xiangzhe Xu, Zian Su, Jinyao Guo, Kaiyuan Zhang, Zhenting Wang, Xiangyu Zhang"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.839782"
  },
  {
    "id": "oai:arXiv.org:2411.13985v2",
    "journal": "arXiv_CS",
    "title": "Representing Hypergraphs by Point-Line Incidences",
    "link": "https://arxiv.org/abs/2411.13985",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2411.13985v2 Announce Type: replace \nAbstract: We consider hypergraph visualizations that represent vertices as points in the plane and hyperedges as curves passing through the points of their incident vertices. Specifically, we consider several different variants of this problem by (a) restricting the curves to be lines or line segments, (b) allowing two curves to cross if they do not share an element, or not; and (c) allowing two curves to overlap or not. We show $\\exists\\mathbb{R}$-hardness for six of the eight resulting decision problem variants and describe polynomial-time algorithms in some restricted settings. Lastly, we briefly touch on what happens if we allow the lines of the represented hyperedges to have bends - to this we generalize a counterexample to a long-standing result that was sometimes assumed to be correct.",
    "authors": [
      "Alexander Dobler, Stephen Kobourov, Debajyoti Mondal, Martin N\\\"ollenburg"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.839790"
  },
  {
    "id": "oai:arXiv.org:2411.14842v2",
    "journal": "arXiv_CS",
    "title": "Who Can Withstand Chat-Audio Attacks? An Evaluation Benchmark for Large Audio-Language Models",
    "link": "https://arxiv.org/abs/2411.14842",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2411.14842v2 Announce Type: replace \nAbstract: Adversarial audio attacks pose a significant threat to the growing use of large audio-language models (LALMs) in voice-based human-machine interactions. While existing research focused on model-specific adversarial methods, real-world applications demand a more generalizable and universal approach to audio adversarial attacks. In this paper, we introduce the Chat-Audio Attacks (CAA) benchmark including four distinct types of audio attacks, which aims to explore the vulnerabilities of LALMs to these audio attacks in conversational scenarios. To evaluate the robustness of LALMs, we propose three evaluation strategies: Standard Evaluation, utilizing traditional metrics to quantify model performance under attacks; GPT-4o-Based Evaluation, which simulates real-world conversational complexities; and Human Evaluation, offering insights into user perception and trust. We evaluate six state-of-the-art LALMs with voice interaction capabilities, including Gemini-1.5-Pro, GPT-4o, and others, using three distinct evaluation methods on the CAA benchmark. Our comprehensive analysis reveals the impact of four types of audio attacks on the performance of these models, demonstrating that GPT-4o exhibits the highest level of resilience. Our data can be accessed via the following link: \\href{https://github.com/crystraldo/CAA}{CAA}.",
    "authors": [
      "Wanqi Yang, Yanda Li, Meng Fang, Yunchao Wei, Ling Chen"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.839799"
  },
  {
    "id": "oai:arXiv.org:2411.16525v2",
    "journal": "arXiv_CS",
    "title": "Fundamental Limits of Prompt Tuning Transformers: Universality, Capacity and Efficiency",
    "link": "https://arxiv.org/abs/2411.16525",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2411.16525v2 Announce Type: replace \nAbstract: We investigate the statistical and computational limits of prompt tuning for transformer-based foundation models. Our key contributions are prompt tuning on \\emph{single-head} transformers with only a \\emph{single} self-attention layer: (i) is universal, and (ii) supports efficient (even almost-linear time) algorithms under the Strong Exponential Time Hypothesis (SETH). Statistically, we prove that prompt tuning on such simplest possible transformers are universal approximators for sequence-to-sequence Lipschitz functions. In addition, we provide an exponential-in-$dL$ and -in-$(1/\\epsilon)$ lower bound on the required soft-prompt tokens for prompt tuning to memorize any dataset with 1-layer, 1-head transformers. Computationally, we identify a phase transition in the efficiency of prompt tuning, determined by the norm of the \\emph{soft-prompt-induced} keys and queries, and provide an upper bound criterion. Beyond this criterion, no sub-quadratic (efficient) algorithm for prompt tuning exists under SETH. Within this criterion, we showcase our theory by proving the existence of almost-linear time prompt tuning inference algorithms. These fundamental limits provide important necessary conditions for designing expressive and efficient prompt tuning methods for practitioners.",
    "authors": [
      "Jerry Yao-Chieh Hu, Wei-Po Wang, Ammar Gilani, Chenyang Li, Zhao Song, Han Liu"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.839808"
  },
  {
    "id": "oai:arXiv.org:2412.00789v3",
    "journal": "arXiv_CS",
    "title": "A Cognac shot to forget bad memories: Corrective Unlearning in GNNs",
    "link": "https://arxiv.org/abs/2412.00789",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2412.00789v3 Announce Type: replace \nAbstract: Graph Neural Networks (GNNs) are increasingly being used for a variety of ML applications on graph data. Because graph data does not follow the independently and identically distributed (i.i.d.) assumption, adversarial manipulations or incorrect data can propagate to other data points through message passing, which deteriorates the model's performance. To allow model developers to remove the adverse effects of manipulated entities from a trained GNN, we study the recently formulated problem of Corrective Unlearning. We find that current graph unlearning methods fail to unlearn the effect of manipulations even when the whole manipulated set is known. We introduce a new graph unlearning method, Cognac, which can unlearn the effect of the manipulation set even when only 5% of it is identified. It recovers most of the performance of a strong oracle with fully corrected training data, even beating retraining from scratch without the deletion set while being 8x more efficient. We hope our work assists GNN developers in mitigating harmful effects caused by issues in real-world data, post-training. Our code is publicly available at https://github.com/cognac-gnn-unlearning/corrective-unlearning-for-gnns",
    "authors": [
      "Varshita Kolipaka, Akshit Sinha, Debangan Mishra, Sumit Kumar, Arvindh Arun, Shashwat Goel, Ponnurangam Kumaraguru"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.839816"
  },
  {
    "id": "oai:arXiv.org:2412.01496v2",
    "journal": "arXiv_CS",
    "title": "Fr\\'echet Radiomic Distance (FRD): A Versatile Metric for Comparing Medical Imaging Datasets",
    "link": "https://arxiv.org/abs/2412.01496",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2412.01496v2 Announce Type: replace \nAbstract: Determining whether two sets of images belong to the same or different distributions or domains is a crucial task in modern medical image analysis and deep learning; for example, to evaluate the output quality of image generative models. Currently, metrics used for this task either rely on the (potentially biased) choice of some downstream task, such as segmentation, or adopt task-independent perceptual metrics (e.g., Fr\\'echet Inception Distance/FID) from natural imaging, which we show insufficiently capture anatomical features. To this end, we introduce a new perceptual metric tailored for medical images, FRD (Fr\\'echet Radiomic Distance), which utilizes standardized, clinically meaningful, and interpretable image features. We show that FRD is superior to other image distribution metrics for a range of medical imaging applications, including out-of-domain (OOD) detection, the evaluation of image-to-image translation (by correlating more with downstream task performance as well as anatomical consistency and realism), and the evaluation of unconditional image generation. Moreover, FRD offers additional benefits such as stability and computational efficiency at low sample sizes, sensitivity to image corruptions and adversarial attacks, feature interpretability, and correlation with radiologist-perceived image quality. Additionally, we address key gaps in the literature by presenting an extensive framework for the multifaceted evaluation of image similarity metrics in medical imaging -- including the first large-scale comparative study of generative models for medical image translation -- and release an accessible codebase to facilitate future research. Our results are supported by thorough experiments spanning a variety of datasets, modalities, and downstream tasks, highlighting the broad potential of FRD for medical image analysis.",
    "authors": [
      "Nicholas Konz, Richard Osuala, Preeti Verma, Yuwen Chen, Hanxue Gu, Haoyu Dong, Yaqian Chen, Andrew Marshall, Lidia Garrucho, Kaisar Kushibar, Daniel M. Lang, Gene S. Kim, Lars J. Grimm, John M. Lewin, James S. Duncan, Julia A. Schnabel, Oliver Diaz, Karim Lekadir, Maciej A. Mazurowski"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.839825"
  },
  {
    "id": "oai:arXiv.org:2412.04140v3",
    "journal": "arXiv_CS",
    "title": "Understanding Memorization in Generative Models via Sharpness in Probability Landscapes",
    "link": "https://arxiv.org/abs/2412.04140",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2412.04140v3 Announce Type: replace \nAbstract: In this paper, we introduce a geometric framework to analyze memorization in diffusion models through the sharpness of the log probability density. We mathematically justify a previously proposed score-difference-based memorization metric by demonstrating its effectiveness in quantifying sharpness. Additionally, we propose a novel memorization metric that captures sharpness at the initial stage of image generation in latent diffusion models, offering early insights into potential memorization. Leveraging this metric, we develop a mitigation strategy that optimizes the initial noise of the generation process using a sharpness-aware regularization term.",
    "authors": [
      "Dongjae Jeon, Dueun Kim, Albert No"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.839834"
  },
  {
    "id": "oai:arXiv.org:2412.05278v2",
    "journal": "arXiv_CS",
    "title": "Birth and Death of a Rose",
    "link": "https://arxiv.org/abs/2412.05278",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2412.05278v2 Announce Type: replace \nAbstract: We study the problem of generating temporal object intrinsics -- temporally evolving sequences of object geometry, reflectance, and texture, such as a blooming rose -- from pre-trained 2D foundation models. Unlike conventional 3D modeling and animation techniques that require extensive manual effort and expertise, we introduce a method that generates such assets with signals distilled from pre-trained 2D diffusion models. To ensure the temporal consistency of object intrinsics, we propose Neural Templates for temporal-state-guided distillation, derived automatically from image features from self-supervised learning. Our method can generate high-quality temporal object intrinsics for several natural phenomena and enable the sampling and controllable rendering of these dynamic objects from any viewpoint, under any environmental lighting conditions, at any time of their lifespan. Project website: https://chen-geng.com/rose4d",
    "authors": [
      "Chen Geng, Yunzhi Zhang, Shangzhe Wu, Jiajun Wu"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.839842"
  },
  {
    "id": "oai:arXiv.org:2412.06329v3",
    "journal": "arXiv_CS",
    "title": "Normalizing Flows are Capable Generative Models",
    "link": "https://arxiv.org/abs/2412.06329",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2412.06329v3 Announce Type: replace \nAbstract: Normalizing Flows (NFs) are likelihood-based models for continuous inputs. They have demonstrated promising results on both density estimation and generative modeling tasks, but have received relatively little attention in recent years. In this work, we demonstrate that NFs are more powerful than previously believed. We present TarFlow: a simple and scalable architecture that enables highly performant NF models. TarFlow can be thought of as a Transformer-based variant of Masked Autoregressive Flows (MAFs): it consists of a stack of autoregressive Transformer blocks on image patches, alternating the autoregression direction between layers. TarFlow is straightforward to train end-to-end, and capable of directly modeling and generating pixels. We also propose three key techniques to improve sample quality: Gaussian noise augmentation during training, a post training denoising procedure, and an effective guidance method for both class-conditional and unconditional settings. Putting these together, TarFlow sets new state-of-the-art results on likelihood estimation for images, beating the previous best methods by a large margin, and generates samples with quality and diversity comparable to diffusion models, for the first time with a stand-alone NF model. We make our code available at https://github.com/apple/ml-tarflow.",
    "authors": [
      "Shuangfei Zhai, Ruixiang Zhang, Preetum Nakkiran, David Berthelot, Jiatao Gu, Huangjie Zheng, Tianrong Chen, Miguel Angel Bautista, Navdeep Jaitly, Josh Susskind"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.839850"
  },
  {
    "id": "oai:arXiv.org:2412.06877v2",
    "journal": "arXiv_CS",
    "title": "The Synergy of LLMs & RL Unlocks Offline Learning of Generalizable Language-Conditioned Policies with Low-fidelity Data",
    "link": "https://arxiv.org/abs/2412.06877",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2412.06877v2 Announce Type: replace \nAbstract: Developing autonomous agents capable of performing complex, multi-step decision-making tasks specified in natural language remains a significant challenge, particularly in realistic settings where labeled data is scarce and real-time experimentation is impractical. Existing reinforcement learning (RL) approaches often struggle to generalize to unseen goals and states, limiting their applicability. In this paper, we introduce TEDUO, a novel training pipeline for offline language-conditioned policy learning in symbolic environments. Unlike conventional methods, TEDUO operates on readily available, unlabeled datasets and addresses the challenge of generalization to previously unseen goals and states. Our approach harnesses large language models (LLMs) in a dual capacity: first, as automatization tools augmenting offline datasets with richer annotations, and second, as generalizable instruction-following agents. Empirical results demonstrate that TEDUO achieves data-efficient learning of robust language-conditioned policies, accomplishing tasks beyond the reach of conventional RL frameworks or out-of-the-box LLMs alone.",
    "authors": [
      "Thomas Pouplin, Katarzyna Kobalczyk, Hao Sun, Mihaela van der Schaar"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.839859"
  },
  {
    "id": "oai:arXiv.org:2412.09625v2",
    "journal": "arXiv_CS",
    "title": "Illusion3D: 3D Multiview Illusion with 2D Diffusion Priors",
    "link": "https://arxiv.org/abs/2412.09625",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2412.09625v2 Announce Type: replace \nAbstract: Automatically generating multiview illusions is a compelling challenge, where a single piece of visual content offers distinct interpretations from different viewing perspectives. Traditional methods, such as shadow art and wire art, create interesting 3D illusions but are limited to simple visual outputs (i.e., figure-ground or line drawing), restricting their artistic expressiveness and practical versatility. Recent diffusion-based illusion generation methods can generate more intricate designs but are confined to 2D images. In this work, we present a simple yet effective approach for creating 3D multiview illusions based on user-provided text prompts or images. Our method leverages a pre-trained text-to-image diffusion model to optimize the textures and geometry of neural 3D representations through differentiable rendering. When viewed from multiple angles, this produces different interpretations. We develop several techniques to improve the quality of the generated 3D multiview illusions. We demonstrate the effectiveness of our approach through extensive experiments and showcase illusion generation with diverse 3D forms.",
    "authors": [
      "Yue Feng, Vaibhav Sanjay, Spencer Lutz, Badour AlBahar, Songwei Ge, Jia-Bin Huang"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.839875"
  },
  {
    "id": "oai:arXiv.org:2412.10345v3",
    "journal": "arXiv_CS",
    "title": "TraceVLA: Visual Trace Prompting Enhances Spatial-Temporal Awareness for Generalist Robotic Policies",
    "link": "https://arxiv.org/abs/2412.10345",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2412.10345v3 Announce Type: replace \nAbstract: Although large vision-language-action (VLA) models pretrained on extensive robot datasets offer promising generalist policies for robotic learning, they still struggle with spatial-temporal dynamics in interactive robotics, making them less effective in handling complex tasks, such as manipulation. In this work, we introduce visual trace prompting, a simple yet effective approach to facilitate VLA models' spatial-temporal awareness for action prediction by encoding state-action trajectories visually. We develop a new TraceVLA model by finetuning OpenVLA on our own collected dataset of 150K robot manipulation trajectories using visual trace prompting. Evaluations of TraceVLA across 137 configurations in SimplerEnv and 4 tasks on a physical WidowX robot demonstrate state-of-the-art performance, outperforming OpenVLA by 10% on SimplerEnv and 3.5x on real-robot tasks and exhibiting robust generalization across diverse embodiments and scenarios. To further validate the effectiveness and generality of our method, we present a compact VLA model based on 4B Phi-3-Vision, pretrained on the Open-X-Embodiment and finetuned on our dataset, rivals the 7B OpenVLA baseline while significantly improving inference efficiency.",
    "authors": [
      "Ruijie Zheng, Yongyuan Liang, Shuaiyi Huang, Jianfeng Gao, Hal Daum\\'e III, Andrey Kolobov, Furong Huang, Jianwei Yang"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.839884"
  },
  {
    "id": "oai:arXiv.org:2412.11014v2",
    "journal": "arXiv_CS",
    "title": "CoopetitiveV: Leveraging LLM-powered Coopetitive Multi-Agent Prompting for High-quality Verilog Generation",
    "link": "https://arxiv.org/abs/2412.11014",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2412.11014v2 Announce Type: replace \nAbstract: Recent advances in agentic LLMs have demonstrated great capabilities in Verilog code generation. However, existing approaches either use LLM-assisted single-agent prompting or cooperation-only multi-agent learning, which will lead to: (i) Degeneration issue for single-agent learning: characterized by diminished error detection and correction capabilities; (ii) Error propagation in cooperation-only multi-agent learning: erroneous information from the former agent will be propagated to the latter through prompts, which can make the latter agents generate buggy code. In this paper, we propose an LLM-based coopetitive multi-agent prompting framework, in which the agents cannot collaborate with each other to form the generation pipeline, but also create a healthy competitive mechanism to improve the generating quality. Our experimental results show that the coopetitive multi-agent framework can effectively mitigate the degeneration risk and reduce the error propagation while improving code error correction capabilities, resulting in higher quality Verilog code generation. The effectiveness of our approach is validated through extensive experiments. On VerilogEval Machine and Human dataset, CoopetitiveV+GPT-4 achieves 99.2% and 99.1% pass@10 scores, respectively. While on RTLLM, CoopetitiveV+GPT-4 obtains 100% syntax and 99.9% functionality pass@5 scores.",
    "authors": [
      "Zhendong Mi, Renming Zheng, Haowen Zhong, Yue Sun, Seth Kneeland, Sayan Moitra, Ken Kutzer, Zhaozhuo Xu Shaoyi Huang"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.839893"
  },
  {
    "id": "oai:arXiv.org:2412.12340v2",
    "journal": "arXiv_CS",
    "title": "A Large Language Model Approach to Identify Flakiness in C++ Projects",
    "link": "https://arxiv.org/abs/2412.12340",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2412.12340v2 Announce Type: replace \nAbstract: The role of regression testing in software testing is crucial as it ensures that any new modifications do not disrupt the existing functionality and behaviour of the software system. The desired outcome is for regression tests to yield identical results without any modifications made to the system being tested. In practice, however, the presence of Flaky Tests introduces non-deterministic behaviour and undermines the reliability of regression testing results.\n  In this paper, we propose an LLM-based approach for identifying the root cause of flaky tests in C++ projects at the code level, with the intention of assisting developers in debugging and resolving them more efficiently. We compile a comprehensive collection of C++ project flaky tests sourced from GitHub repositories. We fine-tune Mistral-7b, Llama2-7b and CodeLlama-7b models on the C++ dataset and an existing Java dataset and evaluate the performance in terms of precision, recall, accuracy, and F1 score. We assess the performance of the models across various datasets and offer recommendations for both research and industry applications.\n  The results indicate that our models exhibit varying performance on the C++ dataset, while their performance is comparable to that of the Java dataset. The Mistral-7b surpasses the other two models regarding all metrics, achieving a score of 1. Our results demonstrate the exceptional capability of LLMs to accurately classify flakiness in C++ and Java projects, providing a promising approach to enhance the efficiency of debugging flaky tests in practice.",
    "authors": [
      "Xin Sun, Daniel St{\\aa}hl, Kristian Sandahl"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.839902"
  },
  {
    "id": "oai:arXiv.org:2412.13540v3",
    "journal": "arXiv_CS",
    "title": "Benchmarking and Improving Large Vision-Language Models for Fundamental Visual Graph Understanding and Reasoning",
    "link": "https://arxiv.org/abs/2412.13540",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2412.13540v3 Announce Type: replace \nAbstract: Large Vision-Language Models (LVLMs) have demonstrated remarkable performance across diverse tasks. Despite great success, recent studies show that LVLMs encounter substantial limitations when engaging with visual graphs. To study the reason behind these limitations, we propose VGCure, a comprehensive benchmark covering 22 tasks for examining the fundamental graph understanding and reasoning capacities of LVLMs. Extensive evaluations conducted on 14 LVLMs reveal that LVLMs are weak in basic graph understanding and reasoning tasks, particularly those concerning relational or structurally complex information. Based on this observation, we propose a structure-aware fine-tuning framework to enhance LVLMs with structure learning abilities through three self-supervised learning tasks. Experiments validate the effectiveness of our method in improving LVLMs' performance on fundamental and downstream graph learning tasks, as well as enhancing their robustness against complex visual graphs.",
    "authors": [
      "Yingjie Zhu, Xuefeng Bai, Kehai Chen, Yang Xiang, Jun Yu, Min Zhang"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.839911"
  },
  {
    "id": "oai:arXiv.org:2412.15118v2",
    "journal": "arXiv_CS",
    "title": "Reasoning Through Execution: Unifying Process and Outcome Rewards for Code Generation",
    "link": "https://arxiv.org/abs/2412.15118",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2412.15118v2 Announce Type: replace \nAbstract: Large Language Models excel at code generation yet struggle with complex programming tasks that demand sophisticated reasoning. To bridge this gap, traditional process supervision relies on learned reward models requiring costly training data and suffering from reward misalignment, while outcome supervision fails for complex tasks needing coordinated intermediate steps. We introduce Outcome Refining Process Supervision, which unifies process and outcome supervision by leveraging executable verification: a tree-structured search framework generates strategic alternatives, profiles execution metrics, and scores candidates via self-critique mechanisms that integrate runtime feedback with reasoning. Experiments across 5 models and 3 benchmarks show consistent gains, with 26.9% higher correctness and 42.2% improved code efficiency. The results demonstrate that ORPS enables LLMs to overcome local optima in code generation, suggesting a promising direction for combining verifiable outcomes with structured reasoning to tackle complex challenges. We open-source at: https://github.com/zhuohaoyu/ORPS",
    "authors": [
      "Zhuohao Yu, Weizheng Gu, Yidong Wang, Xingru Jiang, Zhengran Zeng, Jindong Wang, Wei Ye, Shikun Zhang"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.839920"
  },
  {
    "id": "oai:arXiv.org:2412.17156v2",
    "journal": "arXiv_CS",
    "title": "LLM-based relevance assessment still can't replace human relevance assessment",
    "link": "https://arxiv.org/abs/2412.17156",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2412.17156v2 Announce Type: replace \nAbstract: The use of large language models (LLMs) for relevance assessment in information retrieval has gained significant attention, with recent studies suggesting that LLM-based judgments provide comparable evaluations to human judgments. Notably, based on TREC 2024 data, Upadhyay et al. make a bold claim that LLM-based relevance assessments, such as those generated by the UMBRELA system, can fully replace traditional human relevance assessments in TREC-style evaluations. This paper critically examines this claim, highlighting practical and theoretical limitations that undermine the validity of this conclusion. First, we question whether the evidence provided by Upadhyay et al. really supports their claim, particularly if a test collection is used asa benchmark for future improvements. Second, through a submission deliberately intended to do so, we demonstrate the ease with which automatic evaluation metrics can be subverted, showing that systems designed to exploit these evaluations can achieve artificially high scores. Theoretical challenges -- such as the inherent narcissism of LLMs, the risk of overfitting to LLM-based metrics, and the potential degradation of future LLM performance -- must be addressed before LLM-based relevance assessments can be considered a viable replacement for human judgments.",
    "authors": [
      "Charles L. A. Clarke, Laura Dietz"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.839929"
  },
  {
    "id": "oai:arXiv.org:2412.17318v2",
    "journal": "arXiv_CS",
    "title": "Subspace correction methods for semicoercive and nearly semicoercive convex optimization with applications to nonlinear PDEs",
    "link": "https://arxiv.org/abs/2412.17318",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2412.17318v2 Announce Type: replace \nAbstract: We present new convergence analyses for subspace correction methods for semicoercive and nearly semicoercive convex optimization problems, generalizing the theory of singular and nearly singular linear problems to the nonlinear domain. Our results demonstrate that the elegant theoretical framework developed for singular and nearly singular linear problems can be extended to semicoercive and nearly semicoercive convex optimization problems. For semicoercive problems, we show that the convergence rate can be estimated in terms of a seminorm stable decomposition over the subspaces and the kernel of the problem, aligning with the theory for singular linear problems. For nearly semicoercive problems, we establish a parameter-independent convergence rate, assuming the kernel of the semicoercive part can be decomposed into a sum of local kernels, which aligns with the theory for nearly singular problems. To demonstrate the applicability of our results, we provide convergence analyses of two-level additive Schwarz methods for solving a nonlinear Neumann boundary value problem and its perturbation within the proposed abstract framework.",
    "authors": [
      "Young-Ju Lee, Jongho Park"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.839939"
  },
  {
    "id": "oai:arXiv.org:2412.17767v2",
    "journal": "arXiv_CS",
    "title": "ResearchTown: Simulator of Human Research Community",
    "link": "https://arxiv.org/abs/2412.17767",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2412.17767v2 Announce Type: replace \nAbstract: Large Language Models (LLMs) have demonstrated remarkable potential in scientific domains, yet a fundamental question remains unanswered: Can we simulate human research communities with LLMs? Addressing this question can deepen our understanding of the processes behind idea brainstorming and inspire the automatic discovery of novel scientific insights. In this work, we propose ResearchTown, a multi-agent framework for research community simulation. Within this framework, the human research community is simplified as an agent-data graph, where researchers and papers are represented as agent-type and data-type nodes, respectively, and connected based on their collaboration relationships. We also introduce TextGNN, a text-based inference framework that models various research activities (e.g., paper reading, paper writing, and review writing) as special forms of a unified message-passing process on the agent-data graph. To evaluate the quality of the research community simulation, we present ResearchBench, a benchmark that uses a node-masking prediction task for scalable and objective assessment based on similarity. Our experiments reveal three key findings: (1) ResearchTown can provide a realistic simulation of collaborative research activities, including paper writing and review writing; (2) ResearchTown can maintain robust simulation with multiple researchers and diverse papers; (3) ResearchTown can generate interdisciplinary research ideas that potentially inspire pioneering research directions.",
    "authors": [
      "Haofei Yu, Zhaochen Hong, Zirui Cheng, Kunlun Zhu, Keyang Xuan, Jinwei Yao, Tao Feng, Jiaxuan You"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.839954"
  },
  {
    "id": "oai:arXiv.org:2412.19726v3",
    "journal": "arXiv_CS",
    "title": "Position: Theory of Mind Benchmarks are Broken for Large Language Models",
    "link": "https://arxiv.org/abs/2412.19726",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2412.19726v3 Announce Type: replace \nAbstract: Our paper argues that the majority of theory of mind benchmarks are broken because of their inability to directly test how large language models (LLMs) adapt to new partners. This problem stems from the fact that theory of mind benchmarks for LLMs are overwhelmingly inspired by the methods used to test theory of mind in humans and fall victim to a fallacy of attributing human-like qualities to AI agents. We expect that humans will engage in a consistent reasoning process across various questions about a situation, but this is known to not be the case for current LLMs. Most theory of mind benchmarks only measure what we call literal theory of mind: the ability to predict the behavior of others. However, this type of metric is only informative when agents exhibit self-consistent reasoning. Thus, we introduce the concept of functional theory of mind: the ability to adapt to agents in-context following a rational response to their behavior. We find that many open source LLMs are capable of displaying strong literal theory of mind capabilities, but seem to struggle with functional theory of mind -- even with exceedingly simple partner policies. Simply put, strong literal theory of mind performance does not necessarily imply strong functional theory of mind performance or vice versa. Achieving functional theory of mind, particularly over long interaction horizons with a partner, is a significant challenge deserving a prominent role in any meaningful LLM theory of mind evaluation.",
    "authors": [
      "Matthew Riemer, Zahra Ashktorab, Djallel Bouneffouf, Payel Das, Miao Liu, Justin D. Weisz, Murray Campbell"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.839963"
  },
  {
    "id": "oai:arXiv.org:2412.20266v2",
    "journal": "arXiv_CS",
    "title": "\"Feeling that I was Collaborating with Them:\" A 20-year Systematic Literature Review of Social Virtual Reality Leveraging Collaboration",
    "link": "https://arxiv.org/abs/2412.20266",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2412.20266v2 Announce Type: replace \nAbstract: As more people meet, interact, and socialize online, Social Virtual Reality (VR) emerges as a promising technology that can bridge the gap between traditional face-to-face and online communication. Compared to traditional screen-based applications, Social VR provides immersive, spatial, and three-dimensional social interactions, making it a promising tool for enhancing collaborations. To map the existing research in this domain, we conducted a 20-year systematic literature review to characterize how Social VR has been employed for collaboration. After screening 2,035 articles, we identified 62 articles that addressed how Social VR has supported collaboration among remote users. Our findings show that Social VR can enhance team collaboration on three key levels: enhancing individual perceptions and experiences within their groups, fostering team dynamics with virtual elements that enable realistic interactions, and employing affordances unique in VR that augment users' spaces. Future research should explore how Social VR can support long-term collaboration, foster trust, enable more diverse and inclusive participation, and move beyond replicating physical-world interactions by leveraging the unique affordances of immersive environments. This review highlights the current practices, challenges, and future research opportunities within CSCW, offering insights for theorizing the impact of Social VR on team collaboration and for designing new applications that effectively support remote collaborations.",
    "authors": [
      "Niloofar Sayadi, Sadie Co, Diego Gomez-Zara"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.839981"
  },
  {
    "id": "oai:arXiv.org:2501.00316v2",
    "journal": "arXiv_CS",
    "title": "MapEval: A Map-Based Evaluation of Geo-Spatial Reasoning in Foundation Models",
    "link": "https://arxiv.org/abs/2501.00316",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2501.00316v2 Announce Type: replace \nAbstract: Recent advancements in foundation models have improved autonomous tool usage and reasoning, but their capabilities in map-based reasoning remain underexplored. To address this, we introduce MapEval, a benchmark designed to assess foundation models across three distinct tasks - textual, API-based, and visual reasoning - through 700 multiple-choice questions spanning 180 cities and 54 countries, covering spatial relationships, navigation, travel planning, and real-world map interactions. Unlike prior benchmarks that focus on simple location queries, MapEval requires models to handle long-context reasoning, API interactions, and visual map analysis, making it the most comprehensive evaluation framework for geospatial AI. On evaluation of 30 foundation models, including Claude-3.5-Sonnet, GPT-4o, and Gemini-1.5-Pro, none surpass 67% accuracy, with open-source models performing significantly worse and all models lagging over 20% behind human performance. These results expose critical gaps in spatial inference, as models struggle with distances, directions, route planning, and place-specific reasoning, highlighting the need for better geospatial AI to bridge the gap between foundation models and real-world navigation. All the resources are available at: https://mapeval.github.io/.",
    "authors": [
      "Mahir Labib Dihan, Md Tanvir Hassan, Md Tanvir Parvez, Md Hasebul Hasan, Md Almash Alam, Muhammad Aamir Cheema, Mohammed Eunus Ali, Md Rizwan Parvez"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.839996"
  },
  {
    "id": "oai:arXiv.org:2501.00339v3",
    "journal": "arXiv_CS",
    "title": "GRASP: Replace Redundant Layers with Adaptive Singular Parameters for Efficient Model Compression",
    "link": "https://arxiv.org/abs/2501.00339",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2501.00339v3 Announce Type: replace \nAbstract: Recent studies have demonstrated that many layers are functionally redundant in large language models (LLMs), enabling model compression by removing these layers to reduce inference cost. While such approaches can improve efficiency, indiscriminate layer pruning often results in significant performance degradation. In this paper, we propose GRASP (Gradient-based Retention of Adaptive Singular Parameters), a novel compression framework that mitigates this issue by preserving sensitivity-aware singular values. Unlike direct layer pruning, GRASP leverages gradient-based attribution on a small calibration dataset to adaptively identify and retain critical singular components. By replacing redundant layers with only a minimal set of parameters, GRASP achieves efficient compression while maintaining strong performance with minimal overhead. Experiments across multiple LLMs show that GRASP consistently outperforms existing compression methods, achieving 90% of the original model's performance under a 20% compression ratio.",
    "authors": [
      "Kainan Liu, Yong Zhang, Ning Cheng, Zhitao Li, Shaojun Wang, Jing Xiao"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.840005"
  },
  {
    "id": "oai:arXiv.org:2501.00625v3",
    "journal": "arXiv_CS",
    "title": "Gaussian Building Mesh (GBM): Extract a Building's 3D Mesh with Google Earth and Gaussian Splatting",
    "link": "https://arxiv.org/abs/2501.00625",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2501.00625v3 Announce Type: replace \nAbstract: Recently released open-source pre-trained foundational image segmentation and object detection models (SAM2+GroundingDINO) allow for geometrically consistent segmentation of objects of interest in multi-view 2D images. Users can use text-based or click-based prompts to segment objects of interest without requiring labeled training datasets. Gaussian Splatting allows for the learning of the 3D representation of a scene's geometry and radiance based on 2D images. Combining Google Earth Studio, SAM2+GroundingDINO, 2D Gaussian Splatting, and our improvements in mask refinement based on morphological operations and contour simplification, we created a pipeline to extract the 3D mesh of any building based on its name, address, or geographic coordinates.",
    "authors": [
      "Kyle Gao, Liangzhi Li, Hongjie He, Dening Lu, Linlin Xu, Jonathan Li"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.840014"
  },
  {
    "id": "oai:arXiv.org:2501.01045v4",
    "journal": "arXiv_CS",
    "title": "ZeroFlow: Overcoming Catastrophic Forgetting is Easier than You Think",
    "link": "https://arxiv.org/abs/2501.01045",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2501.01045v4 Announce Type: replace \nAbstract: Backpropagation provides a generalized configuration for overcoming catastrophic forgetting. Optimizers such as SGD and Adam are commonly used for weight updates in continual learning and continual pre-training. However, access to gradient information is not always feasible in practice due to black-box APIs, hardware constraints, or non-differentiable systems, a challenge we refer to as the gradient bans. To bridge this gap, we introduce ZeroFlow, the first benchmark designed to evaluate gradient-free optimization algorithms for overcoming forgetting. ZeroFlow examines a suite of forward pass-based methods across various algorithms, forgetting scenarios, and datasets. Our results show that forward passes alone can be sufficient to mitigate forgetting. We uncover novel optimization principles that highlight the potential of forward pass-based methods in mitigating forgetting, managing task conflicts, and reducing memory demands. Additionally, we propose new enhancements that further improve forgetting resistance using only forward passes. This work provides essential tools and insights to advance the development of forward-pass-based methods for continual learning.",
    "authors": [
      "Tao Feng, Wei Li, Didi Zhu, Hangjie Yuan, Wendi Zheng, Dan Zhang, Jie Tang"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.840023"
  },
  {
    "id": "oai:arXiv.org:2501.02725v3",
    "journal": "arXiv_CS",
    "title": "Artificial Intelligence in Creative Industries: Advances Prior to 2025",
    "link": "https://arxiv.org/abs/2501.02725",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2501.02725v3 Announce Type: replace \nAbstract: The rapid advancements in artificial intelligence (AI), particularly in generative AI and large language models (LLMs), have profoundly impacted the creative industries, enabling more innovative content creation, enhancing workflows, and democratizing access to creative tools. This paper explores these technological shifts, with particular focus on how those that have emerged since our previous review in 2022 have expanded creative opportunities and improved efficiency. These technological advancements have enhanced the capabilities of text-to-image, text-to-video, and multimodal generation technologies. In particular, key breakthroughs in LLMs have established new benchmarks in conversational AI, while advancements in image generators have revolutionized content creation. We also discuss the integration of AI into post-production workflows, which has significantly accelerated and improved traditional processes. Once content has been created, it must be delivered to its audiences the media industry is facing the demands of increased communication traffic due to creative content. We therefore include a discussion of how AI is beginning to transform the way we represent and compress media content. We highlight the trend toward unified AI frameworks capable of addressing and integrating multiple creative tasks, and we underscore the importance of human insight to drive the creative process and oversight to mitigate AI-generated inaccuracies. Finally, we explore AI's future potential in the creative sector, stressing the need to navigate emerging challenges and to maximize its benefits while addressing the associated risks.",
    "authors": [
      "Nantheera Anantrasirichai, Fan Zhang, David Bull"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.840032"
  },
  {
    "id": "oai:arXiv.org:2501.03742v3",
    "journal": "arXiv_CS",
    "title": "Computing accurate eigenvalues using a mixed-precision Jacobi algorithm",
    "link": "https://arxiv.org/abs/2501.03742",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2501.03742v3 Announce Type: replace \nAbstract: We provide a rounding error analysis of a mixed-precision preconditioned Jacobi algorithm, which uses low precision to compute the preconditioner, applies it at high precision (amounting to two matrix-matrix multiplications) and solves the eigenproblem using the Jacobi algorithm at working precision. Our analysis yields meaningfully smaller relative forward error bounds for the computed eigenvalues compared with those of the Jacobi algorithm. We further prove that, after preconditioning, if the off-diagonal entries of the preconditioned matrix are sufficiently small relative to its smallest diagonal entry, the relative forward error bound is independent of the condition number of the original matrix. We present two constructions for the preconditioner that exploit low precision, along with their error analyses. Our numerical experiments confirm our theoretical results and compare the relative forward error of the proposed algorithm with the Jacobi algorithm, a preconditioned Jacobi algorithm, and MATLAB's $\\texttt{eig}$ function. Timings using Julia suggest that the dominant cost of obtaining this level of accuracy comes from the high precision matrix-matrix multiplies; if support in software or hardware for this were improved then this would become a negligible cost.",
    "authors": [
      "Nicholas J. Higham, Fran\\c{c}oise Tisseur, Marcus Webb, Zhengbo Zhou"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.840040"
  },
  {
    "id": "oai:arXiv.org:2501.05334v2",
    "journal": "arXiv_CS",
    "title": "The Bakers and Millers Game with Restricted Locations",
    "link": "https://arxiv.org/abs/2501.05334",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2501.05334v2 Announce Type: replace \nAbstract: We study strategic location choice by customers and sellers, termed the Bakers and Millers Game in the literature. In our generalized setting, each miller can freely choose any location for setting up a mill, while each baker is restricted in the choice of location for setting up a bakery. For optimal bargaining power, a baker would like to select a location with many millers to buy flour from and with little competition from other bakers. Likewise, a miller aims for a location with many bakers and few competing millers. Thus, both types of agents choose locations to optimize the ratio of agents of opposite type divided by agents of the same type at their chosen location. Originally raised in the context of Fractional Hedonic Games, the Bakers and Millers Game has applications that range from commerce to product design.\n  We study the impact of location restrictions on the properties of the game. While pure Nash equilibria trivially exist in the setting without location restrictions, we show via a sophisticated, efficient algorithm that even the more challenging restricted setting admits equilibria. Moreover, the computed equilibrium approximates the optimal social welfare by a factor of at most $2\\left(\\frac{e}{e-1}\\right)$. Furthermore, we give tight bounds on the price of anarchy/stability.\n  On the conceptual side, the location choice feature adds a new layer to the standard setting of Hedonic Games, in the sense that agents that select the same location form a coalition. This allows to naturally restrict the possible coalitions that can be formed. With this, our model generalizes simple symmetric Fractional Hedonic Games on complete bipartite valuation graphs and also Hedonic Diversity Games with utilities single-peaked at 0. We believe that this generalization is also a very interesting direction for other types of Hedonic Games.",
    "authors": [
      "Simon Krogmann, Pascal Lenzner, Alexander Skopalik"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.840049"
  },
  {
    "id": "oai:arXiv.org:2501.11930v3",
    "journal": "arXiv_CS",
    "title": "Nocturnal eye inspired liquid to gas phase change soft actuator with Laser-Induced-Graphene: enhanced environmental light harvesting and photothermal conversion",
    "link": "https://arxiv.org/abs/2501.11930",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2501.11930v3 Announce Type: replace \nAbstract: Robotic systems' mobility is constrained by power sources and wiring. While pneumatic actuators remain tethered to air supplies, we developed a new actuator utilizing light energy. Inspired by nocturnal animals' eyes, we designed a bilayer soft actuator incorporating Laser-Induced Graphene (LIG) on the inner surface of a silicone layer. This design maintains silicone's transparency and flexibility while achieving 54% faster response time compared to conventional actuators through enhanced photothermal conversion.",
    "authors": [
      "Maina Sogabe, Youhyun Kim, Hiroki Miyazako, Kenji Kawashima"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.840082"
  },
  {
    "id": "oai:arXiv.org:2501.16029v2",
    "journal": "arXiv_CS",
    "title": "FDLLM: A Dedicated Detector for Black-Box LLMs Fingerprinting",
    "link": "https://arxiv.org/abs/2501.16029",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2501.16029v2 Announce Type: replace \nAbstract: Large Language Models (LLMs) are rapidly transforming the landscape of digital content creation. However, the prevalent black-box Application Programming Interface (API) access to many LLMs introduces significant challenges in accountability, governance, and security. LLM fingerprinting, which aims to identify the source model by analyzing statistical and stylistic features of generated text, offers a potential solution. Current progress in this area is hindered by a lack of dedicated datasets and the need for efficient, practical methods that are robust against adversarial manipulations. To address these challenges, we introduce FD-Dataset, a comprehensive bilingual fingerprinting benchmark comprising 90,000 text samples from 20 famous proprietary and open-source LLMs. Furthermore, we present FDLLM, a novel fingerprinting method that leverages parameter-efficient Low-Rank Adaptation (LoRA) to fine-tune a foundation model. This approach enables LoRA to extract deep, persistent features that characterize each source LLM. Through our analysis, we find that LoRA adaptation promotes the aggregation of outputs from the same LLM in representation space while enhancing the separation between different LLMs. This mechanism explains why LoRA proves particularly effective for LLM fingerprinting. Extensive empirical evaluations on FD-Dataset demonstrate FDLLM's superiority, achieving a Macro F1 score 22.1% higher than the strongest baseline. FDLLM also exhibits strong generalization to newly released models, achieving an average accuracy of 95% on unseen models. Notably, FDLLM remains consistently robust under various adversarial attacks, including polishing, translation, and synonym substitution. Experimental results show that FDLLM reduces the average attack success rate from 49.2% (LM-D) to 23.9%.",
    "authors": [
      "Zhiyuan Fu, Junfan Chen, Lan Zhang, Ting Yang, Jun Niu, Hongyu Sun, Ruidong Li, Peng Liu, Yuqing Zhang"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.840099"
  },
  {
    "id": "oai:arXiv.org:2501.17585v2",
    "journal": "arXiv_CS",
    "title": "TAPOR: 3D Hand Pose Reconstruction with Fully Passive Thermal Sensing for Around-Device Interactions",
    "link": "https://arxiv.org/abs/2501.17585",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2501.17585v2 Announce Type: replace \nAbstract: This paper presents the design and implementation of TAPOR, a privacy-preserving, non-contact, and fully passive sensing system for accurate and robust 3D hand pose reconstruction for around-device interaction using a single low-cost thermal array sensor. Thermal sensing using inexpensive and miniature thermal arrays emerges with an excellent utility-privacy balance, offering an imaging resolution significantly lower than cameras but far superior to RF signals like radar or WiFi. The design of TAPOR, however, is challenging, mainly because the captured temperature maps are low-resolution and textureless. To overcome the challenges, we investigate thermo-depth and thermo-pose properties, proposing a novel physics-inspired neural network that learns effective 3D spatial representations of potential hand poses. We then formulate the 3D pose reconstruction problem as a distinct retrieval task, enabling accurate hand pose determination from the input temperature map. To deploy TAPOR on IoT devices, we introduce an effective heterogeneous knowledge distillation method, reducing computation by 377x. TAPOR is fully implemented and tested in real-world scenarios, showing remarkable performance, supported by four gesture control and finger tracking case studies. We envision TAPOR to be a ubiquitous interface for around-device control and have open-sourced it at https://github.com/aiot-lab/TAPOR.",
    "authors": [
      "Xie Zhang, Chenxiao Li, Chenshu Wu"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.840108"
  },
  {
    "id": "oai:arXiv.org:2501.18362v3",
    "journal": "arXiv_CS",
    "title": "MedXpertQA: Benchmarking Expert-Level Medical Reasoning and Understanding",
    "link": "https://arxiv.org/abs/2501.18362",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2501.18362v3 Announce Type: replace \nAbstract: We introduce MedXpertQA, a highly challenging and comprehensive benchmark to evaluate expert-level medical knowledge and advanced reasoning. MedXpertQA includes 4,460 questions spanning 17 specialties and 11 body systems. It includes two subsets, Text for text evaluation and MM for multimodal evaluation. Notably, MM introduces expert-level exam questions with diverse images and rich clinical information, including patient records and examination results, setting it apart from traditional medical multimodal benchmarks with simple QA pairs generated from image captions. MedXpertQA applies rigorous filtering and augmentation to address the insufficient difficulty of existing benchmarks like MedQA, and incorporates specialty board questions to improve clinical relevance and comprehensiveness. We perform data synthesis to mitigate data leakage risk and conduct multiple rounds of expert reviews to ensure accuracy and reliability. We evaluate 18 leading models on \\benchmark. Moreover, medicine is deeply connected to real-world decision-making, providing a rich and representative setting for assessing reasoning abilities beyond mathematics and code. To this end, we develop a reasoning-oriented subset to facilitate the assessment of o1-like models. Code and data are available at: https://github.com/TsinghuaC3I/MedXpertQA",
    "authors": [
      "Yuxin Zuo, Shang Qu, Yifei Li, Zhangren Chen, Xuekai Zhu, Ermo Hua, Kaiyan Zhang, Ning Ding, Bowen Zhou"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.840125"
  },
  {
    "id": "oai:arXiv.org:2501.18821v3",
    "journal": "arXiv_CS",
    "title": "An Optimal Cascade Feature-Level Spatiotemporal Fusion Strategy for Anomaly Detection in CAN Bus",
    "link": "https://arxiv.org/abs/2501.18821",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2501.18821v3 Announce Type: replace \nAbstract: Intelligent transportation systems (ITS) play a pivotal role in modern infrastructure but face security risks due to the broadcast-based nature of the in-vehicle Controller Area Network (CAN) buses. While numerous machine learning models and strategies have been proposed to detect CAN anomalies, existing approaches lack robustness evaluations and fail to comprehensively detect attacks due to shifting their focus on a subset of dominant structures of anomalies. To overcome these limitations, the current study proposes a cascade feature-level spatiotemporal fusion framework that integrates the spatial features and temporal features through a two-parameter genetic algorithm (2P-GA)-optimized cascade architecture to cover all dominant structures of anomalies. Extensive paired t-test analysis confirms that the model achieves an AUC-ROC of 0.9987, demonstrating robust anomaly detection capabilities. The Spatial Module improves the precision by approximately 4%, while the Temporal Module compensates for recall losses, ensuring high true positive rates. The proposed framework detects all attack types with 100% accuracy on the CAR-HACKING dataset, outperforming state-of-the-art methods. This study provides a validated, robust solution for real-world CAN security challenges.",
    "authors": [
      "Mohammad Fatahi, Danial Sadrian Zadeh, Benyamin Ghojogh, Behzad Moshiri, Otman Basir"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.840134"
  },
  {
    "id": "oai:arXiv.org:2501.19116v2",
    "journal": "arXiv_CS",
    "title": "A Theoretical Justification for Asymmetric Actor-Critic Algorithms",
    "link": "https://arxiv.org/abs/2501.19116",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2501.19116v2 Announce Type: replace \nAbstract: In reinforcement learning for partially observable environments, many successful algorithms have been developed within the asymmetric learning paradigm. This paradigm leverages additional state information available at training time for faster learning. Although the proposed learning objectives are usually theoretically sound, these methods still lack a precise theoretical justification for their potential benefits. We propose such a justification for asymmetric actor-critic algorithms with linear function approximators by adapting a finite-time convergence analysis to this setting. The resulting finite-time bound reveals that the asymmetric critic eliminates error terms arising from aliasing in the agent state.",
    "authors": [
      "Gaspard Lambrechts, Damien Ernst, Aditya Mahajan"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.840143"
  },
  {
    "id": "oai:arXiv.org:2502.01618v4",
    "journal": "arXiv_CS",
    "title": "Rollout Roulette: A Probabilistic Inference Approach to Inference-Time Scaling of LLMs using Particle-Based Monte Carlo Methods",
    "link": "https://arxiv.org/abs/2502.01618",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2502.01618v4 Announce Type: replace \nAbstract: Large language models (LLMs) have achieved significant performance gains via scaling up model sizes and/or data. However, recent evidence suggests diminishing returns from such approaches, motivating scaling the computation spent at inference time. Existing inference-time scaling methods, usually with reward models, cast the task as a search problem, which tends to be vulnerable to reward hacking as a consequence of approximation errors in reward models. In this paper, we instead cast inference-time scaling as a probabilistic inference task and leverage sampling-based techniques to explore the typical set of the state distribution of a state-space model with an approximate likelihood, rather than optimize for its mode directly. We propose a novel inference-time scaling approach by adapting particle-based Monte Carlo methods to this task. Our empirical evaluation demonstrates that our methods have a 4-16x better scaling rate over our deterministic search counterparts on various challenging mathematical reasoning tasks. Using our approach, we show that Qwen2.5-Math-1.5B-Instruct can surpass GPT-4o accuracy in only 4 rollouts, while Qwen2.5-Math-7B-Instruct scales to o1 level accuracy in only 32 rollouts. Our work not only presents an effective method to inference-time scaling, but also connects the rich literature in probabilistic inference with inference-time scaling of LLMs to develop more robust algorithms in future work. Code, videos, and further information available at https://probabilistic-inference-scaling.github.io.",
    "authors": [
      "Isha Puri, Shivchander Sudalairaj, Guangxuan Xu, Kai Xu, Akash Srivastava"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.840152"
  },
  {
    "id": "oai:arXiv.org:2502.01940v2",
    "journal": "arXiv_CS",
    "title": "Toward a Low-Cost Perception System in Autonomous Vehicles: A Spectrum Learning Approach",
    "link": "https://arxiv.org/abs/2502.01940",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2502.01940v2 Announce Type: replace \nAbstract: We present a cost-effective new approach for generating denser depth maps for Autonomous Driving (AD) and Autonomous Vehicles (AVs) by integrating the images obtained from deep neural network (DNN) 4D radar detectors with conventional camera RGB images. Our approach introduces a novel pixel positional encoding algorithm inspired by Bartlett's spatial spectrum estimation technique. This algorithm transforms both radar depth maps and RGB images into a unified pixel image subspace called the Spatial Spectrum, facilitating effective learning based on their similarities and differences. Our method effectively leverages high-resolution camera images to train radar depth map generative models, addressing the limitations of conventional radar detectors in complex vehicular environments, thus sharpening the radar output. We develop spectrum estimation algorithms tailored for radar depth maps and RGB images, a comprehensive training framework for data-driven generative models, and a camera-radar deployment scheme for AV operation. Our results demonstrate that our approach also outperforms the state-of-the-art (SOTA) by 27.95% in terms of Unidirectional Chamfer Distance (UCD).",
    "authors": [
      "Mohammed Alsakabi, Aidan Erickson, John M. Dolan, Ozan K. Tonguz"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.840161"
  },
  {
    "id": "oai:arXiv.org:2502.02732v3",
    "journal": "arXiv_CS",
    "title": "Peri-LN: Revisiting Normalization Layer in the Transformer Architecture",
    "link": "https://arxiv.org/abs/2502.02732",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2502.02732v3 Announce Type: replace \nAbstract: Selecting a layer normalization (LN) strategy that stabilizes training and speeds convergence in Transformers remains difficult, even for today's large language models (LLM). We present a comprehensive analytical foundation for understanding how different LN strategies influence training dynamics in large-scale Transformers. Until recently, Pre-LN and Post-LN have long dominated practices despite their limitations in large-scale training. However, several open-source models have recently begun silently adopting a third strategy without much explanation. This strategy places normalization layer peripherally around sublayers, a design we term Peri-LN. While Peri-LN has demonstrated promising performance, its precise mechanisms and benefits remain almost unexplored. Our in-depth analysis delineates the distinct behaviors of LN strategies, showing how each placement shapes activation variance and gradient propagation. To validate our theoretical insight, we conduct extensive experiments on Transformers up to $3.2$B parameters, showing that Peri-LN consistently achieves more balanced variance growth, steadier gradient flow, and convergence stability. Our results suggest that Peri-LN warrants broader consideration for large-scale Transformer architectures, providing renewed insights into the optimal placement of LN.",
    "authors": [
      "Jeonghoon Kim, Byeongchan Lee, Cheonbok Park, Yeontaek Oh, Beomjun Kim, Taehwan Yoo, Seongjin Shin, Dongyoon Han, Jinwoo Shin, Kang Min Yoo"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.840169"
  },
  {
    "id": "oai:arXiv.org:2502.03576v2",
    "journal": "arXiv_CS",
    "title": "Clone-Robust Weights in Metric Spaces: Handling Redundancy Bias for Benchmark Aggregation",
    "link": "https://arxiv.org/abs/2502.03576",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2502.03576v2 Announce Type: replace \nAbstract: We are given a set of elements in a metric space. The distribution of the elements is arbitrary, possibly adversarial. Can we weigh the elements in a way that is resistant to such (adversarial) manipulations? This problem arises in various contexts. For instance, the elements could represent data points, requiring robust domain adaptation. Alternatively, they might represent tasks to be aggregated into a benchmark; or questions about personal political opinions in voting advice applications. This article introduces a theoretical framework for dealing with such problems. We propose clone-proof weighting functions as a solution concept. These functions distribute importance across elements of a set such that similar objects (``clones'') share (some of) their weights, thus avoiding a potential bias introduced by their multiplicity. Our framework extends the maximum uncertainty principle to accommodate general metric spaces and includes a set of axioms -- symmetry, continuity, and clone-proofness -- that guide the construction of weighting functions. Finally, we address the existence of weighting functions satisfying our axioms in the significant case of Euclidean spaces and propose a general method for their construction.",
    "authors": [
      "Damien Berriaud, Roger Wattenhofer"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.840178"
  },
  {
    "id": "oai:arXiv.org:2502.05164v2",
    "journal": "arXiv_CS",
    "title": "In-context denoising with one-layer transformers: connections between attention and associative memory retrieval",
    "link": "https://arxiv.org/abs/2502.05164",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2502.05164v2 Announce Type: replace \nAbstract: We introduce in-context denoising, a task that refines the connection between attention-based architectures and dense associative memory (DAM) networks, also known as modern Hopfield networks. Using a Bayesian framework, we show theoretically and empirically that certain restricted denoising problems can be solved optimally even by a single-layer transformer. We demonstrate that a trained attention layer processes each denoising prompt by performing a single gradient descent update on a context-aware DAM energy landscape, where context tokens serve as associative memories and the query token acts as an initial state. This one-step update yields better solutions than exact retrieval of either a context token or a spurious local minimum, providing a concrete example of DAM networks extending beyond the standard retrieval paradigm. Overall, this work solidifies the link between associative memory and attention mechanisms first identified by Ramsauer et al., and demonstrates the relevance of associative memory models in the study of in-context learning.",
    "authors": [
      "Matthew Smart, Alberto Bietti, Anirvan M. Sengupta"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.840187"
  },
  {
    "id": "oai:arXiv.org:2502.05407v3",
    "journal": "arXiv_CS",
    "title": "The Complexity of Learning Sparse Superposed Features with Feedback",
    "link": "https://arxiv.org/abs/2502.05407",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2502.05407v3 Announce Type: replace \nAbstract: The success of deep networks is crucially attributed to their ability to capture latent features within a representation space. In this work, we investigate whether the underlying learned features of a model can be efficiently retrieved through feedback from an agent, such as a large language model (LLM), in the form of relative \\textit{triplet comparisons}. These features may represent various constructs, including dictionaries in LLMs or a covariance matrix of Mahalanobis distances. We analyze the feedback complexity associated with learning a feature matrix in sparse settings. Our results establish tight bounds when the agent is permitted to construct activations and demonstrate strong upper bounds in sparse scenarios when the agent's feedback is limited to distributional information. We validate our theoretical findings through experiments on two distinct applications: feature recovery from Recursive Feature Machines and dictionary extraction from sparse autoencoders trained on Large Language Models.",
    "authors": [
      "Akash Kumar"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.840195"
  },
  {
    "id": "oai:arXiv.org:2502.05749v5",
    "journal": "arXiv_CS",
    "title": "UniDB: A Unified Diffusion Bridge Framework via Stochastic Optimal Control",
    "link": "https://arxiv.org/abs/2502.05749",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2502.05749v5 Announce Type: replace \nAbstract: Recent advances in diffusion bridge models leverage Doob's $h$-transform to establish fixed endpoints between distributions, demonstrating promising results in image translation and restoration tasks. However, these approaches frequently produce blurred or excessively smoothed image details and lack a comprehensive theoretical foundation to explain these shortcomings. To address these limitations, we propose UniDB, a unified framework for diffusion bridges based on Stochastic Optimal Control (SOC). UniDB formulates the problem through an SOC-based optimization and derives a closed-form solution for the optimal controller, thereby unifying and generalizing existing diffusion bridge models. We demonstrate that existing diffusion bridges employing Doob's $h$-transform constitute a special case of our framework, emerging when the terminal penalty coefficient in the SOC cost function tends to infinity. By incorporating a tunable terminal penalty coefficient, UniDB achieves an optimal balance between control costs and terminal penalties, substantially improving detail preservation and output quality. Notably, UniDB seamlessly integrates with existing diffusion bridge models, requiring only minimal code modifications. Extensive experiments across diverse image restoration tasks validate the superiority and adaptability of the proposed framework. Our code is available at https://github.com/UniDB-SOC/UniDB/.",
    "authors": [
      "Kaizhen Zhu, Mokai Pan, Yuexin Ma, Yanwei Fu, Jingyi Yu, Jingya Wang, Ye Shi"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.840204"
  },
  {
    "id": "oai:arXiv.org:2502.06258v2",
    "journal": "arXiv_CS",
    "title": "Emergent Response Planning in LLMs",
    "link": "https://arxiv.org/abs/2502.06258",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2502.06258v2 Announce Type: replace \nAbstract: In this work, we argue that large language models (LLMs), though trained to predict only the next token, exhibit emergent planning behaviors: $\\textbf{their hidden representations encode future outputs beyond the next token}$. Through simple probing, we demonstrate that LLM prompt representations encode global attributes of their entire responses, including $\\textit{structure attributes}$ (e.g., response length, reasoning steps), $\\textit{content attributes}$ (e.g., character choices in storywriting, multiple-choice answers at the end of response), and $\\textit{behavior attributes}$ (e.g., answer confidence, factual consistency). In addition to identifying response planning, we explore how it scales with model size across tasks and how it evolves during generation. The findings that LLMs plan ahead for the future in their hidden representations suggest potential applications for improving transparency and generation control.",
    "authors": [
      "Zhichen Dong, Zhanhui Zhou, Zhixuan Liu, Chao Yang, Chaochao Lu"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.840212"
  },
  {
    "id": "oai:arXiv.org:2502.06805v3",
    "journal": "arXiv_CS",
    "title": "Efficient Diffusion Models: A Survey",
    "link": "https://arxiv.org/abs/2502.06805",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2502.06805v3 Announce Type: replace \nAbstract: Diffusion models have emerged as powerful generative models capable of producing high-quality contents such as images, videos, and audio, demonstrating their potential to revolutionize digital content creation. However, these capabilities come at the cost of their significant computational resources and lengthy generation time, underscoring the critical need to develop efficient techniques for practical deployment. In this survey, we provide a systematic and comprehensive review of research on efficient diffusion models. We organize the literature in a taxonomy consisting of three main categories, covering distinct yet interconnected efficient diffusion model topics from algorithm-level, system-level, and framework perspective, respectively. We have also created a GitHub repository where we organize the papers featured in this survey at https://github.com/AIoT-MLSys-Lab/Efficient-Diffusion-Model-Survey. We hope our survey can serve as a valuable resource to help researchers and practitioners gain a systematic understanding of efficient diffusion model research and inspire them to contribute to this important and exciting field.",
    "authors": [
      "Hui Shen, Jingxuan Zhang, Boning Xiong, Rui Hu, Shoufa Chen, Zhongwei Wan, Xin Wang, Yu Zhang, Zixuan Gong, Guangyin Bao, Chaofan Tao, Yongfeng Huang, Ye Yuan, Mi Zhang"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.840220"
  },
  {
    "id": "oai:arXiv.org:2502.07599v2",
    "journal": "arXiv_CS",
    "title": "DPO-Shift: Shifting the Distribution of Direct Preference Optimization",
    "link": "https://arxiv.org/abs/2502.07599",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2502.07599v2 Announce Type: replace \nAbstract: Direct Preference Optimization (DPO) and its variants have become increasingly popular for aligning language models with human preferences. These methods aim to teach models to better distinguish between chosen (or preferred) and rejected (or dispreferred) responses. However, prior research has identified that the probability of chosen responses often decreases during training, and this phenomenon is known as likelihood displacement. To tackle this challenge, in this work we introduce DPO-Shift to controllably shift the distribution of the chosen probability. Then, we show that DPO-Shift exhibits a fundamental trade-off between improving the chosen probability and sacrificing the reward margin, as supported by both theoretical analysis and experimental validation. Furthermore, we demonstrate the superiority of DPO-Shift over DPO on downstream tasks such as MT-Bench and a designed win rate experiment. We believe this study shows that the likelihood displacement issue of DPO can be effectively mitigated with a simple, theoretically grounded solution. Our code is available at https://github.com/Meaquadddd/DPO-Shift.",
    "authors": [
      "Xiliang Yang, Feng Jiang, Qianen Zhang, Lei Zhao, Xiao Li"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.840236"
  },
  {
    "id": "oai:arXiv.org:2502.08503v3",
    "journal": "arXiv_CS",
    "title": "Revisiting 3D LLM Benchmarks: Are We Really Testing 3D Capabilities?",
    "link": "https://arxiv.org/abs/2502.08503",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2502.08503v3 Announce Type: replace \nAbstract: In this work, we identify the \"2D-Cheating\" problem in 3D LLM evaluation, where these tasks might be easily solved by VLMs with rendered images of point clouds, exposing ineffective evaluation of 3D LLMs' unique 3D capabilities. We test VLM performance across multiple 3D LLM benchmarks and, using this as a reference, propose principles for better assessing genuine 3D understanding. We also advocate explicitly separating 3D abilities from 1D or 2D aspects when evaluating 3D LLMs. Code and data are available at https://github.com/LLM-class-group/Revisiting-3D-LLM-Benchmarks",
    "authors": [
      "Jiahe Jin, Yanheng He, Mingyan Yang"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.840244"
  },
  {
    "id": "oai:arXiv.org:2502.09003v3",
    "journal": "arXiv_CS",
    "title": "RoSTE: An Efficient Quantization-Aware Supervised Fine-Tuning Approach for Large Language Models",
    "link": "https://arxiv.org/abs/2502.09003",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2502.09003v3 Announce Type: replace \nAbstract: Supervised fine-tuning is a standard method for adapting pre-trained large language models (LLMs) to downstream tasks. Quantization has been recently studied as a post-training technique for efficient LLM deployment. To obtain quantized fine-tuned LLMs, conventional pipelines would first fine-tune the pre-trained models, followed by post-training quantization. This often yields suboptimal performance as it fails to leverage the synergy between fine-tuning and quantization. To effectively realize low-bit quantization of weights, activations and KV caches in LLMs, we propose an algorithm named Rotated Straight-Through-Estimator (RoSTE), which combines quantization-aware supervised fine-tuning (QA-SFT) with an adaptive rotation strategy that identifies an effective rotation configuration to reduce activation outliers. We provide theoretical insights on RoSTE by analyzing its prediction error when applied to an overparameterized least square quantized training problem. Our findings reveal that the prediction error is directly proportional to the quantization error of the converged weights, which can be effectively managed through an optimized rotation configuration. Experiments on Pythia, Qwen and Llama models of different sizes demonstrate the effectiveness of RoSTE. Compared to existing post-SFT quantization baselines, our method consistently achieves superior performances across various tasks and different LLM architectures. Our code is available at https://github.com/OptimAI-Lab/RoSTE.",
    "authors": [
      "Quan Wei, Chung-Yiu Yau, Hoi-To Wai, Yang Katie Zhao, Dongyeop Kang, Youngsuk Park, Mingyi Hong"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.840254"
  },
  {
    "id": "oai:arXiv.org:2502.09443v2",
    "journal": "arXiv_CS",
    "title": "Relational Conformal Prediction for Correlated Time Series",
    "link": "https://arxiv.org/abs/2502.09443",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2502.09443v2 Announce Type: replace \nAbstract: We address the problem of uncertainty quantification in time series forecasting by exploiting observations at correlated sequences. Relational deep learning methods leveraging graph representations are among the most effective tools for obtaining point estimates from spatiotemporal data and correlated time series. However, the problem of exploiting relational structures to estimate the uncertainty of such predictions has been largely overlooked in the same context. To this end, we propose a novel distribution-free approach based on the conformal prediction framework and quantile regression. Despite the recent applications of conformal prediction to sequential data, existing methods operate independently on each target time series and do not account for relationships among them when constructing the prediction interval. We fill this void by introducing a novel conformal prediction method based on graph deep learning operators. Our approach, named Conformal Relational Prediction (CoRel), does not require the relational structure (graph) to be known a priori and can be applied on top of any pre-trained predictor. Additionally, CoRel includes an adaptive component to handle non-exchangeable data and changes in the input time series. Our approach provides accurate coverage and achieves state-of-the-art uncertainty quantification in relevant benchmarks.",
    "authors": [
      "Andrea Cini, Alexander Jenkins, Danilo Mandic, Cesare Alippi, Filippo Maria Bianchi"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.840262"
  },
  {
    "id": "oai:arXiv.org:2502.09502v2",
    "journal": "arXiv_CS",
    "title": "Scalable First-order Method for Certifying Optimal k-Sparse GLMs",
    "link": "https://arxiv.org/abs/2502.09502",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2502.09502v2 Announce Type: replace \nAbstract: This paper investigates the problem of certifying optimality for sparse generalized linear models (GLMs), where sparsity is enforced through an $\\ell_0$ cardinality constraint. While branch-and-bound (BnB) frameworks can certify optimality by pruning nodes using dual bounds, existing methods for computing these bounds are either computationally intensive or exhibit slow convergence, limiting their scalability to large-scale problems. To address this challenge, we propose a first-order proximal gradient algorithm designed to solve the perspective relaxation of the problem within a BnB framework. Specifically, we formulate the relaxed problem as a composite optimization problem and demonstrate that the proximal operator of the non-smooth component can be computed exactly in log-linear time complexity, eliminating the need to solve a computationally expensive second-order cone program. Furthermore, we introduce a simple restart strategy that enhances convergence speed while maintaining low per-iteration complexity. Extensive experiments on synthetic and real-world datasets show that our approach significantly accelerates dual bound computations and is highly effective in providing optimality certificates for large-scale problems.",
    "authors": [
      "Jiachang Liu, Soroosh Shafiee, Andrea Lodi"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.840271"
  },
  {
    "id": "oai:arXiv.org:2502.10215v2",
    "journal": "arXiv_CS",
    "title": "Do Large Language Models Reason Causally Like Us? Even Better?",
    "link": "https://arxiv.org/abs/2502.10215",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2502.10215v2 Announce Type: replace \nAbstract: Causal reasoning is a core component of intelligence. Large language models (LLMs) have shown impressive capabilities in generating human-like text, raising questions about whether their responses reflect true understanding or statistical patterns. We compared causal reasoning in humans and four LLMs using tasks based on collider graphs, rating the likelihood of a query variable occurring given evidence from other variables. LLMs' causal inferences ranged from often nonsensical (GPT-3.5) to human-like to often more normatively aligned than those of humans (GPT-4o, Gemini-Pro, and Claude). Computational model fitting showed that one reason for GPT-4o, Gemini-Pro, and Claude's superior performance is they didn't exhibit the \"associative bias\" that plagues human causal reasoning. Nevertheless, even these LLMs did not fully capture subtler reasoning patterns associated with collider graphs, such as \"explaining away\".",
    "authors": [
      "Hanna M. Dettki, Brenden M. Lake, Charley M. Wu, Bob Rehder"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.840279"
  },
  {
    "id": "oai:arXiv.org:2502.10634v2",
    "journal": "arXiv_CS",
    "title": "Lost in the Passage: Passage-level In-context Learning Does Not Necessarily Need a \"Passage\"",
    "link": "https://arxiv.org/abs/2502.10634",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2502.10634v2 Announce Type: replace \nAbstract: By simply incorporating demonstrations into the context, in-context learning (ICL) enables large language models (LLMs) to yield awesome performance on many tasks. In this study, we focus on passage-level long-context ICL for generation tasks and find that LLMs cannot learn the intrinsic relationship between the demonstration passage and the generation output. We conduct experiments with different LLMs on two typical generation tasks including single-document question answering and distractor generation, demonstrating that even a completely meaningless demonstration passage with 1/4 length achieves much better performance than the original full passage. Analysis via attention and information flow reveals that LLMs pay little attention to passages compared to other components in the prompt and little information flows from the passage to other parts of the demonstration, which further confirms our finding. Additionally, experiments on context compression indicate that compression approaches proven effective on other long-context tasks are not suitable for passage-level ICL, since simply using shorter meaningless demonstration passages already achieves competitive performance.",
    "authors": [
      "Hao Sun, Chenming Tang, Gengyang Li, Yunfang Wu"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.840288"
  },
  {
    "id": "oai:arXiv.org:2502.11187v3",
    "journal": "arXiv_CS",
    "title": "TituLLMs: A Family of Bangla LLMs with Comprehensive Benchmarking",
    "link": "https://arxiv.org/abs/2502.11187",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2502.11187v3 Announce Type: replace \nAbstract: In this paper, we present TituLLMs, the first large pretrained Bangla LLMs, available in 1b and 3b parameter sizes. Due to computational constraints during both training and inference, we focused on smaller models. To train TituLLMs, we collected a pretraining dataset of approximately ~37 billion tokens. We extended the Llama-3.2 tokenizer to incorporate language- and culture-specific knowledge, which also enables faster training and inference. There was a lack of benchmarking datasets to benchmark LLMs for Bangla. To address this gap, we developed five benchmarking datasets. We benchmarked various LLMs, including TituLLMs, and demonstrated that TituLLMs outperforms its initial multilingual versions. However, this is not always the case, highlighting the complexities of language adaptation. Our work lays the groundwork for adapting existing multilingual open models to other low-resource languages. To facilitate broader adoption and further research, we have made the TituLLMs models and benchmarking datasets publicly available (https://huggingface.co/collections/hishab/titulm-llama-family-6718d31fc1b83529276f490a).",
    "authors": [
      "Shahriar Kabir Nahin, Rabindra Nath Nandi, Sagor Sarker, Quazi Sarwar Muhtaseem, Md Kowsher, Apu Chandraw Shill, Md Ibrahim, Mehadi Hasan Menon, Tareq Al Muntasir, Firoj Alam"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.840303"
  },
  {
    "id": "oai:arXiv.org:2502.11612v3",
    "journal": "arXiv_CS",
    "title": "Maximum Entropy Reinforcement Learning with Diffusion Policy",
    "link": "https://arxiv.org/abs/2502.11612",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2502.11612v3 Announce Type: replace \nAbstract: The Soft Actor-Critic (SAC) algorithm with a Gaussian policy has become a mainstream implementation for realizing the Maximum Entropy Reinforcement Learning (MaxEnt RL) objective, which incorporates entropy maximization to encourage exploration and enhance policy robustness. While the Gaussian policy performs well on simpler tasks, its exploration capacity and potential performance in complex multi-goal RL environments are limited by its inherent unimodality. In this paper, we employ the diffusion model, a powerful generative model capable of capturing complex multimodal distributions, as the policy representation to fulfill the MaxEnt RL objective, developing a method named MaxEnt RL with Diffusion Policy (MaxEntDP). Our method enables efficient exploration and brings the policy closer to the optimal MaxEnt policy. Experimental results on Mujoco benchmarks show that MaxEntDP outperforms the Gaussian policy and other generative models within the MaxEnt RL framework, and performs comparably to other state-of-the-art diffusion-based online RL algorithms. Our code is available at https://github.com/diffusionyes/MaxEntDP.",
    "authors": [
      "Xiaoyi Dong, Jian Cheng, Xi Sheryl Zhang"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.840312"
  },
  {
    "id": "oai:arXiv.org:2502.12120v2",
    "journal": "arXiv_CS",
    "title": "LLMs on the Line: Data Determines Loss-to-Loss Scaling Laws",
    "link": "https://arxiv.org/abs/2502.12120",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2502.12120v2 Announce Type: replace \nAbstract: Scaling laws guide the development of large language models (LLMs) by offering estimates for the optimal balance of model size, tokens, and compute. More recently, loss-to-loss scaling laws that relate losses across pretraining datasets and downstream tasks have emerged as a powerful tool for understanding and improving LLM performance. In this work, we investigate which factors most strongly influence loss-to-loss scaling. Our experiments reveal that the pretraining data and tokenizer determine the scaling trend. In contrast, model size, optimization hyperparameters, and even significant architectural differences, such as between transformer-based models like Llama and state-space models like Mamba, have limited impact. Consequently, practitioners should carefully curate suitable pretraining datasets for optimal downstream performance, while architectures and other settings can be freely optimized for training efficiency.",
    "authors": [
      "Prasanna Mayilvahanan, Thadd\\\"aus Wiedemer, Sayak Mallick, Matthias Bethge, Wieland Brendel"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.840320"
  },
  {
    "id": "oai:arXiv.org:2502.12123v2",
    "journal": "arXiv_CS",
    "title": "On the Query Complexity of Verifier-Assisted Language Generation",
    "link": "https://arxiv.org/abs/2502.12123",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2502.12123v2 Announce Type: replace \nAbstract: Recently, a plethora of works have proposed inference-time algorithms (e.g. best-of-n), which incorporate verifiers to assist the generation process. Their quality-efficiency trade-offs have been empirically benchmarked on a variety of constrained generation tasks, but the algorithmic design landscape is still largely poorly understood. In this paper, we develop a mathematical framework for reasoning about constrained generation using a pre-trained language model generator oracle and a process verifier--which can decide whether a prefix can be extended to a string which satisfies the constraints of choice. We show that even in very simple settings, access to a verifier can render an intractable problem (information-theoretically or computationally) to a tractable one. In fact, we show even simple algorithms, like tokenwise rejection sampling, can enjoy significant benefits from access to a verifier. Empirically, we show that a natural modification of tokenwise rejection sampling, in which the sampler is allowed to \"backtrack\" (i.e., erase the final few generated tokens) has robust and substantive benefits over natural baselines (e.g. (blockwise) rejection sampling, nucleus sampling)--both in terms of computational efficiency, accuracy and diversity.",
    "authors": [
      "Edoardo Botta, Yuchen Li, Aashay Mehta, Jordan T. Ash, Cyril Zhang, Andrej Risteski"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.840329"
  },
  {
    "id": "oai:arXiv.org:2502.13060v2",
    "journal": "arXiv_CS",
    "title": "Practical Secure Delegated Linear Algebra with Trapdoored Matrices",
    "link": "https://arxiv.org/abs/2502.13060",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2502.13060v2 Announce Type: replace \nAbstract: Most heavy computation occurs on servers owned by a second party. This reduces data privacy, resulting in interest in data-oblivious computation, which typically severely degrades performance. Secure and fast delegated computation is particularly important for linear algebra, which comprises a large fraction of total computation and is best run on highly specialized hardware often only accessible through the cloud.\n  We state the natural efficiency and security desiderata for fast and data-oblivious delegated linear algebra. We demonstrate the existence of trapdoored matrix families based on a LPN assumption, and provide a scheme for secure delegated matrix-matrix and matrix-vectors multiplication based on the existence of trapdoored matrices. We achieve sublinear overhead for the server, dramatically reduced computation cost for the client, and various practical advantages over previous algorithms.",
    "authors": [
      "Mark Braverman, Stephen Newman"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.840337"
  },
  {
    "id": "oai:arXiv.org:2502.13287v2",
    "journal": "arXiv_CS",
    "title": "A new pathway to generative artificial intelligence by minimizing the maximum entropy",
    "link": "https://arxiv.org/abs/2502.13287",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2502.13287v2 Announce Type: replace \nAbstract: Generative artificial intelligence revolutionized society. Current models are trained by minimizing the distance between the produced data and the training set. Consequently, development is plateauing as they are intrinsically data-hungry and challenging to direct during the generative process. To overcome these limitations, we introduce a paradigm shift through a framework where we do not fit the training set but find the most informative yet least noisy representation of the data simultaneously minimizing the entropy to reduce noise and maximizing it to remain unbiased via adversary training. The result is a general physics-driven model, which is data-efficient and flexible, permitting to control and influence the generative process. Benchmarking shows that our approach outperforms variational autoencoders. We demonstrate the methods effectiveness in generating images, even with limited training data, and its unprecedented capability to customize the generation process a posteriori without any fine-tuning or retraining",
    "authors": [
      "Mattia Miotto, Lorenzo Monacelli"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.840346"
  },
  {
    "id": "oai:arXiv.org:2502.13581v2",
    "journal": "arXiv_CS",
    "title": "ActionPiece: Contextually Tokenizing Action Sequences for Generative Recommendation",
    "link": "https://arxiv.org/abs/2502.13581",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2502.13581v2 Announce Type: replace \nAbstract: Generative recommendation (GR) is an emerging paradigm where user actions are tokenized into discrete token patterns and autoregressively generated as predictions. However, existing GR models tokenize each action independently, assigning the same fixed tokens to identical actions across all sequences without considering contextual relationships. This lack of context-awareness can lead to suboptimal performance, as the same action may hold different meanings depending on its surrounding context. To address this issue, we propose ActionPiece to explicitly incorporate context when tokenizing action sequences. In ActionPiece, each action is represented as a set of item features. Given the action sequence corpora, we construct the vocabulary by merging feature patterns as new tokens, based on their co-occurrence frequency both within individual sets and across adjacent sets. Considering the unordered nature of feature sets, we further introduce set permutation regularization, which produces multiple segmentations of action sequences with the same semantics. Our code is available at: https://github.com/google-deepmind/action_piece.",
    "authors": [
      "Yupeng Hou, Jianmo Ni, Zhankui He, Noveen Sachdeva, Wang-Cheng Kang, Ed H. Chi, Julian McAuley, Derek Zhiyuan Cheng"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.840356"
  },
  {
    "id": "oai:arXiv.org:2502.14074v3",
    "journal": "arXiv_CS",
    "title": "Investigating Non-Transitivity in LLM-as-a-Judge",
    "link": "https://arxiv.org/abs/2502.14074",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2502.14074v3 Announce Type: replace \nAbstract: Automatic evaluation methods based on large language models (LLMs) are emerging as the standard tool for assessing the instruction-following abilities of LLM-based agents. The most common method in this paradigm, pairwise comparisons with a baseline model, critically depends on the assumption of transitive preferences. However, the validity of this assumption remains largely unexplored. In this study, we investigate the presence of non-transitivity within the AlpacaEval framework and analyze its effects on model rankings. We find that LLM judges exhibit non-transitive preferences, leading to rankings that are sensitive to the choice of the baseline model. To mitigate this issue, we show that round-robin tournaments combined with Bradley-Terry models of preference can produce more reliable rankings. Notably, our method increases both the Spearman correlation and the Kendall correlation with Chatbot Arena (95.0% -> 96.4% and 82.1% -> 86.3% respectively). To address the computational cost of round-robin tournaments, we propose Swiss-Wise Iterative Matchmaking (Swim) tournaments, using a dynamic matching strategy to capture the benefits of round-robin tournaments while maintaining computational efficiency.",
    "authors": [
      "Yi Xu, Laura Ruis, Tim Rockt\\\"aschel, Robert Kirk"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.840364"
  },
  {
    "id": "oai:arXiv.org:2502.14896v2",
    "journal": "arXiv_CS",
    "title": "A Comprehensive Survey on Concept Erasure in Text-to-Image Diffusion Models",
    "link": "https://arxiv.org/abs/2502.14896",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2502.14896v2 Announce Type: replace \nAbstract: Text-to-Image (T2I) models have made remarkable progress in generating high-quality, diverse visual content from natural language prompts. However, their ability to reproduce copyrighted styles, sensitive imagery, and harmful content raises significant ethical and legal concerns. Concept erasure offers a proactive alternative to external filtering by modifying T2I models to prevent the generation of undesired content. In this survey, we provide a structured overview of concept erasure, categorizing existing methods based on their optimization strategies and the architectural components they modify. We categorize concept erasure methods into fine-tuning for parameter updates, closed-form solutions for efficient edits, and inference-time interventions for content restriction without weight modification. Additionally, we explore adversarial attacks that bypass erasure techniques and discuss emerging defenses. To support further research, we consolidate key datasets, evaluation metrics, and benchmarks for assessing erasure effectiveness and model robustness. This survey serves as a comprehensive resource, offering insights into the evolving landscape of concept erasure, its challenges, and future directions.",
    "authors": [
      "Changhoon Kim, Yanjun Qi"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.840373"
  },
  {
    "id": "oai:arXiv.org:2502.14914v3",
    "journal": "arXiv_CS",
    "title": "CAPability: A Comprehensive Visual Caption Benchmark for Evaluating Both Correctness and Thoroughness",
    "link": "https://arxiv.org/abs/2502.14914",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2502.14914v3 Announce Type: replace \nAbstract: Visual captioning benchmarks have become outdated with the emergence of modern multimodal large language models (MLLMs), as the brief ground-truth sentences and traditional metrics fail to assess detailed captions effectively. While recent benchmarks attempt to address this by focusing on keyword extraction or object-centric evaluation, they remain limited to vague-view or object-view analyses and incomplete visual element coverage. In this paper, we introduce CAPability, a comprehensive multi-view benchmark for evaluating visual captioning across 12 dimensions spanning six critical views. We curate nearly 11K human-annotated images and videos with visual element annotations to evaluate the generated captions. CAPability stably assesses both the correctness and thoroughness of captions with \\textit{precision} and \\textit{hit} metrics. By converting annotations to QA pairs, we further introduce a heuristic metric, \\textit{know but cannot tell} ($K\\bar{T}$), indicating a significant performance gap between QA and caption capabilities. Our work provides a holistic analysis of MLLMs' captioning abilities, as we identify their strengths and weaknesses across various dimensions, guiding future research to enhance specific aspects of their capabilities.",
    "authors": [
      "Zhihang Liu, Chen-Wei Xie, Bin Wen, Feiwu Yu, Jixuan Chen, Pandeng Li, Boqiang Zhang, Nianzu Yang, Yinglu Li, Zuan Gao, Yun Zheng, Hongtao Xie"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.840382"
  },
  {
    "id": "oai:arXiv.org:2502.14921v2",
    "journal": "arXiv_CS",
    "title": "The Canary's Echo: Auditing Privacy Risks of LLM-Generated Synthetic Text",
    "link": "https://arxiv.org/abs/2502.14921",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2502.14921v2 Announce Type: replace \nAbstract: How much information about training samples can be leaked through synthetic data generated by Large Language Models (LLMs)? Overlooking the subtleties of information flow in synthetic data generation pipelines can lead to a false sense of privacy. In this paper, we assume an adversary has access to some synthetic data generated by a LLM. We design membership inference attacks (MIAs) that target the training data used to fine-tune the LLM that is then used to synthesize data. The significant performance of our MIA shows that synthetic data leak information about the training data. Further, we find that canaries crafted for model-based MIAs are sub-optimal for privacy auditing when only synthetic data is released. Such out-of-distribution canaries have limited influence on the model's output when prompted to generate useful, in-distribution synthetic data, which drastically reduces their effectiveness. To tackle this problem, we leverage the mechanics of auto-regressive models to design canaries with an in-distribution prefix and a high-perplexity suffix that leave detectable traces in synthetic data. This enhances the power of data-based MIAs and provides a better assessment of the privacy risks of releasing synthetic data generated by LLMs.",
    "authors": [
      "Matthieu Meeus, Lukas Wutschitz, Santiago Zanella-B\\'eguelin, Shruti Tople, Reza Shokri"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.840392"
  },
  {
    "id": "oai:arXiv.org:2502.14977v2",
    "journal": "arXiv_CS",
    "title": "Feedforward Few-shot Species Range Estimation",
    "link": "https://arxiv.org/abs/2502.14977",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2502.14977v2 Announce Type: replace \nAbstract: Knowing where a particular species can or cannot be found on Earth is crucial for ecological research and conservation efforts. By mapping the spatial ranges of all species, we would obtain deeper insights into how global biodiversity is affected by climate change and habitat loss. However, accurate range estimates are only available for a relatively small proportion of all known species. For the majority of the remaining species, we typically only have a small number of records denoting the spatial locations where they have previously been observed. We outline a new approach for few-shot species range estimation to address the challenge of accurately estimating the range of a species from limited data. During inference, our model takes a set of spatial locations as input, along with optional metadata such as text or an image, and outputs a species encoding that can be used to predict the range of a previously unseen species in a feedforward manner. We evaluate our approach on two challenging benchmarks, where we obtain state-of-the-art range estimation performance, in a fraction of the compute time, compared to recent alternative approaches.",
    "authors": [
      "Christian Lange, Max Hamilton, Elijah Cole, Alexander Shepard, Samuel Heinrich, Angela Zhu, Subhransu Maji, Grant Van Horn, Oisin Mac Aodha"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.840400"
  },
  {
    "id": "oai:arXiv.org:2502.15051v2",
    "journal": "arXiv_CS",
    "title": "Approximating Latent Manifolds in Neural Networks via Vanishing Ideals",
    "link": "https://arxiv.org/abs/2502.15051",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2502.15051v2 Announce Type: replace \nAbstract: Deep neural networks have reshaped modern machine learning by learning powerful latent representations that often align with the manifold hypothesis: high-dimensional data lie on lower-dimensional manifolds. In this paper, we establish a connection between manifold learning and computational algebra by demonstrating how vanishing ideals can characterize the latent manifolds of deep networks. To that end, we propose a new neural architecture that (i) truncates a pretrained network at an intermediate layer, (ii) approximates each class manifold via polynomial generators of the vanishing ideal, and (iii) transforms the resulting latent space into linearly separable features through a single polynomial layer. The resulting models have significantly fewer layers than their pretrained baselines, while maintaining comparable accuracy, achieving higher throughput, and utilizing fewer parameters. Furthermore, drawing on spectral complexity analysis, we derive sharper theoretical guarantees for generalization, showing that our approach can in principle offer tighter bounds than standard deep networks. Numerical experiments confirm the effectiveness and efficiency of the proposed approach.",
    "authors": [
      "Nico Pelleriti, Max Zimmer, Elias Wirth, Sebastian Pokutta"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.840409"
  },
  {
    "id": "oai:arXiv.org:2502.16671v2",
    "journal": "arXiv_CS",
    "title": "MimeQA: Towards Socially-Intelligent Nonverbal Foundation Models",
    "link": "https://arxiv.org/abs/2502.16671",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2502.16671v2 Announce Type: replace \nAbstract: As AI becomes more closely integrated with peoples' daily activities, socially intelligent AI that can understand and interact seamlessly with humans in daily lives is increasingly important. However, current works in AI social reasoning all rely on language-only or language-dominant approaches to benchmark and training models, resulting in systems that are improving in verbal communication but struggle with nonverbal social understanding. To address this limitation, we tap into a novel data source rich in nonverbal social interactions -- mime videos. Mimes refer to the art of expression through gesture and movement without spoken words, which presents unique challenges and opportunities in interpreting nonverbal social communication. We contribute a new dataset called MimeQA, obtained by sourcing 8 hours of videos clips from YouTube and developing a comprehensive video question-answering benchmark comprising 806 carefully annotated and verified question-answer pairs, designed to probe nonverbal social reasoning capabilities. Using MimeQA, we evaluate state-of-the-art video large language models (vLLMs) and find that they achieve low overall accuracy, ranging from 20-30%, while humans score 86%. Our analysis reveals that vLLMs often fail to ground imagined objects and over-rely on the text prompt while ignoring subtle nonverbal interactions. We hope to inspire future work in AI models that embody true social intelligence capable of interpreting non-verbal human interactions.",
    "authors": [
      "Hengzhi Li, Megan Tjandrasuwita, Yi R. Fung, Armando Solar-Lezama, Paul Pu Liang"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.840425"
  },
  {
    "id": "oai:arXiv.org:2502.16772v4",
    "journal": "arXiv_CS",
    "title": "Model-Based Exploration in Monitored Markov Decision Processes",
    "link": "https://arxiv.org/abs/2502.16772",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2502.16772v4 Announce Type: replace \nAbstract: A tenet of reinforcement learning is that the agent always observes rewards. However, this is not true in many realistic settings, e.g., a human observer may not always be available to provide rewards, sensors may be limited or malfunctioning, or rewards may be inaccessible during deployment. Monitored Markov decision processes (Mon-MDPs) have recently been proposed to model such settings. However, existing Mon-MDP algorithms have several limitations: they do not fully exploit the problem structure, cannot leverage a known monitor, lack worst-case guarantees for 'unsolvable' Mon-MDPs without specific initialization, and offer only asymptotic convergence proofs. This paper makes three contributions. First, we introduce a model-based algorithm for Mon-MDPs that addresses these shortcomings. The algorithm employs two instances of model-based interval estimation: one to ensure that observable rewards are reliably captured, and another to learn the minimax-optimal policy. Second, we empirically demonstrate the advantages. We show faster convergence than prior algorithms in over four dozen benchmarks, and even more dramatic improvement when the monitoring process is known. Third, we present the first finite-sample bound on performance. We show convergence to a minimax-optimal policy even when some rewards are never observable.",
    "authors": [
      "Alireza Kazemipour, Simone Parisi, Matthew E. Taylor, Michael Bowling"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.840433"
  },
  {
    "id": "oai:arXiv.org:2502.18147v2",
    "journal": "arXiv_CS",
    "title": "Jacobian Sparse Autoencoders: Sparsify Computations, Not Just Activations",
    "link": "https://arxiv.org/abs/2502.18147",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2502.18147v2 Announce Type: replace \nAbstract: Sparse autoencoders (SAEs) have been successfully used to discover sparse and human-interpretable representations of the latent activations of LLMs. However, we would ultimately like to understand the computations performed by LLMs and not just their representations. The extent to which SAEs can help us understand computations is unclear because they are not designed to \"sparsify\" computations in any sense, only latent activations. To solve this, we propose Jacobian SAEs (JSAEs), which yield not only sparsity in the input and output activations of a given model component but also sparsity in the computation (formally, the Jacobian) connecting them. With a na\\\"ive implementation, the Jacobians in LLMs would be computationally intractable due to their size. One key technical contribution is thus finding an efficient way of computing Jacobians in this setup. We find that JSAEs extract a relatively large degree of computational sparsity while preserving downstream LLM performance approximately as well as traditional SAEs. We also show that Jacobians are a reasonable proxy for computational sparsity because MLPs are approximately linear when rewritten in the JSAE basis. Lastly, we show that JSAEs achieve a greater degree of computational sparsity on pre-trained LLMs than on the equivalent randomized LLM. This shows that the sparsity of the computational graph appears to be a property that LLMs learn through training, and suggests that JSAEs might be more suitable for understanding learned transformer computations than standard SAEs.",
    "authors": [
      "Lucy Farnik, Tim Lawson, Conor Houghton, Laurence Aitchison"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.840449"
  },
  {
    "id": "oai:arXiv.org:2502.18952v2",
    "journal": "arXiv_CS",
    "title": "DualSpec: Text-to-spatial-audio Generation via Dual-Spectrogram Guided Diffusion Model",
    "link": "https://arxiv.org/abs/2502.18952",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2502.18952v2 Announce Type: replace \nAbstract: Text-to-audio (TTA), which generates audio signals from textual descriptions, has received huge attention in recent years. However, recent works focused on text to monaural audio only. As we know, spatial audio provides more immersive auditory experience than monaural audio, e.g. in virtual reality. To address this issue, we propose a text-to-spatial-audio (TTSA) generation framework named DualSpec. Specifically, it first trains variational autoencoders (VAEs) for extracting the latent acoustic representations from sound event audio. Then, given text that describes sound events and event directions, the proposed method uses the encoder of a pretrained large language model to transform the text into text features. Finally, it trains a diffusion model from the latent acoustic representations and text features for the spatial audio generation. In the inference stage, only the text description is needed to generate spatial audio. Particularly, to improve the synthesis quality and azimuth accuracy of the spatial sound events simultaneously, we propose to use two kinds of acoustic features. One is the Mel spectrograms which is good for improving the synthesis quality, and the other is the short-time Fourier transform spectrograms which is good at improving the azimuth accuracy. We provide a pipeline of constructing spatial audio dataset with text prompts, for the training of the VAEs and diffusion model. We also introduce new spatial-aware evaluation metrics to quantify the azimuth errors of the generated spatial audio recordings. Experimental results demonstrate that the proposed method can generate spatial audio with high directional and event consistency.",
    "authors": [
      "Lei Zhao, Sizhou Chen, Linfeng Feng, Jichao Zhang, Xiao-Lei Zhang, Chi Zhang, Xuelong Li"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.840458"
  },
  {
    "id": "oai:arXiv.org:2502.19285v3",
    "journal": "arXiv_CS",
    "title": "On the Importance of Text Preprocessing for Multimodal Representation Learning and Pathology Report Generation",
    "link": "https://arxiv.org/abs/2502.19285",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2502.19285v3 Announce Type: replace \nAbstract: Vision-language models in pathology enable multimodal case retrieval and automated report generation. Many of the models developed so far, however, have been trained on pathology reports that include information which cannot be inferred from paired whole slide images (e.g., patient history), potentially leading to hallucinated sentences in generated reports. To this end, we investigate how the selection of information from pathology reports for vision-language modeling affects the quality of the multimodal representations and generated reports. More concretely, we compare a model trained on full reports against a model trained on preprocessed reports that only include sentences describing the cell and tissue appearances based on the H&amp;E-stained slides. For the experiments, we built upon the BLIP-2 framework and used a cutaneous melanocytic lesion dataset of 42,433 H&amp;E-stained whole slide images and 19,636 corresponding pathology reports. Model performance was assessed using image-to-text and text-to-image retrieval, as well as qualitative evaluation of the generated reports by an expert pathologist. Our results demonstrate that text preprocessing prevents hallucination in report generation. Despite the improvement in the quality of the generated reports, training the vision-language model on full reports showed better cross-modal retrieval performance.",
    "authors": [
      "Ruben T. Lucassen, Tijn van de Luijtgaarden, Sander P. J. Moonemans, Gerben E. Breimer, Willeke A. M. Blokx, Mitko Veta"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.840476"
  },
  {
    "id": "oai:arXiv.org:2502.19979v2",
    "journal": "arXiv_CS",
    "title": "A novel non-convex minimax $p$-th order concave penalty function approach to low-rank tensor completion",
    "link": "https://arxiv.org/abs/2502.19979",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2502.19979v2 Announce Type: replace \nAbstract: The low-rank tensor completion (LRTC) problem aims to reconstruct a tensor from partial sample information, which has attracted significant interest in a wide range of practical applications such as image processing and computer vision. Among the various techniques employed for the LRTC problem, non-convex relaxation methods have been widely studied for their effectiveness in handling tensor singular values, which are crucial for accurate tensor recovery. While the minimax concave penalty (MCP) non-convex relaxation method has achieved promising results in tackling the LRTC problem and gained widely adopted, it exhibits a notable limitation: insufficient penalty on small singular values during the singular value handling process, resulting in inefficient tensor recovery. To address this issue and enhance recovery performance, a novel minimax $p$-th order concave penalty (MPCP) function is proposed. Based on this novel function, a tensor $p$-th order $\\tau$ norm is proposed as a non-convex relaxation for tensor rank approximation, thereby establishing an MPCP-based LRTC model. Furthermore, theoretical convergence guarantees are rigorously established for the proposed method. Extensive numerical experiments conducted on multiple real datasets demonstrate that the proposed method outperforms the state-of-the-art methods in both visual quality and quantitative metrics.",
    "authors": [
      "Hongbing Zhang, Bing Zheng"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.840485"
  },
  {
    "id": "oai:arXiv.org:2502.20332v2",
    "journal": "arXiv_CS",
    "title": "Emergent Symbolic Mechanisms Support Abstract Reasoning in Large Language Models",
    "link": "https://arxiv.org/abs/2502.20332",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2502.20332v2 Announce Type: replace \nAbstract: Many recent studies have found evidence for emergent reasoning capabilities in large language models (LLMs), but debate persists concerning the robustness of these capabilities, and the extent to which they depend on structured reasoning mechanisms. To shed light on these issues, we study the internal mechanisms that support abstract reasoning in LLMs. We identify an emergent symbolic architecture that implements abstract reasoning via a series of three computations. In early layers, symbol abstraction heads convert input tokens to abstract variables based on the relations between those tokens. In intermediate layers, symbolic induction heads perform sequence induction over these abstract variables. Finally, in later layers, retrieval heads predict the next token by retrieving the value associated with the predicted abstract variable. These results point toward a resolution of the longstanding debate between symbolic and neural network approaches, suggesting that emergent reasoning in neural networks depends on the emergence of symbolic mechanisms.",
    "authors": [
      "Yukang Yang, Declan Campbell, Kaixuan Huang, Mengdi Wang, Jonathan Cohen, Taylor Webb"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.840494"
  },
  {
    "id": "oai:arXiv.org:2502.20338v2",
    "journal": "arXiv_CS",
    "title": "KeBaB: $k$-mer based breaking for finding long MEMs",
    "link": "https://arxiv.org/abs/2502.20338",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2502.20338v2 Announce Type: replace \nAbstract: Long maximal exact matches (MEMs) are used in many genomics applications such as read classification and sequence alignment. Li's ropebwt3 finds long MEMs quickly because it can often ignore much of its input. In this paper we show that a fast and space efficient $k$-mer filtration step using a Bloom filter speeds up MEM-finders such as ropebwt3 even further by letting them ignore even more. We also show experimentally that our approach can accelerate metagenomic classification without significantly hurting accuracy.",
    "authors": [
      "Nathaniel K. Brown, Anas Alhadi, Nour Allam, Dove Begleiter, Nithin Bharathi Kabilan Karpagavalli, Suchith Sridhar Khajjayam, Hamza Wahed, Travis Gagie"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.840503"
  },
  {
    "id": "oai:arXiv.org:2502.20785v2",
    "journal": "arXiv_CS",
    "title": "GraphCheck: Multi-Path Fact-Checking with Entity-Relationship Graphs",
    "link": "https://arxiv.org/abs/2502.20785",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2502.20785v2 Announce Type: replace \nAbstract: Automated fact-checking aims to assess the truthfulness of textual claims based on relevant evidence. However, verifying complex claims that require multi-hop reasoning remains a significant challenge. We propose GraphCheck, a novel framework that transforms claims into entity-relationship graphs for structured and systematic verification. By explicitly modeling both explicit and latent entities and exploring multiple reasoning paths, GraphCheck improves verification robustness. While GraphCheck excels in complex scenarios, it may be unnecessarily elaborate for simpler claims. To address this, we introduce DP-GraphCheck, a variant that employs a lightweight strategy selector to adaptively choose between direct prompting and GraphCheck. This selective mechanism improves both accuracy and efficiency by applying the appropriate level of reasoning to each claim. Experiments on the HOVER and EX-FEVER datasets demonstrate that our approach outperforms existing methods, particularly on multi-hop claims. Moreover, the strategy selection mechanism in DP-GraphCheck generalizes well to other fact-checking pipelines, highlighting the versatility of our framework.",
    "authors": [
      "Hyewon Jeon, Jay-Yoon Lee"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.840511"
  },
  {
    "id": "oai:arXiv.org:2503.00211v2",
    "journal": "arXiv_CS",
    "title": "SafeAuto: Knowledge-Enhanced Safe Autonomous Driving with Multimodal Foundation Models",
    "link": "https://arxiv.org/abs/2503.00211",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2503.00211v2 Announce Type: replace \nAbstract: Traditional autonomous driving systems often struggle to connect high-level reasoning with low-level control, leading to suboptimal and sometimes unsafe behaviors. Recent advances in multimodal large language models (MLLMs), which process both visual and textual data, offer an opportunity to unify perception and reasoning. However, effectively embedding precise safety knowledge into MLLMs for autonomous driving remains a significant challenge. To address this, we propose SafeAuto, a framework that enhances MLLM-based autonomous driving by incorporating both unstructured and structured knowledge. First, we introduce a Position-Dependent Cross-Entropy (PDCE) loss to improve low-level control signal predictions when values are represented as text. Second, to explicitly integrate safety knowledge, we develop a reasoning component that translates traffic rules into first-order logic (e.g., \"red light $\\implies$ stop\") and embeds them into a probabilistic graphical model (e.g., Markov Logic Network) to verify predicted actions using recognized environmental attributes. Additionally, our Multimodal Retrieval-Augmented Generation (RAG) model leverages video, control signals, and environmental attributes to learn from past driving experiences. Integrating PDCE, MLN, and Multimodal RAG, SafeAuto outperforms existing baselines across multiple datasets, enabling more accurate, reliable, and safer autonomous driving. The code is available at https://github.com/AI-secure/SafeAuto.",
    "authors": [
      "Jiawei Zhang, Xuan Yang, Taiqi Wang, Yu Yao, Aleksandr Petiushko, Bo Li"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.840520"
  },
  {
    "id": "oai:arXiv.org:2503.01713v3",
    "journal": "arXiv_CS",
    "title": "SAGE: A Framework of Precise Retrieval for RAG",
    "link": "https://arxiv.org/abs/2503.01713",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2503.01713v3 Announce Type: replace \nAbstract: Retrieval-augmented generation (RAG) has demonstrated significant proficiency in conducting question-answering (QA) tasks within a specified corpus. Nonetheless, numerous failure instances of RAG in QA still exist. These failures are not solely attributable to the limitations of Large Language Models (LLMs); instead, they predominantly arise from the retrieval of inaccurate information for LLMs due to two limitations: (1) Current RAG methods segment the corpus without considering semantics, making it difficult to find relevant context due to impaired correlation between questions and the segments. (2) There is a trade-off between missing essential context with fewer context retrieved and getting irrelevant context with more context retrieved.\n  In this paper, we introduce a RAG framework (SAGE), to overcome these limitations. First, to address the segmentation issue without considering semantics, we propose to train a semantic segmentation model. This model is trained to segment the corpus into semantically complete chunks. Second, to ensure that only the most relevant chunks are retrieved while the irrelevant ones are ignored, we design a chunk selection algorithm to dynamically select chunks based on the decreasing speed of the relevance score, leading to a more relevant selection. Third, to further ensure the precision of the retrieved chunks, we propose letting LLMs assess whether retrieved chunks are excessive or lacking and then adjust the amount of context accordingly. Experiments show that SAGE outperforms baselines by 61.25% in the quality of QA on average. Moreover, by avoiding retrieving noisy context, SAGE lowers the cost of the tokens consumed in LLM inference and achieves a 49.41% enhancement in cost efficiency on average. Additionally, our work offers valuable insights for boosting RAG.",
    "authors": [
      "Jintao Zhang, Guoliang Li, Jinyang Su"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.840545"
  },
  {
    "id": "oai:arXiv.org:2503.02169v2",
    "journal": "arXiv_CS",
    "title": "One Stone, Two Birds: Enhancing Adversarial Defense Through the Lens of Distributional Discrepancy",
    "link": "https://arxiv.org/abs/2503.02169",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2503.02169v2 Announce Type: replace \nAbstract: Statistical adversarial data detection (SADD) detects whether an upcoming batch contains adversarial examples (AEs) by measuring the distributional discrepancies between clean examples (CEs) and AEs. In this paper, we explore the strength of SADD-based methods by theoretically showing that minimizing distributional discrepancy can help reduce the expected loss on AEs. Despite these advantages, SADD-based methods have a potential limitation: they discard inputs that are detected as AEs, leading to the loss of useful information within those inputs. To address this limitation, we propose a two-pronged adversarial defense method, named Distributional-discrepancy-based Adversarial Defense (DAD). In the training phase, DAD first optimizes the test power of the maximum mean discrepancy (MMD) to derive MMD-OPT, which is a stone that kills two birds. MMD-OPT first serves as a guiding signal to minimize the distributional discrepancy between CEs and AEs to train a denoiser. Then, it serves as a discriminator to differentiate CEs and AEs during inference. Overall, in the inference stage, DAD consists of a two-pronged process: (1) directly feeding the detected CEs into the classifier, and (2) removing noise from the detected AEs by the distributional-discrepancy-based denoiser. Extensive experiments show that DAD outperforms current state-of-the-art (SOTA) defense methods by simultaneously improving clean and robust accuracy on CIFAR-10 and ImageNet-1K against adaptive white-box attacks. Codes are publicly available at: https://github.com/tmlr-group/DAD.",
    "authors": [
      "Jiacheng Zhang, Benjamin I. P. Rubinstein, Jingfeng Zhang, Feng Liu"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.840562"
  },
  {
    "id": "oai:arXiv.org:2503.02174v2",
    "journal": "arXiv_CS",
    "title": "Adversarial Tokenization",
    "link": "https://arxiv.org/abs/2503.02174",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2503.02174v2 Announce Type: replace \nAbstract: Current LLM pipelines account for only one possible tokenization for a given string, ignoring exponentially many alternative tokenizations during training and inference. For example, the standard Llama3 tokenization of penguin is [p,enguin], yet [peng,uin] is another perfectly valid alternative. In this paper, we show that despite LLMs being trained solely on one tokenization, they still retain semantic understanding of other tokenizations, raising questions about their implications in LLM safety. Put succinctly, we answer the following question: can we adversarially tokenize an obviously malicious string to evade safety and alignment restrictions? We show that not only is adversarial tokenization an effective yet previously neglected axis of attack, but it is also competitive against existing state-of-the-art adversarial approaches without changing the text of the harmful request. We empirically validate this exploit across three state-of-the-art LLMs and adversarial datasets, revealing a previously unknown vulnerability in subword models.",
    "authors": [
      "Renato Lui Geh, Zilei Shao, Guy Van den Broeck"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.840570"
  },
  {
    "id": "oai:arXiv.org:2503.03025v2",
    "journal": "arXiv_CS",
    "title": "Hierarchical Refinement: Optimal Transport to Infinity and Beyond",
    "link": "https://arxiv.org/abs/2503.03025",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2503.03025v2 Announce Type: replace \nAbstract: Optimal transport (OT) has enjoyed great success in machine learning as a principled way to align datasets via a least-cost correspondence, driven in large part by the runtime efficiency of the Sinkhorn algorithm (Cuturi, 2013). However, Sinkhorn has quadratic space complexity in the number of points, limiting scalability to larger datasets. Low-rank OT achieves linear-space complexity, but by definition, cannot compute a one-to-one correspondence between points. When the optimal transport problem is an assignment problem between datasets then an optimal mapping, known as the Monge map, is guaranteed to be a bijection. In this setting, we show that the factors of an optimal low-rank coupling co-cluster each point with its image under the Monge map. We leverage this invariant to derive an algorithm, Hierarchical Refinement (HiRef), that dynamically constructs a multiscale partition of each dataset using low-rank OT subproblems, culminating in a bijective coupling. Hierarchical Refinement uses linear space and has log-linear runtime, retaining the space advantage of low-rank OT while overcoming its limited resolution. We demonstrate the advantages of Hierarchical Refinement on several datasets, including ones containing over a million points, scaling full-rank OT to problems previously beyond Sinkhorn's reach.",
    "authors": [
      "Peter Halmos, Julian Gold, Xinhao Liu, Benjamin J. Raphael"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.840578"
  },
  {
    "id": "oai:arXiv.org:2503.04256v4",
    "journal": "arXiv_CS",
    "title": "Knowledge Retention for Continual Model-Based Reinforcement Learning",
    "link": "https://arxiv.org/abs/2503.04256",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2503.04256v4 Announce Type: replace \nAbstract: We propose DRAGO, a novel approach for continual model-based reinforcement learning aimed at improving the incremental development of world models across a sequence of tasks that differ in their reward functions but not the state space or dynamics. DRAGO comprises two key components: Synthetic Experience Rehearsal, which leverages generative models to create synthetic experiences from past tasks, allowing the agent to reinforce previously learned dynamics without storing data, and Regaining Memories Through Exploration, which introduces an intrinsic reward mechanism to guide the agent toward revisiting relevant states from prior tasks. Together, these components enable the agent to maintain a comprehensive and continually developing world model, facilitating more effective learning and adaptation across diverse environments. Empirical evaluations demonstrate that DRAGO is able to preserve knowledge across tasks, achieving superior performance in various continual learning scenarios.",
    "authors": [
      "Yixiang Sun, Haotian Fu, Michael Littman, George Konidaris"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.840587"
  },
  {
    "id": "oai:arXiv.org:2503.05574v2",
    "journal": "arXiv_CS",
    "title": "BARK: A Fully Bayesian Tree Kernel for Black-box Optimization",
    "link": "https://arxiv.org/abs/2503.05574",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2503.05574v2 Announce Type: replace \nAbstract: We perform Bayesian optimization using a Gaussian process perspective on Bayesian Additive Regression Trees (BART). Our BART Kernel (BARK) uses tree agreement to define a posterior over piecewise-constant functions, and we explore the space of tree kernels using a Markov chain Monte Carlo approach. Where BART only samples functions, the resulting BARK model obtains samples of Gaussian processes defining distributions over functions, which allow us to build acquisition functions for Bayesian optimization. Our tree-based approach enables global optimization over the surrogate, even for mixed-feature spaces. Moreover, where many previous tree-based kernels provide uncertainty quantification over function values, our sampling scheme captures uncertainty over the tree structure itself. Our experiments show the strong performance of BARK on both synthetic and applied benchmarks, due to the combination of our fully Bayesian surrogate and the optimization procedure.",
    "authors": [
      "Toby Boyne, Jose Pablo Folch, Robert M Lee, Behrang Shafei, Ruth Misener"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.840610"
  },
  {
    "id": "oai:arXiv.org:2503.05613v2",
    "journal": "arXiv_CS",
    "title": "A Survey on Sparse Autoencoders: Interpreting the Internal Mechanisms of Large Language Models",
    "link": "https://arxiv.org/abs/2503.05613",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2503.05613v2 Announce Type: replace \nAbstract: Large Language Models (LLMs) have transformed natural language processing, yet their internal mechanisms remain largely opaque. Recently, mechanistic interpretability has attracted significant attention from the research community as a means to understand the inner workings of LLMs. Among various mechanistic interpretability approaches, Sparse Autoencoders (SAEs) have emerged as a promising method due to their ability to disentangle the complex, superimposed features within LLMs into more interpretable components. This paper presents a comprehensive survey of SAEs for interpreting and understanding the internal workings of LLMs. Our major contributions include: (1) exploring the technical framework of SAEs, covering basic architecture, design improvements, and effective training strategies; (2) examining different approaches to explaining SAE features, categorized into input-based and output-based explanation methods; (3) discussing evaluation methods for assessing SAE performance, covering both structural and functional metrics; and (4) investigating real-world applications of SAEs in understanding and manipulating LLM behaviors.",
    "authors": [
      "Dong Shu, Xuansheng Wu, Haiyan Zhao, Daking Rai, Ziyu Yao, Ninghao Liu, Mengnan Du"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.840619"
  },
  {
    "id": "oai:arXiv.org:2503.06542v2",
    "journal": "arXiv_CS",
    "title": "ARMOR: Empowering Multimodal Understanding Model with Interleaved Multimodal Generation Capability",
    "link": "https://arxiv.org/abs/2503.06542",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2503.06542v2 Announce Type: replace \nAbstract: Unified multimodal understanding and generation have recently received much attention in the area of vision and language. Existing UniMs are designed to simultaneously learn both multimodal understanding and generation capabilities, demanding substantial computational resources, and often struggle to generate interleaved text-image. We present ARMOR, a resource-efficient and pure autoregressive framework that achieves both understanding and generation by fine-tuning existing multimodal large language models (MLLMs). Specifically, ARMOR extends existing MLLMs from three perspectives: (1) For model architecture, an asymmetric encoder-decoder architecture with a forward-switching mechanism is introduced to unify embedding space integrating textual and visual modalities for enabling natural text-image interleaved generation with minimal computational overhead. (2) For training data, a meticulously curated, high-quality interleaved dataset is collected for fine-tuning MLLMs. (3) For the training algorithm, we propose a ``what or how to generate'' algorithm to empower existing MLLMs with multimodal generation capabilities while preserving their multimodal understanding capabilities, through three progressive training stages based on the collected dataset. Experimental results demonstrate that ARMOR upgrades existing MLLMs to UniMs with promising image generation capabilities, using limited training resources. Our code will be released soon at https://github.com/finyorko/armor.",
    "authors": [
      "Jianwen Sun, Yukang Feng, Chuanhao Li, Fanrui Zhang, Zizhen Li, Jiaxin Ai, Sizhuo Zhou, Yu Dai, Shenglin Zhang, Kaipeng Zhang"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.840628"
  },
  {
    "id": "oai:arXiv.org:2503.06608v2",
    "journal": "arXiv_CS",
    "title": "GroMo: Plant Growth Modeling with Multiview Images",
    "link": "https://arxiv.org/abs/2503.06608",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2503.06608v2 Announce Type: replace \nAbstract: Understanding plant growth dynamics is essential for applications in agriculture and plant phenotyping. We present the Growth Modelling (GroMo) challenge, which is designed for two primary tasks: (1) plant age prediction and (2) leaf count estimation, both essential for crop monitoring and precision agriculture. For this challenge, we introduce GroMo25, a dataset with images of four crops: radish, okra, wheat, and mustard. Each crop consists of multiple plants (p1, p2, ..., pn) captured over different days (d1, d2, ..., dm) and categorized into five levels (L1, L2, L3, L4, L5). Each plant is captured from 24 different angles with a 15-degree gap between images. Participants are required to perform both tasks for all four crops with these multiview images. We proposed a Multiview Vision Transformer (MVVT) model for the GroMo challenge and evaluated the crop-wise performance on GroMo25. MVVT reports an average MAE of 7.74 for age prediction and an MAE of 5.52 for leaf count. The GroMo Challenge aims to advance plant phenotyping research by encouraging innovative solutions for tracking and predicting plant growth. The GitHub repository is publicly available at https://github.com/mriglab/GroMo-Plant-Growth-Modeling-with-Multiview-Images.",
    "authors": [
      "Ruchi Bhatt, Shreya Bansal, Amanpreet Chander, Rupinder Kaur, Malya Singh, Mohan Kankanhalli, Abdulmotaleb El Saddik, Mukesh Kumar Saini"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.840636"
  },
  {
    "id": "oai:arXiv.org:2503.08485v2",
    "journal": "arXiv_CS",
    "title": "TT-Occ: Test-Time Compute for Self-Supervised Occupancy via Spatio-Temporal Gaussian Splatting",
    "link": "https://arxiv.org/abs/2503.08485",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2503.08485v2 Announce Type: replace \nAbstract: Self-supervised 3D occupancy prediction offers a promising solution for understanding complex driving scenes without requiring costly 3D annotations. However, training dense occupancy decoders to capture fine-grained geometry and semantics can demand hundreds of GPU hours, and once trained, such models struggle to adapt to varying voxel resolutions or novel object categories without extensive retraining. To overcome these limitations, we propose a practical and flexible test-time occupancy prediction framework termed TT-Occ. Our method incrementally constructs, optimizes and voxelizes time-aware 3D Gaussians from raw sensor streams by integrating vision foundation models (VLMs) at runtime. The flexible nature of 3D Gaussians allows voxelization at arbitrary user-specified resolutions, while the generalization ability of VLMs enables accurate perception and open-vocabulary recognition, without any network training or fine-tuning. Specifically, TT-Occ operates in a lift-track-voxelize symphony: We first lift the geometry and semantics of surrounding-view extracted from VLMs to instantiate Gaussians at 3D space; Next, we track dynamic Gaussians while accumulating static ones to complete the scene and enforce temporal consistency; Finally, we voxelize the optimized Gaussians to generate occupancy prediction. Optionally, inherent noise in VLM predictions and tracking is mitigated by periodically smoothing neighboring Gaussians during optimization. To validate the generality and effectiveness of our framework, we offer two variants: one LiDAR-based and one vision-centric, and conduct extensive experiments on Occ3D and nuCraft benchmarks with varying voxel resolutions. Code will be available at https://github.com/Xian-Bei/TT-Occ.",
    "authors": [
      "Fengyi Zhang, Huitong Yang, Zheng Zhang, Zi Huang, Yadan Luo"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.840645"
  },
  {
    "id": "oai:arXiv.org:2503.10966v4",
    "journal": "arXiv_CS",
    "title": "Is Your Imitation Learning Policy Better than Mine? Policy Comparison with Near-Optimal Stopping",
    "link": "https://arxiv.org/abs/2503.10966",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2503.10966v4 Announce Type: replace \nAbstract: Imitation learning has enabled robots to perform complex, long-horizon tasks in challenging dexterous manipulation settings. As new methods are developed, they must be rigorously evaluated and compared against corresponding baselines through repeated evaluation trials. However, policy comparison is fundamentally constrained by a small feasible sample size (e.g., 10 or 50) due to significant human effort and limited inference throughput of policies. This paper proposes a novel statistical framework for rigorously comparing two policies in the small sample size regime. Prior work in statistical policy comparison relies on batch testing, which requires a fixed, pre-determined number of trials and lacks flexibility in adapting the sample size to the observed evaluation data. Furthermore, extending the test with additional trials risks inducing inadvertent p-hacking, undermining statistical assurances. In contrast, our proposed statistical test is sequential, allowing researchers to decide whether or not to run more trials based on intermediate results. This adaptively tailors the number of trials to the difficulty of the underlying comparison, saving significant time and effort without sacrificing probabilistic correctness. Extensive numerical simulation and real-world robot manipulation experiments show that our test achieves near-optimal stopping, letting researchers stop evaluation and make a decision in a near-minimal number of trials. Specifically, it reduces the number of evaluation trials by up to 32% as compared to state-of-the-art baselines, while preserving the probabilistic correctness and statistical power of the comparison. Moreover, our method is strongest in the most challenging comparison instances (requiring the most evaluation trials); in a multi-task comparison scenario, we save the evaluator more than 160 simulation rollouts.",
    "authors": [
      "David Snyder, Asher James Hancock, Apurva Badithela, Emma Dixon, Patrick Miller, Rares Andrei Ambrus, Anirudha Majumdar, Masha Itkina, Haruki Nishimura"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.840654"
  },
  {
    "id": "oai:arXiv.org:2503.10996v2",
    "journal": "arXiv_CS",
    "title": "Taming Knowledge Conflicts in Language Models",
    "link": "https://arxiv.org/abs/2503.10996",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2503.10996v2 Announce Type: replace \nAbstract: Language Models (LMs) often encounter knowledge conflicts when parametric memory contradicts contextual knowledge. Previous works attribute this conflict to the interplay between \"memory heads\" and \"context heads\", attention heads assumed to promote either memory or context exclusively. In this study, we go beyond this fundamental assumption by uncovering a critical phenomenon we term the superposition of contextual information and parametric memory, where highly influential attention heads simultaneously contribute to both memory and context. Building upon this insight, we propose Just Run Twice (JuICE), a test-time attention intervention method that steers LMs toward either parametric beliefs or contextual knowledge without requiring fine-tuning. JuICE identifies a set of reliable attention heads and leverages a dual-run approach to mitigate the superposition effects. Extensive experiments across 11 datasets and 6 model architectures demonstrate that JuICE sets the new state-of-the-art performance and robust generalization, achieving significant and consistent improvement across different domains under various conflict types. Finally, we theoretically analyze knowledge conflict and the superposition of contextual information and parametric memory in attention heads, which further elucidates the effectiveness of JuICE in these settings. Our code is available at https://github.com/GaotangLi/JUICE.",
    "authors": [
      "Gaotang Li, Yuzhong Chen, Hanghang Tong"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.840662"
  },
  {
    "id": "oai:arXiv.org:2503.11423v2",
    "journal": "arXiv_CS",
    "title": "TASTE-Rob: Advancing Video Generation of Task-Oriented Hand-Object Interaction for Generalizable Robotic Manipulation",
    "link": "https://arxiv.org/abs/2503.11423",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2503.11423v2 Announce Type: replace \nAbstract: We address key limitations in existing datasets and models for task-oriented hand-object interaction video generation, a critical approach of generating video demonstrations for robotic imitation learning. Current datasets, such as Ego4D, often suffer from inconsistent view perspectives and misaligned interactions, leading to reduced video quality and limiting their applicability for precise imitation learning tasks. Towards this end, we introduce TASTE-Rob -- a pioneering large-scale dataset of 100,856 ego-centric hand-object interaction videos. Each video is meticulously aligned with language instructions and recorded from a consistent camera viewpoint to ensure interaction clarity. By fine-tuning a Video Diffusion Model (VDM) on TASTE-Rob, we achieve realistic object interactions, though we observed occasional inconsistencies in hand grasping postures. To enhance realism, we introduce a three-stage pose-refinement pipeline that improves hand posture accuracy in generated videos. Our curated dataset, coupled with the specialized pose-refinement framework, provides notable performance gains in generating high-quality, task-oriented hand-object interaction videos, resulting in achieving superior generalizable robotic manipulation. The TASTE-Rob dataset is publicly available to foster further advancements in the field, TASTE-Rob dataset and source code will be made publicly available on our website https://taste-rob.github.io.",
    "authors": [
      "Hongxiang Zhao, Xingchen Liu, Mutian Xu, Yiming Hao, Weikai Chen, Xiaoguang Han"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.840672"
  },
  {
    "id": "oai:arXiv.org:2503.12730v3",
    "journal": "arXiv_CS",
    "title": "TinySQL: A Progressive Text-to-SQL Dataset for Mechanistic Interpretability Research",
    "link": "https://arxiv.org/abs/2503.12730",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2503.12730v3 Announce Type: replace \nAbstract: Mechanistic interpretability research faces a gap between analyzing simple circuits in toy tasks and discovering features in large models. To bridge this gap, we propose text-to-SQL generation as an ideal task to study, as it combines the formal structure of toy tasks with real-world complexity. We introduce TinySQL, a synthetic dataset, progressing from basic to advanced SQL operations, and train models ranging from 33M to 1B parameters to establish a comprehensive testbed for interpretability. We apply multiple complementary interpretability techniques, including Edge Attribution Patching and Sparse Autoencoders, to identify minimal circuits and components supporting SQL generation. We compare circuits for different SQL subskills, evaluating their minimality, reliability, and identifiability. Finally, we conduct a layerwise logit lens analysis to reveal how models compose SQL queries across layers: from intent recognition to schema resolution to structured generation. Our work provides a robust framework for probing and comparing interpretability methods in a structured, progressively complex setting.",
    "authors": [
      "Abir Harrasse, Philip Quirke, Clement Neo, Dhruv Nathawani, Luke Marks, Amir Abdullah"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.840681"
  },
  {
    "id": "oai:arXiv.org:2503.14887v2",
    "journal": "arXiv_CS",
    "title": "Pseudo Relevance Feedback is Enough to Close the Gap Between Small and Large Dense Retrieval Models",
    "link": "https://arxiv.org/abs/2503.14887",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2503.14887v2 Announce Type: replace \nAbstract: Scaling dense retrievers to larger large language model (LLM) backbones has been a dominant strategy for improving their retrieval effectiveness. However, this has substantial cost implications: larger backbones require more expensive hardware (e.g. GPUs with more memory) and lead to higher indexing and querying costs (latency, energy consumption). In this paper, we challenge this paradigm by introducing PromptPRF, a feature-based pseudo-relevance feedback (PRF) framework that enables small LLM-based dense retrievers to achieve effectiveness comparable to much larger models.\n  PromptPRF uses LLMs to extract query-independent, structured and unstructured features (e.g., entities, summaries, chain-of-thought keywords, essay) from top-ranked documents. These features are generated offline and integrated into dense query representations via prompting, enabling efficient retrieval without additional training. Unlike prior methods such as GRF, which rely on online, query-specific generation and sparse retrieval, PromptPRF decouples feedback generation from query processing and supports dense retrievers in a fully zero-shot setting.\n  Experiments on TREC DL and BEIR benchmarks demonstrate that PromptPRF consistently improves retrieval effectiveness and offers favourable cost-effectiveness trade-offs. We further present ablation studies to understand the role of positional feedback and analyse the interplay between feature extractor size, PRF depth, and model performance. Our findings demonstrate that with effective PRF design, scaling the retriever is not always necessary, narrowing the gap between small and large models while reducing inference cost.",
    "authors": [
      "Hang Li, Xiao Wang, Bevan Koopman, Guido Zuccon"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.840690"
  },
  {
    "id": "oai:arXiv.org:2503.16139v2",
    "journal": "arXiv_CS",
    "title": "Aging-aware Energy Management for Residential Multi-Carrier Energy Systems",
    "link": "https://arxiv.org/abs/2503.16139",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2503.16139v2 Announce Type: replace \nAbstract: In the context of building electrification, the operation of distributed energy resources integrating multiple energy carriers (electricity, heat, mobility) poses a significant challenge due to the nonlinear device dynamics, uncertainty, and computational issues. As such, energy management systems seek to decide set points for the primary control layer in the best way possible. The objective is to minimize and balance operative costs (energy bills or asset degradation) with user requirements (mobility, heating, etc.). This paper presents a novel aging-aware day-ahead algorithm for electrified buildings. The proposed energy management algorithm incorporates physics-based battery aging models to enhance the operational performance, making explicit the trade-off between grid cost and battery degradation. The proposed day-ahead algorithm can either cut-down on grid costs or extend battery lifetime (electric vehicle or static packs). Moreover, it exploits the differences between cathode chemistries improving grid costs by 25\\% when using LFP cells, with respect to NMC cells. Finally the performance using aged batteries is also enhanced, with respect to the benchmarks.",
    "authors": [
      "Dar\\'io Slaifstein (Delft University of Technology), Gautham Ram Chandra Mouli (Delft University of Technology), Laura Ramirez-Elizondo (Delft University of Technology), Pavol Bauer (Delft University of Technology)"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.840700"
  },
  {
    "id": "oai:arXiv.org:2503.17496v2",
    "journal": "arXiv_CS",
    "title": "The Akhiezer iteration and inverse-free solvers for Sylvester matrix equations",
    "link": "https://arxiv.org/abs/2503.17496",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2503.17496v2 Announce Type: replace \nAbstract: Two inverse-free iterative methods are developed for solving Sylvester matrix equations when the spectra of the coefficient matrices are on, or near, known disjoint subintervals of the real axis. Both methods use the recently-introduced Akhiezer iteration: one to address an equivalent problem of approximating the matrix sign function applied to a block matrix and the other to directly approximate the inverse of the Sylvester operator. In each case this results in provable and computable geometric rates of convergence. When the right-hand side matrix is low rank, both methods require only low-rank matrix-matrix products. Relative to existing approaches, the methods presented here can be more efficient and require less storage when the coefficient matrices are dense or otherwise costly to invert. Applications include solving partial differential equations and computing Fr\\'echet derivatives.",
    "authors": [
      "Cade Ballew, Thomas Trogdon, Heather Wilber"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.840708"
  },
  {
    "id": "oai:arXiv.org:2503.19476v2",
    "journal": "arXiv_CS",
    "title": "Extracting Interpretable Logic Rules from Graph Neural Networks",
    "link": "https://arxiv.org/abs/2503.19476",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2503.19476v2 Announce Type: replace \nAbstract: Graph neural networks (GNNs) operate over both input feature spaces and combinatorial graph structures, making it challenging to understand the rationale behind their predictions. As GNNs gain widespread popularity and demonstrate success across various domains, such as drug discovery, studying their interpretability has become a critical task. To address this, many explainability methods have been proposed, with recent efforts shifting from instance-specific explanations to global concept-based explainability. However, these approaches face several limitations, such as relying on predefined concepts and explaining only a limited set of patterns. To address this, we propose a novel framework, LOGICXGNN, for extracting interpretable logic rules from GNNs. LOGICXGNN is model-agnostic, efficient, and data-driven, eliminating the need for predefined concepts. More importantly, it can serve as a rule-based classifier and even outperform the original neural models. Its interpretability facilitates knowledge discovery, as demonstrated by its ability to extract detailed and accurate chemistry knowledge that is often overlooked by existing methods. Another key advantage of LOGICXGNN is its ability to generate new graph instances in a controlled and transparent manner, offering significant potential for applications such as drug design. We empirically demonstrate these merits through experiments on real-world datasets such as MUTAG and BBBP.",
    "authors": [
      "Chuqin Geng, Ziyu Zhao, Zhaoyue Wang, Haolin Ye, Xujie Si"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.840717"
  },
  {
    "id": "oai:arXiv.org:2503.19868v2",
    "journal": "arXiv_CS",
    "title": "GENIUS: A Generative Framework for Universal Multimodal Search",
    "link": "https://arxiv.org/abs/2503.19868",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2503.19868v2 Announce Type: replace \nAbstract: Generative retrieval is an emerging approach in information retrieval that generates identifiers (IDs) of target data based on a query, providing an efficient alternative to traditional embedding-based retrieval methods. However, existing models are task-specific and fall short of embedding-based retrieval in performance. This paper proposes GENIUS, a universal generative retrieval framework supporting diverse tasks across multiple modalities and domains. At its core, GENIUS introduces modality-decoupled semantic quantization, transforming multimodal data into discrete IDs encoding both modality and semantics. Moreover, to enhance generalization, we propose a query augmentation that interpolates between a query and its target, allowing GENIUS to adapt to varied query forms. Evaluated on the M-BEIR benchmark, it surpasses prior generative methods by a clear margin. Unlike embedding-based retrieval, GENIUS consistently maintains high retrieval speed across database size, with competitive performance across multiple benchmarks. With additional re-ranking, GENIUS often achieves results close to those of embedding-based methods while preserving efficiency.",
    "authors": [
      "Sungyeon Kim, Xinliang Zhu, Xiaofan Lin, Muhammet Bastan, Douglas Gray, Suha Kwak"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.840725"
  },
  {
    "id": "oai:arXiv.org:2503.20652v4",
    "journal": "arXiv_CS",
    "title": "Imitating Radiological Scrolling: A Global-Local Attention Model for 3D Chest CT Volumes Multi-Label Anomaly Classification",
    "link": "https://arxiv.org/abs/2503.20652",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2503.20652v4 Announce Type: replace \nAbstract: The rapid increase in the number of Computed Tomography (CT) scan examinations has created an urgent need for automated tools, such as organ segmentation, anomaly classification, and report generation, to assist radiologists with their growing workload. Multi-label classification of Three-Dimensional (3D) CT scans is a challenging task due to the volumetric nature of the data and the variety of anomalies to be detected. Existing deep learning methods based on Convolutional Neural Networks (CNNs) struggle to capture long-range dependencies effectively, while Vision Transformers require extensive pre-training, posing challenges for practical use. Additionally, these existing methods do not explicitly model the radiologist's navigational behavior while scrolling through CT scan slices, which requires both global context understanding and local detail awareness. In this study, we present CT-Scroll, a novel global-local attention model specifically designed to emulate the scrolling behavior of radiologists during the analysis of 3D CT scans. Our approach is evaluated on two public datasets, demonstrating its efficacy through comprehensive experiments and an ablation study that highlights the contribution of each model component.",
    "authors": [
      "Theo Di Piazza, Carole Lazarus, Olivier Nempont, Loic Boussel"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.840735"
  },
  {
    "id": "oai:arXiv.org:2503.21288v2",
    "journal": "arXiv_CS",
    "title": "Haptic bilateral teleoperation system for free-hand dental procedures",
    "link": "https://arxiv.org/abs/2503.21288",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2503.21288v2 Announce Type: replace \nAbstract: Free-hand dental procedures are typically repetitive, time-consuming and require high precision and manual dexterity. Robots can play a key role in improving procedural accuracy and safety, enhancing patient comfort, and reducing operator workload. However, robotic solutions for free-hand procedures remain limited or completely lacking, and their acceptance is still low. To address this gap, we develop a haptic bilateral teleoperation system (HBTS) for free-hand dental procedures (FH-HBTS). The system includes a dedicated mechanical end-effector, compatible with standard clinical tools, and equipped with an endoscopic camera for improved visibility of the intervention site. By ensuring motion and force correspondence between the operator's actions and the robot's movements, monitored through visual feedback, we enhance the operator's sensory awareness and motor accuracy. Furthermore, recognizing the need to ensure procedural safety, we limit interaction forces by scaling the motion references provided to the admittance controller based solely on measured contact forces. This ensures effective force limitation in all contact states without requiring prior knowledge of the environment. The proposed FH-HBTS is validated in a dental scaling procedure using a dental phantom. The results show that the system improves the naturalness, safety, and accuracy of teleoperation, highlighting its potential to enhance free-hand dental procedures.",
    "authors": [
      "Lorenzo Pagliara, Enrico Ferrentino, Andrea Chiacchio, Giovanni Russo"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.840751"
  },
  {
    "id": "oai:arXiv.org:2503.23441v2",
    "journal": "arXiv_CS",
    "title": "Spatially-Embedded Lens Visualization: A Design Space",
    "link": "https://arxiv.org/abs/2503.23441",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2503.23441v2 Announce Type: replace \nAbstract: Lens visualization has been a prominent research area in the visualization community, fueled by the continuous need to mitigate visual clutter and occlusion resulting from the increase in data volume. Interactive lenses for spatial data, particularly, challenge designers to conceive design strategies to support the analysis of high-density, multifaceted data with spatial referents. Despite their relevance, there is a lack of systematic understanding regarding the various design elements that compose spatially-embedded lens visualizations. To fill in this gap, we unify these components under a common hood in the form of a design space, which we propose in this paper. Building our knowledge on top of the initial insights gained from Tominski et al.'s survey [57], we construct a design space spanning 7 dimensions through our analysis of 45 papers published in the visualization community over the past 15 years. We describe each design dimension through representative examples and examine the range of design choices available within each, discussing their benefits and pitfalls that affect lens performance and usability. In doing so, we offer a cohesive catalog of considerations for designers-both when examining existing lenses and when conceptualizing novel spatially-embedded lens visualizations. We conclude by shedding light on regions of the design space that remain largely understudied, revealing open opportunities for future research.",
    "authors": [
      "Roberta Mota, Ehud Sharlin, Usman Alim"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.840760"
  },
  {
    "id": "oai:arXiv.org:2503.23781v2",
    "journal": "arXiv_CS",
    "title": "DebFlow: Automating Agent Creation via Agent Debate",
    "link": "https://arxiv.org/abs/2503.23781",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2503.23781v2 Announce Type: replace \nAbstract: Large language models (LLMs) have demonstrated strong potential and impressive performance in automating the generation and optimization of workflows. However, existing approaches are marked by limited reasoning capabilities, high computational demands, and significant resource requirements. To address these issues, we propose DebFlow, a framework that employs a debate mechanism to optimize workflows and integrates reflexion to improve based on previous experiences. We evaluated our method across six benchmark datasets, including HotpotQA, MATH, and ALFWorld. Our approach achieved a 3\\% average performance improvement over the latest baselines, demonstrating its effectiveness in diverse problem domains. In particular, during training, our framework reduces resource consumption by 37\\% compared to the state-of-the-art baselines. Additionally, we performed ablation studies. Removing the Debate component resulted in a 4\\% performance drop across two benchmark datasets, significantly greater than the 2\\% drop observed when the Reflection component was removed. These findings strongly demonstrate the critical role of Debate in enhancing framework performance, while also highlighting the auxiliary contribution of reflexion to overall optimization.",
    "authors": [
      "Jinwei Su, Yinghui Xia, Ronghua Shi, Jianhui Wang, Jianuo Huang, Yijin Wang, Tianyu Shi, Yang Jingsong, Lewei He"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.840768"
  },
  {
    "id": "oai:arXiv.org:2504.01230v2",
    "journal": "arXiv_CS",
    "title": "Highway to Hull: An Algorithm for Solving the General Matrix Code Equivalence Problem",
    "link": "https://arxiv.org/abs/2504.01230",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2504.01230v2 Announce Type: replace \nAbstract: The matrix code equivalence problem consists, given two matrix spaces $\\mathcal{C},\\mathcal{D} \\subset \\mathbb{F}_q^{m\\times n}$ of dimension $k$, in finding invertible matrices $P\\in\\mathrm{GL}_m(\\mathbb{F}_q)$ and $Q\\in\\mathrm{GL}_n(\\mathbb{F}_q)$ such that $\\mathcal{D}=P\\mathcal{C} Q^{-1}$. Recent signature schemes such as MEDS and ALTEQ relate their security to the hardness of this problem. Recent works by Narayanan, Qiao and Tang on the one hand and by Ran and Samardjiska on the other hand tackle this problem. The former is restricted to the ``cubic'' case $k = m =n$ and succeeds in $\\widetilde{\\mathcal{O}}(q^{\\frac k 2})$ operations. The latter is an algebraic attack on the general problem whose complexity is not fully understood and which succeeds only on $\\mathcal{O}(1/q)$ instances. We present a novel algorithm which solves the problem in the general case. Our approach consists in reducing the problem to the matrix code conjugacy problem, \\emph{i.e.} the case $P=Q$. For the latter problem, similarly to the permutation code equivalence problem in Hamming metric, a natural invariant based on the \\emph{Hull} of the code can be used. Next, the equivalence of codes can be deduced using a usual list collision argument. For $k=m=n$, our algorithm achieves the same time complexity as Narayanan \\emph{et al.} but with a lower space complexity. Moreover, ours extends to a much broader range of parameters.",
    "authors": [
      "Alain Couvreur, Christophe Levrat"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.840777"
  },
  {
    "id": "oai:arXiv.org:2504.02821v2",
    "journal": "arXiv_CS",
    "title": "Sparse Autoencoders Learn Monosemantic Features in Vision-Language Models",
    "link": "https://arxiv.org/abs/2504.02821",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2504.02821v2 Announce Type: replace \nAbstract: Given that interpretability and steerability are crucial to AI safety, Sparse Autoencoders (SAEs) have emerged as a tool to enhance them in Large Language Models (LLMs). In this work, we extend the application of SAEs to Vision-Language Models (VLMs), such as CLIP, and introduce a comprehensive framework for evaluating monosemanticity at the neuron-level in vision representations. To ensure that our evaluation aligns with human perception, we propose a benchmark derived from a large-scale user study. Our experimental results reveal that SAEs trained on VLMs significantly enhance the monosemanticity of individual neurons, with sparsity and wide latents being the most influential factors. Notably, we demonstrate that applying SAE interventions on CLIP's vision encoder directly steers multimodal LLM outputs (e.g., LLaVA), without any modifications to the underlying model. These findings emphasize the practicality and efficacy of SAEs as an unsupervised tool for enhancing both interpretability and control of VLMs. Code is available at https://github.com/ExplainableML/sae-for-vlm.",
    "authors": [
      "Mateusz Pach, Shyamgopal Karthik, Quentin Bouniot, Serge Belongie, Zeynep Akata"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.840801"
  },
  {
    "id": "oai:arXiv.org:2504.07309v2",
    "journal": "arXiv_CS",
    "title": "An Integrated Visual Servoing Framework for Precise Robotic Pruning Operations in Modern Commercial Orchard",
    "link": "https://arxiv.org/abs/2504.07309",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2504.07309v2 Announce Type: replace \nAbstract: This study presents a vision-guided robotic control system for automated fruit tree pruning applications. Traditional pruning practices are labor-intensive and limit agricultural efficiency and scalability, highlighting the need for advanced automation. A key challenge is the precise, robust positioning of the cutting tool in complex orchard environments, where dense branches and occlusions make target access difficult. To address this, an Intel RealSense D435 camera is mounted on the flange of a UR5e robotic arm and CoTracker3, a transformer-based point tracker, is utilized for visual servoing control that centers tracked points in the camera view. The system integrates proportional control with iterative inverse kinematics to achieve precise end-effector positioning. The system was validated in Gazebo simulation, achieving a 77.77% success rate within 5mm positional tolerance and 100% success rate within 10mm tolerance, with a mean end-effector error of 4.28 +/- 1.36 mm. The vision controller demonstrated robust performance across diverse target positions within the pixel workspace. The results validate the effectiveness of integrating vision-based tracking with kinematic control for precision agricultural tasks. Future work will focus on real-world implementation and the integration of force sensing for actual cutting operations.",
    "authors": [
      "Dawood Ahmed, Basit Muhammad Imran, Martin Churuvija, Manoj Karkee"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.840825"
  },
  {
    "id": "oai:arXiv.org:2504.07402v2",
    "journal": "arXiv_CS",
    "title": "LauraTSE: Target Speaker Extraction using Auto-Regressive Decoder-Only Language Models",
    "link": "https://arxiv.org/abs/2504.07402",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2504.07402v2 Announce Type: replace \nAbstract: We propose LauraTSE, an Auto-Regressive Decoder-Only Language Model for Target Speaker Extraction built upon the LauraGPT backbone. LauraTSE employs a small-scale auto-regressive decoder-only language model that generates the initial layers of the target speech's discrete codec representations from the continuous embeddings of both the mixture and reference speech. These outputs serve as coarse-grained predictions. To refine them, a one-step encoder-only language model reconstructs the full codec representation by integrating information from both the mixture and the reference speech, adding fine-grained details. Our approach achieves superior or comparable performance to existing TSE models. Additionally, we conduct ablation studies to investigate the data scalability and the contribution of the encoder-only model.",
    "authors": [
      "Beilong Tang, Bang Zeng, Ming Li"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.840834"
  },
  {
    "id": "oai:arXiv.org:2504.07637v2",
    "journal": "arXiv_CS",
    "title": "Global approximation to the Boys functions for vectorized computation",
    "link": "https://arxiv.org/abs/2504.07637",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2504.07637v2 Announce Type: replace \nAbstract: A fast approximation to the Boys functions (related to the lower incomplete gamma function of half-integer parameter) by a single closed-form analytical expression for all argument values have been developed and tested. Besides the exponential function needed anyway for downward recursion, it uses a small number of addition, multiplication, division, and square root operations, and thus is straightforward to vectorize.",
    "authors": [
      "Dimitri N. Laikov"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.840843"
  },
  {
    "id": "oai:arXiv.org:2504.10984v2",
    "journal": "arXiv_CS",
    "title": "Seeing like a Cephalopod: Colour Vision with a Monochrome Event Camera",
    "link": "https://arxiv.org/abs/2504.10984",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2504.10984v2 Announce Type: replace \nAbstract: Cephalopods exhibit unique colour discrimination capabilities despite having one type of photoreceptor, relying instead on chromatic aberration induced by their ocular optics and pupil shapes to perceive spectral information. We took inspiration from this biological mechanism to design a spectral imaging system that combines a ball lens with an event-based camera. Our approach relies on a motorised system that shifts the focal position, mirroring the adaptive lens motion in cephalopods. This approach has enabled us to achieve wavelength-dependent focusing across the visible light and near-infrared spectrum, making the event a spectral sensor. We characterise chromatic aberration effects, using both event-based and conventional frame-based sensors, validating the effectiveness of bio-inspired spectral discrimination both in simulation and in a real setup as well as assessing the spectral discrimination performance. Our proposed approach provides a robust spectral sensing capability without conventional colour filters or computational demosaicing. This approach opens new pathways toward new spectral sensing systems inspired by nature's evolutionary solutions. Code and analysis are available at: https://samiarja.github.io/neuromorphic_octopus_eye/",
    "authors": [
      "Sami Arja, Nimrod Kruger, Alexandre Marcireau, Nicholas Owen Ralph, Saeed Afshar, Gregory Cohen"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.840858"
  },
  {
    "id": "oai:arXiv.org:2504.11165v2",
    "journal": "arXiv_CS",
    "title": "YOLO-RS: Remote Sensing Enhanced Crop Detection Methods",
    "link": "https://arxiv.org/abs/2504.11165",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2504.11165v2 Announce Type: replace \nAbstract: With the rapid development of remote sensing technology, crop classification and health detection based on deep learning have gradually become a research hotspot. However, the existing target detection methods show poor performance when dealing with small targets in remote sensing images, especially in the case of complex background and image mixing, which is difficult to meet the practical application requirementsite. To address this problem, a novel target detection model YOLO-RS is proposed in this paper. The model is based on the latest Yolov11 which significantly enhances the detection of small targets by introducing the Context Anchor Attention (CAA) mechanism and an efficient multi-field multi-scale feature fusion network. YOLO-RS adopts a bidirectional feature fusion strategy in the feature fusion process, which effectively enhances the model's performance in the detection of small targets. Small target detection. Meanwhile, the ACmix module at the end of the model backbone network solves the category imbalance problem by adaptively adjusting the contrast and sample mixing, thus enhancing the detection accuracy in complex scenes. In the experiments on the PDT remote sensing crop health detection dataset and the CWC crop classification dataset, YOLO-RS improves both the recall and the mean average precision (mAP) by about 2-3\\% or so compared with the existing state-of-the-art methods, while the F1-score is also significantly improved. Moreover, the computational complexity of the model only increases by about 5.2 GFLOPs, indicating its significant advantages in both performance and efficiency. The experimental results validate the effectiveness and application potential of YOLO-RS in the task of detecting small targets in remote sensing images.",
    "authors": [
      "Linlin Xiao, Zhang Tiancong, Yutong Jia, Xinyu Nie, Mengyao Wang, Xiaohang Shao"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.840866"
  },
  {
    "id": "oai:arXiv.org:2504.12643v3",
    "journal": "arXiv_CS",
    "title": "RoPETR: Improving Temporal Camera-Only 3D Detection by Integrating Enhanced Rotary Position Embedding",
    "link": "https://arxiv.org/abs/2504.12643",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2504.12643v3 Announce Type: replace \nAbstract: This technical report introduces a targeted improvement to the StreamPETR framework, specifically aimed at enhancing velocity estimation, a critical factor influencing the overall NuScenes Detection Score. While StreamPETR exhibits strong 3D bounding box detection performance as reflected by its high mean Average Precision our analysis identified velocity estimation as a substantial bottleneck when evaluated on the NuScenes dataset. To overcome this limitation, we propose a customized positional embedding strategy tailored to enhance temporal modeling capabilities. Experimental evaluations conducted on the NuScenes test set demonstrate that our improved approach achieves a state-of-the-art NDS of 70.86% using the ViT-L backbone, setting a new benchmark for camera-only 3D object detection.",
    "authors": [
      "Hang Ji, Tao Ni, Xufeng Huang, Zhan Shi, Tao Luo, Xin Zhan, Junbo Chen"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.840876"
  },
  {
    "id": "oai:arXiv.org:2504.12880v3",
    "journal": "arXiv_CS",
    "title": "Can Masked Autoencoders Also Listen to Birds?",
    "link": "https://arxiv.org/abs/2504.12880",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2504.12880v3 Announce Type: replace \nAbstract: Masked Autoencoders (MAEs) have shown competitive results in audio classification by learning rich semantic representations through an efficient self-supervised reconstruction task. However, general-purpose models fail to generalize well when applied directly to fine-grained audio domains. Specifically, bird-sound classification requires distinguishing subtle inter-species differences and managing high intra-species acoustic variability, thereby revealing the performance limitations of general-domain Audio-MAE models. This work demonstrates that bridging this domain gap requires more than domain-specific pretraining data; adapting the entire training pipeline is crucial. We systematically revisit and adapt the pretraining recipe, fine-tuning methods, and frozen feature utilization to bird sounds using BirdSet, a large-scale bioacoustic dataset comparable to AudioSet. Our resulting Bird-MAE achieves new state-of-the-art results in BirdSet's multi-label classification benchmark. Additionally, we introduce the parameter-efficient prototypical probing, enhancing the utility of frozen MAE representations and closely approaching fine-tuning performance in low-resource settings. Bird-MAE's prototypical probes outperform linear probing by up to 37%$_\\text{p}$ in MAP and narrow the gap to fine-tuning to approximately 3.3%$_\\text{p}$ on average across BirdSet downstream tasks. Bird-MAE also demonstrates robust few-shot capabilities with prototypical probing in our newly established few-shot benchmark on BirdSet, highlighting the potential of tailored self-supervised learning pipelines for fine-grained audio domains.",
    "authors": [
      "Lukas Rauch, Ren\\'e Heinrich, Ilyass Moummad, Alexis Joly, Bernhard Sick, Christoph Scholz"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.840884"
  },
  {
    "id": "oai:arXiv.org:2504.13816v2",
    "journal": "arXiv_CS",
    "title": "Analyzing LLMs' Knowledge Boundary Cognition Across Languages Through the Lens of Internal Representations",
    "link": "https://arxiv.org/abs/2504.13816",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2504.13816v2 Announce Type: replace \nAbstract: While understanding the knowledge boundaries of LLMs is crucial to prevent hallucination, research on the knowledge boundaries of LLMs has predominantly focused on English. In this work, we present the first study to analyze how LLMs recognize knowledge boundaries across different languages by probing their internal representations when processing known and unknown questions in multiple languages. Our empirical studies reveal three key findings: 1) LLMs' perceptions of knowledge boundaries are encoded in the middle to middle-upper layers across different languages. 2) Language differences in knowledge boundary perception follow a linear structure, which motivates our proposal of a training-free alignment method that effectively transfers knowledge boundary perception ability across languages, thereby helping reduce hallucination risk in low-resource languages; 3) Fine-tuning on bilingual question pair translation further enhances LLMs' recognition of knowledge boundaries across languages. Given the absence of standard testbeds for cross-lingual knowledge boundary analysis, we construct a multilingual evaluation suite comprising three representative types of knowledge boundary data. Our code and datasets are publicly available at https://github.com/DAMO-NLP-SG/LLM-Multilingual-Knowledge-Boundaries.",
    "authors": [
      "Chenghao Xiao, Hou Pong Chan, Hao Zhang, Mahani Aljunied, Lidong Bing, Noura Al Moubayed, Yu Rong"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.840893"
  },
  {
    "id": "oai:arXiv.org:2504.13818v2",
    "journal": "arXiv_CS",
    "title": "Not All Rollouts are Useful: Down-Sampling Rollouts in LLM Reinforcement Learning",
    "link": "https://arxiv.org/abs/2504.13818",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2504.13818v2 Announce Type: replace \nAbstract: Reinforcement learning with verifiable rewards (RLVR) has emerged as a powerful paradigm for enhancing reasoning capabilities in large language models. However, it is constrained by a fundamental asymmetry in computation and memory requirements: rollout generation is embarrassingly parallel and memory-light, whereas policy updates are communication-heavy and memory-intensive. To address this, we introduce PODS (Policy Optimization with Down-Sampling). PODS produces numerous rollouts in parallel, then trains on only an informative subset, preserving learning signals while slashing update cost. We instantiate PODS with max-variance down-sampling, a principled criterion that maximises reward diversity and show it admits an $O(n\\log n)$ solution. Empirically, coupling PODS with Group Relative Policy Optimization (GRPO) achieves superior performance over standard GRPO across different reasoning benchmarks and hardware environments.",
    "authors": [
      "Yixuan Even Xu, Yash Savani, Fei Fang, Zico Kolter"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.840902"
  },
  {
    "id": "oai:arXiv.org:2504.14268v4",
    "journal": "arXiv_CS",
    "title": "Mixed-Precision Conjugate Gradient Solvers with RL-Driven Precision Tuning",
    "link": "https://arxiv.org/abs/2504.14268",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2504.14268v4 Announce Type: replace \nAbstract: This paper presents a novel reinforcement learning (RL) framework for dynamically optimizing numerical precision in the preconditioned conjugate gradient (CG) method. By modeling precision selection as a Markov Decision Process (MDP), we employ Q-learning to adaptively assign precision levels to key operations, striking an optimal balance between computational efficiency and numerical accuracy, while ensuring stability through double-precision scalar computations and residual computing. In practice, the algorithm is trained on a set of data and subsequently performs inference for precision selection on out-of-sample data, without requiring re-analysis or retraining for new datasets. This enables the method to adapt seamlessly to new problem instances without the computational overhead of recalibration. Our results demonstrate the effectiveness of RL in enhancing solver's performance, marking the first application of RL to mixed-precision numerical methods. The findings highlight the approach's practical advantages, robustness, and scalability, providing valuable insights into its integration with iterative solvers and paving the way for AI-driven advancements in scientific computing.",
    "authors": [
      "Xinye Chen"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.840911"
  },
  {
    "id": "oai:arXiv.org:2504.14493v3",
    "journal": "arXiv_CS",
    "title": "FinSage: A Multi-aspect RAG System for Financial Filings Question Answering",
    "link": "https://arxiv.org/abs/2504.14493",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2504.14493v3 Announce Type: replace \nAbstract: Leveraging large language models in real-world settings often entails a need to utilize domain-specific data and tools in order to follow the complex regulations that need to be followed for acceptable use. Within financial sectors, modern enterprises increasingly rely on Retrieval-Augmented Generation (RAG) systems to address complex compliance requirements in financial document workflows. However, existing solutions struggle to account for the inherent heterogeneity of data (e.g., text, tables, diagrams) and evolving nature of regulatory standards used in financial filings, leading to compromised accuracy in critical information extraction. We propose the FinSage framework as a solution, utilizing a multi-aspect RAG framework tailored for regulatory compliance analysis in multi-modal financial documents. FinSage introduces three innovative components: (1) a multi-modal pre-processing pipeline that unifies diverse data formats and generates chunk-level metadata summaries, (2) a multi-path sparse-dense retrieval system augmented with query expansion (HyDE) and metadata-aware semantic search, and (3) a domain-specialized re-ranking module fine-tuned via Direct Preference Optimization (DPO) to prioritize compliance-critical content. Extensive experiments demonstrate that FinSage achieves an impressive recall of 92.51% on 75 expert-curated questions derived from surpasses the best baseline method on the FinanceBench question answering datasets by 24.06% in accuracy. Moreover, FinSage has been successfully deployed as financial question-answering agent in online meetings, where it has already served more than 1,200 people.",
    "authors": [
      "Xinyu Wang, Jijun Chi, Zhenghan Tai, Tung Sum Thomas Kwok, Muzhi Li, Zhuhong Li, Hailin He, Yuchen Hua, Peng Lu, Suyuchen Wang, Yihong Wu, Jerry Huang, Jingrui Tian, Fengran Mo, Yufei Cui, Ling Zhou"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.840920"
  },
  {
    "id": "oai:arXiv.org:2504.15455v2",
    "journal": "arXiv_CS",
    "title": "Field Report on Ground Penetrating Radar for Localization at the Mars Desert Research Station",
    "link": "https://arxiv.org/abs/2504.15455",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2504.15455v2 Announce Type: replace \nAbstract: In this field report, we detail the lessons learned from our field expedition to collect Ground Penetrating Radar (GPR) data in a Mars analog environment for the purpose of validating GPR localization techniques in rugged environments. Planetary rovers are already equipped with GPR for geologic subsurface characterization. GPR has been successfully used to localize vehicles on Earth, but it has not yet been explored as another modality for localization on a planetary rover. Leveraging GPR for localization can aid in efficient and robust rover pose estimation. In order to demonstrate localizing GPR in a Mars analog environment, we collected over 50 individual survey trajectories during a two-week period at the Mars Desert Research Station (MDRS). In this report, we discuss our methodology, lessons learned, and opportunities for future work.",
    "authors": [
      "Anja Sheppard, Katherine A. Skinner"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.840929"
  },
  {
    "id": "oai:arXiv.org:2504.15704v2",
    "journal": "arXiv_CS",
    "title": "On relaxing the N-Reachability Implicit Requirement in NMPC Design",
    "link": "https://arxiv.org/abs/2504.15704",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2504.15704v2 Announce Type: replace \nAbstract: This paper proposes a proof of stability for Model Predictive Control formulations involving a prediction horizon that might be too short to meet the reachability condition generally invoked as a sufficient condition for closed-loop stability. This condition is replaced by a contraction condition on the stage cost. But unlike the contraction based existing formulations where the prediction horizon becomes a decision variable, the formulation proposed in this paper remains standard in that it uses constant and short prediction horizon. An illustrative example is provided to assess the relevance of the proposed formulation.",
    "authors": [
      "Mazen Alamir"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.840938"
  },
  {
    "id": "oai:arXiv.org:2504.16656v4",
    "journal": "arXiv_CS",
    "title": "Skywork R1V2: Multimodal Hybrid Reinforcement Learning for Reasoning",
    "link": "https://arxiv.org/abs/2504.16656",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2504.16656v4 Announce Type: replace \nAbstract: We present Skywork R1V2, a next-generation multimodal reasoning model and a major leap forward from its predecessor, Skywork R1V. At its core, R1V2 introduces a hybrid reinforcement learning paradigm that jointly leverages the Mixed Preference Optimization (MPO) and the Group Relative Policy Optimization (GRPO), which harmonizes reward-model guidance with rule-based strategies, thereby addressing the long-standing challenge of balancing sophisticated reasoning capabilities with broad generalization. To further enhance training efficiency, we propose the Selective Sample Buffer (SSB) mechanism, which effectively addresses the vanishing advantages dilemma inherent in GRPO by prioritizing high-value samples throughout the optimization process. Notably, we observe that excessive reinforcement signals can induce visual hallucinations--a phenomenon we systematically monitor and mitigate through calibrated reward thresholds throughout the training process. Empirical results affirm the exceptional capability of R1V2, with benchmark-leading performances such as 62.6 on OlympiadBench, 78.9 on AIME2024, 63.6 on LiveCodeBench, and 73.6 on MMMU. These results underscore R1V2's superiority over existing open-source models and demonstrate significant progress in closing the performance gap with premier proprietary systems, including Gemini 2.5 and OpenAI-o4-mini. The Skywork R1V2 model weights have been publicly released to promote openness and reproducibility https://huggingface.co/Skywork/Skywork-R1V2-38B.",
    "authors": [
      "Peiyu Wang, Yichen Wei, Yi Peng, Xiaokun Wang, Weijie Qiu, Wei Shen, Tianyidan Xie, Jiangbo Pei, Jianhao Zhang, Yunzhuo Hao, Xuchen Song, Yang Liu, Yahui Zhou"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.840946"
  },
  {
    "id": "oai:arXiv.org:2504.19607v2",
    "journal": "arXiv_CS",
    "title": "Adaptive Locomotion on Mud through Proprioceptive Sensing of Substrate Properties",
    "link": "https://arxiv.org/abs/2504.19607",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2504.19607v2 Announce Type: replace \nAbstract: Muddy terrains present significant challenges for terrestrial robots, as subtle changes in composition and water content can lead to large variations in substrate strength and force responses, causing the robot to slip or get stuck. This paper presents a method to estimate mud properties using proprioceptive sensing, enabling a flipper-driven robot to adapt its locomotion through muddy substrates of varying strength. First, we characterize mud reaction forces through actuator current and position signals from a statically mounted robotic flipper. We use the measured force to determine key coefficients that characterize intrinsic mud properties. The proprioceptively estimated coefficients match closely with measurements from a lab-grade load cell, validating the effectiveness of the proposed method. Next, we extend the method to a locomoting robot to estimate mud properties online as it crawls across different mud mixtures. Experimental data reveal that mud reaction forces depend sensitively on robot motion, requiring joint analysis of robot movement with proprioceptive force to determine mud properties correctly. Lastly, we deploy this method in a flipper-driven robot moving across muddy substrates of varying strengths, and demonstrate that the proposed method allows the robot to use the estimated mud properties to adapt its locomotion strategy, and successfully avoid locomotion failures. Our findings highlight the potential of proprioception-based terrain sensing to enhance robot mobility in complex, deformable natural environments, paving the way for more robust field exploration capabilities.",
    "authors": [
      "Shipeng Liu, Jiaze Tang, Siyuan Meng, Feifei Qian"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.840971"
  },
  {
    "id": "oai:arXiv.org:2504.19989v2",
    "journal": "arXiv_CS",
    "title": "HJRNO: Hamilton-Jacobi Reachability with Neural Operators",
    "link": "https://arxiv.org/abs/2504.19989",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2504.19989v2 Announce Type: replace \nAbstract: Ensuring the safety of autonomous systems under uncertainty is a critical challenge. Hamilton-Jacobi reachability (HJR) analysis is a widely used method for guaranteeing safety under worst-case disturbances. In this work, we propose HJRNO, a neural operator-based framework for solving backward reachable tubes (BRTs) efficiently and accurately. By leveraging neural operators, HJRNO learns a mapping between value functions, enabling fast inference with strong generalization across different obstacle shapes and system configurations. We demonstrate that HJRNO achieves low error on random obstacle scenarios and generalizes effectively across varying system dynamics. These results suggest that HJRNO offers a promising foundation model approach for scalable, real-time safety analysis in autonomous systems.",
    "authors": [
      "Yankai Li, Mo Chen"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.840979"
  },
  {
    "id": "oai:arXiv.org:2504.20941v2",
    "journal": "arXiv_CS",
    "title": "Conformal-DP: Data Density Aware Privacy on Riemannian Manifolds via Conformal Transformation",
    "link": "https://arxiv.org/abs/2504.20941",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2504.20941v2 Announce Type: replace \nAbstract: Differential Privacy (DP) enables privacy-preserving data analysis by adding calibrated noise. While recent works extend DP to curved manifolds (e.g., diffusion-tensor MRI, social networks) by adding geodesic noise, these assume uniform data distribution. This assumption is not always practical, hence these approaches may introduce biased noise and suboptimal privacy-utility trade-offs for non-uniform data. To address this issue, we propose \\emph{Conformal}-DP that utilizes conformal transformations on Riemannian manifolds. This approach locally equalizes sample density and redefines geodesic distances while preserving intrinsic manifold geometry. Our theoretical analysis demonstrates that the conformal factor, which is derived from local kernel density estimates, is data density-aware. We show that under these conformal metrics, \\emph{Conformal}-DP satisfies $\\varepsilon$-differential privacy on any complete Riemannian manifold and offers a closed-form expected geodesic error bound dependent only on the maximal density ratio, and not global curvature. We show through experiments on synthetic and real-world datasets that our mechanism achieves superior privacy-utility trade-offs, particularly for heterogeneous manifold data, and also is beneficial for homogeneous datasets.",
    "authors": [
      "Peilin He, Liou Tang, M. Amin Rahimian, James Joshi"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.840988"
  },
  {
    "id": "oai:arXiv.org:2504.21577v2",
    "journal": "arXiv_CS",
    "title": "Latent Feature-Guided Conditional Diffusion for Generative Image Semantic Communication",
    "link": "https://arxiv.org/abs/2504.21577",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2504.21577v2 Announce Type: replace \nAbstract: Semantic communication is proposed and expected to improve the efficiency of massive data transmission over sixth generation (6G) networks. However, existing image semantic communication schemes are primarily focused on optimizing pixel-level metrics, while neglecting the crucial aspect of region of interest (ROI) preservation. To address this issue, we propose an ROI-aware latent representation-oriented image semantic communication (LRISC) system. In particular, we first map the source image to latent features in a high-dimensional semantic space, these latent features are then fused with ROI mask through a feature-weighting mechanism. Subsequently, these features are encoded using a joint source and channel coding (JSCC) scheme with adaptive rate for efficient transmission over a wireless channel. At the receiver, a conditional diffusion model is developed by using the received latent features as conditional guidance to steer the reverse diffusion process, progressively reconstructing high-fidelity images while preserving semantic consistency. Moreover, we introduce a channel signal-to-noise ratio (SNR) adaptation mechanism, allowing one model to work across various channel states. Experiments show that the proposed method significantly outperforms existing methods, in terms of learned perceptual image patch similarity (LPIPS) and robustness against channel noise, with an average LPIPS reduction of 43.3% compared to DeepJSCC, while guaranteeing the semantic consistency.",
    "authors": [
      "Zehao Chen, Xinfeng Wei, Haonan Tong, Zhaohui Yang, Changchuan Yin"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.840997"
  },
  {
    "id": "oai:arXiv.org:2504.21682v2",
    "journal": "arXiv_CS",
    "title": "Visual Text Processing: A Comprehensive Review and Unified Evaluation",
    "link": "https://arxiv.org/abs/2504.21682",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2504.21682v2 Announce Type: replace \nAbstract: Visual text is a crucial component in both document and scene images, conveying rich semantic information and attracting significant attention in the computer vision community. Beyond traditional tasks such as text detection and recognition, visual text processing has witnessed rapid advancements driven by the emergence of foundation models, including text image reconstruction and text image manipulation. Despite significant progress, challenges remain due to the unique properties that differentiate text from general objects. Effectively capturing and leveraging these distinct textual characteristics is essential for developing robust visual text processing models. In this survey, we present a comprehensive, multi-perspective analysis of recent advancements in visual text processing, focusing on two key questions: (1) What textual features are most suitable for different visual text processing tasks? (2) How can these distinctive text features be effectively incorporated into processing frameworks? Furthermore, we introduce VTPBench, a new benchmark that encompasses a broad range of visual text processing datasets. Leveraging the advanced visual quality assessment capabilities of multimodal large language models (MLLMs), we propose VTPScore, a novel evaluation metric designed to ensure fair and reliable evaluation. Our empirical study with more than 20 specific models reveals substantial room for improvement in the current techniques. Our aim is to establish this work as a fundamental resource that fosters future exploration and innovation in the dynamic field of visual text processing. The relevant repository is available at https://github.com/shuyansy/Visual-Text-Processing-survey.",
    "authors": [
      "Yan Shu, Weichao Zeng, Fangmin Zhao, Zeyu Chen, Zhenhang Li, Xiaomeng Yang, Yu Zhou, Paolo Rota, Xiang Bai, Lianwen Jin, Xu-Cheng Yin, Nicu Sebe"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.841006"
  },
  {
    "id": "oai:arXiv.org:2505.00685v2",
    "journal": "arXiv_CS",
    "title": "On the Importance of Gaussianizing Representations",
    "link": "https://arxiv.org/abs/2505.00685",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2505.00685v2 Announce Type: replace \nAbstract: The normal distribution plays a central role in information theory - it is at the same time the best-case signal and worst-case noise distribution, has the greatest representational capacity of any distribution, and offers an equivalence between uncorrelatedness and independence for joint distributions. Accounting for the mean and variance of activations throughout the layers of deep neural networks has had a significant effect on facilitating their effective training, but seldom has a prescription for precisely what distribution these activations should take, and how this might be achieved, been offered. Motivated by the information-theoretic properties of the normal distribution, we address this question and concurrently present normality normalization: a novel normalization layer which encourages normality in the feature representations of neural networks using the power transform and employs additive Gaussian noise during training. Our experiments comprehensively demonstrate the effectiveness of normality normalization, in regards to its generalization performance on an array of widely used model and dataset combinations, its strong performance across various common factors of variation such as model width, depth, and training minibatch size, its suitability for usage wherever existing normalization layers are conventionally used, and as a means to improving model robustness to random perturbations.",
    "authors": [
      "Daniel Eftekhari, Vardan Papyan"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.841014"
  },
  {
    "id": "oai:arXiv.org:2505.03673v2",
    "journal": "arXiv_CS",
    "title": "RoboOS: A Hierarchical Embodied Framework for Cross-Embodiment and Multi-Agent Collaboration",
    "link": "https://arxiv.org/abs/2505.03673",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2505.03673v2 Announce Type: replace \nAbstract: The dawn of embodied intelligence has ushered in an unprecedented imperative for resilient, cognition-enabled multi-agent collaboration across next-generation ecosystems, revolutionizing paradigms in autonomous manufacturing, adaptive service robotics, and cyber-physical production architectures. However, current robotic systems face significant limitations, such as limited cross-embodiment adaptability, inefficient task scheduling, and insufficient dynamic error correction. While End-to-end VLA models demonstrate inadequate long-horizon planning and task generalization, hierarchical VLA models suffer from a lack of cross-embodiment and multi-agent coordination capabilities. To address these challenges, we introduce RoboOS, the first open-source embodied system built on a Brain-Cerebellum hierarchical architecture, enabling a paradigm shift from single-agent to multi-agent intelligence. Specifically, RoboOS consists of three key components: (1) Embodied Brain Model (RoboBrain), a MLLM designed for global perception and high-level decision-making; (2) Cerebellum Skill Library, a modular, plug-and-play toolkit that facilitates seamless execution of multiple skills; and (3) Real-Time Shared Memory, a spatiotemporal synchronization mechanism for coordinating multi-agent states. By integrating hierarchical information flow, RoboOS bridges Embodied Brain and Cerebellum Skill Library, facilitating robust planning, scheduling, and error correction for long-horizon tasks, while ensuring efficient multi-agent collaboration through Real-Time Shared Memory. Furthermore, we enhance edge-cloud communication and cloud-based distributed inference to facilitate high-frequency interactions and enable scalable deployment. Extensive real-world experiments across various scenarios, demonstrate RoboOS's versatility in supporting heterogeneous embodiments. Project website: https://github.com/FlagOpen/RoboOS",
    "authors": [
      "Huajie Tan, Xiaoshuai Hao, Cheng Chi, Minglan Lin, Yaoxu Lyu, Mingyu Cao, Dong Liang, Zhuo Chen, Mengsi Lyu, Cheng Peng, Chenrui He, Yulong Ao, Yonghua Lin, Pengwei Wang, Zhongyuan Wang, Shanghang Zhang"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.841023"
  },
  {
    "id": "oai:arXiv.org:2505.04422v2",
    "journal": "arXiv_CS",
    "title": "Pool Formation in Oceanic Games: Shapley Value and Proportional Sharing",
    "link": "https://arxiv.org/abs/2505.04422",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2505.04422v2 Announce Type: replace \nAbstract: We study a game-theoretic model for pool formation in Proof of Stake blockchain protocols. In such systems, stakeholders can form pools as a means of obtaining regular rewards from participation in ledger maintenance, with the power of each pool being dependent on its collective stake. The question we are interested in is the design of mechanisms that suitably split rewards among pool members and achieve favorable properties in the resulting pool configuration. With this in mind, we initiate a non-cooperative game-theoretic analysis of the well known Shapley value scheme from cooperative game theory into the context of blockchains. In particular, we focus on the oceanic model of games, proposed by Milnor and Shapley (1978), which is suitable for populations where a small set of large players coexists with a big mass of rather small, negligible players. This provides an appropriate level of abstraction for pool formation processes among the stakeholders. We provide comparisons between the Shapley mechanism and the more standard proportional scheme, in terms of attained decentralization, via a Price of Stability analysis and in terms of susceptibility to Sybil attacks, i.e., the strategic splitting of a players' stake with the intention of participating in multiple pools for increased profit. Interestingly, while the widely deployed proportional scheme appears to have certain advantages, the Shapley value scheme, which rewards higher the most pivotal players, emerges as a competitive alternative, by being able to bypass some of the downsides of proportional sharing, while also not being far from optimal guarantees w.r.t. decentralization. Finally, we complement our study with some variations of proportional sharing, where the profit is split in proportion to a superadditive or a subadditive function of the stake, showing that the Shapley value scheme still maintains the same advantages.",
    "authors": [
      "Aggelos Kiayias, Elias Koutsoupias, Evangelos Markakis, Panagiotis Tsamopoulos"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.841040"
  },
  {
    "id": "oai:arXiv.org:2505.07855v2",
    "journal": "arXiv_CS",
    "title": "A Physics-informed End-to-End Occupancy Framework for Motion Planning of Autonomous Vehicles",
    "link": "https://arxiv.org/abs/2505.07855",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2505.07855v2 Announce Type: replace \nAbstract: Accurate and interpretable motion planning is essential for autonomous vehicles (AVs) navigating complex and uncertain environments. While recent end-to-end occupancy prediction methods have improved environmental understanding, they typically lack explicit physical constraints, limiting safety and generalization. In this paper, we propose a unified end-to-end framework that integrates verifiable physical rules into the occupancy learning process. Specifically, we embed artificial potential fields (APF) as physics-informed guidance during network training to ensure that predicted occupancy maps are both data-efficient and physically plausible. Our architecture combines convolutional and recurrent neural networks to capture spatial and temporal dependencies while preserving model flexibility. Experimental results demonstrate that our method improves task completion rate, safety margins, and planning efficiency across diverse driving scenarios, confirming its potential for reliable deployment in real-world AV systems.",
    "authors": [
      "Shuqi Shen, Junjie Yang, Hongliang Lu, Hui Zhong, Qiming Zhang, Xinhu Zheng"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.841049"
  },
  {
    "id": "oai:arXiv.org:2505.08266v3",
    "journal": "arXiv_CS",
    "title": "Open Your Eyes: Vision Enhances Message Passing Neural Networks in Link Prediction",
    "link": "https://arxiv.org/abs/2505.08266",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2505.08266v3 Announce Type: replace \nAbstract: Message-passing graph neural networks (MPNNs) and structural features (SFs) are cornerstones for the link prediction task. However, as a common and intuitive mode of understanding, the potential of visual perception has been overlooked in the MPNN community. For the first time, we equip MPNNs with vision structural awareness by proposing an effective framework called Graph Vision Network (GVN), along with a more efficient variant (E-GVN). Extensive empirical results demonstrate that with the proposed frameworks, GVN consistently benefits from the vision enhancement across seven link prediction datasets, including challenging large-scale graphs. Such improvements are compatible with existing state-of-the-art (SOTA) methods and GVNs achieve new SOTA results, thereby underscoring a promising novel direction for link prediction.",
    "authors": [
      "Yanbin Wei, Xuehao Wang, Zhan Zhuang, Yang Chen, Shuhao Chen, Yulong Zhang, Yu Zhang, James Kwok"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.841058"
  },
  {
    "id": "oai:arXiv.org:2505.09370v2",
    "journal": "arXiv_CS",
    "title": "A Dynamic Working Set Method for Compressed Sensing",
    "link": "https://arxiv.org/abs/2505.09370",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2505.09370v2 Announce Type: replace \nAbstract: We propose a dynamic working set method (DWS) for the problem $\\min_{\\mathtt{x} \\in \\mathbb{R}^n} \\frac{1}{2}\\|\\mathtt{Ax}-\\mathtt{b}\\|^2 + \\eta\\|\\mathtt{x}\\|_1$ that arises from compressed sensing. DWS manages the working set while iteratively calling a regression solver to generate progressively better solutions. Our experiments show that DWS is more efficient than other state-of-the-art software in the context of compressed sensing. Scale space such that $\\|b\\|=1$. Let $s$ be the number of non-zeros in the unknown signal. We prove that for any given $\\varepsilon > 0$, DWS reaches a solution with an additive error $\\varepsilon/\\eta^2$ such that each call of the solver uses only $O(\\frac{1}{\\varepsilon}s\\log s \\log\\frac{1}{\\varepsilon})$ variables, and each intermediate solution has $O(\\frac{1}{\\varepsilon}s\\log s\\log\\frac{1}{\\varepsilon})$ non-zero coordinates.",
    "authors": [
      "Siu-Wing Cheng, Man Ting Wong"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.841066"
  },
  {
    "id": "oai:arXiv.org:2505.11593v2",
    "journal": "arXiv_CS",
    "title": "Mechanically Programming the Cross-Sectional Shape of Soft Growing Robotic Structures for Patient Transfer",
    "link": "https://arxiv.org/abs/2505.11593",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2505.11593v2 Announce Type: replace \nAbstract: Pneumatic soft everting robotic structures have the potential to facilitate human transfer tasks due to their ability to grow underneath humans without sliding friction and their utility as a flexible sling when deflated. Tubular structures naturally yield circular cross-sections when inflated, whereas a robotic sling must be both thin enough to grow between them and their resting surface and wide enough to cradle the human. Recent works have achieved flattened cross-sections by including rigid components into the structure, but this reduces conformability to the human. We present a method of mechanically programming the cross-section of soft everting robotic structures using flexible strips that constrain radial expansion between points along the outer membrane. Our method enables simultaneously wide and thin profiles while maintaining the full multi-axis flexibility of traditional slings. We develop and validate a model relating the geometric design specifications to the fabrication parameters, and experimentally characterize their effects on growth rate. Finally, we prototype a soft growing robotic sling system and demonstrate its use for assisting a single caregiver in bed-to-chair patient transfer.",
    "authors": [
      "O. Godson Osele, Kentaro Barhydt, Teagan Sullivan, H. Harry Asada, Allison M. Okamura"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.841083"
  },
  {
    "id": "oai:arXiv.org:2505.11936v2",
    "journal": "arXiv_CS",
    "title": "How can Diffusion Models Evolve into Continual Generators?",
    "link": "https://arxiv.org/abs/2505.11936",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2505.11936v2 Announce Type: replace \nAbstract: While diffusion models have achieved remarkable success in static data generation, their deployment in streaming or continual learning (CL) scenarios faces a major challenge: catastrophic forgetting (CF), where newly acquired generative capabilities overwrite previously learned ones. To systematically address this, we introduce a formal Continual Diffusion Generation (CDG) paradigm that characterizes and redefines CL in the context of generative diffusion models. Prior efforts often adapt heuristic strategies from continual classification tasks but lack alignment with the underlying diffusion process. In this work, we develop the first theoretical framework for CDG by analyzing cross-task dynamics in diffusion-based generative modeling. Our analysis reveals that the retention and stability of generative knowledge across tasks are governed by three key consistency criteria: inter-task knowledge consistency (IKC), unconditional knowledge consistency (UKC), and label knowledge consistency (LKC). Building on these insights, we propose Continual Consistency Diffusion (CCD), a principled framework that integrates these consistency objectives into training via hierarchical loss terms $\\mathcal{L}_{IKC}$, $\\mathcal{L}_{UKC}$, and $\\mathcal{L}_{LKC}$. This promotes effective knowledge retention while enabling the assimilation of new generative capabilities. Extensive experiments on four benchmark datasets demonstrate that CCD achieves state-of-the-art performance under continual settings, with substantial gains in Mean Fidelity (MF) and Incremental Mean Fidelity (IMF), particularly in tasks with rich cross-task knowledge overlap.",
    "authors": [
      "Jingren Liu, Zhong Ji, Xiangyu Chen"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.841092"
  },
  {
    "id": "oai:arXiv.org:2505.12655v2",
    "journal": "arXiv_CS",
    "title": "Web Intellectual Property at Risk: Preventing Unauthorized Real-Time Retrieval by Large Language Models",
    "link": "https://arxiv.org/abs/2505.12655",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2505.12655v2 Announce Type: replace \nAbstract: The protection of cyber Intellectual Property (IP) such as web content is an increasingly critical concern. The rise of large language models (LLMs) with online retrieval capabilities enables convenient access to information but often undermines the rights of original content creators. As users increasingly rely on LLM-generated responses, they gradually diminish direct engagement with original information sources, which will significantly reduce the incentives for IP creators to contribute, and lead to a saturating cyberspace with more AI-generated content. In response, we propose a novel defense framework that empowers web content creators to safeguard their web-based IP from unauthorized LLM real-time extraction and redistribution by leveraging the semantic understanding capability of LLMs themselves. Our method follows principled motivations and effectively addresses an intractable black-box optimization problem. Real-world experiments demonstrated that our methods improve defense success rates from 2.5% to 88.6% on different LLMs, outperforming traditional defenses such as configuration-based restrictions.",
    "authors": [
      "Yisheng Zhong, Yizhu Wen, Junfeng Guo, Mehran Kafai, Heng Huang, Hanqing Guo, Zhuangdi Zhu"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.841101"
  },
  {
    "id": "oai:arXiv.org:2505.13212v2",
    "journal": "arXiv_CS",
    "title": "RB-SCD: A New Benchmark for Semantic Change Detection of Roads and Bridges in Traffic Scenes",
    "link": "https://arxiv.org/abs/2505.13212",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2505.13212v2 Announce Type: replace \nAbstract: With the rapid modernization of urban transportation, accurately detecting changes such as road and bridge construction, renovation, and demolition is crucial for urban planning and traffic management. However, existing methods often struggle to extract fine-grained semantic changes in complex traffic scenes, largely due to the lack of high-quality annotated change detection (CD) datasets. To address this, we introduce the Road and Bridge Semantic Change Detection (RB-SCD) dataset, a comprehensive benchmark consisting of 260 pairs of high-resolution remote sensing images. RB-SCD spans diverse geographic areas and includes a wide variety of road and bridge types across over ten cities in multiple countries. It covers 11 distinct categories of semantic changes, enabling detailed structural and functional analysis. Based on this challenging dataset, we propose a novel framework called the Multimodal Frequency-Driven Change Detector (MFDCD). For the first time, MFDCD integrates multimodal feature characteristics in the frequency domain. It comprises two key components: the Dynamic Frequency Coupler (DFC) and the Textual Frequency Filter (TFF). DFC couples hierarchical visual features with wavelet-based frequency components, enhancing the perception of fine-grained and cross-temporal structural changes. TFF transforms textual features extracted by the CLIP model into the frequency domain via Fourier transform and applies graph-based filtering to extract salient frequency responses. These are then fused with visual features to enable effective multimodal representation learning. Extensive experiments show that MFDCD achieves strong performance on RB-SCD and three public benchmarks. The RB-SCD dataset, with its rich and diverse annotations, serves as a valuable resource for advancing research in road and bridge change detection under complex traffic conditions.",
    "authors": [
      "Qingling Shu, Sibao Chen, Zhihui You, Wei Lu, Jin Tang, Bin Luo"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.841110"
  },
  {
    "id": "oai:arXiv.org:2505.14211v2",
    "journal": "arXiv_CS",
    "title": "A PID-Controlled Tensor Wheel Decomposition Model for Dynamic Link Prediction",
    "link": "https://arxiv.org/abs/2505.14211",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2505.14211v2 Announce Type: replace \nAbstract: Link prediction in dynamic networks remains a fundamental challenge in network science, requiring the inference of potential interactions and their evolving strengths through spatiotemporal pattern analysis. Traditional static network methods have inherent limitations in capturing temporal dependencies and weight dynamics, while tensor-based methods offer a promising paradigm by encoding dynamic networks into high-order tensors to explicitly model multidimensional interactions across nodes and time. Among them, tensor wheel decomposition (TWD) stands out for its innovative topological structure, which decomposes high-order tensors into cyclic factors and core tensors to maintain structural integrity. To improve the prediction accuracy, this study introduces a PID-controlled tensor wheel decomposition (PTWD) model, which mainly adopts the following two ideas: 1) exploiting the representation power of TWD to capture the latent features of dynamic network topology and weight evolution, and 2) integrating the proportional-integral-derivative (PID) control principle into the optimization process to obtain a stable model parameter learning scheme. The performance on four real datasets verifies that the proposed PTWD model has more accurate link prediction capabilities compared to other models.",
    "authors": [
      "Qu Wang, Yan Xia"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.841119"
  },
  {
    "id": "oai:arXiv.org:2505.14527v3",
    "journal": "arXiv_CS",
    "title": "diffDemorph: Extending Reference-Free Demorphing to Unseen Faces",
    "link": "https://arxiv.org/abs/2505.14527",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2505.14527v3 Announce Type: replace \nAbstract: A face morph is created by combining two face images corresponding to two identities to produce a composite that successfully matches both the constituent identities. Reference-free (RF) demorphing reverses this process using only the morph image, without the need for additional reference images. Previous RF demorphing methods are overly constrained, as they rely on assumptions about the distributions of training and testing morphs such as the morphing technique used (e.g., landmark-based) and face image style (e.g., passport photos). In this paper, we introduce a novel diffusion-based approach, referred to as diffDeMorph, that effectively disentangles component images from a composite morph image with high visual fidelity. Our method is the first to generalize across morph techniques and face styles, beating the current state of the art by $\\geq 59.46\\%$ under a common training protocol across all datasets tested. We train our method on morphs created using synthetically generated face images and test on real morphs, thereby enhancing the practicality of the technique. Experiments on six datasets and two face matchers establish the utility and efficacy of our method.",
    "authors": [
      "Nitish Shukla, Arun Ross"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.841128"
  },
  {
    "id": "oai:arXiv.org:2505.14804v2",
    "journal": "arXiv_CS",
    "title": "Automated Journalistic Questions: A New Method for Extracting 5W1H in French",
    "link": "https://arxiv.org/abs/2505.14804",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2505.14804v2 Announce Type: replace \nAbstract: The 5W1H questions -- who, what, when, where, why and how -- are commonly used in journalism to ensure that an article describes events clearly and systematically. Answering them is a crucial prerequisites for tasks such as summarization, clustering, and news aggregation. In this paper, we design the first automated extraction pipeline to get 5W1H information from French news articles. To evaluate the performance of our algorithm, we also create a corpus of 250 Quebec news articles with 5W1H answers marked by four human annotators. Our results demonstrate that our pipeline performs as well in this task as the large language model GPT-4o.",
    "authors": [
      "Maxence Verhaverbeke, Julie A. Gramaccia, Richard Khoury"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.841137"
  },
  {
    "id": "oai:arXiv.org:2505.15670v2",
    "journal": "arXiv_CS",
    "title": "Efficient and Direct Duplex Modeling for Speech-to-Speech Language Model",
    "link": "https://arxiv.org/abs/2505.15670",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2505.15670v2 Announce Type: replace \nAbstract: Spoken dialogue is an intuitive form of human-computer interaction, yet current speech language models often remain constrained to turn-based exchanges, lacking real-time adaptability such as user barge-in. We propose a novel duplex speech to speech (S2S) architecture featuring continuous user inputs and codec agent outputs with channel fusion that directly models simultaneous user and agent streams. Using a pretrained streaming encoder for user input enables the first duplex S2S model without requiring speech pretrain. Separate architectures for agent and user modeling facilitate codec fine-tuning for better agent voices and halve the bitrate (0.6 kbps) compared to previous works. Experimental results show that the proposed model outperforms previous duplex models in reasoning, turn-taking, and barge-in abilities. The model requires significantly less speech data, as speech pretrain is skipped, which markedly simplifies the process of building a duplex S2S model from any LLMs. Finally, it is the first openly available duplex S2S model with training and inference code to foster reproducibility.",
    "authors": [
      "Ke Hu, Ehsan Hosseini-Asl, Chen Chen, Edresson Casanova, Subhankar Ghosh, Piotr \\.Zelasko, Zhehuai Chen, Jason Li, Jagadeesh Balam, Boris Ginsburg"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.841146"
  },
  {
    "id": "oai:arXiv.org:2505.15820v2",
    "journal": "arXiv_CS",
    "title": "Common Data Format (CDF): A Standardized Format for Match-Data in Football (Soccer)",
    "link": "https://arxiv.org/abs/2505.15820",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2505.15820v2 Announce Type: replace \nAbstract: During football matches, a variety of different parties (e.g., companies) each collect (possibly overlapping) data about the match ranging from basic information (e.g., starting players) to detailed positional data. This data is provided to clubs, federations, and other organizations who are increasingly interested in leveraging this data to inform their decision making. Unfortunately, analyzing such data pose significant barriers because each provider may (1) collect different data, (2) use different specifications even within the same category of data, (3) represent the data differently, and (4) delivers the data in a different manner (e.g., file format, protocol). Consequently, working with these data requires a significant investment of time and money. The goal of this work is to propose a uniform and standardized format for football data called the Common Data Format (CDF). The CDF specifies a minimal schema for five types of match data: match sheet data, video footage, event data, tracking data, and match meta data. It aims to ensure that the provided data is clear, sufficiently contextualized (e.g., its provenance is clear), and complete such that it enables common downstream analysis tasks. Concretely, this paper will detail the technical specifications of the CDF, the representational choices that were made to help ensure the clarity of the provided data, and a concrete approach for delivering data in the CDF.",
    "authors": [
      "Gabriel Anzer, Kilian Arnsmeyer, Pascal Bauer, Joris Bekkers, Ulf Brefeld, Jesse Davis, Nicolas Evans, Matthias Kempe, Samuel J Robertson, Joshua Wyatt Smith, Jan Van Haaren"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.841155"
  },
  {
    "id": "oai:arXiv.org:2505.17309v2",
    "journal": "arXiv_CS",
    "title": "Decoupling Representation and Learning in Genetic Programming: the LaSER Approach",
    "link": "https://arxiv.org/abs/2505.17309",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2505.17309v2 Announce Type: replace \nAbstract: Genetic Programming (GP) has traditionally entangled the evolution of symbolic representations with their performance-based evaluation, often relying solely on raw fitness scores. This tight coupling makes GP solutions more fragile and prone to overfitting, reducing their ability to generalize. In this work, we propose LaSER (Latent Semantic Representation Regression)} -- a general framework that decouples representation evolution from lifetime learning. At each generation, candidate programs produce features which are passed to an external learner to model the target task. This approach enables any function approximator, from linear models to neural networks, to serve as a lifetime learner, allowing expressive modeling beyond conventional symbolic forms.\n  Here we show for the first time that LaSER can outcompete standard GP and GP followed by linear regression when it employs non-linear methods to fit coefficients to GP-generated equations against complex data sets. Further, we explore how LaSER enables the emergence of innate representations, supporting long-standing hypotheses in evolutionary learning such as the Baldwin Effect. By separating the roles of representation and adaptation, LaSER offers a principled and extensible framework for symbolic regression and classification.",
    "authors": [
      "Nam H. Le, Josh Bongard"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.841172"
  },
  {
    "id": "oai:arXiv.org:2505.17312v2",
    "journal": "arXiv_CS",
    "title": "AdaReasoner: Adaptive Reasoning Enables More Flexible Thinking",
    "link": "https://arxiv.org/abs/2505.17312",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2505.17312v2 Announce Type: replace \nAbstract: LLMs often need effective configurations, like temperature and reasoning steps, to handle tasks requiring sophisticated reasoning and problem-solving, ranging from joke generation to mathematical reasoning. Existing prompting approaches usually adopt general-purpose, fixed configurations that work 'well enough' across tasks but seldom achieve task-specific optimality. To address this gap, we introduce AdaReasoner, an LLM-agnostic plugin designed for any LLM to automate adaptive reasoning configurations for tasks requiring different types of thinking. AdaReasoner is trained using a reinforcement learning (RL) framework, combining a factorized action space with a targeted exploration strategy, along with a pretrained reward model to optimize the policy model for reasoning configurations with only a few-shot guide. AdaReasoner is backed by theoretical guarantees and experiments of fast convergence and a sublinear policy gap. Across six different LLMs and a variety of reasoning tasks, it consistently outperforms standard baselines, preserves out-of-distribution robustness, and yield gains on knowledge-intensive tasks through tailored prompts.",
    "authors": [
      "Xiangqi Wang, Yue Huang, Yanbo Wang, Xiaonan Luo, Kehan Guo, Yujun Zhou, Xiangliang Zhang"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.841180"
  },
  {
    "id": "oai:arXiv.org:2505.18223v2",
    "journal": "arXiv_CS",
    "title": "IDA-Bench: Evaluating LLMs on Interactive Guided Data Analysis",
    "link": "https://arxiv.org/abs/2505.18223",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2505.18223v2 Announce Type: replace \nAbstract: Large Language Models (LLMs) show promise as data analysis agents, but existing benchmarks overlook the iterative nature of the field, where experts' decisions evolve with deeper insights of the dataset. To address this, we introduce IDA-Bench, a novel benchmark evaluating LLM agents in multi-round interactive scenarios. Derived from complex Kaggle notebooks, tasks are presented as sequential natural language instructions by an LLM-simulated user. Agent performance is judged by comparing its final numerical output to the human-derived baseline. Initial results show that even state-of-the-art coding agents (like Claude-3.7-thinking) succeed on < 50% of the tasks, highlighting limitations not evident in single-turn tests. This work underscores the need to improve LLMs' multi-round capabilities for building more reliable data analysis agents, highlighting the necessity of achieving a balance between instruction following and reasoning.",
    "authors": [
      "Hanyu Li, Haoyu Liu, Tingyu Zhu, Tianyu Guo, Zeyu Zheng, Xiaotie Deng, Michael I. Jordan"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.841188"
  },
  {
    "id": "oai:arXiv.org:2505.18480v2",
    "journal": "arXiv_CS",
    "title": "Local Taylor-based polynomial quasi-Trefftz spaces for scalar linear equations",
    "link": "https://arxiv.org/abs/2505.18480",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2505.18480v2 Announce Type: replace \nAbstract: Trefftz-type of Galerkin methods for numerical PDEs use discrete spaces of problem-dependent functions. While Trefftz methods leverage discrete spaces of local exact solutions to the governing PDE, Taylor-based quasi-Trefftz methods leverage discrete spaces of local approximate solutions to the governing PDE. This notion of approximate solution, understood in the sense of a small Taylor remainder, is defined for differential operators with smooth variable coefficients. In both cases, it is possible to use discrete spaces much smaller than standard polynomial space to achieve the same orders of approximation properties.\n  The present work is the first systematic study of local Taylor-based polynomial quasi-Trefftz spaces characterized as the kernel of the quasi-Trefftz operator, defined as the composition of Taylor truncation with the differential operator. The proposed linear algebra framework reveals the general structure of this linear operator and applies to any non-trivial linear scalar differential operator with smooth coefficients. It results in a fully explicit procedure to construct a local quasi-Trefftz basis valid in all dimension and for operators of any order, guaranteeing a minimal computational cost for the construction of these equation-dependent bases.\n  The local quasi-Trefftz space is formally defined as the kernel of a linear operator between spaces of polynomials. The systematic approach relies on a detailed study of the structure of this operator, strongly leveraging the graded structure of polynomial spaces.",
    "authors": [
      "Lise-Marie Imbert-Gerard"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.841197"
  },
  {
    "id": "oai:arXiv.org:2505.18574v2",
    "journal": "arXiv_CS",
    "title": "Autocomp: LLM-Driven Code Optimization for Tensor Accelerators",
    "link": "https://arxiv.org/abs/2505.18574",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2505.18574v2 Announce Type: replace \nAbstract: Hardware accelerators, especially those designed for tensor processing, have become ubiquitous in today's computing landscape. However, even with significant efforts in building compilers, programming these tensor accelerators remains challenging, leaving much of their potential underutilized. Recently, large language models (LLMs), trained on large amounts of code, have shown significant promise in code generation and optimization tasks, but generating low-resource languages like specialized tensor accelerator code still poses a significant challenge. We tackle this challenge with Autocomp, an approach that empowers accelerator programmers to leverage domain knowledge and hardware feedback to optimize code via an automated LLM-driven search. We accomplish this by: 1) formulating each optimization pass as a structured two-phase prompt, divided into planning and code generation phases, 2) inserting domain knowledge during planning via a concise and adaptable optimization menu, and 3) integrating correctness and performance metrics from hardware as feedback at each search iteration. Across three categories of representative workloads and two different accelerators, we demonstrate that Autocomp-optimized code runs 5.6x (GEMM) and 2.7x (convolution) faster than the vendor-provided library, and outperforms expert-level hand-tuned code by 1.4x (GEMM), 1.1x (convolution), and 1.3x (fine-grained linear algebra). Additionally, we demonstrate that optimization schedules generated from Autocomp can be reused across similar tensor operations, improving speedups by up to 24% under a fixed sample budget.",
    "authors": [
      "Charles Hong, Sahil Bhatia, Alvin Cheung, Yakun Sophia Shao"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.841205"
  },
  {
    "id": "oai:arXiv.org:2505.19493v2",
    "journal": "arXiv_CS",
    "title": "Multi-Channel Acoustic Echo Cancellation Based on Direction-of-Arrival Estimation",
    "link": "https://arxiv.org/abs/2505.19493",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2505.19493v2 Announce Type: replace \nAbstract: Acoustic echo cancellation (AEC) is an important speech signal processing technology that can remove echoes from microphone signals to enable natural-sounding full-duplex speech communication. While single-channel AEC is widely adopted, multi-channel AEC can leverage spatial cues afforded by multiple microphones to achieve better performance. Existing multi-channel AEC approaches typically combine beamforming with deep neural networks (DNN). This work proposes a two-stage algorithm that enhances multi-channel AEC by incorporating sound source directional cues. Specifically, a lightweight DNN is first trained to predict the sound source directions, and then the predicted directional information, multi-channel microphone signals, and single-channel far-end signal are jointly fed into an AEC network to estimate the near-end signal. Evaluation results show that the proposed algorithm outperforms baseline approaches and exhibits robust generalization across diverse acoustic environments.",
    "authors": [
      "Fei Zhao, Xueliang Zhang, Zhong-Qiu Wang"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.841214"
  },
  {
    "id": "oai:arXiv.org:2505.21136v3",
    "journal": "arXiv_CS",
    "title": "SageAttention2++: A More Efficient Implementation of SageAttention2",
    "link": "https://arxiv.org/abs/2505.21136",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2505.21136v3 Announce Type: replace \nAbstract: The efficiency of attention is critical because its time complexity grows quadratically with sequence length. SageAttention2 addresses this by utilizing quantization to accelerate matrix multiplications (Matmul) in attention. To further accelerate SageAttention2, we propose to utilize the faster instruction of FP8 Matmul accumulated in FP16. The instruction is 2x faster than the FP8 Matmul used in SageAttention2. Our experiments show that SageAttention2++ achieves a 3.9x speedup over FlashAttention while maintaining the same attention accuracy as SageAttention2. This means SageAttention2++ effectively accelerates various models, including those for language, image, and video generation, with negligible end-to-end metrics loss. The code will be available at https://github.com/thu-ml/SageAttention.",
    "authors": [
      "Jintao Zhang, Xiaoming Xu, Jia Wei, Haofeng Huang, Pengle Zhang, Chendong Xiang, Jun Zhu, Jianfei Chen"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.841223"
  },
  {
    "id": "oai:arXiv.org:2505.21360v2",
    "journal": "arXiv_CS",
    "title": "CRISP-NAM: Competing Risks Interpretable Survival Prediction with Neural Additive Models",
    "link": "https://arxiv.org/abs/2505.21360",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2505.21360v2 Announce Type: replace \nAbstract: Competing risks are crucial considerations in survival modelling, particularly in healthcare domains where patients may experience multiple distinct event types. We propose CRISP-NAM (Competing Risks Interpretable Survival Prediction with Neural Additive Models), an interpretable neural additive model for competing risks survival analysis which extends the neural additive architecture to model cause-specific hazards while preserving feature-level interpretability. Each feature contributes independently to risk estimation through dedicated neural networks, allowing for visualization of complex non-linear relationships between covariates and each competing risk. We demonstrate competitive performance on multiple datasets compared to existing approaches.",
    "authors": [
      "Dhanesh Ramachandram"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.841239"
  },
  {
    "id": "oai:arXiv.org:2505.21577v2",
    "journal": "arXiv_CS",
    "title": "RepoMaster: Autonomous Exploration and Understanding of GitHub Repositories for Complex Task Solving",
    "link": "https://arxiv.org/abs/2505.21577",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2505.21577v2 Announce Type: replace \nAbstract: The ultimate goal of code agents is to solve complex tasks autonomously. Although large language models (LLMs) have made substantial progress in code generation, real-world tasks typically demand full-fledged code repositories rather than simple scripts. Building such repositories from scratch remains a major challenge. Fortunately, GitHub hosts a vast, evolving collection of open-source repositories, which developers frequently reuse as modular components for complex tasks. Yet, existing frameworks like OpenHands and SWE-Agent still struggle to effectively leverage these valuable resources. Relying solely on README files provides insufficient guidance, and deeper exploration reveals two core obstacles: overwhelming information and tangled dependencies of repositories, both constrained by the limited context windows of current LLMs. To tackle these issues, we propose RepoMaster, an autonomous agent framework designed to explore and reuse GitHub repositories for solving complex tasks. For efficient understanding, RepoMaster constructs function-call graphs, module-dependency graphs, and hierarchical code trees to identify essential components, providing only identified core elements to the LLMs rather than the entire repository. During autonomous execution, it progressively explores related components using our exploration tools and prunes information to optimize context usage. Evaluated on the adjusted MLE-bench, RepoMaster achieves a 110% relative boost in valid submissions over the strongest baseline OpenHands. On our newly released GitTaskBench, RepoMaster lifts the task-pass rate from 24.1% to 62.9% while reducing token usage by 95%. Our code and demonstration materials are publicly available at https://github.com/wanghuacan/RepoMaster.",
    "authors": [
      "Huacan Wang, Ziyi Ni, Shuo Zhang, Shuo Lu, Sen Hu, Ziyang He, Chen Hu, Jiaye Lin, Yifu Guo, Yuntao Du, Pin Lyu"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.841249"
  },
  {
    "id": "oai:arXiv.org:2505.21824v2",
    "journal": "arXiv_CS",
    "title": "Unsupervised Latent Pattern Analysis for Estimating Type 2 Diabetes Risk in Undiagnosed Populations",
    "link": "https://arxiv.org/abs/2505.21824",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2505.21824v2 Announce Type: replace \nAbstract: The global prevalence of diabetes, particularly type 2 diabetes mellitus (T2DM), is rapidly increasing, posing significant health and economic challenges. T2DM not only disrupts blood glucose regulation but also damages vital organs such as the heart, kidneys, eyes, nerves, and blood vessels, leading to substantial morbidity and mortality. In the US alone, the economic burden of diagnosed diabetes exceeded \\$400 billion in 2022. Early detection of individuals at risk is critical to mitigating these impacts. While machine learning approaches for T2DM prediction are increasingly adopted, many rely on supervised learning, which is often limited by the lack of confirmed negative cases. To address this limitation, we propose a novel unsupervised framework that integrates Non-negative Matrix Factorization (NMF) with statistical techniques to identify individuals at risk of developing T2DM. Our method identifies latent patterns of multimorbidity and polypharmacy among diagnosed T2DM patients and applies these patterns to estimate the T2DM risk in undiagnosed individuals. By leveraging data-driven insights from comorbidity and medication usage, our approach provides an interpretable and scalable solution that can assist healthcare providers in implementing timely interventions, ultimately improving patient outcomes and potentially reducing the future health and economic burden of T2DM.",
    "authors": [
      "Praveen Kumar, Vincent T. Metzger, Scott A. Malec"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.841258"
  },
  {
    "id": "oai:arXiv.org:2505.21969v3",
    "journal": "arXiv_CS",
    "title": "DORAEMON: Decentralized Ontology-aware Reliable Agent with Enhanced Memory Oriented Navigation",
    "link": "https://arxiv.org/abs/2505.21969",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2505.21969v3 Announce Type: replace \nAbstract: Adaptive navigation in unfamiliar environments is crucial for household service robots but remains challenging due to the need for both low-level path planning and high-level scene understanding. While recent vision-language model (VLM) based zero-shot approaches reduce dependence on prior maps and scene-specific training data, they face significant limitations: spatiotemporal discontinuity from discrete observations, unstructured memory representations, and insufficient task understanding leading to navigation failures. We propose DORAEMON (Decentralized Ontology-aware Reliable Agent with Enhanced Memory Oriented Navigation), a novel cognitive-inspired framework consisting of Ventral and Dorsal Streams that mimics human navigation capabilities. The Dorsal Stream implements the Hierarchical Semantic-Spatial Fusion and Topology Map to handle spatiotemporal discontinuities, while the Ventral Stream combines RAG-VLM and Policy-VLM to improve decision-making. Our approach also develops Nav-Ensurance to ensure navigation safety and efficiency. We evaluate DORAEMON on the HM3D, MP3D, and GOAT datasets, where it achieves state-of-the-art performance on both success rate (SR) and success weighted by path length (SPL) metrics, significantly outperforming existing methods. We also introduce a new evaluation metric (AORI) to assess navigation intelligence better. Comprehensive experiments demonstrate DORAEMON's effectiveness in zero-shot autonomous navigation without requiring prior map building or pre-training.",
    "authors": [
      "Tianjun Gu, Linfeng Li, Xuhong Wang, Chenghua Gong, Jingyu Gong, Zhizhong Zhang, Yuan Xie, Lizhuang Ma, Xin Tan"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.841267"
  },
  {
    "id": "oai:arXiv.org:2505.23091v2",
    "journal": "arXiv_CS",
    "title": "Infi-MMR: Curriculum-based Unlocking Multimodal Reasoning via Phased Reinforcement Learning in Multimodal Small Language Models",
    "link": "https://arxiv.org/abs/2505.23091",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2505.23091v2 Announce Type: replace \nAbstract: Recent advancements in large language models (LLMs) have demonstrated substantial progress in reasoning capabilities, such as DeepSeek-R1, which leverages rule-based reinforcement learning to enhance logical reasoning significantly. However, extending these achievements to multimodal large language models (MLLMs) presents critical challenges, which are frequently more pronounced for Multimodal Small Language Models (MSLMs) given their typically weaker foundational reasoning abilities: (1) the scarcity of high-quality multimodal reasoning datasets, (2) the degradation of reasoning capabilities due to the integration of visual processing, and (3) the risk that direct application of reinforcement learning may produce complex yet incorrect reasoning processes. To address these challenges, we design a novel framework Infi-MMR to systematically unlock the reasoning potential of MSLMs through a curriculum of three carefully structured phases and propose our multimodal reasoning model Infi-MMR-3B. The first phase, Foundational Reasoning Activation, leverages high-quality textual reasoning datasets to activate and strengthen the model's logical reasoning capabilities. The second phase, Cross-Modal Reasoning Adaptation, utilizes caption-augmented multimodal data to facilitate the progressive transfer of reasoning skills to multimodal contexts. The third phase, Multimodal Reasoning Enhancement, employs curated, caption-free multimodal data to mitigate linguistic biases and promote robust cross-modal reasoning. Infi-MMR-3B achieves both state-of-the-art multimodal math reasoning ability (43.68% on MathVerse testmini, 27.04% on MathVision test, and 21.33% on OlympiadBench) and general reasoning ability (67.2% on MathVista testmini). Resources are available at https://huggingface.co/Reallm-Labs/Infi-MMR-3B.",
    "authors": [
      "Zeyu Liu, Yuhang Liu, Guanghao Zhu, Congkai Xie, Zhen Li, Jianbo Yuan, Xinyao Wang, Qing Li, Shing-Chi Cheung, Shengyu Zhang, Fei Wu, Hongxia Yang"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.841300"
  },
  {
    "id": "oai:arXiv.org:2505.24108v2",
    "journal": "arXiv_CS",
    "title": "Federated Foundation Model for GI Endoscopy Images",
    "link": "https://arxiv.org/abs/2505.24108",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2505.24108v2 Announce Type: replace \nAbstract: Gastrointestinal (GI) endoscopy is essential in identifying GI tract abnormalities in order to detect diseases in their early stages and improve patient outcomes. Although deep learning has shown success in supporting GI diagnostics and decision-making, these models require curated datasets with labels that are expensive to acquire. Foundation models offer a promising solution by learning general-purpose representations, which can be finetuned for specific tasks, overcoming data scarcity. Developing foundation models for medical imaging holds significant potential, but the sensitive and protected nature of medical data presents unique challenges. Foundation model training typically requires extensive datasets, and while hospitals generate large volumes of data, privacy restrictions prevent direct data sharing, making foundation model training infeasible in most scenarios. In this work, we propose a FL framework for training foundation models for gastroendoscopy imaging, enabling data to remain within local hospital environments while contributing to a shared model. We explore several established FL algorithms, assessing their suitability for training foundation models without relying on task-specific labels, conducting experiments in both homogeneous and heterogeneous settings. We evaluate the trained foundation model on three critical downstream tasks--classification, detection, and segmentation--and demonstrate that it achieves improved performance across all tasks, highlighting the effectiveness of our approach in a federated, privacy-preserving setting.",
    "authors": [
      "Alina Devkota, Annahita Amireskandari, Joel Palko, Shyam Thakkar, Donald Adjeroh, Xiajun Jiang, Binod Bhattarai, Prashnna K. Gyawali"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.841308"
  },
  {
    "id": "oai:arXiv.org:2505.24226v4",
    "journal": "arXiv_CS",
    "title": "E^2GraphRAG: Streamlining Graph-based RAG for High Efficiency and Effectiveness",
    "link": "https://arxiv.org/abs/2505.24226",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2505.24226v4 Announce Type: replace \nAbstract: Graph-based RAG methods like GraphRAG have shown promising global understanding of the knowledge base by constructing hierarchical entity graphs. However, they often suffer from inefficiency and rely on manually pre-defined query modes, limiting practical use. In this paper, we propose E^2GraphRAG, a streamlined graph-based RAG framework that improves both Efficiency and Effectiveness. During the indexing stage, E^2GraphRAG constructs a summary tree with large language models and an entity graph with SpaCy based on document chunks. We then construct bidirectional indexes between entities and chunks to capture their many-to-many relationships, enabling fast lookup during both local and global retrieval. For the retrieval stage, we design an adaptive retrieval strategy that leverages the graph structure to retrieve and select between local and global modes. Experiments show that E^2GraphRAG achieves up to 10 times faster indexing than GraphRAG and 100 times speedup over LightRAG in retrieval while maintaining competitive QA performance.",
    "authors": [
      "Yibo Zhao, Jiapeng Zhu, Ye Guo, Kangkang He, Xiang Li"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.841317"
  },
  {
    "id": "oai:arXiv.org:2505.24757v2",
    "journal": "arXiv_CS",
    "title": "LGAR: Zero-Shot LLM-Guided Neural Ranking for Abstract Screening in Systematic Literature Reviews",
    "link": "https://arxiv.org/abs/2505.24757",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2505.24757v2 Announce Type: replace \nAbstract: The scientific literature is growing rapidly, making it hard to keep track of the state-of-the-art. Systematic literature reviews (SLRs) aim to identify and evaluate all relevant papers on a topic. After retrieving a set of candidate papers, the abstract screening phase determines initial relevance. To date, abstract screening methods using large language models (LLMs) focus on binary classification settings; existing question answering (QA) based ranking approaches suffer from error propagation. LLMs offer a unique opportunity to evaluate the SLR's inclusion and exclusion criteria, yet, existing benchmarks do not provide them exhaustively. We manually extract these criteria as well as research questions for 57 SLRs, mostly in the medical domain, enabling principled comparisons between approaches. Moreover, we propose LGAR, a zero-shot LLM Guided Abstract Ranker composed of an LLM based graded relevance scorer and a dense re-ranker. Our extensive experiments show that LGAR outperforms existing QA-based methods by 5-10 pp. in mean average precision. Our code and data is publicly available.",
    "authors": [
      "Christian Jaumann, Andreas Wiedholz, Annemarie Friedrich"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.841326"
  },
  {
    "id": "oai:arXiv.org:2505.24870v2",
    "journal": "arXiv_CS",
    "title": "GenSpace: Benchmarking Spatially-Aware Image Generation",
    "link": "https://arxiv.org/abs/2505.24870",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2505.24870v2 Announce Type: replace \nAbstract: Humans can intuitively compose and arrange scenes in the 3D space for photography. However, can advanced AI image generators plan scenes with similar 3D spatial awareness when creating images from text or image prompts? We present GenSpace, a novel benchmark and evaluation pipeline to comprehensively assess the spatial awareness of current image generation models. Furthermore, standard evaluations using general Vision-Language Models (VLMs) frequently fail to capture the detailed spatial errors. To handle this challenge, we propose a specialized evaluation pipeline and metric, which reconstructs 3D scene geometry using multiple visual foundation models and provides a more accurate and human-aligned metric of spatial faithfulness. Our findings show that while AI models create visually appealing images and can follow general instructions, they struggle with specific 3D details like object placement, relationships, and measurements. We summarize three core limitations in the spatial perception of current state-of-the-art image generation models: 1) Object Perspective Understanding, 2) Egocentric-Allocentric Transformation and 3) Metric Measurement Adherence, highlighting possible directions for improving spatial intelligence in image generation.",
    "authors": [
      "Zehan Wang, Jiayang Xu, Ziang Zhang, Tianyu Pang, Chao Du, Hengshuang Zhao, Zhou Zhao"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.841342"
  },
  {
    "id": "oai:arXiv.org:2506.00283v2",
    "journal": "arXiv_CS",
    "title": "Direct-to-Cell: A First Look into Starlink's Direct Satellite-to-Device Radio Access Network through Crowdsourced Measurements",
    "link": "https://arxiv.org/abs/2506.00283",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.00283v2 Announce Type: replace \nAbstract: Low Earth Orbit (LEO) satellite mega-constellations have recently emerged as a viable access solution for broadband services in underserved areas. In 2024, Direct Satellite-to-Device (DS2D) communications, which enable unmodified smartphones to connect directly to spaceborne base stations, entered large-scale beta testing, with Starlink globally leading deployments. This paper presents the first measurement study of commercial DS2D services. Using crowdsourced mobile network data collected in the U.S. between October 2024 and April 2025, our research derives evidence-based insights into the capabilities, limitations, and prospective evolution of DS2D technologies providing Supplemental Coverage from Space (SCS) services to expand existing mobile network connectivity. We observe a strong correlation between the number of satellites deployed and the expanding extension of observed measurements, concentrated in accessible but poorly covered areas by terrestrial networks, such as national parks and large low-density counties. The data reveal stable physical-layer value measurement throughout the observation period, with a lower median RSRP (24-dB difference) and a higher RSRQ (3 dB difference) compared to terrestrial networks, reflecting the SMS-only usage of the DS2D network during this period. Based on SINR measurements, we estimate the expected performance of the announced DS2D mobile data service to be around 4 Mbps per beam in outdoor conditions. We also discuss strategies to expand this capacity up to 24 Mbps in the future, depending on key regulatory decisions regarding satellite licenses, spectrum availability, and allowable radiated power levels.",
    "authors": [
      "Jorge Garcia-Cabeza, Javier Albert-Smet, Zoraida Frias, Luis Mendo, Santiago Andr\\'es Azcoitia, Eduardo Yraola"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.841352"
  },
  {
    "id": "oai:arXiv.org:2506.00741v2",
    "journal": "arXiv_CS",
    "title": "Data Swarms: Optimizable Generation of Synthetic Evaluation Data",
    "link": "https://arxiv.org/abs/2506.00741",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.00741v2 Announce Type: replace \nAbstract: We propose Data Swarms, an algorithm to optimize the generation of synthetic evaluation data and advance quantitative desiderata of LLM evaluation. We first train a swarm of initial data generators using existing data, and define various evaluation objectives to reflect the desired properties of evaluation (e.g., generate more difficult problems for the evaluated models) and quantitatively evaluate data generators. We then employ particle swarm optimization to optimize the swarm of data generators, where they collaboratively search through the model parameter space to find new generators that advance these objectives. We further extend it to Adversarial Swarms, where the data generator swarm generates harder data while the test taker model swarm learns from such data, co-evolving dynamically for better data and models simultaneously. Extensive experiments demonstrate that Data Swarms outperforms eight data generation baselines across five evaluation objectives, while Adversarial Swarms produce more robust learning of synthetic data and stronger generalization. Further analysis reveals that Data Swarms successfully optimizes compositions of multiple evaluation objectives and generalizes to new off-the-shelf LLMs, unseen at optimization time.",
    "authors": [
      "Shangbin Feng, Yike Wang, Weijia Shi, Yulia Tsvetkov"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.841360"
  },
  {
    "id": "oai:arXiv.org:2506.00814v2",
    "journal": "arXiv_CS",
    "title": "GuessBench: Sensemaking Multimodal Creativity in the Wild",
    "link": "https://arxiv.org/abs/2506.00814",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.00814v2 Announce Type: replace \nAbstract: We propose GuessBench, a novel benchmark that evaluates Vision Language Models (VLMs) on modeling the pervasive, noisy, and pluralistic human creativity. GuessBench sources data from \"Guess the Build\", an online multiplayer Minecraft minigame where one player constructs a Minecraft build given a concept (e.g. caterpillar) and others try to guess it with natural language hints, presenting a pristine testbed for sensemaking creativity in the wild with VLMs acting as guessers. We curate 1500 images from the actual gameplay and design 2000 problems spanning static and dynamic image settings, natural language hints of varying completeness, and more. Extensive experiments with six open/API VLMs and five reasoning enhancement approaches demonstrate that GuessBench presents a uniquely challenging task in creativity modeling: even the start-of-the-art GPT-4o is incorrect on 34% of instances, while we observe a huge performance gap (13.87% vs. 53.93% on average) between open and API models. When used as a resource to improve VLMs, fine-tuning on the reasoning traces for GuessBench problems improves visual perception tasks by 15.36% on average. Further analysis reveals that VLM performance in creativity sensemaking correlates with the frequency of the concept in training data, while the accuracy drops sharply for concepts in underrepresented cultural contexts and low-resource languages.",
    "authors": [
      "Zifeng Zhu, Shangbin Feng, Herun Wan, Ningnan Wang, Minnan Luo, Yulia Tsvetkov"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.841368"
  },
  {
    "id": "oai:arXiv.org:2506.00845v2",
    "journal": "arXiv_CS",
    "title": "Generalizable LLM Learning of Graph Synthetic Data with Reinforcement Learning",
    "link": "https://arxiv.org/abs/2506.00845",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.00845v2 Announce Type: replace \nAbstract: Previous research has sought to enhance the graph reasoning capabilities of LLMs by supervised fine-tuning on synthetic graph data. While these led to specialized LLMs better at solving graph algorithm problems, we don't need LLMs for shortest path: we need generalization from synthetic graph data to real-world tasks with implicit graph structures. In this work, we propose to unlock generalizable learning of graph synthetic data with reinforcement learning. We first design solution-based and process-based rewards for synthetic graph problems: instead of rigid memorizing response patterns in direct fine-tuning, we posit that RL would help LLMs grasp the essentials underlying graph reasoning and alleviate overfitting. We employ RL algorithms such as GRPO and DPO, aligning both off-the-shelf LLMs and LLMs fine-tuned on synthetic graph data. We then compare them against existing settings on both in-domain synthetic tasks and out-of-domain real-world tasks with implicit graph structures such as multi-hop QA, structured planning, and more. Extensive experiments demonstrate that our RL recipe leads to statistically significant improvement on 5 datasets, with an average gain of 12.9\\% over baseline settings. Further analysis reveals that process-based rewards consistently outperform solution-based rewards, mixing synthetic and real-world task data yields potential gains, while compositionality and explainable intermediate steps remains a critical challenge even after RL.",
    "authors": [
      "Yizhuo Zhang, Heng Wang, Shangbin Feng, Zhaoxuan Tan, Xinyun Liu, Yulia Tsvetkov"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.841377"
  },
  {
    "id": "oai:arXiv.org:2506.00895v2",
    "journal": "arXiv_CS",
    "title": "State-Covering Trajectory Stitching for Diffusion Planners",
    "link": "https://arxiv.org/abs/2506.00895",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.00895v2 Announce Type: replace \nAbstract: Diffusion-based generative models are emerging as powerful tools for long-horizon planning in reinforcement learning (RL), particularly with offline datasets. However, their performance is fundamentally limited by the quality and diversity of training data. This often restricts their generalization to tasks outside their training distribution or longer planning horizons. To overcome this challenge, we propose State-Covering Trajectory Stitching (SCoTS), a novel reward-free trajectory augmentation method that incrementally stitches together short trajectory segments, systematically generating diverse and extended trajectories. SCoTS first learns a temporal distance-preserving latent representation that captures the underlying temporal structure of the environment, then iteratively stitches trajectory segments guided by directional exploration and novelty to effectively cover and expand this latent space. We demonstrate that SCoTS significantly improves the performance and generalization capabilities of diffusion planners on offline goal-conditioned benchmarks requiring stitching and long-horizon reasoning. Furthermore, augmented trajectories generated by SCoTS significantly improve the performance of widely used offline goal-conditioned RL algorithms across diverse environments.",
    "authors": [
      "Kyowoon Lee, Jaesik Choi"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.841385"
  },
  {
    "id": "oai:arXiv.org:2506.01245v2",
    "journal": "arXiv_CS",
    "title": "Comprehensive Vulnerability Analysis is Necessary for Trustworthy LLM-MAS",
    "link": "https://arxiv.org/abs/2506.01245",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.01245v2 Announce Type: replace \nAbstract: This paper argues that a comprehensive vulnerability analysis is essential for building trustworthy Large Language Model-based Multi-Agent Systems (LLM-MAS). These systems, which consist of multiple LLM-powered agents working collaboratively, are increasingly deployed in high-stakes applications but face novel security threats due to their complex structures. While single-agent vulnerabilities are well-studied, LLM-MAS introduces unique attack surfaces through inter-agent communication, trust relationships, and tool integration that remain significantly underexplored. We present a systematic framework for vulnerability analysis of LLM-MAS that unifies diverse research. For each type of vulnerability, we define formal threat models grounded in practical attacker capabilities and illustrate them using real-world LLM-MAS applications. This formulation enables rigorous quantification of vulnerability across different architectures and provides a foundation for designing meaningful evaluation benchmarks. Our analysis reveals that LLM-MAS faces elevated risk due to compositional effects -- vulnerabilities in individual components can cascade through agent communication, creating threat models not present in single-agent systems. We conclude by identifying critical open challenges: (1) developing benchmarks specifically tailored to LLM-MAS vulnerability assessment, (2) considering new potential attacks specific to multi-agent architectures, and (3) implementing trust management systems that can enforce security in LLM-MAS. This research provides essential groundwork for future efforts to enhance LLM-MAS trustworthiness as these systems continue their expansion into critical applications.",
    "authors": [
      "Pengfei He, Yue Xing, Shen Dong, Juanhui Li, Zhenwei Dai, Xianfeng Tang, Hui Liu, Han Xu, Zhen Xiang, Charu C. Aggarwal, Hui Liu"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.841402"
  },
  {
    "id": "oai:arXiv.org:2506.01484v2",
    "journal": "arXiv_CS",
    "title": "LLM in the Loop: Creating the ParaDeHate Dataset for Hate Speech Detoxification",
    "link": "https://arxiv.org/abs/2506.01484",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.01484v2 Announce Type: replace \nAbstract: Detoxification, the task of rewriting harmful language into non-toxic text, has become increasingly important amid the growing prevalence of toxic content online. However, high-quality parallel datasets for detoxification, especially for hate speech, remain scarce due to the cost and sensitivity of human annotation. In this paper, we propose a novel LLM-in-the-loop pipeline leveraging GPT-4o-mini for automated detoxification. We first replicate the ParaDetox pipeline by replacing human annotators with an LLM and show that the LLM performs comparably to human annotation. Building on this, we construct ParaDeHate, a large-scale parallel dataset specifically for hatespeech detoxification. We release ParaDeHate as a benchmark of over 8K hate/non-hate text pairs and evaluate a wide range of baseline methods. Experimental results show that models such as BART, fine-tuned on ParaDeHate, achieve better performance in style accuracy, content preservation, and fluency, demonstrating the effectiveness of LLM-generated detoxification text as a scalable alternative to human annotation.",
    "authors": [
      "Shuzhou Yuan, Ercong Nie, Lukas Kouba, Ashish Yashwanth Kangen, Helmut Schmid, Hinrich Sch\\\"utze, Michael F\\\"arber"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.841411"
  },
  {
    "id": "oai:arXiv.org:2506.01563v2",
    "journal": "arXiv_CS",
    "title": "Hierarchical Intention-Aware Expressive Motion Generation for Humanoid Robots",
    "link": "https://arxiv.org/abs/2506.01563",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.01563v2 Announce Type: replace \nAbstract: Effective human-robot interaction requires robots to identify human intentions and generate expressive, socially appropriate motions in real-time. Existing approaches often rely on fixed motion libraries or computationally expensive generative models. We propose a hierarchical framework that combines intention-aware reasoning via in-context learning (ICL) with real-time motion generation using diffusion models. Our system introduces structured prompting with confidence scoring, fallback behaviors, and social context awareness to enable intention refinement and adaptive response. Leveraging large-scale motion datasets and efficient latent-space denoising, the framework generates diverse, physically plausible gestures suitable for dynamic humanoid interactions. Experimental validation on a physical platform demonstrates the robustness and social alignment of our method in realistic scenarios.",
    "authors": [
      "Lingfan Bao, Yan Pan, Tianhu Peng, Kanoulas Dimitrios, Chengxu Zhou"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.841427"
  },
  {
    "id": "oai:arXiv.org:2506.01723v3",
    "journal": "arXiv_CS",
    "title": "Tug-of-war between idiom's figurative and literal meanings in LLMs",
    "link": "https://arxiv.org/abs/2506.01723",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.01723v3 Announce Type: replace \nAbstract: Idioms present a unique challenge for language models due to their non-compositional figurative meanings, which often strongly diverge from the idiom's literal interpretation. This duality requires a model to learn representing and deciding between the two meanings to interpret an idiom in a figurative sense, or literally. In this paper, we employ tools from mechanistic interpretability to trace how a large pretrained causal transformer (LLama3.2-1B-base) deals with this ambiguity. We localize three steps of idiom processing: First, the idiom's figurative meaning is retrieved in early attention and MLP sublayers. We identify specific attention heads which boost the figurative meaning of the idiom while suppressing the idiom's literal interpretation. The model subsequently represents the figurative representation through an intermediate path. Meanwhile, a parallel bypass route forwards literal interpretation, ensuring that a both reading remain available. Overall, our findings provide a mechanistic evidence for idiom comprehension in an autoregressive transformer.",
    "authors": [
      "Soyoung Oh, Xinting Huang, Mathis Pink, Michael Hahn, Vera Demberg"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.841435"
  },
  {
    "id": "oai:arXiv.org:2506.01819v2",
    "journal": "arXiv_CS",
    "title": "Not All Jokes Land: Evaluating Large Language Models Understanding of Workplace Humor",
    "link": "https://arxiv.org/abs/2506.01819",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.01819v2 Announce Type: replace \nAbstract: With the recent advances in Artificial Intelligence (AI) and Large Language Models (LLMs), the automation of daily tasks, like automatic writing, is getting more and more attention. Hence, efforts have focused on aligning LLMs with human values, yet humor, particularly professional industrial humor used in workplaces, has been largely neglected. To address this, we develop a dataset of professional humor statements along with features that determine the appropriateness of each statement. Our evaluation of five LLMs shows that LLMs often struggle to judge the appropriateness of humor accurately.",
    "authors": [
      "Mohammadamin Shafiei, Hamidreza Saffari"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.841445"
  },
  {
    "id": "oai:arXiv.org:2506.02290v2",
    "journal": "arXiv_CS",
    "title": "HEC: Equivalence Verification Checking for Code Transformation via Equality Saturation",
    "link": "https://arxiv.org/abs/2506.02290",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.02290v2 Announce Type: replace \nAbstract: In modern computing systems, compilation employs numerous optimization techniques to enhance code performance. Source-to-source code transformations, which include control flow and datapath transformations, have been widely used in High-Level Synthesis (HLS) and compiler optimization.\n  While researchers actively investigate methods to improve performance with source-to-source code transformations, they often overlook the significance of verifying their correctness. Current tools cannot provide a holistic verification of these transformations. This paper introduces HEC, a framework for equivalence checking that leverages the e-graph data structure to comprehensively verify functional equivalence between programs. HEC utilizes the MLIR as its frontend and integrates MLIR into the e-graph framework. Through the combination of dynamic and static e-graph rewriting, HEC facilitates the validation of comprehensive code transformations.\n  We demonstrate effectiveness of HEC on PolyBenchC benchmarks, successfully verifying loop unrolling, tiling, and fusion transformations. HEC processes over 100,000 lines of MLIR code in 40 minutes with predictable runtime scaling. Importantly, HEC identified two critical compilation errors in mlir-opt: loop boundary check errors causing unintended executions during unrolling, and memory read-after-write violations in loop fusion that alter program semantics. These findings demonstrate HEC practical value in detecting real-world compiler bugs and highlight the importance of formal verification in optimization pipelines.",
    "authors": [
      "Jiaqi Yin, Zhan Song, Nicolas Bohm Agostini, Antonino Tumeo, Cunxi Yu"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.841453"
  },
  {
    "id": "oai:arXiv.org:2506.02345v2",
    "journal": "arXiv_CS",
    "title": "PandasBench: A Benchmark for the Pandas API",
    "link": "https://arxiv.org/abs/2506.02345",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.02345v2 Announce Type: replace \nAbstract: The Pandas API has been central to the success of pandas and its alternatives. Despite its importance, there is no benchmark for it, and we argue that we cannot repurpose existing benchmarks (from other domains) for the Pandas API.\n  In this paper, we introduce requirements that are necessary for a Pandas API enchmark, and present the first benchmark that fulfills them: PandasBench. We argue that it should evaluate the real-world coverage of a technique. Yet, real-world coverage is not sufficient for a useful benchmark, and so we also: cleaned it from irrelevant code, adapted it for benchmark usage, and introduced input scaling. We claim that uniform scaling used in other benchmarks (e.g., TPC-H) is too coarse-grained for PandasBench, and use a non-uniform scaling scheme. PandasBench is the largest Pandas API benchmark to date, with 102 notebooks and 3,721 cells.\n  We used PandasBench to evaluate Modin, Dask, Koalas, and Dias. This is the largest-scale evaluation of all these techniques to date. Prior works report significant speedups using constrained benchmarks, but we show that on a larger benchmark with real-world code, the most notebooks that got a speedup were 8/102 (~8%) for Modin, and 0 for both Koalas and Dask. Dias showed speedups in up to 55 notebooks (~54%), but it rewrites code incorrectly in certain cases, which had not been observed in prior work. Second, we identified many failures: Modin runs only 72/102 (~70%) notebooks, Dask 4 (~4%), Koalas 10 (~10%), and Dias 97 (95%).",
    "authors": [
      "Alex Broihier, Stefanos Baziotis, Daniel Kang, Charith Mendis"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.841462"
  },
  {
    "id": "oai:arXiv.org:2506.02604v2",
    "journal": "arXiv_CS",
    "title": "Application of convolutional neural networks in image super-resolution",
    "link": "https://arxiv.org/abs/2506.02604",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.02604v2 Announce Type: replace \nAbstract: Due to strong learning abilities of convolutional neural networks (CNNs), they have become mainstream methods for image super-resolution. However, there are big differences of different deep learning methods with different types. There is little literature to summarize relations and differences of different methods in image super-resolution. Thus, summarizing these literatures are important, according to loading capacity and execution speed of devices. This paper first introduces principles of CNNs in image super-resolution, then introduces CNNs based bicubic interpolation, nearest neighbor interpolation, bilinear interpolation, transposed convolution, sub-pixel layer, meta up-sampling for image super-resolution to analyze differences and relations of different CNNs based interpolations and modules, and compare performance of these methods by experiments. Finally, this paper gives potential research points and drawbacks and summarizes the whole paper, which can facilitate developments of CNNs in image super-resolution.",
    "authors": [
      "Chunwei Tian, Mingjian Song, Wangmeng Zuo, Bo Du, Yanning Zhang, Shichao Zhang"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.841470"
  },
  {
    "id": "oai:arXiv.org:2506.02698v2",
    "journal": "arXiv_CS",
    "title": "Smoothed Preference Optimization via ReNoise Inversion for Aligning Diffusion Models with Varied Human Preferences",
    "link": "https://arxiv.org/abs/2506.02698",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.02698v2 Announce Type: replace \nAbstract: Direct Preference Optimization (DPO) aligns text-to-image (T2I) generation models with human preferences using pairwise preference data. Although substantial resources are expended in collecting and labeling datasets, a critical aspect is often neglected: \\textit{preferences vary across individuals and should be represented with more granularity.} To address this, we propose SmPO-Diffusion, a novel method for modeling preference distributions to improve the DPO objective, along with a numerical upper bound estimation for the diffusion optimization objective. First, we introduce a smoothed preference distribution to replace the original binary distribution. We employ a reward model to simulate human preferences and apply preference likelihood averaging to improve the DPO loss, such that the loss function approaches zero when preferences are similar. Furthermore, we utilize an inversion technique to simulate the trajectory preference distribution of the diffusion model, enabling more accurate alignment with the optimization objective. Our approach effectively mitigates issues of excessive optimization and objective misalignment present in existing methods through straightforward modifications. Our SmPO-Diffusion achieves state-of-the-art performance in preference evaluation, outperforming baselines across metrics with lower training costs. The project page is https://jaydenlyh.github.io/SmPO-project-page/.",
    "authors": [
      "Yunhong Lu, Qichao Wang, Hengyuan Cao, Xiaoyin Xu, Min Zhang"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.841480"
  },
  {
    "id": "oai:arXiv.org:2506.02761v2",
    "journal": "arXiv_CS",
    "title": "Rethinking Machine Unlearning in Image Generation Models",
    "link": "https://arxiv.org/abs/2506.02761",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.02761v2 Announce Type: replace \nAbstract: With the surge and widespread application of image generation models, data privacy and content safety have become major concerns and attracted great attention from users, service providers, and policymakers. Machine unlearning (MU) is recognized as a cost-effective and promising means to address these challenges. Despite some advancements, image generation model unlearning (IGMU) still faces remarkable gaps in practice, e.g., unclear task discrimination and unlearning guidelines, lack of an effective evaluation framework, and unreliable evaluation metrics. These can hinder the understanding of unlearning mechanisms and the design of practical unlearning algorithms. We perform exhaustive assessments over existing state-of-the-art unlearning algorithms and evaluation standards, and discover several critical flaws and challenges in IGMU tasks. Driven by these limitations, we make several core contributions, to facilitate the comprehensive understanding, standardized categorization, and reliable evaluation of IGMU. Specifically, (1) We design CatIGMU, a novel hierarchical task categorization framework. It provides detailed implementation guidance for IGMU, assisting in the design of unlearning algorithms and the construction of testbeds. (2) We introduce EvalIGMU, a comprehensive evaluation framework. It includes reliable quantitative metrics across five critical aspects. (3) We construct DataIGM, a high-quality unlearning dataset, which can be used for extensive evaluations of IGMU, training content detectors for judgment, and benchmarking the state-of-the-art unlearning algorithms. With EvalIGMU and DataIGM, we discover that most existing IGMU algorithms cannot handle the unlearning well across different evaluation dimensions, especially for preservation and robustness. Code and models are available at https://github.com/ryliu68/IGMU.",
    "authors": [
      "Renyang Liu, Wenjie Feng, Tianwei Zhang, Wei Zhou, Xueqi Cheng, See-Kiong Ng"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.841489"
  },
  {
    "id": "oai:arXiv.org:2506.02887v2",
    "journal": "arXiv_CS",
    "title": "Overcoming Challenges of Partial Client Participation in Federated Learning : A Comprehensive Review",
    "link": "https://arxiv.org/abs/2506.02887",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.02887v2 Announce Type: replace \nAbstract: Federated Learning (FL) is a learning mechanism that falls under the distributed training umbrella, which collaboratively trains a shared global model without disclosing the raw data from different clients. This paper presents an extensive survey on the impact of partial client participation in federated learning. While much of the existing research focuses on addressing issues such as generalization, robustness, and fairness caused by data heterogeneity under the assumption of full client participation, limited attention has been given to the practical and theoretical challenges arising from partial client participation, which is common in real-world scenarios. This survey provides an in-depth review of existing FL methods designed to cope with partial client participation. We offer a comprehensive analysis supported by theoretical insights and empirical findings, along with a structured categorization of these methods, highlighting their respective advantages and disadvantages.",
    "authors": [
      "Mrinmay Sen, Shruti Aparna, Rohit Agarwal, Chalavadi Krishna Mohan"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.841499"
  },
  {
    "id": "oai:arXiv.org:2506.03006v2",
    "journal": "arXiv_CS",
    "title": "A Preference-Driven Methodology for High-Quality Solidity Code Generation",
    "link": "https://arxiv.org/abs/2506.03006",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.03006v2 Announce Type: replace \nAbstract: While Large Language Models (LLMs) have demonstrated remarkable progress in generating functionally correct Solidity code, they continue to face critical challenges in producing gas-efficient and secure code, which are critical requirements for real-world smart contract deployment. Although recent advances leverage Supervised Fine-Tuning (SFT) and Direct Preference Optimization (DPO) for code preference alignment, existing approaches treat functional correctness, gas optimization, and security as independent objectives, resulting in contracts that may achieve operational soundness but suffer from prohibitive execution costs or dangerous vulnerabilities. To address these limitations, we propose \\textbf{\\mytitle}, a novel framework that extends standard DPO beyond human preferences to incorporate quantifiable blockchain-specific metrics, enabling holistic multi-objective optimization specifically tailored for smart contract generation. Our framework introduces a comprehensive evaluation methodology with four complementary metrics: Pass@k (functional correctness), Compile@k (syntactic correctness), Gas@k (gas efficiency), and Secure@k (security assessment), providing rigorous multi-dimensional contract evaluation. Through extensive experimentation, we demonstrate that \\mytitle significantly outperforms existing approaches across all critical dimensions, achieving 66.7\\% Pass@5, 58.9\\% Gas@5, and 62.5\\% Secure@5, while generating production-ready smart contracts that are functionally correct, cost-efficient, and secure.",
    "authors": [
      "Zhiyuan Peng, Xin Yin, Chenhao Ying, Chao Ni, Yuan Luo"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.841508"
  },
  {
    "id": "oai:arXiv.org:2506.03070v2",
    "journal": "arXiv_CS",
    "title": "GPU-Parallelizable Randomized Sketch-and-Precondition for Linear Regression using Sparse Sign Sketches",
    "link": "https://arxiv.org/abs/2506.03070",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.03070v2 Announce Type: replace \nAbstract: A litany of theoretical and numerical results have established the sketch-and-precondition paradigm as a powerful approach to solving large linear regression problems in standard computing environments. Perhaps surprisingly, much less work has been done on understanding how sketch-and-precondition performs on graphics processing unit (GPU) systems. We address this gap by benchmarking an implementation of sketch-and-precondition based on sparse sign-sketches on single and multi-GPU systems. In doing so, we describe a novel, easily parallelized, rejection-sampling based method for generating sparse sign sketches. Our approach, which is particularly well-suited for GPUs, is easily adapted to a variety of computing environments. Taken as a whole, our numerical experiments indicate that sketch-and-precondition with sparse sign sketches is particularly well-suited for GPUs, and may be suitable for use in black-box least-squares solvers.",
    "authors": [
      "Tyler Chen, Pradeep Niroula, Archan Ray, Pragna Subrahmanya, Marco Pistoia, Niraj Kumar"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.841518"
  },
  {
    "id": "oai:arXiv.org:2506.03083v2",
    "journal": "arXiv_CS",
    "title": "Labelling Data with Unknown References",
    "link": "https://arxiv.org/abs/2506.03083",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.03083v2 Announce Type: replace \nAbstract: An evaluator is trustworthy when there exists some agreed-upon way to measure its performance as a labeller. The two ways to establish trustworthiness are either by testing it, or by assuming the evaluator `knows' somehow the way to label the corpus. However, if labelled references (e.g., a development set) are unavailable, neither of these approaches work: the former requires the data, and the latter is an assumption, not evidence. To address this, we introduce an algorithm (the `No-Data Algorithm') by which to establish trust in an evaluator without any existing references. Our algorithm works by successively posing challenges to said evaluator. We show that this is sufficient to establish trustworthiness w.h.p., in such a way that when the evaluator actually knows the way to label the corpus, the No-Data Algorithm accepts its output; and, conversely, flags untrustworthy evaluators when these are unable to prove it. We present formal proofs of correctness and limited experiments.",
    "authors": [
      "Adrian de Wynter"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.841527"
  },
  {
    "id": "oai:arXiv.org:2506.03085v2",
    "journal": "arXiv_CS",
    "title": "Non-Asymptotic Length Generalization",
    "link": "https://arxiv.org/abs/2506.03085",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.03085v2 Announce Type: replace \nAbstract: Length generalization is the ability of a learning algorithm to learn a hypothesis which generalizes to longer inputs than the inputs in the training set. In this paper, we provide provable guarantees of length generalization for various classes of functions in an idealized setting. First, we formalize the framework of non-asymptotic length generalization, which requires a computable upper bound for the minimum input length that guarantees length generalization, as a function of the complexity of ground-truth function under some given complexity measure. We refer to this minimum input length to length generalize as length complexity. We show the Minimum-Complexity Interpolator learning algorithm achieves optimal length complexity. We further show that whether a function class admits non-asymptotic length generalization is equivalent to the decidability of its language equivalence problem, which implies that there is no computable upper bound for the length complexity of Context-Free Grammars. On the positive side, we show that the length complexity of Deterministic Finite Automata is $2n - 2$ where $n$ is the number of states of the ground-truth automaton. Our main results are upper bounds of length complexity for a subset of a transformer-related function class called C-RASP (Yang & Chiang, 2024). We show that the length complexity of 1-layer C-RASP functions is $O(T^2)$ when the ground-truth function has precision $T$, and that the length complexity of 2-layer C-RASP functions is $O(T^{O(K)})$ when the ground-truth function has precision $T$ and $K$ heads.",
    "authors": [
      "Thomas Chen, Tengyu Ma, Zhiyuan Li"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.841535"
  },
  {
    "id": "oai:arXiv.org:2506.03294v2",
    "journal": "arXiv_CS",
    "title": "Prefix-free parsing for merging big BWTs",
    "link": "https://arxiv.org/abs/2506.03294",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.03294v2 Announce Type: replace \nAbstract: When building Burrows-Wheeler Transforms (BWTs) of truly huge datasets, prefix-free parsing (PFP) can use an unreasonable amount of memory. In this paper we show how if a dataset can be broken down into small datasets that are not very similar to each other -- such as collections of many copies of genomes of each of several species, or collections of many copies of each of the human chromosomes -- then we can drastically reduce PFP's memory footprint by building the BWTs of the small datasets and then merging them into the BWT of the whole dataset.",
    "authors": [
      "Diego Diaz-Dominguez, Travis Gagie, Veronica Guerrini, Ben Langmead, Zsuzsanna Liptak, Giovanni Manzini, Francesco Masillo, Vikram Shivakumar"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.841543"
  },
  {
    "id": "oai:arXiv.org:2506.03582v2",
    "journal": "arXiv_CS",
    "title": "SemiOccam: A Robust Semi-Supervised Image Recognition Network Using Sparse Labels",
    "link": "https://arxiv.org/abs/2506.03582",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.03582v2 Announce Type: replace \nAbstract: We present SemiOccam, an image recognition network that leverages semi-supervised learning in a highly efficient manner. Existing works often rely on complex training techniques and architectures, requiring hundreds of GPU hours for training, while their generalization ability when dealing with extremely limited labeled data remains to be improved. To address these limitations, we construct a hierarchical mixture density classification decision mechanism by optimizing mutual information between feature representations and target classes, compressing redundant information while retaining crucial discriminative components. Experimental results demonstrate that our method achieves state-of-the-art performance on various datasets when using negligible labeled samples, and its simple architecture keeps training time to minute-level. Notably, this paper reveals a long-overlooked data leakage issue in the STL-10 dataset for semi-supervised learning tasks and removes duplicates to ensure the reliability of experimental results. We also release the deduplicated CleanSTL-10 dataset to facilitate fair and reliable research in future semi-supervised learning. Code available at https://github.com/Shu1L0n9/SemiOccam.",
    "authors": [
      "Rui Yann, Xianglei Xing"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.841552"
  },
  {
    "id": "oai:arXiv.org:2506.03720v2",
    "journal": "arXiv_CS",
    "title": "Design of a visual environment for programming by direct data manipulation",
    "link": "https://arxiv.org/abs/2506.03720",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.03720v2 Announce Type: replace \nAbstract: The use of applications on computers, smartphones, and tablets has been considerably simplified thanks to interactive and dynamic graphical interfaces coupled with the mouse and touch screens. It is no longer necessary to be a computer specialist to use them. Paradoxically, the development of computer programs generally requires writing lines of code in a programming language whose syntax is particularly strict. This process poses many difficulties for programmers. We propose an original tool in which arbitrary programs (Turing-complete) can be developed in a completely visual manner by direct manipulation of the data, without writing a line of code. The user can thus develop an algorithm by directly visualizing the result of actions taken on the data. A method for constructing iterations is associated with the tool. It proposes to create each part, including the loop body, in a non-linear manner under visual control of the state of the data. In addition, the tool supports the production of lines of code in several languages including Python, C, Java, that correspond to the actions performed. In this article, we present the tool, the design choices, the problems to be solved, and the limits and the contributions of the direct-data-manipulation approach.",
    "authors": [
      "Michel Adam (UBS, IRISA), Patrice Frison (UBS, IRISA), Moncef Daoud (UBS), Sabine Letellier Zarshenas (UBS)"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.841568"
  },
  {
    "id": "oai:arXiv.org:2506.04165v2",
    "journal": "arXiv_CS",
    "title": "Faster Approx. Top-K: Harnessing the Full Power of Two Stages",
    "link": "https://arxiv.org/abs/2506.04165",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.04165v2 Announce Type: replace \nAbstract: We consider the Top-$K$ selection problem, which aims to identify the largest-$K$ elements from an array. Top-$K$ selection arises in many machine learning algorithms and often becomes a bottleneck on accelerators, which are optimized for dense matrix multiplications. To address this problem, \\citet{chern2022tpuknnknearestneighbor} proposed a fast two-stage \\textit{approximate} Top-$K$ algorithm: (i) partition the input array and select the top-$1$ element from each partition, (ii) sort this \\textit{smaller subset} and return the top $K$ elements. In this paper, we consider a generalized version of this algorithm, where the first stage selects top-$K'$ elements, for some $1 \\leq K' \\leq K$, from each partition. Our contributions are as follows: (i) we derive an expression for the expected recall of this generalized algorithm and show that choosing $K' > 1$ with fewer partitions in the first stage reduces the input size to the second stage more effectively while maintaining the same expected recall as the original algorithm, (ii) we derive a bound on the expected recall for the original algorithm in \\citet{chern2022tpuknnknearestneighbor} that is provably tighter by a factor of $2$ than the one in that paper, and (iii) we implement our algorithm on Cloud TPUv5e and achieve around an order of magnitude speedups over the original algorithm without sacrificing recall on real-world tasks.",
    "authors": [
      "Yashas Samaga, Varun Yerram, Spandana Raj Babbula, Prateek Jain, Praneeth Netrapalli"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.841576"
  },
  {
    "id": "oai:arXiv.org:2506.04202v2",
    "journal": "arXiv_CS",
    "title": "TracLLM: A Generic Framework for Attributing Long Context LLMs",
    "link": "https://arxiv.org/abs/2506.04202",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.04202v2 Announce Type: replace \nAbstract: Long context large language models (LLMs) are deployed in many real-world applications such as RAG, agent, and broad LLM-integrated applications. Given an instruction and a long context (e.g., documents, PDF files, webpages), a long context LLM can generate an output grounded in the provided context, aiming to provide more accurate, up-to-date, and verifiable outputs while reducing hallucinations and unsupported claims. This raises a research question: how to pinpoint the texts (e.g., sentences, passages, or paragraphs) in the context that contribute most to or are responsible for the generated output by an LLM? This process, which we call context traceback, has various real-world applications, such as 1) debugging LLM-based systems, 2) conducting post-attack forensic analysis for attacks (e.g., prompt injection attack, knowledge corruption attacks) to an LLM, and 3) highlighting knowledge sources to enhance the trust of users towards outputs generated by LLMs. When applied to context traceback for long context LLMs, existing feature attribution methods such as Shapley have sub-optimal performance and/or incur a large computational cost. In this work, we develop TracLLM, the first generic context traceback framework tailored to long context LLMs. Our framework can improve the effectiveness and efficiency of existing feature attribution methods. To improve the efficiency, we develop an informed search based algorithm in TracLLM. We also develop contribution score ensemble/denoising techniques to improve the accuracy of TracLLM. Our evaluation results show TracLLM can effectively identify texts in a long context that lead to the output of an LLM. Our code and data are at: https://github.com/Wang-Yanting/TracLLM.",
    "authors": [
      "Yanting Wang, Wei Zou, Runpeng Geng, Jinyuan Jia"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.841585"
  },
  {
    "id": "oai:arXiv.org:2506.04525v2",
    "journal": "arXiv_CS",
    "title": "User Altruism in Recommendation Systems",
    "link": "https://arxiv.org/abs/2506.04525",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.04525v2 Announce Type: replace \nAbstract: Users of social media platforms based on recommendation systems (RecSys) (e.g. TikTok, X, YouTube) strategically interact with platform content to influence future recommendations. On some such platforms, users have been documented to form large-scale grassroots movements encouraging others to purposefully interact with algorithmically suppressed content in order to \"boost\" its recommendation; we term this behavior user altruism. To capture this behavior, we study a game between users and a RecSys, where users provide the RecSys (potentially manipulated) preferences over the contents available to them, and the RecSys -- limited by data and computation constraints -- creates a low-rank approximation preference matrix, and ultimately provides each user her (approximately) most-preferred item. We compare the users' social welfare under truthful preference reporting and under a class of strategies capturing user altruism. In our theoretical analysis, we provide sufficient conditions to ensure strict increases in user social welfare under user altruism, and provide an algorithm to find an effective altruistic strategy. Interestingly, we show that for commonly assumed recommender utility functions, effectively altruistic strategies also improve the utility of the RecSys! We show that our results are robust to several model misspecifications, thus strengthening our conclusions. Our theoretical analysis is complemented by empirical results of effective altruistic strategies on the GoodReads dataset, and an online survey on how real-world users behave altruistically in RecSys. Overall, our findings serve as a proof-of-concept of the reasons why traditional RecSys may incentivize users to form collectives and/or follow altruistic strategies when interacting with them.",
    "authors": [
      "Ekaterina Fedorova, Madeline Kitch, Chara Podimata"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.841600"
  },
  {
    "id": "oai:arXiv.org:2506.04668v2",
    "journal": "arXiv_CS",
    "title": "Feature-Based Lie Group Transformer for Real-World Applications",
    "link": "https://arxiv.org/abs/2506.04668",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.04668v2 Announce Type: replace \nAbstract: The main goal of representation learning is to acquire meaningful representations from real-world sensory inputs without supervision. Representation learning explains some aspects of human development. Various neural network (NN) models have been proposed that acquire empirically good representations. However, the formulation of a good representation has not been established. We recently proposed a method for categorizing changes between a pair of sensory inputs. A unique feature of this approach is that transformations between two sensory inputs are learned to satisfy algebraic structural constraints. Conventional representation learning often assumes that disentangled independent feature axes is a good representation; however, we found that such a representation cannot account for conditional independence. To overcome this problem, we proposed a new method using group decomposition in Galois algebra theory. Although this method is promising for defining a more general representation, it assumes pixel-to-pixel translation without feature extraction, and can only process low-resolution images with no background, which prevents real-world application. In this study, we provide a simple method to apply our group decomposition theory to a more realistic scenario by combining feature extraction and object segmentation. We replace pixel translation with feature translation and formulate object segmentation as grouping features under the same transformation. We validated the proposed method on a practical dataset containing both real-world object and background. We believe that our model will lead to a better understanding of human development of object recognition in the real world.",
    "authors": [
      "Takayuki Komatsu, Yoshiyuki Ohmura, Kayato Nishitsunoi, Yasuo Kuniyoshi"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.841616"
  },
  {
    "id": "oai:arXiv.org:2506.04682v2",
    "journal": "arXiv_CS",
    "title": "MARS: Radio Map Super-resolution and Reconstruction Method under Sparse Channel Measurements",
    "link": "https://arxiv.org/abs/2506.04682",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.04682v2 Announce Type: replace \nAbstract: Radio maps reflect the spatial distribution of signal strength and are essential for applications like smart cities, IoT, and wireless network planning. However, reconstructing accurate radio maps from sparse measurements remains challenging. Traditional interpolation and inpainting methods lack environmental awareness, while many deep learning approaches depend on detailed scene data, limiting generalization. To address this, we propose MARS, a Multi-scale Aware Radiomap Super-resolution method that combines CNNs and Transformers with multi-scale feature fusion and residual connections. MARS focuses on both global and local feature extraction, enhancing feature representation across different receptive fields and improving reconstruction accuracy. Experiments across different scenes and antenna locations show that MARS outperforms baseline models in both MSE and SSIM, while maintaining low computational cost, demonstrating strong practical potential.",
    "authors": [
      "Chuyun Deng, Na Liu, Wei Xie, Lianming Xu, Li Wang"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.841625"
  },
  {
    "id": "oai:arXiv.org:2506.04737v2",
    "journal": "arXiv_CS",
    "title": "Bridging Annotation Gaps: Transferring Labels to Align Object Detection Datasets",
    "link": "https://arxiv.org/abs/2506.04737",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.04737v2 Announce Type: replace \nAbstract: Combining multiple object detection datasets offers a path to improved generalisation but is hindered by inconsistencies in class semantics and bounding box annotations. Some methods to address this assume shared label taxonomies and address only spatial inconsistencies; others require manual relabelling, or produce a unified label space, which may be unsuitable when a fixed target label space is required. We propose Label-Aligned Transfer (LAT), a label transfer framework that systematically projects annotations from diverse source datasets into the label space of a target dataset. LAT begins by training dataset-specific detectors to generate pseudo-labels, which are then combined with ground-truth annotations via a Privileged Proposal Generator (PPG) that replaces the region proposal network in two-stage detectors. To further refine region features, a Semantic Feature Fusion (SFF) module injects class-aware context and features from overlapping proposals using a confidence-weighted attention mechanism. This pipeline preserves dataset-specific annotation granularity while enabling many-to-one label space transfer across heterogeneous datasets, resulting in a semantically and spatially aligned representation suitable for training a downstream detector. LAT thus jointly addresses both class-level misalignments and bounding box inconsistencies without relying on shared label spaces or manual annotations. Across multiple benchmarks, LAT demonstrates consistent improvements in target-domain detection performance, achieving gains of up to +4.8AP over semi-supervised baselines.",
    "authors": [
      "Mikhail Kennerley, Angelica Aviles-Rivero, Carola-Bibiane Sch\\\"onlieb, Robby T. Tan"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.841634"
  },
  {
    "id": "oai:arXiv.org:2506.04772v2",
    "journal": "arXiv_CS",
    "title": "Identifying Reliable Evaluation Metrics for Scientific Text Revision",
    "link": "https://arxiv.org/abs/2506.04772",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.04772v2 Announce Type: replace \nAbstract: Evaluating text revision in scientific writing remains a challenge, as traditional metrics such as ROUGE and BERTScore primarily focus on similarity rather than capturing meaningful improvements. In this work, we analyse and identify the limitations of these metrics and explore alternative evaluation methods that better align with human judgments. We first conduct a manual annotation study to assess the quality of different revisions. Then, we investigate reference-free evaluation metrics from related NLP domains. Additionally, we examine LLM-as-a-judge approaches, analysing their ability to assess revisions with and without a gold reference. Our results show that LLMs effectively assess instruction-following but struggle with correctness, while domain-specific metrics provide complementary insights. We find that a hybrid approach combining LLM-as-a-judge evaluation and task-specific metrics offers the most reliable assessment of revision quality.",
    "authors": [
      "L\\'eane Jourdan, Florian Boudin, Richard Dufour, Nicolas Hernandez"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.841642"
  },
  {
    "id": "oai:arXiv.org:2506.04924v2",
    "journal": "arXiv_CS",
    "title": "Predicting ICU In-Hospital Mortality Using Adaptive Transformer Layer Fusion",
    "link": "https://arxiv.org/abs/2506.04924",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.04924v2 Announce Type: replace \nAbstract: Early identification of high-risk ICU patients is crucial for directing limited medical resources. We introduce ALFIA (Adaptive Layer Fusion with Intelligent Attention), a modular, attention-based architecture that jointly trains LoRA (Low-Rank Adaptation) adapters and an adaptive layer-weighting mechanism to fuse multi-layer semantic features from a BERT backbone. Trained on our rigorous cw-24 (CriticalWindow-24) benchmark, ALFIA surpasses state-of-the-art tabular classifiers in AUPRC while preserving a balanced precision-recall profile. The embeddings produced by ALFIA's fusion module, capturing both fine-grained clinical cues and high-level concepts, enable seamless pairing with GBDTs (CatBoost/LightGBM) as ALFIA-boost, and deep neuro networks as ALFIA-nn, yielding additional performance gains. Our experiments confirm ALFIA's superior early-warning performance, by operating directly on routine clinical text, it furnishes clinicians with a convenient yet robust tool for risk stratification and timely intervention in critical-care settings.",
    "authors": [
      "Han Wang, Ruoyun He, Guoguang Lao, Ting Liu, Hejiao Luo, Changqi Qin, Hongying Luo, Junmin Huang, Zihan Wei, Lu Chen, Yongzhi Xu, Ziqian Bi, Junhao Song, Tianyang Wang, Chia Xin Liang, Xinyuan Song, Huafeng Liu, Junfeng Hao, Chunjie Tian"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.841659"
  },
  {
    "id": "oai:arXiv.org:2506.04941v2",
    "journal": "arXiv_CS",
    "title": "ArtVIP: Articulated Digital Assets of Visual Realism, Modular Interaction, and Physical Fidelity for Robot Learning",
    "link": "https://arxiv.org/abs/2506.04941",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.04941v2 Announce Type: replace \nAbstract: Robot learning increasingly relies on simulation to advance complex ability such as dexterous manipulations and precise interactions, necessitating high-quality digital assets to bridge the sim-to-real gap. However, existing open-source articulated-object datasets for simulation are limited by insufficient visual realism and low physical fidelity, which hinder their utility for training models mastering robotic tasks in real world. To address these challenges, we introduce ArtVIP, a comprehensive open-source dataset comprising high-quality digital-twin articulated objects, accompanied by indoor-scene assets. Crafted by professional 3D modelers adhering to unified standards, ArtVIP ensures visual realism through precise geometric meshes and high-resolution textures, while physical fidelity is achieved via fine-tuned dynamic parameters. Meanwhile, the dataset pioneers embedded modular interaction behaviors within assets and pixel-level affordance annotations. Feature-map visualization and optical motion capture are employed to quantitatively demonstrate ArtVIP's visual and physical fidelity, with its applicability validated across imitation learning and reinforcement learning experiments. Provided in USD format with detailed production guidelines, ArtVIP is fully open-source, benefiting the research community and advancing robot learning research. Our project is at https://x-humanoid-artvip.github.io/ .",
    "authors": [
      "Zhao Jin, Zhengping Che, Zhen Zhao, Kun Wu, Yuheng Zhang, Yinuo Zhao, Zehui Liu, Qiang Zhang, Xiaozhu Ju, Jing Tian, Yousong Xue, Jian Tang"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.841668"
  },
  {
    "id": "oai:arXiv.org:2506.04962v2",
    "journal": "arXiv_CS",
    "title": "PoCGen: Generating Proof-of-Concept Exploits for Vulnerabilities in Npm Packages",
    "link": "https://arxiv.org/abs/2506.04962",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.04962v2 Announce Type: replace \nAbstract: Security vulnerabilities in software packages are a significant concern for developers and users alike. Patching these vulnerabilities in a timely manner is crucial to restoring the integrity and security of software systems. However, previous work has shown that vulnerability reports often lack proof-of-concept (PoC) exploits, which are essential for fixing the vulnerability, testing patches, and avoiding regressions. Creating a PoC exploit is challenging because vulnerability reports are informal and often incomplete, and because it requires a detailed understanding of how inputs passed to potentially vulnerable APIs may reach security-relevant sinks. In this paper, we present PoCGen, a novel approach to autonomously generate and validate PoC exploits for vulnerabilities in npm packages. This is the first fully autonomous approach to use large language models (LLMs) in tandem with static and dynamic analysis techniques for PoC exploit generation. PoCGen leverages an LLM for understanding vulnerability reports, for generating candidate PoC exploits, and for validating and refining them. Our approach successfully generates exploits for 77% of the vulnerabilities in the SecBench$.$js dataset and 39% in a new, more challenging dataset of 794 recent vulnerabilities. This success rate significantly outperforms a recent baseline (by 45 absolute percentage points), while imposing an average cost of $0.02 per generated exploit.",
    "authors": [
      "Deniz Simsek, Aryaz Eghbali, Michael Pradel"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.841677"
  },
  {
    "id": "oai:arXiv.org:2506.05068v2",
    "journal": "arXiv_CS",
    "title": "Does It Make Sense to Speak of Introspection in Large Language Models?",
    "link": "https://arxiv.org/abs/2506.05068",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05068v2 Announce Type: replace \nAbstract: Large language models (LLMs) exhibit compelling linguistic behaviour, and sometimes offer self-reports, that is to say statements about their own nature, inner workings, or behaviour. In humans, such reports are often attributed to a faculty of introspection and are typically linked to consciousness. This raises the question of how to interpret self-reports produced by LLMs, given their increasing linguistic fluency and cognitive capabilities. To what extent (if any) can the concept of introspection be meaningfully applied to LLMs? Here, we present and critique two examples of apparent introspective self-report from LLMs. In the first example, an LLM attempts to describe the process behind its own \"creative\" writing, and we argue this is not a valid example of introspection. In the second example, an LLM correctly infers the value of its own temperature parameter, and we argue that this can be legitimately considered a minimal example of introspection, albeit one that is (presumably) not accompanied by conscious experience.",
    "authors": [
      "Iulia M. Comsa, Murray Shanahan"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.841685"
  },
  {
    "id": "oai:arXiv.org:2506.05083v2",
    "journal": "arXiv_CS",
    "title": "SeedEdit 3.0: Fast and High-Quality Generative Image Editing",
    "link": "https://arxiv.org/abs/2506.05083",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05083v2 Announce Type: replace \nAbstract: We introduce SeedEdit 3.0, in companion with our T2I model Seedream 3.0, which significantly improves over our previous SeedEdit versions in both aspects of edit instruction following and image content (e.g., ID/IP) preservation on real image inputs. Additional to model upgrading with T2I, in this report, we present several key improvements. First, we develop an enhanced data curation pipeline with a meta-info paradigm and meta-info embedding strategy that help mix images from multiple data sources. This allows us to scale editing data effectively, and meta information is helpfult to connect VLM with diffusion model more closely. Second, we introduce a joint learning pipeline for computing a diffusion loss and reward losses. Finally, we evaluate SeedEdit 3.0 on our testing benchmarks, for real/synthetic image editing, where it achieves a best trade-off between multiple aspects, yielding a high usability rate of 56.1%, compared to SeedEdit 1.6 (38.4%), GPT4o (37.1%) and Gemini 2.0 (30.3%).",
    "authors": [
      "Peng Wang, Yichun Shi, Xiaochen Lian, Zhonghua Zhai, Xin Xia, Xuefeng Xiao, Weilin Huang, Jianchao Yang"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.841693"
  },
  {
    "id": "oai:arXiv.org:2506.05096v2",
    "journal": "arXiv_CS",
    "title": "Astraea: A GPU-Oriented Token-wise Acceleration Framework for Video Diffusion Transformers",
    "link": "https://arxiv.org/abs/2506.05096",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05096v2 Announce Type: replace \nAbstract: Video diffusion transformers (vDiTs) have made impressive progress in text-to-video generation, but their high computational demands present major challenges for practical deployment. While existing acceleration methods reduce workload at various granularities, they often rely on heuristics, limiting their applicability.\n  We introduce ASTRAEA, an automatic framework that searches for near-optimal configurations for vDiT-based video generation. At its core, ASTRAEA proposes a lightweight token selection mechanism and a memory-efficient, GPU-parallel sparse attention strategy, enabling linear reductions in execution time with minimal impact on generation quality. To determine optimal token reduction for different timesteps, we further design a search framework that leverages a classic evolutionary algorithm to automatically determine the distribution of the token budget effectively. Together, ASTRAEA achieves up to 2.4x inference speedup on a single GPU with great scalability (up to 13.2x speedup on 8 GPUs) while retaining better video quality compared to the state-of-the-art methods (<0.5% loss on the VBench score compared to the baseline vDiT models).",
    "authors": [
      "Haosong Liu, Yuge Cheng, Zihan Liu, Aiyue Chen, Yiwu Yao, Chen Chen, Jingwen Leng, Yu Feng, Minyi Guo"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.841702"
  },
  {
    "id": "oai:arXiv.org:2506.05166v2",
    "journal": "arXiv_CS",
    "title": "Dissecting Bias in LLMs: A Mechanistic Interpretability Perspective",
    "link": "https://arxiv.org/abs/2506.05166",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05166v2 Announce Type: replace \nAbstract: Large Language Models (LLMs) are known to exhibit social, demographic, and gender biases, often as a consequence of the data on which they are trained. In this work, we adopt a mechanistic interpretability approach to analyze how such biases are structurally represented within models such as GPT-2 and Llama2. Focusing on demographic and gender biases, we explore different metrics to identify the internal edges responsible for biased behavior. We then assess the stability, localization, and generalizability of these components across dataset and linguistic variations. Through systematic ablations, we demonstrate that bias-related computations are highly localized, often concentrated in a small subset of layers. Moreover, the identified components change across fine-tuning settings, including those unrelated to bias. Finally, we show that removing these components not only reduces biased outputs but also affects other NLP tasks, such as named entity recognition and linguistic acceptability judgment because of the sharing of important components with these tasks.",
    "authors": [
      "Bhavik Chandna, Zubair Bashir, Procheta Sen"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.841711"
  },
  {
    "id": "oai:arXiv.org:2506.05167v2",
    "journal": "arXiv_CS",
    "title": "ECoRAG: Evidentiality-guided Compression for Long Context RAG",
    "link": "https://arxiv.org/abs/2506.05167",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05167v2 Announce Type: replace \nAbstract: Large Language Models (LLMs) have shown remarkable performance in Open-Domain Question Answering (ODQA) by leveraging external documents through Retrieval-Augmented Generation (RAG). To reduce RAG overhead, from longer context, context compression is necessary. However, prior compression methods do not focus on filtering out non-evidential information, which limit the performance in LLM-based RAG. We thus propose Evidentiality-guided RAG, or ECoRAG framework. ECoRAG improves LLM performance by compressing retrieved documents based on evidentiality, ensuring whether answer generation is supported by the correct evidence. As an additional step, ECoRAG reflects whether the compressed content provides sufficient evidence, and if not, retrieves more until sufficient. Experiments show that ECoRAG improves LLM performance on ODQA tasks, outperforming existing compression methods. Furthermore, ECoRAG is highly cost-efficient, as it not only reduces latency but also minimizes token usage by retaining only the necessary information to generate the correct answer. Code is available at https://github.com/ldilab/ECoRAG.",
    "authors": [
      "Yeonseok Jeong, Jinsu Kim, Dohyeon Lee, Seung-won Hwang"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.841719"
  },
  {
    "id": "oai:arXiv.org:2506.05256v2",
    "journal": "arXiv_CS",
    "title": "Just Enough Thinking: Efficient Reasoning with Adaptive Length Penalties Reinforcement Learning",
    "link": "https://arxiv.org/abs/2506.05256",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05256v2 Announce Type: replace \nAbstract: Large reasoning models (LRMs) achieve higher performance on challenging reasoning tasks by generating more tokens at inference time, but this verbosity often wastes computation on easy problems. Existing solutions, including supervised finetuning on shorter traces, user-controlled budgets, or RL with uniform penalties, either require data curation, manual configuration, or treat all problems alike regardless of difficulty. We introduce Adaptive Length Penalty (ALP), a reinforcement learning objective tailoring generation length to per-prompt solve rate. During training, ALP monitors each prompt's online solve rate through multiple rollouts and adds a differentiable penalty whose magnitude scales inversely with that rate, so confident (easy) prompts incur a high cost for extra tokens while hard prompts remain unhindered. Posttraining DeepScaleR-1.5B with ALP cuts average token usage by 50\\% without significantly dropping performance. Relative to fixed-budget and uniform penalty baselines, ALP redistributes its reduced budget more intelligently by cutting compute on easy prompts and reallocating saved tokens to difficult ones, delivering higher accuracy on the hardest problems with higher cost.",
    "authors": [
      "Violet Xiang, Chase Blagden, Rafael Rafailov, Nathan Lile, Sang Truong, Chelsea Finn, Nick Haber"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.841728"
  },
  {
    "id": "oai:arXiv.org:2506.05280v2",
    "journal": "arXiv_CS",
    "title": "Unifying Appearance Codes and Bilateral Grids for Driving Scene Gaussian Splatting",
    "link": "https://arxiv.org/abs/2506.05280",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05280v2 Announce Type: replace \nAbstract: Neural rendering techniques, including NeRF and Gaussian Splatting (GS), rely on photometric consistency to produce high-quality reconstructions. However, in real-world scenarios, it is challenging to guarantee perfect photometric consistency in acquired images. Appearance codes have been widely used to address this issue, but their modeling capability is limited, as a single code is applied to the entire image. Recently, the bilateral grid was introduced to perform pixel-wise color mapping, but it is difficult to optimize and constrain effectively. In this paper, we propose a novel multi-scale bilateral grid that unifies appearance codes and bilateral grids. We demonstrate that this approach significantly improves geometric accuracy in dynamic, decoupled autonomous driving scene reconstruction, outperforming both appearance codes and bilateral grids. This is crucial for autonomous driving, where accurate geometry is important for obstacle avoidance and control. Our method shows strong results across four datasets: Waymo, NuScenes, Argoverse, and PandaSet. We further demonstrate that the improvement in geometry is driven by the multi-scale bilateral grid, which effectively reduces floaters caused by photometric inconsistency.",
    "authors": [
      "Nan Wang, Yuantao Chen, Lixing Xiao, Weiqing Xiao, Bohan Li, Zhaoxi Chen, Chongjie Ye, Shaocong Xu, Saining Zhang, Ziyang Yan, Pierre Merriaux, Lei Lei, Tianfan Xue, Hao Zhao"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.841745"
  },
  {
    "id": "oai:arXiv.org:2506.05333v2",
    "journal": "arXiv_CS",
    "title": "Kinetics: Rethinking Test-Time Scaling Laws",
    "link": "https://arxiv.org/abs/2506.05333",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05333v2 Announce Type: replace \nAbstract: We rethink test-time scaling laws from a practical efficiency perspective, revealing that the effectiveness of smaller models is significantly overestimated. Prior work, grounded in compute-optimality, overlooks critical memory access bottlenecks introduced by inference-time strategies (e.g., Best-of-$N$, long CoTs). Our holistic analysis, spanning models from 0.6B to 32B parameters, reveals a new Kinetics Scaling Law that better guides resource allocation by incorporating both computation and memory access costs. Kinetics Scaling Law suggests that test-time compute is more effective when used on models above a threshold than smaller ones. A key reason is that in TTS, attention, rather than parameter count, emerges as the dominant cost factor. Motivated by this, we propose a new scaling paradigm centered on sparse attention, which lowers per-token cost and enables longer generations and more parallel samples within the same resource budget. Empirically, we show that sparse attention models consistently outperform dense counterparts, achieving over 60 points gains in low-cost regimes and over 5 points gains in high-cost regimes for problem-solving accuracy on AIME, encompassing evaluations on state-of-the-art MoEs. These results suggest that sparse attention is essential and increasingly important with more computing invested, for realizing the full potential of test-time scaling where, unlike training, accuracy has yet to saturate as a function of computation, and continues to improve through increased generation. The code is available at https://github.com/Infini-AI-Lab/Kinetics.",
    "authors": [
      "Ranajoy Sadhukhan, Zhuoming Chen, Haizhong Zheng, Yang Zhou, Emma Strubell, Beidi Chen"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.841761"
  },
  {
    "id": "oai:arXiv.org:2506.05338v2",
    "journal": "arXiv_CS",
    "title": "Defurnishing with X-Ray Vision: Joint Removal of Furniture from Panoramas and Mesh",
    "link": "https://arxiv.org/abs/2506.05338",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05338v2 Announce Type: replace \nAbstract: We present a pipeline for generating defurnished replicas of indoor spaces represented as textured meshes and corresponding multi-view panoramic images. To achieve this, we first segment and remove furniture from the mesh representation, extend planes, and fill holes, obtaining a simplified defurnished mesh (SDM). This SDM acts as an ``X-ray'' of the scene's underlying structure, guiding the defurnishing process. We extract Canny edges from depth and normal images rendered from the SDM. We then use these as a guide to remove the furniture from panorama images via ControlNet inpainting. This control signal ensures the availability of global geometric information that may be hidden from a particular panoramic view by the furniture being removed. The inpainted panoramas are used to texture the mesh. We show that our approach produces higher quality assets than methods that rely on neural radiance fields, which tend to produce blurry low-resolution images, or RGB-D inpainting, which is highly susceptible to hallucinations.",
    "authors": [
      "Alan Dolhasz, Chen Ma, Dave Gausebeck, Kevin Chen, Gregor Miller, Lucas Hayne, Gunnar Hovden, Azwad Sabik, Olaf Brandt, Mira Slavcheva"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.841769"
  },
  {
    "id": "oai:arXiv.org:2506.05340v2",
    "journal": "arXiv_CS",
    "title": "Exploring Diffusion Transformer Designs via Grafting",
    "link": "https://arxiv.org/abs/2506.05340",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05340v2 Announce Type: replace \nAbstract: Designing model architectures requires decisions such as selecting operators (e.g., attention, convolution) and configurations (e.g., depth, width). However, evaluating the impact of these decisions on model quality requires costly pretraining, limiting architectural investigation. Inspired by how new software is built on existing code, we ask: can new architecture designs be studied using pretrained models? To this end, we present grafting, a simple approach for editing pretrained diffusion transformers (DiTs) to materialize new architectures under small compute budgets. Informed by our analysis of activation behavior and attention locality, we construct a testbed based on the DiT-XL/2 design to study the impact of grafting on model quality. Using this testbed, we develop a family of hybrid designs via grafting: replacing softmax attention with gated convolution, local attention, and linear attention, and replacing MLPs with variable expansion ratio and convolutional variants. Notably, many hybrid designs achieve good quality (FID: 2.38-2.64 vs. 2.27 for DiT-XL/2) using <2% pretraining compute. We then graft a text-to-image model (PixArt-Sigma), achieving a 1.43x speedup with less than a 2% drop in GenEval score. Finally, we present a case study that restructures DiT-XL/2 by converting every pair of sequential transformer blocks into parallel blocks via grafting. This reduces model depth by 2x and yields better quality (FID: 2.77) than other models of comparable depth. Together, we show that new diffusion model designs can be explored by grafting pretrained DiTs, with edits ranging from operator replacement to architecture restructuring. Code and grafted models: https://grafting.stanford.edu",
    "authors": [
      "Keshigeyan Chandrasegaran, Michael Poli, Daniel Y. Fu, Dongjun Kim, Lea M. Hadzic, Manling Li, Agrim Gupta, Stefano Massaroli, Azalia Mirhoseini, Juan Carlos Niebles, Stefano Ermon, Li Fei-Fei"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.841777"
  },
  {
    "id": "oai:arXiv.org:2506.05348v2",
    "journal": "arXiv_CS",
    "title": "FreeTimeGS: Free Gaussian Primitives at Anytime and Anywhere for Dynamic Scene Reconstruction",
    "link": "https://arxiv.org/abs/2506.05348",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05348v2 Announce Type: replace \nAbstract: This paper addresses the challenge of reconstructing dynamic 3D scenes with complex motions. Some recent works define 3D Gaussian primitives in the canonical space and use deformation fields to map canonical primitives to observation spaces, achieving real-time dynamic view synthesis. However, these methods often struggle to handle scenes with complex motions due to the difficulty of optimizing deformation fields. To overcome this problem, we propose FreeTimeGS, a novel 4D representation that allows Gaussian primitives to appear at arbitrary time and locations. In contrast to canonical Gaussian primitives, our representation possesses the strong flexibility, thus improving the ability to model dynamic 3D scenes. In addition, we endow each Gaussian primitive with an motion function, allowing it to move to neighboring regions over time, which reduces the temporal redundancy. Experiments results on several datasets show that the rendering quality of our method outperforms recent methods by a large margin. Project page: https://zju3dv.github.io/freetimegs/ .",
    "authors": [
      "Yifan Wang, Peishan Yang, Zhen Xu, Jiaming Sun, Zhanhua Zhang, Yong Chen, Hujun Bao, Sida Peng, Xiaowei Zhou"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.841786"
  },
  {
    "id": "oai:arXiv.org:2103.01189v3",
    "journal": "arXiv_CS",
    "title": "Learners' Languages",
    "link": "https://arxiv.org/abs/2103.01189",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2103.01189v3 Announce Type: replace-cross \nAbstract: In \"Backprop as functor\", the authors show that the fundamental elements of deep learning -- gradient descent and backpropagation -- can be conceptualized as a strong monoidal functor Para(Euc)$\\to$Learn from the category of parameterized Euclidean spaces to that of learners, a category developed explicitly to capture parameter update and backpropagation. It was soon realized that there is an isomorphism Learn$\\cong$Para(Slens), where Slens is the symmetric monoidal category of simple lenses as used in functional programming.\n  In this note, we observe that Slens is a full subcategory of Poly, the category of polynomial functors in one variable, via the functor $A\\mapsto Ay^A$. Using the fact that (Poly,$\\otimes$) is monoidal closed, we show that a map $A\\to B$ in Para(Slens) has a natural interpretation in terms of dynamical systems (more precisely, generalized Moore machines) whose interface is the internal-hom type $[Ay^A,By^B]$.\n  Finally, we review the fact that the category p-Coalg of dynamical systems on any $p \\in$ Poly forms a topos, and consider the logical propositions that can be stated in its internal language. We give gradient descent as an example, and we conclude by discussing some directions for future work.",
    "authors": [
      "David I. Spivak (Topos Institute)"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.841795"
  },
  {
    "id": "oai:arXiv.org:2212.12097v3",
    "journal": "arXiv_CS",
    "title": "Tightening Quadratic Convex Relaxations for the AC Optimal Transmission Switching Problem",
    "link": "https://arxiv.org/abs/2212.12097",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2212.12097v3 Announce Type: replace-cross \nAbstract: The Alternating Current Optimal Transmission Switching (ACOTS) problem incorporates line switching decisions into the AC Optimal Power Flow (ACOPF) framework, offering well-known benefits in reducing operational costs and enhancing system reliability. ACOTS optimization models contain discrete variables and nonlinear, non-convex constraints, which make it difficult to solve. In this work, we develop strengthened quadratic convex (QC) relaxations for ACOTS, where we tighten the relaxation with several new valid inequalities, including a novel kind of on/off cycle-based polynomial constraints by taking advantage of the network structure. We linearize the sum of on/off trilinear terms in the relaxation using extreme-point representation, demonstrating theoretical tightness, and efficiently incorporate on/off cycle-based polynomial constraints through disjunctive programming-based cutting planes. Combined with an optimization-based bound tightening algorithm, this results in the tightest QC-based ACOTS relaxation to date. We additionally propose a novel maximum spanning tree-based heuristic to improve the computational performance by fixing certain lines to be switched on. Our extensive numerical experiments on medium-scale PGLib instances show significant improvements on relaxation bounds, while tests on large-scale instances with up to 2,312 buses demonstrate substantial performance gains. To our knowledge, this is the first ACOTS relaxation-based approach to demonstrate near-optimal switching solutions on realistic large-scale power grid instances.",
    "authors": [
      "Cheng Guo, Harsha Nagarajan, Merve Bodur"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.841804"
  },
  {
    "id": "oai:arXiv.org:2302.10130v3",
    "journal": "arXiv_CS",
    "title": "Infinite-Dimensional Diffusion Models",
    "link": "https://arxiv.org/abs/2302.10130",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2302.10130v3 Announce Type: replace-cross \nAbstract: Diffusion models have had a profound impact on many application areas, including those where data are intrinsically infinite-dimensional, such as images or time series. The standard approach is first to discretize and then to apply diffusion models to the discretized data. While such approaches are practically appealing, the performance of the resulting algorithms typically deteriorates as discretization parameters are refined. In this paper, we instead directly formulate diffusion-based generative models in infinite dimensions and apply them to the generative modelling of functions. We prove that our formulations are well posed in the infinite-dimensional setting and provide dimension-independent distance bounds from the sample to the target measure. Using our theory, we also develop guidelines for the design of infinite-dimensional diffusion models. For image distributions, these guidelines are in line with current canonical choices. For other distributions, however, we can improve upon these canonical choices. We demonstrate these results both theoretically and empirically, by applying the algorithms to data distributions on manifolds and to distributions arising in Bayesian inverse problems or simulation-based inference.",
    "authors": [
      "Jakiw Pidstrigach, Youssef Marzouk, Sebastian Reich, Sven Wang"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.841812"
  },
  {
    "id": "oai:arXiv.org:2307.14012v3",
    "journal": "arXiv_CS",
    "title": "MCMC-Correction of Score-Based Diffusion Models for Model Composition",
    "link": "https://arxiv.org/abs/2307.14012",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2307.14012v3 Announce Type: replace-cross \nAbstract: Diffusion models can be parameterized in terms of either a score or an energy function. The energy parameterization is attractive as it enables sampling procedures such as Markov Chain Monte Carlo (MCMC) that incorporates a Metropolis-Hastings (MH) correction step based on energy differences between proposed samples. Such corrections can significantly improve sampling quality, particularly in the context of model composition, where pre-trained models are combined to generate samples from novel distributions. Score-based diffusion models, on the other hand, are more widely adopted and come with a rich ecosystem of pre-trained models. However, they do not, in general, define an underlying energy function, making MH-based sampling inapplicable. In this work, we address this limitation by retaining the score parameterization and introducing a novel MH-like acceptance rule based on line integration of the score function. This allows the reuse of existing diffusion models while still combining the reverse process with various MCMC techniques, viewed as an instance of annealed MCMC. Through experiments on synthetic and real-world data, we show that our MH-like samplers offer comparable improvements to those obtained with energy-based models, without requiring explicit energy parameterization.",
    "authors": [
      "Anders Sj\\\"oberg, Jakob Lindqvist, Magnus \\\"Onnheim, Mats Jirstrand, Lennart Svensson"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.841821"
  },
  {
    "id": "oai:arXiv.org:2309.00902v2",
    "journal": "arXiv_CS",
    "title": "Characterising 4-tangles through a connectivity property",
    "link": "https://arxiv.org/abs/2309.00902",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2309.00902v2 Announce Type: replace-cross \nAbstract: Every large $k$-connected graph-minor induces a $k$-tangle in its ambient graph. The converse holds for $k\\le 3$, but fails for $k\\ge 4$. This raises the question whether `$k$-connected' can be relaxed to obtain a characterisation of $k$-tangles through highly cohesive graph-minors. We show that this can be achieved for $k=4$ by proving that internally 4-connected graphs have unique 4-tangles, and that every graph with a 4-tangle $\\tau$ has an internally 4-connected minor whose unique 4-tangle lifts to $\\tau$.",
    "authors": [
      "Johannes Carmesin, Jan Kurkofka"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.841829"
  },
  {
    "id": "oai:arXiv.org:2310.02951v3",
    "journal": "arXiv_CS",
    "title": "A Fisher-Rao gradient flow for entropy-regularised Markov decision processes in Polish spaces",
    "link": "https://arxiv.org/abs/2310.02951",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2310.02951v3 Announce Type: replace-cross \nAbstract: We study the global convergence of a Fisher-Rao policy gradient flow for infinite-horizon entropy-regularised Markov decision processes with Polish state and action space. The flow is a continuous-time analogue of a policy mirror descent method. We establish the global well-posedness of the gradient flow and demonstrate its exponential convergence to the optimal policy. Moreover, we prove the flow is stable with respect to gradient evaluation, offering insights into the performance of a natural policy gradient flow with log-linear policy parameterisation. To overcome challenges stemming from the lack of the convexity of the objective function and the discontinuity arising from the entropy regulariser, we leverage the performance difference lemma and the duality relationship between the gradient and mirror descent flows. Our analysis provides a theoretical foundation for developing various discrete policy gradient algorithms.",
    "authors": [
      "Bekzhan Kerimkulov, James-Michael Leahy, David Siska, Lukasz Szpruch, Yufei Zhang"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.841838"
  },
  {
    "id": "oai:arXiv.org:2402.03819v5",
    "journal": "arXiv_CS",
    "title": "Do we need rebalancing strategies? A theoretical and empirical study around SMOTE and its variants",
    "link": "https://arxiv.org/abs/2402.03819",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2402.03819v5 Announce Type: replace-cross \nAbstract: Synthetic Minority Oversampling Technique (SMOTE) is a common rebalancing strategy for handling imbalanced tabular data sets. However, few works analyze SMOTE theoretically. In this paper, we derive several non-asymptotic upper bound on SMOTE density. From these results, we prove that SMOTE (with default parameter) tends to copy the original minority samples asymptotically. We confirm and illustrate empirically this first theoretical behavior on a real-world data-set.bFurthermore, we prove that SMOTE density vanishes near the boundary of the support of the minority class distribution. We then adapt SMOTE based on our theoretical findings to introduce two new variants. These strategies are compared on 13 tabular data sets with 10 state-of-the-art rebalancing procedures, including deep generative and diffusion models. One of our key findings is that, for most data sets, applying no rebalancing strategy is competitive in terms of predictive performances, would it be with LightGBM, tuned random forests or logistic regression. However, when the imbalance ratio is artificially augmented, one of our two modifications of SMOTE leads to promising predictive performances compared to SMOTE and other state-of-the-art strategies.",
    "authors": [
      "Abdoulaye Sakho (LPSM), Emmanuel Malherbe (LPSM), Erwan Scornet (LPSM)"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.841855"
  },
  {
    "id": "oai:arXiv.org:2403.03455v2",
    "journal": "arXiv_CS",
    "title": "Robust Control Lyapunov-Value Functions for Nonlinear Disturbed Systems",
    "link": "https://arxiv.org/abs/2403.03455",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2403.03455v2 Announce Type: replace-cross \nAbstract: Control Lyapunov Functions (CLFs) have been extensively used in the control community. A well-known drawback is the absence of a systematic way to construct CLFs for general nonlinear systems, and the problem can become more complex with input or state constraints. Our preliminary work on constructing Control Lyapunov Value Functions (CLVFs) using Hamilton-Jacobi (HJ) reachability analysis provides a method for finding a non-smooth CLF. In this paper, we extend our work on CLVFs to systems with bounded disturbance and define the Robust CLVF (R-CLVF). The R-CLVF naturally inherits all properties of the CLVF; i.e., it first identifies the \"smallest robust control invariant set (SRCIS)\" and stabilizes the system to it with a user-specified exponential rate. The region from which the exponential rate can be met is called the \"region of exponential stabilizability (ROES).\" We provide clearer definitions of the SRCIS and more rigorous proofs of several important theorems. Since the computation of the R-CLVF suffers from the \"curse of dimensionality,\" we also provide two techniques (warmstart and system decomposition) that solve it, along with necessary proofs. Three numerical examples are provided, validating our definition of SRCIS, illustrating the trade-off between a faster decay rate and a smaller ROES, and demonstrating the efficiency of computation using warmstart and decomposition.",
    "authors": [
      "Zheng Gong, Sylvia Herbert"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.841871"
  },
  {
    "id": "oai:arXiv.org:2404.04399v2",
    "journal": "arXiv_CS",
    "title": "Longitudinal Targeted Minimum Loss-based Estimation with Temporal-Difference Heterogeneous Transformer",
    "link": "https://arxiv.org/abs/2404.04399",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2404.04399v2 Announce Type: replace-cross \nAbstract: We propose Deep Longitudinal Targeted Minimum Loss-based Estimation (Deep LTMLE), a novel approach to estimate the counterfactual mean of outcome under dynamic treatment policies in longitudinal problem settings. Our approach utilizes a transformer architecture with heterogeneous type embedding trained using temporal-difference learning. After obtaining an initial estimate using the transformer, following the targeted minimum loss-based likelihood estimation (TMLE) framework, we statistically corrected for the bias commonly associated with machine learning algorithms. Furthermore, our method also facilitates statistical inference by enabling the provision of 95% confidence intervals grounded in asymptotic statistical theory. Simulation results demonstrate our method's superior performance over existing approaches, particularly in complex, long time-horizon scenarios. It remains effective in small-sample, short-duration contexts, matching the performance of asymptotically efficient estimators. To demonstrate our method in practice, we applied our method to estimate counterfactual mean outcomes for standard versus intensive blood pressure management strategies in a real-world cardiovascular epidemiology cohort study.",
    "authors": [
      "Toru Shirakawa, Yi Li, Yulun Wu, Sky Qiu, Yuxuan Li, Mingduo Zhao, Hiroyasu Iso, Mark van der Laan"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.841881"
  },
  {
    "id": "oai:arXiv.org:2405.16339v2",
    "journal": "arXiv_CS",
    "title": "BOLD: Boolean Logic Deep Learning",
    "link": "https://arxiv.org/abs/2405.16339",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2405.16339v2 Announce Type: replace-cross \nAbstract: Deep learning is computationally intensive, with significant efforts focused on reducing arithmetic complexity, particularly regarding energy consumption dominated by data movement. While existing literature emphasizes inference, training is considerably more resource-intensive. This paper proposes a novel mathematical principle by introducing the notion of Boolean variation such that neurons made of Boolean weights and inputs can be trained -- for the first time -- efficiently in Boolean domain using Boolean logic instead of gradient descent and real arithmetic. We explore its convergence, conduct extensively experimental benchmarking, and provide consistent complexity evaluation by considering chip architecture, memory hierarchy, dataflow, and arithmetic precision. Our approach achieves baseline full-precision accuracy in ImageNet classification and surpasses state-of-the-art results in semantic segmentation, with notable performance in image super-resolution, and natural language understanding with transformer-based models. Moreover, it significantly reduces energy consumption during both training and inference.",
    "authors": [
      "Van Minh Nguyen, Cristian Ocampo, Aymen Askri, Louis Leconte, Ba-Hien Tran"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.841889"
  },
  {
    "id": "oai:arXiv.org:2406.04592v3",
    "journal": "arXiv_CS",
    "title": "Provable Complexity Improvement of AdaGrad over SGD: Upper and Lower Bounds in Stochastic Non-Convex Optimization",
    "link": "https://arxiv.org/abs/2406.04592",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2406.04592v3 Announce Type: replace-cross \nAbstract: Adaptive gradient methods, such as AdaGrad, are among the most successful optimization algorithms for neural network training. While these methods are known to achieve better dimensional dependence than stochastic gradient descent (SGD) for stochastic convex optimization under favorable geometry, the theoretical justification for their success in stochastic non-convex optimization remains elusive. In fact, under standard assumptions of Lipschitz gradients and bounded noise variance, it is known that SGD is worst-case optimal in terms of finding a near-stationary point with respect to the $l_2$-norm, making further improvements impossible. Motivated by this limitation, we introduce refined assumptions on the smoothness structure of the objective and the gradient noise variance, which better suit the coordinate-wise nature of adaptive gradient methods. Moreover, we adopt the $l_1$-norm of the gradient as the stationarity measure, as opposed to the standard $l_2$-norm, to align with the coordinate-wise analysis and obtain tighter convergence guarantees for AdaGrad. Under these new assumptions and the $l_1$-norm stationarity measure, we establish an upper bound on the convergence rate of AdaGrad and a corresponding lower bound for SGD. In particular, we identify non-convex settings in which the iteration complexity of AdaGrad is favorable over SGD and show that, for certain configurations of problem parameters, it outperforms SGD by a factor of $d$, where $d$ is the problem dimension. To the best of our knowledge, this is the first result to demonstrate a provable gain of adaptive gradient methods over SGD in a non-convex setting. We also present supporting lower bounds, including one specific to AdaGrad and one applicable to general deterministic first-order methods, showing that our upper bound for AdaGrad is tight and unimprovable up to a logarithmic factor under certain conditions.",
    "authors": [
      "Ruichen Jiang, Devyani Maladkar, Aryan Mokhtari"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.841898"
  },
  {
    "id": "oai:arXiv.org:2407.00680v2",
    "journal": "arXiv_CS",
    "title": "Did Turing prove the undecidability of the halting problem?",
    "link": "https://arxiv.org/abs/2407.00680",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2407.00680v2 Announce Type: replace-cross \nAbstract: We discuss the accuracy of the attribution commonly given to Turing's 1936 paper \"On computable numbers...\" for the computable undecidability of the halting problem, coming eventually to a nuanced conclusion.",
    "authors": [
      "Joel David Hamkins, Theodor Nenu"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.841907"
  },
  {
    "id": "oai:arXiv.org:2408.07588v3",
    "journal": "arXiv_CS",
    "title": "Adjusting Model Size in Continual Gaussian Processes: How Big is Big Enough?",
    "link": "https://arxiv.org/abs/2408.07588",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2408.07588v3 Announce Type: replace-cross \nAbstract: Many machine learning models require setting a parameter that controls their size before training, e.g. number of neurons in DNNs, or inducing points in GPs. Increasing capacity typically improves performance until all the information from the dataset is captured. After this point, computational cost keeps increasing, without improved performance. This leads to the question \"How big is big enough?\" We investigate this problem for Gaussian processes (single-layer neural networks) in continual learning. Here, data becomes available incrementally, and the final dataset size will therefore not be known before training, preventing the use of heuristics for setting a fixed model size. We develop a method to automatically adjust model size while maintaining near-optimal performance. Our experimental procedure follows the constraint that any hyperparameters must be set without seeing dataset properties, and we show that our method performs well across diverse datasets without the need to adjust its hyperparameter, showing it requires less tuning than others.",
    "authors": [
      "Guiomar Pescador-Barrios, Sarah Filippi, Mark van der Wilk"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.841915"
  },
  {
    "id": "oai:arXiv.org:2408.12063v2",
    "journal": "arXiv_CS",
    "title": "Deconfounding Multi-Cause Latent Confounders: A Factor-Model Approach to Climate Model Bias Correction",
    "link": "https://arxiv.org/abs/2408.12063",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2408.12063v2 Announce Type: replace-cross \nAbstract: Global Climate Models (GCMs) are crucial for predicting future climate changes by simulating the Earth systems. However, the GCM Outputs exhibit systematic biases due to model uncertainties, parameterization simplifications, and inadequate representation of complex climate phenomena. Traditional bias correction methods, which rely on historical observation data and statistical techniques, often neglect unobserved confounders, leading to biased results. This paper proposes a novel bias correction approach to utilize both GCM and observational data to learn a factor model that captures multi-cause latent confounders. Inspired by recent advances in causality based time series deconfounding, our method first constructs a factor model to learn latent confounders from historical data and then applies them to enhance the bias correction process using advanced time series forecasting models. The experimental results demonstrate significant improvements in the accuracy of precipitation outputs. By addressing unobserved confounders, our approach offers a robust and theoretically grounded solution for climate model bias correction.",
    "authors": [
      "Wentao Gao, Jiuyong Li, Debo Cheng, Lin Liu, Jixue Liu, Thuc Duy Le, Xiaojing Du, Xiongren Chen, Yanchang Zhao, Yun Chen"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.841924"
  },
  {
    "id": "oai:arXiv.org:2408.13276v3",
    "journal": "arXiv_CS",
    "title": "Non-convex matrix sensing: Breaking the quadratic rank barrier in the sample complexity",
    "link": "https://arxiv.org/abs/2408.13276",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2408.13276v3 Announce Type: replace-cross \nAbstract: For the problem of reconstructing a low-rank matrix from a few linear measurements, two classes of algorithms have been widely studied in the literature: convex approaches based on nuclear norm minimization, and non-convex approaches that use factorized gradient descent. Under certain statistical model assumptions, it is known that nuclear norm minimization recovers the ground truth as soon as the number of samples scales linearly with the number of degrees of freedom of the ground truth. In contrast, while non-convex approaches are computationally less expensive, existing recovery guarantees assume that the number of samples scales at least quadratically with the rank $r$ of the ground-truth matrix. In this paper, we close this gap by showing that the non-convex approaches can be as efficient as nuclear norm minimization in terms of sample complexity. Namely, we consider the problem of reconstructing a positive semidefinite matrix from a few Gaussian measurements. We show that factorized gradient descent with spectral initialization converges to the ground truth with a linear rate as soon as the number of samples scales with $ \\Omega (rd\\kappa^2)$, where $d$ is the dimension, and $\\kappa$ is the condition number of the ground truth matrix. This improves the previous rank-dependence in the sample complexity of non-convex matrix factorization from quadratic to linear. Our proof relies on a probabilistic decoupling argument, where we show that the gradient descent iterates are only weakly dependent on the individual entries of the measurement matrices. We expect that our proof technique is of independent interest for other non-convex problems.",
    "authors": [
      "Dominik St\\\"oger, Yizhe Zhu"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.841933"
  },
  {
    "id": "oai:arXiv.org:2410.13112v2",
    "journal": "arXiv_CS",
    "title": "Distributional Matrix Completion via Nearest Neighbors in the Wasserstein Space",
    "link": "https://arxiv.org/abs/2410.13112",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2410.13112v2 Announce Type: replace-cross \nAbstract: We study the problem of distributional matrix completion: Given a sparsely observed matrix of empirical distributions, we seek to impute the true distributions associated with both observed and unobserved matrix entries. This is a generalization of traditional matrix completion, where the observations per matrix entry are scalar-valued. To do so, we utilize tools from optimal transport to generalize the nearest neighbors method to the distributional setting. Under a suitable latent factor model on probability distributions, we establish that our method recovers the distributions in the Wasserstein metric. We demonstrate through simulations that our method (i) provides better distributional estimates for an entry compared to using observed samples for that entry alone, (ii) yields accurate estimates of distributional quantities such as standard deviation and value-at-risk, and (iii) inherently supports heteroscedastic distributions. In addition, we demonstrate our method on a real-world dataset of quarterly earnings prediction distributions. We also prove novel asymptotic results for Wasserstein barycenters over one-dimensional distributions.",
    "authors": [
      "Jacob Feitelberg, Kyuseong Choi, Anish Agarwal, Raaz Dwivedi"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.841942"
  },
  {
    "id": "oai:arXiv.org:2410.13681v2",
    "journal": "arXiv_CS",
    "title": "Ab Initio Nonparametric Variable Selection for Scalable Symbolic Regression with Large $p$",
    "link": "https://arxiv.org/abs/2410.13681",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2410.13681v2 Announce Type: replace-cross \nAbstract: Symbolic regression (SR) is a powerful technique for discovering symbolic expressions that characterize nonlinear relationships in data, gaining increasing attention for its interpretability, compactness, and robustness. However, existing SR methods do not scale to datasets with a large number of input variables (referred to as extreme-scale SR), which is common in modern scientific applications. This ``large $p$'' setting, often accompanied by measurement error, leads to slow performance of SR methods and overly complex expressions that are difficult to interpret. To address this scalability challenge, we propose a method called PAN+SR, which combines a key idea of ab initio nonparametric variable selection with SR to efficiently pre-screen large input spaces and reduce search complexity while maintaining accuracy. The use of nonparametric methods eliminates model misspecification, supporting a strategy called parametric-assisted nonparametric (PAN). We also extend SRBench, an open-source benchmarking platform, by incorporating high-dimensional regression problems with various signal-to-noise ratios. Our results demonstrate that PAN+SR consistently enhances the performance of 19 contemporary SR methods, enabling several to achieve state-of-the-art performance on these challenging datasets.",
    "authors": [
      "Shengbin Ye, Meng Li"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.841951"
  },
  {
    "id": "oai:arXiv.org:2411.01704v2",
    "journal": "arXiv_CS",
    "title": "Understanding the decision-making process of choice modellers",
    "link": "https://arxiv.org/abs/2411.01704",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2411.01704v2 Announce Type: replace-cross \nAbstract: Discrete Choice Modelling serves as a robust framework for modelling human choice behaviour across various disciplines. Building a choice model is a semi structured research process that involves a combination of a priori assumptions, behavioural theories, and statistical methods. This complex set of decisions, coupled with diverse workflows, can lead to substantial variability in model outcomes. To better understand these dynamics, we developed the Serious Choice Modelling Game, which simulates the real world modelling process and tracks modellers' decisions in real time using a stated preference dataset. Participants were asked to develop choice models to estimate Willingness to Pay values to inform policymakers about strategies for reducing noise pollution. The game recorded actions across multiple phases, including descriptive analysis, model specification, and outcome interpretation, allowing us to analyse both individual decisions and differences in modelling approaches. While our findings reveal a strong preference for using data visualisation tools in descriptive analysis, it also identifies gaps in missing values handling before model specification. We also found significant variation in the modelling approach, even when modellers were working with the same choice dataset. Despite the availability of more complex models, simpler models such as Multinomial Logit were often preferred, suggesting that modellers tend to avoid complexity when time and resources are limited. Participants who engaged in more comprehensive data exploration and iterative model comparison tended to achieve better model fit and parsimony, which demonstrate that the methodological choices made throughout the workflow have significant implications, particularly when modelling outcomes are used for policy formulation.",
    "authors": [
      "Gabriel Nova, Sander van Cranenburgh, Stephane Hess"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.841967"
  },
  {
    "id": "oai:arXiv.org:2411.02951v3",
    "journal": "arXiv_CS",
    "title": "LDPM: Towards undersampled MRI reconstruction with MR-VAE and Latent Diffusion Prior",
    "link": "https://arxiv.org/abs/2411.02951",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2411.02951v3 Announce Type: replace-cross \nAbstract: Diffusion models, as powerful generative models, have found a wide range of applications and shown great potential in solving image reconstruction problems. Some works attempted to solve MRI reconstruction with diffusion models, but these methods operate directly in pixel space, leading to higher computational costs for optimization and inference. Latent diffusion models, pre-trained on natural images with rich visual priors, are expected to solve the high computational cost problem in MRI reconstruction by operating in a lower-dimensional latent space. However, direct application to MRI reconstruction faces three key challenges: (1) absence of explicit control mechanisms for medical fidelity, (2) domain gap between natural images and MR physics, and (3) undefined data consistency in latent space. To address these challenges, a novel Latent Diffusion Prior-based undersampled MRI reconstruction (LDPM) method is proposed. Our LDPM framework addresses these challenges by: (1) a sketch-guided pipeline with a two-step reconstruction strategy, which balances perceptual quality and anatomical fidelity, (2) an MRI-optimized VAE (MR-VAE), which achieves an improvement of approximately 3.92 dB in PSNR for undersampled MRI reconstruction compared to that with SD-VAE \\cite{sd}, and (3) Dual-Stage Sampler, a modified version of spaced DDPM sampler, which enforces high-fidelity reconstruction in the latent space. Experiments on the fastMRI dataset\\cite{fastmri} demonstrate the state-of-the-art performance of the proposed method and its robustness across various scenarios. The effectiveness of each module is also verified through ablation experiments.",
    "authors": [
      "Xingjian Tang, Jingwei Guan, Linge Li, Ran Shi, Youmei Zhang, Mengye Lyu, Li Yan"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.841975"
  },
  {
    "id": "oai:arXiv.org:2411.05141v2",
    "journal": "arXiv_CS",
    "title": "Audiobox TTA-RAG: Improving Zero-Shot and Few-Shot Text-To-Audio with Retrieval-Augmented Generation",
    "link": "https://arxiv.org/abs/2411.05141",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2411.05141v2 Announce Type: replace-cross \nAbstract: This work focuses on improving Text-To-Audio (TTA) generation on zero-shot and few-shot settings (i.e. generating unseen or uncommon audio events). Inspired by the success of Retrieval-Augmented Generation (RAG) in Large Language Models, we propose Audiobox TTA-RAG, a novel retrieval-augmented TTA approach based on Audiobox, a flow-matching audio generation model. Unlike the vanilla Audiobox TTA solution that generates audio conditioned on text only, we extend the TTA process by augmenting the conditioning input with both text and retrieved audio samples. Our retrieval method does not require the external database to have labeled audio, offering more practical use cases. We show that the proposed model can effectively leverage the retrieved audio samples and significantly improve zero-shot and few-shot TTA performance, with large margins on multiple evaluation metrics, while maintaining the ability to generate semantically aligned audio for the in-domain setting.",
    "authors": [
      "Mu Yang, Bowen Shi, Matthew Le, Wei-Ning Hsu, Andros Tjandra"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.841984"
  },
  {
    "id": "oai:arXiv.org:2411.05771v4",
    "journal": "arXiv_CS",
    "title": "Sketched Equivariant Imaging Regularization and Deep Internal Learning for Inverse Problems",
    "link": "https://arxiv.org/abs/2411.05771",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2411.05771v4 Announce Type: replace-cross \nAbstract: Equivariant Imaging (EI) regularization has become the de-facto technique for unsupervised training of deep imaging networks, without any need of ground-truth data. Observing that the EI-based unsupervised training paradigm currently has significant computational redundancy leading to inefficiency in high-dimensional applications, we propose a sketched EI regularization which leverages the randomized sketching techniques for acceleration. We apply our sketched EI regularization to develop an accelerated deep internal learning framework, which can be efficiently applied for test-time network adaptation. Additionally, for network adaptation tasks, we propose a parameter-efficient approach to accelerate both EI and Sketched-EI via optimizing only the normalization layers. Our numerical study on X-ray CT and multicoil magnetic resonance image reconstruction tasks demonstrate that our approach can achieve significant computational acceleration over standard EI counterpart in single-input setting and network adaptation at test time.",
    "authors": [
      "Guixian Xu, Jinglai Li, Junqi Tang"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.841993"
  },
  {
    "id": "oai:arXiv.org:2412.14031v4",
    "journal": "arXiv_CS",
    "title": "A Riemannian Optimization Perspective of the Gauss-Newton Method for Feedforward Neural Networks",
    "link": "https://arxiv.org/abs/2412.14031",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2412.14031v4 Announce Type: replace-cross \nAbstract: We analyze the convergence of Gauss-Newton dynamics for training neural networks with smooth activation functions. In the underparameterized regime, the Gauss-Newton gradient flow induces a Riemannian gradient flow on a low-dimensional, smooth, embedded submanifold of the Euclidean output space. Using tools from Riemannian optimization, we prove \\emph{last-iterate} convergence of the Riemannian gradient flow to the optimal in-class predictor at an \\emph{exponential rate} that is independent of the conditioning of the Gram matrix, \\emph{without} requiring explicit regularization. We further characterize the critical impacts of the neural network scaling factor and the initialization on the convergence behavior. In the overparameterized regime, we show that the Levenberg-Marquardt dynamics with an appropriately chosen damping schedule yields fast convergence rate despite potentially ill-conditioned neural tangent kernel matrices, analogous to the underparameterized regime. These findings demonstrate the potential of Gauss-Newton methods for efficiently optimizing neural networks in the near-initialization regime, particularly in ill-conditioned problems where kernel and Gram matrices have small singular values.",
    "authors": [
      "Semih Cayci"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.842010"
  },
  {
    "id": "oai:arXiv.org:2503.08028v2",
    "journal": "arXiv_CS",
    "title": "Computational bottlenecks for denoising diffusions",
    "link": "https://arxiv.org/abs/2503.08028",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2503.08028v2 Announce Type: replace-cross \nAbstract: Denoising diffusions sample from a probability distribution $\\mu$ in $\\mathbb{R}^d$ by constructing a stochastic process $({\\hat{\\boldsymbol x}}_t:t\\ge 0)$ in $\\mathbb{R}^d$ such that ${\\hat{\\boldsymbol x}}_0$ is easy to sample, but the distribution of $\\hat{\\boldsymbol x}_T$ at large $T$ approximates $\\mu$. The drift ${\\boldsymbol m}:\\mathbb{R}^d\\times\\mathbb{R}\\to\\mathbb{R}^d$ of this diffusion process is learned my minimizing a score-matching objective.\n  Is every probability distribution $\\mu$, for which sampling is tractable, also amenable to sampling via diffusions? We provide evidence to the contrary by studying a probability distribution $\\mu$ for which sampling is easy, but the drift of the diffusion process is intractable -- under a popular conjecture on information-computation gaps in statistical estimation. We show that there exist drifts that are superpolynomially close to the optimum value (among polynomial time drifts) and yet yield samples with distribution that is very far from the target one.",
    "authors": [
      "Andrea Montanari, Viet Vu"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.842032"
  },
  {
    "id": "oai:arXiv.org:2503.10312v3",
    "journal": "arXiv_CS",
    "title": "An Ensemble-Based Two-Step Framework for Classification of Pap Smear Cell Images",
    "link": "https://arxiv.org/abs/2503.10312",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2503.10312v3 Announce Type: replace-cross \nAbstract: Early detection of cervical cancer is crucial for improving patient outcomes and reducing mortality by identifying precancerous lesions as soon as possible. As a result, the use of pap smear screening has significantly increased, leading to a growing demand for automated tools that can assist cytologists managing their rising workload. To address this, the Pap Smear Cell Classification Challenge (PS3C) has been organized in association with ISBI in 2025. This project aims to promote the development of automated tools for pap smear images classification. The analyzed images are grouped into four categories: healthy, unhealthy, both, and rubbish images which are considered as unsuitable for diagnosis. In this work, we propose a two-stage ensemble approach: first, a neural network determines whether an image is rubbish or not. If not, a second neural network classifies the image as containing a healthy cell, an unhealthy cell, or both.",
    "authors": [
      "Theo Di Piazza, Loic Boussel"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.842041"
  },
  {
    "id": "oai:arXiv.org:2503.12808v3",
    "journal": "arXiv_CS",
    "title": "Estimating stationary mass, frequency by frequency",
    "link": "https://arxiv.org/abs/2503.12808",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2503.12808v3 Announce Type: replace-cross \nAbstract: Suppose we observe a trajectory of length $n$ from an exponentially $\\alpha$-mixing stochastic process over a finite but potentially large state space. We consider the problem of estimating the probability mass placed by the stationary distribution of any such process on elements that occur with a certain frequency in the observed sequence. We estimate this vector of probabilities in total variation distance, showing universal consistency in $n$ and recovering known results for i.i.d. sequences as special cases. Our proposed methodology -- implementable in linear time -- carefully combines the plug-in (or empirical) estimator with a recently-proposed modification of the Good--Turing estimator called WingIt, which was originally developed for Markovian sequences. En route to controlling the error of our estimator, we develop new performance bounds on WingIt and the plug-in estimator for exponentially $\\alpha$-mixing stochastic processes. Importantly, the extensively used method of Poissonization can no longer be applied in our non i.i.d. setting, and so we develop complementary tools -- including concentration inequalities for a natural self-normalized statistic of mixing sequences -- that may prove independently useful in the design and analysis of estimators for related problems. Simulation studies corroborate our theoretical findings.",
    "authors": [
      "Milind Nakul, Vidya Muthukumar, Ashwin Pananjady"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.842050"
  },
  {
    "id": "oai:arXiv.org:2504.03461v2",
    "journal": "arXiv_CS",
    "title": "Conditioning Diffusions Using Malliavin Calculus",
    "link": "https://arxiv.org/abs/2504.03461",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2504.03461v2 Announce Type: replace-cross \nAbstract: In generative modelling and stochastic optimal control, a central computational task is to modify a reference diffusion process to maximise a given terminal-time reward. Most existing methods require this reward to be differentiable, using gradients to steer the diffusion towards favourable outcomes. However, in many practical settings, like diffusion bridges, the reward is singular, taking an infinite value if the target is hit and zero otherwise. We introduce a novel framework, based on Malliavin calculus and centred around a generalisation of the Tweedie score formula to nonlinear stochastic differential equations, that enables the development of methods robust to such singularities. This allows our approach to handle a broad range of applications, like diffusion bridges, or adding conditional controls to an already trained diffusion model. We demonstrate that our approach offers stable and reliable training, outperforming existing techniques. As a byproduct, we also introduce a novel score matching objective. Our loss functions are formulated such that they could readily be extended to manifold-valued and infinite dimensional diffusions.",
    "authors": [
      "Jakiw Pidstrigach, Elizabeth Baker, Carles Domingo-Enrich, George Deligiannidis, Nikolas N\\\"usken"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.842058"
  },
  {
    "id": "oai:arXiv.org:2504.18707v2",
    "journal": "arXiv_CS",
    "title": "The spectral map for weighted Cauchy matrices is an involution",
    "link": "https://arxiv.org/abs/2504.18707",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2504.18707v2 Announce Type: replace-cross \nAbstract: Let $N$ be a natural number. We consider weighted Cauchy matrices of the form \\[ \\mathcal{C}_{a,A}=\\left\\{\\frac{\\sqrt{A_j A_k}}{a_k+a_j}\\right\\}_{j,k=1}^N, \\] where $A_1,\\dots,A_N$ are positive real numbers and $a_1,\\dots,a_N$ are distinct positive real numbers, listed in increasing order. Let $b_1,\\dots,b_N$ be the eigenvalues of $\\mathcal{C}_{a,A}$, listed in increasing order. Let $B_k$ be positive real numbers such that $\\sqrt{B_k}$ is the Euclidean norm of the orthogonal projection of the vector \\[ v_A=(\\sqrt{A_1},\\dots,\\sqrt{A_N}) \\] onto the $k$'th eigenspace of $\\mathcal{C}_{a,A}$. We prove that the spectral map $(a,A)\\mapsto (b,B)$ is an involution and discuss simple properties of this map.",
    "authors": [
      "Alexander Pushnitski, Sergei Treil"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.842066"
  },
  {
    "id": "oai:arXiv.org:2504.19203v3",
    "journal": "arXiv_CS",
    "title": "Improving Generalization in MRI-Based Deep Learning Models for Total Knee Replacement Prediction",
    "link": "https://arxiv.org/abs/2504.19203",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2504.19203v3 Announce Type: replace-cross \nAbstract: Knee osteoarthritis (KOA) is a common joint disease that causes pain and mobility issues. While MRI-based deep learning models have demonstrated superior performance in predicting total knee replacement (TKR) and disease progression, their generalizability remains challenging, particularly when applied to imaging data from different sources. In this study, we have shown that replacing batch normalization with instance normalization, using data augmentation, and applying contrastive loss improves model generalization in a baseline deep learning model for knee osteoarthritis (KOA) prediction. We trained and evaluated our model using MRI data from the Osteoarthritis Initiative (OAI) database, considering sagittal fat-suppressed intermediate-weighted turbo spin-echo (FS-IW-TSE) images as the source domain and sagittal fat-suppressed three-dimensional (3D) dual-echo in steady state (DESS) images as the target domain. The results demonstrate a statistically significant improvement in classification accuracy across both domains, with our approach outperforming the baseline model.",
    "authors": [
      "Ehsan Karami, Hamid Soltanian-Zadeh"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.842102"
  },
  {
    "id": "oai:arXiv.org:2504.19596v2",
    "journal": "arXiv_CS",
    "title": "Towards Robust Multimodal Physiological Foundation Models: Handling Arbitrary Missing Modalities",
    "link": "https://arxiv.org/abs/2504.19596",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2504.19596v2 Announce Type: replace-cross \nAbstract: Multimodal physiological signals, such as EEG, ECG, EOG, and EMG, are crucial for healthcare and brain-computer interfaces. While existing methods rely on specialized architectures and dataset-specific fusion strategies, they struggle to learn universal representations that generalize across datasets and handle missing modalities at inference time. To address these issues, we propose PhysioOmni, a foundation model for multimodal physiological signal analysis that models both homogeneous and heterogeneous features to decouple multimodal signals and extract generic representations while maintaining compatibility with arbitrary missing modalities. PhysioOmni trains a decoupled multimodal tokenizer, enabling masked signal pre-training via modality-invariant and modality-specific objectives. To ensure adaptability to diverse and incomplete modality combinations, the pre-trained encoders undergo resilient fine-tuning with prototype alignment on downstream datasets. Extensive experiments on four downstream tasks, emotion recognition, sleep stage classification, motor prediction, and mental workload detection, demonstrate that PhysioOmni achieves state-of-the-art performance while maintaining strong robustness to missing modalities. Our code and model weights will be released.",
    "authors": [
      "Wei-Bang Jiang, Xi Fu, Yi Ding, Cuntai Guan"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.842111"
  },
  {
    "id": "oai:arXiv.org:2504.21419v2",
    "journal": "arXiv_CS",
    "title": "Kernel Density Machines",
    "link": "https://arxiv.org/abs/2504.21419",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2504.21419v2 Announce Type: replace-cross \nAbstract: We introduce kernel density machines (KDM), a nonparametric estimator of a Radon--Nikodym derivative, based on reproducing kernel Hilbert spaces. KDM applies to general probability measures on countably generated measurable spaces under minimal assumptions. For computational efficiency, we incorporate a low-rank approximation with precisely controlled error that grants scalability to large-sample settings. We provide rigorous theoretical guarantees, including asymptotic consistency, a functional central limit theorem, and finite-sample error bounds, establishing a strong foundation for practical use. Empirical results based on simulated and real data demonstrate the efficacy and precision of KDM.",
    "authors": [
      "Damir Filipovic, Paul Schneider"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.842119"
  },
  {
    "id": "oai:arXiv.org:2505.07244v2",
    "journal": "arXiv_CS",
    "title": "The Influence of the Memory Capacity of Neural DDEs on the Universal Approximation Property",
    "link": "https://arxiv.org/abs/2505.07244",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2505.07244v2 Announce Type: replace-cross \nAbstract: Neural Ordinary Differential Equations (Neural ODEs), which are the continuous-time analog of Residual Neural Networks (ResNets), have gained significant attention in recent years. Similarly, Neural Delay Differential Equations (Neural DDEs) can be interpreted as an infinite depth limit of Densely Connected Residual Neural Networks (DenseResNets). In contrast to traditional ResNet architectures, DenseResNets are feed-forward networks that allow for shortcut connections across all layers. These additional connections introduce memory in the network architecture, as typical in many modern architectures. In this work, we explore how the memory capacity in neural DDEs influences the universal approximation property. The key parameter for studying the memory capacity is the product $K \\tau$ of the Lipschitz constant and the delay of the DDE. In the case of non-augmented architectures, where the network width is not larger than the input and output dimensions, neural ODEs and classical feed-forward neural networks cannot have the universal approximation property. We show that if the memory capacity $K\\tau$ is sufficiently small, the dynamics of the neural DDE can be approximated by a neural ODE. Consequently, non-augmented neural DDEs with a small memory capacity also lack the universal approximation property. In contrast, if the memory capacity $K\\tau$ is sufficiently large, we can establish the universal approximation property of neural DDEs for continuous functions. If the neural DDE architecture is augmented, we can expand the parameter regions in which universal approximation is possible. Overall, our results show that by increasing the memory capacity $K\\tau$, the infinite-dimensional phase space of DDEs with positive delay $\\tau>0$ is not sufficient to guarantee a direct jump transition to universal approximation, but only after a certain memory threshold, universal approximation holds.",
    "authors": [
      "Christian Kuehn, Sara-Viola Kuntz"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.842129"
  },
  {
    "id": "oai:arXiv.org:2505.07449v4",
    "journal": "arXiv_CS",
    "title": "Ophora: A Large-Scale Data-Driven Text-Guided Ophthalmic Surgical Video Generation Model",
    "link": "https://arxiv.org/abs/2505.07449",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2505.07449v4 Announce Type: replace-cross \nAbstract: In ophthalmic surgery, developing an AI system capable of interpreting surgical videos and predicting subsequent operations requires numerous ophthalmic surgical videos with high-quality annotations, which are difficult to collect due to privacy concerns and labor consumption. Text-guided video generation (T2V) emerges as a promising solution to overcome this issue by generating ophthalmic surgical videos based on surgeon instructions. In this paper, we present Ophora, a pioneering model that can generate ophthalmic surgical videos following natural language instructions. To construct Ophora, we first propose a Comprehensive Data Curation pipeline to convert narrative ophthalmic surgical videos into a large-scale, high-quality dataset comprising over 160K video-instruction pairs, Ophora-160K. Then, we propose a Progressive Video-Instruction Tuning scheme to transfer rich spatial-temporal knowledge from a T2V model pre-trained on natural video-text datasets for privacy-preserved ophthalmic surgical video generation based on Ophora-160K. Experiments on video quality evaluation via quantitative analysis and ophthalmologist feedback demonstrate that Ophora can generate realistic and reliable ophthalmic surgical videos based on surgeon instructions. We also validate the capability of Ophora for empowering downstream tasks of ophthalmic surgical workflow understanding. Code is available at https://github.com/mar-cry/Ophora.",
    "authors": [
      "Wei Li, Ming Hu, Guoan Wang, Lihao Liu, Kaijin Zhou, Junzhi Ning, Xin Guo, Zongyuan Ge, Lixu Gu, Junjun He"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.842138"
  },
  {
    "id": "oai:arXiv.org:2505.18795v2",
    "journal": "arXiv_CS",
    "title": "Distributed Expectation Propagation for Multi-Object Tracking over Sensor Networks",
    "link": "https://arxiv.org/abs/2505.18795",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2505.18795v2 Announce Type: replace-cross \nAbstract: In this paper, we present a novel distributed expectation propagation algorithm for multiple sensors, multiple objects tracking in cluttered environments. The proposed framework enables each sensor to operate locally while collaboratively exchanging moment estimates with other sensors, thus eliminating the need to transmit all data to a central processing node. Specifically, we introduce a fast and parallelisable Rao-Blackwellised Gibbs sampling scheme to approximate the tilted distributions, which enhances the accuracy and efficiency of expectation propagation updates. Results demonstrate that the proposed algorithm improves both communication and inference efficiency for multi-object tracking tasks with dynamic sensor connectivity and varying clutter levels.",
    "authors": [
      "Qing Li, Runze Gan, James R. Hopgood, Michael E. Davies, Simon J. Godsill"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.842147"
  },
  {
    "id": "oai:arXiv.org:2505.21928v2",
    "journal": "arXiv_CS",
    "title": "Subspecialty-Specific Foundation Model for Intelligent Gastrointestinal Pathology",
    "link": "https://arxiv.org/abs/2505.21928",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2505.21928v2 Announce Type: replace-cross \nAbstract: Gastrointestinal (GI) diseases represent a clinically significant burden, necessitating precise diagnostic approaches to optimize patient outcomes. Conventional histopathological diagnosis suffers from limited reproducibility and diagnostic variability. To overcome these limitations, we develop Digepath, a specialized foundation model for GI pathology. Our framework introduces a dual-phase iterative optimization strategy combining pretraining with fine-screening, specifically designed to address the detection of sparsely distributed lesion areas in whole-slide images. Digepath is pretrained on over 353 million multi-scale images from 210,043 H&amp;E-stained slides of GI diseases. It attains state-of-the-art performance on 33 out of 34 tasks related to GI pathology, including pathological diagnosis, protein expression status prediction, gene mutation prediction, and prognosis evaluation. We further translate the intelligent screening module for early GI cancer and achieve near-perfect 99.70% sensitivity across nine independent medical institutions. This work not only advances AI-driven precision pathology for GI diseases but also bridge critical gaps in histopathological practice.",
    "authors": [
      "Lianghui Zhu, Xitong Ling, Minxi Ouyang, Xiaoping Liu, Tian Guan, Mingxi Fu, Zhiqiang Cheng, Fanglei Fu, Maomao Zeng, Liming Liu, Song Duan, Qiang Huang, Ying Xiao, Jianming Li, Shanming Lu, Zhenghua Piao, Mingxi Zhu, Yibo Jin, Shan Xu, Qiming He, Yizhi Wang, Junru Cheng, Xuanyu Wang, Luxi Xie, Houqiang Li, Sufang Tian, Yonghong He"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.842155"
  },
  {
    "id": "oai:arXiv.org:2505.24429v2",
    "journal": "arXiv_CS",
    "title": "Deep Learning Weather Models for Subregional Ocean Forecasting: A Case Study on the Canary Current Upwelling System",
    "link": "https://arxiv.org/abs/2505.24429",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2505.24429v2 Announce Type: replace-cross \nAbstract: Oceanographic forecasting impacts various sectors of society by supporting environmental conservation and economic activities. Based on global circulation models, traditional forecasting methods are computationally expensive and slow, limiting their ability to provide rapid forecasts. Recent advances in deep learning offer faster and more accurate predictions, although these data-driven models are often trained with global data from numerical simulations, which may not reflect reality. The emergence of such models presents great potential for improving ocean prediction at a subregional domain. However, their ability to predict fine-scale ocean processes, like mesoscale structures, remains largely unknown. This work aims to adapt a graph neural network initially developed for global weather forecasting to improve subregional ocean prediction, specifically focusing on the Canary Current upwelling system. The model is trained with satellite data and compared to state-of-the-art physical ocean models to assess its performance in capturing ocean dynamics. Our results show that the deep learning model surpasses traditional methods in precision despite some challenges in upwelling areas. It demonstrated superior performance in reducing RMSE errors compared to ConvLSTM and the GLORYS reanalysis, particularly in regions with complex oceanic dynamics such as Cape Ghir, Cape Bojador, and Cape Blanc. The model achieved improvements of up to 26.5% relative to ConvLSTM and error reductions of up to 76% in 5-day forecasts compared to the GLORYS reanalysis at these critical locations, highlighting its enhanced capability to capture spatial variability and improve predictive accuracy in complex areas. These findings suggest the viability of adapting meteorological data-driven models for improving subregional medium-term ocean forecasting.",
    "authors": [
      "Giovanny A. Cuervo-Londo\\~no, Javier S\\'anchez, \\'Angel Rodr\\'iguez-Santana"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.842171"
  },
  {
    "id": "oai:arXiv.org:2506.00506v2",
    "journal": "arXiv_CS",
    "title": "Quality Assessment of Noisy and Enhanced Speech with Limited Data: UWB-NTIS System for VoiceMOS 2024 and Beyond",
    "link": "https://arxiv.org/abs/2506.00506",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.00506v2 Announce Type: replace-cross \nAbstract: In this preprint, we present the UWB-NTIS-TTS team's submission to Track 3 of the VoiceMOS 2024 Challenge, the goal of which was to automatically assess the speech quality of noisy and de-noised speech in terms of the ITU-T P.835 metrics of \"SIG\", \"BAK\", and \"OVRL\". Our proposed system, based on wav2vec 2.0, placed among the top systems in the challenge, achieving the best prediction of the BAK scores (background noise intrusiveness), the second-best prediction of the OVRL score (overall audio quality), and the third-best prediction of SIG (speech signal quality) out of the five participating systems. We describe our approach, such as the two-stage fine-tuning process we used to contend with the challenge's very limiting restrictions on allowable training data, and present the results achieved both on the VoiceMOS 2024 Challenge data and on the recently released CHiME 7 - UDASE dataset.",
    "authors": [
      "Marie Kune\\v{s}ov\\'a"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.842180"
  },
  {
    "id": "oai:arXiv.org:2506.03471v2",
    "journal": "arXiv_CS",
    "title": "GP-Recipe: Gaussian Process approximation to linear operations in numerical methods",
    "link": "https://arxiv.org/abs/2506.03471",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.03471v2 Announce Type: replace-cross \nAbstract: We introduce new Gaussian Process (GP) high-order approximations to linear operations that are frequently used in various numerical methods. Our method employs the kernel-based GP regression modeling, a non-parametric Bayesian approach to regression that operates on the probability distribution over all admissible functions that fit observed data. We begin in the first part with discrete data approximations to various linear operators applied to smooth data using the most popular squared exponential kernel function. In the second part, we discuss data interpolation across discontinuities with sharp gradients, for which we introduce a new GP kernel that fits discontinuous data without oscillations. The current study extends our previous GP work on polynomial-free shock-capturing methods in finite difference and finite volume methods to a suite of linear operator approximations on smooth data. The formulations introduced in this paper can be readily adopted in daily practices in numerical methods, including numerical approximations of finite differences, quadrature rules, interpolations, and reconstructions, which are most frequently used in numerical modeling in modern science and engineering applications. In the test problems, we demonstrate that the GP approximated solutions feature improved solution accuracy compared to the conventional finite-difference counterparts.",
    "authors": [
      "Christopher DeGrendele, Dongwook Lee"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.842190"
  },
  {
    "id": "oai:arXiv.org:2506.05202v2",
    "journal": "arXiv_CS",
    "title": "Causal Effect Identification in lvLiNGAM from Higher-Order Cumulants",
    "link": "https://arxiv.org/abs/2506.05202",
    "published": "Mon, 09 Jun 2025 00:00:00 -0400",
    "summary": "arXiv:2506.05202v2 Announce Type: replace-cross \nAbstract: This paper investigates causal effect identification in latent variable Linear Non-Gaussian Acyclic Models (lvLiNGAM) using higher-order cumulants, addressing two prominent setups that are challenging in the presence of latent confounding: (1) a single proxy variable that may causally influence the treatment and (2) underspecified instrumental variable cases where fewer instruments exist than treatments. We prove that causal effects are identifiable with a single proxy or instrument and provide corresponding estimation methods. Experimental results demonstrate the accuracy and robustness of our approaches compared to existing methods, advancing the theoretical and practical understanding of causal inference in linear systems with latent confounders.",
    "authors": [
      "Daniele Tramontano, Yaroslav Kivva, Saber Salehkaleybar, Mathias Drton, Negar Kiyavash"
    ],
    "doi": "",
    "parser_type": "arxiv",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.842213"
  },
  {
    "id": "https://www.nature.com/articles/s41598-025-94881-7",
    "journal": "Nature_SystemsBiology",
    "title": "Modelling the effects of virus-resistant planting material on the transmission dynamics of banana bunchy top disease",
    "link": "https://www.nature.com/articles/s41598-025-94881-7",
    "published": "2025-06-06T00:00:00+00:00",
    "summary": "",
    "authors": [
      "John J. Mapinda et al."
    ],
    "doi": "",
    "parser_type": "nature",
    "feed_priority": "high",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.842238"
  },
  {
    "id": "https://www.nature.com/articles/s42256-025-01047-1",
    "journal": "Nature_SystemsBiology",
    "title": "A multimodal conversational agent for DNA, RNA and protein tasks",
    "link": "https://www.nature.com/articles/s42256-025-01047-1",
    "published": "2025-06-06T00:00:00+00:00",
    "summary": "",
    "authors": [
      "Bernardo P. de Almeida et al."
    ],
    "doi": "",
    "parser_type": "nature",
    "feed_priority": "high",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.842246"
  },
  {
    "id": "https://www.nature.com/articles/s41598-025-05030-z",
    "journal": "Nature_SystemsBiology",
    "title": "Genomic and metabolic network properties in thermophiles and psychrophiles compared to mesophiles",
    "link": "https://www.nature.com/articles/s41598-025-05030-z",
    "published": "2025-06-05T00:00:00+00:00",
    "summary": "",
    "authors": [
      "Amal Saeed Alblooshi et al."
    ],
    "doi": "",
    "parser_type": "nature",
    "feed_priority": "high",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.842255"
  },
  {
    "id": "https://www.nature.com/articles/s41467-025-60578-8",
    "journal": "Nature_SystemsBiology",
    "title": "Sucrose-driven carbon redox rebalancing eliminates the Crabtree effect and boosts energy metabolism in yeast",
    "link": "https://www.nature.com/articles/s41467-025-60578-8",
    "published": "2025-06-05T00:00:00+00:00",
    "summary": "",
    "authors": [
      "Zhiqiang Xiao et al."
    ],
    "doi": "",
    "parser_type": "nature",
    "feed_priority": "high",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.842264"
  },
  {
    "id": "https://www.nature.com/articles/s41591-025-03719-2",
    "journal": "Nature_SystemsBiology",
    "title": "Individual variations in glycemic responses to carbohydrates and underlying metabolic physiology",
    "link": "https://www.nature.com/articles/s41591-025-03719-2",
    "published": "2025-06-04T00:00:00+00:00",
    "summary": "",
    "authors": [
      "Yue Wu et al."
    ],
    "doi": "",
    "parser_type": "nature",
    "feed_priority": "high",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.842281"
  },
  {
    "id": "https://www.nature.com/articles/s41589-025-01930-3",
    "journal": "Nature_SystemsBiology",
    "title": "A consortium to synthesize lignans",
    "link": "https://www.nature.com/articles/s41589-025-01930-3",
    "published": "2025-06-03T00:00:00+00:00",
    "summary": "",
    "authors": [
      "Nicolas Gautron et al."
    ],
    "doi": "",
    "parser_type": "nature",
    "feed_priority": "high",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.842289"
  },
  {
    "id": "https://www.nature.com/articles/s42003-025-08043-6",
    "journal": "Nature_SystemsBiology",
    "title": "Palaeo-bioinspiration draws on the fossil record to advance innovation",
    "link": "https://www.nature.com/articles/s42003-025-08043-6",
    "published": "2025-06-02T00:00:00+00:00",
    "summary": "",
    "authors": [
      "Annabelle Aish et al."
    ],
    "doi": "",
    "parser_type": "nature",
    "feed_priority": "high",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.842298"
  },
  {
    "id": "https://www.nature.com/articles/s41467-025-60233-2",
    "journal": "Nature_SystemsBiology",
    "title": "Metabolic modeling reveals a multi-level deregulation of host-microbiome metabolic networks in IBD",
    "link": "https://www.nature.com/articles/s41467-025-60233-2",
    "published": "2025-06-02T00:00:00+00:00",
    "summary": "",
    "authors": [
      "Jan Taubenheim et al."
    ],
    "doi": "",
    "parser_type": "nature",
    "feed_priority": "high",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.842321"
  },
  {
    "id": "https://www.nature.com/articles/s41598-025-04227-6",
    "journal": "Nature_SystemsBiology",
    "title": "Exploring syphilis transmission dynamics with congenital infection and disability compartments",
    "link": "https://www.nature.com/articles/s41598-025-04227-6",
    "published": "2025-06-02T00:00:00+00:00",
    "summary": "",
    "authors": [
      "Rahat Zarin et al."
    ],
    "doi": "",
    "parser_type": "nature",
    "feed_priority": "high",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.842331"
  },
  {
    "id": "https://www.nature.com/articles/s41467-025-59653-x",
    "journal": "Nature_SystemsBiology",
    "title": "Precision multiplexed base editing in human cells using Cas12a-derived base editors",
    "link": "https://www.nature.com/articles/s41467-025-59653-x",
    "published": "2025-05-31T00:00:00+00:00",
    "summary": "",
    "authors": [
      "Anabel Y. Schweitzer et al."
    ],
    "doi": "",
    "parser_type": "nature",
    "feed_priority": "high",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.842340"
  },
  {
    "id": "https://www.nature.com/articles/s41598-025-03993-7",
    "journal": "Nature_SystemsBiology",
    "title": "Two dynamical models for male infertility and their stability and sensitivity analysis",
    "link": "https://www.nature.com/articles/s41598-025-03993-7",
    "published": "2025-05-29T00:00:00+00:00",
    "summary": "",
    "authors": [
      "Somaye Ghiasi Hafezi et al."
    ],
    "doi": "",
    "parser_type": "nature",
    "feed_priority": "high",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.842349"
  },
  {
    "id": "https://www.nature.com/articles/s41540-025-00539-5",
    "journal": "Nature_SystemsBiology",
    "title": "Translational disease modeling of peripheral blood identifies type 2 diabetes biomarkers predictive of Alzheimer’s disease",
    "link": "https://www.nature.com/articles/s41540-025-00539-5",
    "published": "2025-05-29T00:00:00+00:00",
    "summary": "",
    "authors": [
      "Brendan K. Ball et al."
    ],
    "doi": "",
    "parser_type": "nature",
    "feed_priority": "high",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.842363"
  },
  {
    "id": "https://www.nature.com/articles/s41598-025-00725-9",
    "journal": "Nature_SystemsBiology",
    "title": "Drug-drug interaction prediction of traditional Chinese medicine based on graph attention networks",
    "link": "https://www.nature.com/articles/s41598-025-00725-9",
    "published": "2025-05-28T00:00:00+00:00",
    "summary": "",
    "authors": [
      "Bin Yang et al."
    ],
    "doi": "",
    "parser_type": "nature",
    "feed_priority": "high",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.842399"
  },
  {
    "id": "https://www.nature.com/articles/s41467-025-60126-4",
    "journal": "Nature_SystemsBiology",
    "title": "Expanded ribosomal synthesis of non-standard cyclic backbones in vitro",
    "link": "https://www.nature.com/articles/s41467-025-60126-4",
    "published": "2025-05-28T00:00:00+00:00",
    "summary": "",
    "authors": [
      "Kanghun Lee et al."
    ],
    "doi": "",
    "parser_type": "nature",
    "feed_priority": "high",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.842408"
  },
  {
    "id": "https://www.nature.com/articles/s41540-025-00537-7",
    "journal": "Nature_SystemsBiology",
    "title": "Deep exploration of logical models of cell differentiation in human preimplantation embryos",
    "link": "https://www.nature.com/articles/s41540-025-00537-7",
    "published": "2025-05-27T00:00:00+00:00",
    "summary": "",
    "authors": [
      "Mathieu Bolteau et al."
    ],
    "doi": "",
    "parser_type": "nature",
    "feed_priority": "high",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.842417"
  },
  {
    "id": "https://www.nature.com/articles/s41467-025-59564-x",
    "journal": "Nature_SystemsBiology",
    "title": "Depletion-dependent activity-based protein profiling using SWATH/DIA-MS detects serine hydrolase lipid remodeling in lung adenocarcinoma progression",
    "link": "https://www.nature.com/articles/s41467-025-59564-x",
    "published": "2025-05-27T00:00:00+00:00",
    "summary": "",
    "authors": [
      "Tatjana Sajic et al."
    ],
    "doi": "",
    "parser_type": "nature",
    "feed_priority": "high",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.842436"
  },
  {
    "id": "https://www.nature.com/articles/s42003-025-08109-5",
    "journal": "Nature_SystemsBiology",
    "title": "High efficiency rare earth element bioleaching with systems biology guided engineering of Gluconobacter oxydans",
    "link": "https://www.nature.com/articles/s42003-025-08109-5",
    "published": "2025-05-27T00:00:00+00:00",
    "summary": "",
    "authors": [
      "Alexa M. Schmitz et al."
    ],
    "doi": "",
    "parser_type": "nature",
    "feed_priority": "high",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.842446"
  },
  {
    "id": "https://www.nature.com/articles/s41598-024-78011-3",
    "journal": "Nature_SystemsBiology",
    "title": "Uncovering dendritic cell specific biomarkers for diagnosis and prognosis of cardiomyopathy using single cell RNA sequencing and comprehensive bioinformatics analysis",
    "link": "https://www.nature.com/articles/s41598-024-78011-3",
    "published": "2025-05-26T00:00:00+00:00",
    "summary": "",
    "authors": [
      "Md. Mizanur Rahman et al."
    ],
    "doi": "",
    "parser_type": "nature",
    "feed_priority": "high",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.842465"
  },
  {
    "id": "https://www.nature.com/articles/s41467-025-59827-7",
    "journal": "Nature_SystemsBiology",
    "title": "Designing pathways for bioproducing complex chemicals by combining tools for pathway extraction and ranking",
    "link": "https://www.nature.com/articles/s41467-025-59827-7",
    "published": "2025-05-24T00:00:00+00:00",
    "summary": "",
    "authors": [
      "Anastasia Sveshnikova et al."
    ],
    "doi": "",
    "parser_type": "nature",
    "feed_priority": "high",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.842474"
  },
  {
    "id": "https://www.nature.com/articles/s41540-025-00521-1",
    "journal": "Nature_SystemsBiology",
    "title": "Model of metabolism and gene expression predicts proteome allocation in Pseudomonas putida",
    "link": "https://www.nature.com/articles/s41540-025-00521-1",
    "published": "2025-05-24T00:00:00+00:00",
    "summary": "",
    "authors": [
      "Juan D. Tibocha-Bonilla et al."
    ],
    "doi": "",
    "parser_type": "nature",
    "feed_priority": "high",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.842489"
  },
  {
    "id": "https://www.nature.com/articles/s41467-025-60120-w",
    "journal": "Nature_SystemsBiology",
    "title": "Directed evolution of aminoacyl-tRNA synthetases through in vivo hypermutation",
    "link": "https://www.nature.com/articles/s41467-025-60120-w",
    "published": "2025-05-24T00:00:00+00:00",
    "summary": "",
    "authors": [
      "Yuichi Furuhata et al."
    ],
    "doi": "",
    "parser_type": "nature",
    "feed_priority": "high",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:37:16.842498"
  },
  {
    "id": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00486-3?rss=yes",
    "journal": "Cell_Reports",
    "title": "Systems and synthetic biology for plant natural product pathway elucidation",
    "link": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00486-3?rss=yes",
    "published": "",
    "summary": "Qin et al. summarize recent advances in systems and synthetic biology approaches for characterizing and engineering plant metabolic pathways to enhance the production of valuable natural products. Additionally, they discuss advanced metabolic engineering strategies aimed at achieving more cost-effective and environmentally friendly production of these compounds.",
    "authors": [
      "Kezhen Qin, Fang Liu, Caibin Zhang, Rui Deng, Alisdair R. Fernie, Youjun Zhang"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.492479"
  },
  {
    "id": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00522-4?rss=yes",
    "journal": "Cell_Reports",
    "title": "Hormonal regulation of primary root development",
    "link": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00522-4?rss=yes",
    "published": "",
    "summary": "Dynamic hormone networks orchestrate Arabidopsis root meristem growth. In this review, Nittis et al. highlight recent advances in how these regulatory systems shape root development and discuss their conservation across species.",
    "authors": [
      "Michela De Nittis, Mirko De Vivo, Raffaele Dello Ioio, Sabrina Sabatini"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.492517"
  },
  {
    "id": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00503-0?rss=yes",
    "journal": "Cell_Reports",
    "title": "Exploring adipose tissue-derived extracellular vesicles in inter-organ crosstalk: Implications for metabolic regulation and adipose tissue function",
    "link": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00503-0?rss=yes",
    "published": "",
    "summary": "Extracellular vesicles (EVs) are critical mediators of intercellular and interorgan communication. Adipocyte-derived EVs contribute to autocrine, paracrine, and endocrine signaling, impacting tissue homeostasis and disease. This review explores recent findings on EVs in adipose tissue and their emerging therapeutic potential.",
    "authors": [
      "Soazig Le Lay, Philipp E. Scherer"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.492546"
  },
  {
    "id": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00471-1?rss=yes",
    "journal": "Cell_Reports",
    "title": "Future threats: Animal orthoflaviviruses that currently infect fewer than 100 people per year",
    "link": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00471-1?rss=yes",
    "published": "",
    "summary": "Worden-Sapper et al. document animal orthoflaviviruses currently infecting fewer than 100 people per year. These viruses have a non-trivial chance of causing human epidemics or pandemics, yet this review highlights how little is known about their biology.",
    "authors": [
      "Emma R. Worden-Sapper, Paul Gendler, Rachel E. Lange, Jens H. Kuhn, Sara L. Sawyer"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.492558"
  },
  {
    "id": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00504-2?rss=yes",
    "journal": "Cell_Reports",
    "title": "Targeting WEE1 in tumor-associated dendritic cells potentiates antitumor immunity via the cGAS/STING pathway",
    "link": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00504-2?rss=yes",
    "published": "",
    "summary": "Ng et al. demonstrate that targeting WEE1 in tumor-associated dendritic cells (TADCs) enhances antitumor immunity via the cGAS/STING pathway. WEE1 inhibition augments DC vaccine efficacy and synergizes with immune checkpoint blockade therapy, offering a promising strategy for cancer immunotherapy.",
    "authors": [
      "Ian-Ian Ng, Zhihua Zhang, Kaimin Xiao, Minjie Ye, Tingzhong Tian, Yaoji Zhu, Yuan He, Ling Chu, Haidong Tang"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.492578"
  },
  {
    "id": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00505-4?rss=yes",
    "journal": "Cell_Reports",
    "title": "Regulatory network analysis of Dclk1 gene expression reveals a tuft cell-ILC2 axis that inhibits pancreatic tumor progression",
    "link": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00505-4?rss=yes",
    "published": "",
    "summary": "Valenti, Laise, Wu et al. find a paracrine loop in pancreatic neoplasia involving Dclk1+ tuft cells, ILC2s, and CAFs. This loop suppresses tumor progression through angiotensinogen release by Dclk1+ cells, therefore providing a potential therapeutic target for pancreatic tumors.",
    "authors": [
      "Giovanni Valenti, Pasquale Laise, Feijing Wu, Ryota Takahashi, Tuo Ruan, Alessandro Vasciaveo, Zhengyu Jiang, Hiroki Kobayashi, Masaki Sunagawa, Moritz Middelhoff, Henrik Nienhüser, Na Fu, Ermanno Malagola, Osmel Companioni, Yoku Hayakawa, Alina C. Iuga, Andrea Califano, Timothy C. Wang"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.492592"
  },
  {
    "id": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00571-6?rss=yes",
    "journal": "Cell_Reports",
    "title": "Distinct TAM subset with cross-dressing capability determines the bifurcation of tumor immunity",
    "link": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00571-6?rss=yes",
    "published": "",
    "summary": "Shimizu et al. identified a unique subset of CD9hiCD63hiCD206+Class IIlo hypoxic TAMs in the vicinity of tumor cells that “cross-dress” major histocompatibility gene complex (MHC)/tumor antigen epitopes through trogocytosis. This TAM trogocytosis is regulated by Ch25h expression, and their elimination can enhance antitumor effects of immunotherapy.",
    "authors": [
      "Kanako Shimizu, An Sanpei, Hiroshi Nakazato, Jun Shinga, Shogo Ueda, Yan Liu, Tomonori Iyoda, Satoru Yamasaki, Jun Nakabayashi, Shin-ichiro Fujii"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.492620"
  },
  {
    "id": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00560-1?rss=yes",
    "journal": "Cell_Reports",
    "title": "Pro-ferroptotic lipids as key control points for caveola formation and disassembly",
    "link": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00560-1?rss=yes",
    "published": "",
    "summary": "Wu et al. identified pro-ferroptotic lipids as essential regulators of the formation and disassembly of caveolae, stress-sensing structures at the plasma membrane. A targeted miniscreen uncovered a lipid-driven mechanism that links caveola stability and dynamics to lipid metabolism, peroxidation, and cellular stress responses.",
    "authors": [
      "Yeping Wu, Ye-Wheen Lim, Kerrie-Ann McMahon, Nick Martel, James Rae, Harriet P. Lo, Ya Gao, Vikas Tillu, Elin Larsson, Richard Lundmark, Daniel S. Levic, Michel Bagnat, Junxian Lim, David P. Fairlie, Albert Pol, Brett M. Collins, Nicholas Ariotti, Thomas E. Hall, Robert G. Parton"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.492650"
  },
  {
    "id": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00581-9?rss=yes",
    "journal": "Cell_Reports",
    "title": "Phase separation of TTBK2 and CEP164 is necessary for ciliogenesis",
    "link": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00581-9?rss=yes",
    "published": "",
    "summary": "Chou et al. demonstrate that CEP164 recruits TTBK2 to centriole distal appendages through phase separation driven by electrostatic interactions between their intrinsically disordered regions. This multivalent interaction forms dynamic condensates, facilitating efficient TTBK2 recruitment and initiating ciliogenesis, highlighting the critical role of phase separation in cilia formation.",
    "authors": [
      "Po-Chun Chou, Yu-Hao Lin, I-Hsuan Lin, Tzu-Ying Lin, Yun-Chia Huang, Shi-Rong Hong, Ting-Jui Ben Chang, Yin Fang, Yizhi Lin, T. Tony Yang, Yu-Chun Lin, Jie-rong Huang, Won-Jing Wang"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.492659"
  },
  {
    "id": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00547-9?rss=yes",
    "journal": "Cell_Reports",
    "title": "miRNA-GABA influences female Aedes aegypti reproduction by modulating midgut homeostasis",
    "link": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00547-9?rss=yes",
    "published": "",
    "summary": "Cao et al. identify miR-7 as a blood meal digestion regulator in Aedes aegypti females through sRNA-seq and physiological assays. CRISPR-Cas9-mediated miR-7 knockout combined with GABA delivery via the digestive tract reveals that midgut dysfunction subsequently impairs reproductive fitness.",
    "authors": [
      "Jianping Cao, Lin Ling"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.492669"
  },
  {
    "id": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00561-3?rss=yes",
    "journal": "Cell_Reports",
    "title": "Dissecting pre- to post-implantation transition of DNA methylome-transcriptome dynamics in early mammalian development",
    "link": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00561-3?rss=yes",
    "published": "",
    "summary": "Zhu et al. found that peri-implantation embryos undergo lineage-specific DNA methylation remodeling, segregated methylation dynamics in visceral endoderm subtypes, asynchronous DNA methylation of parental transposons, and non-canonical DNA methylation-transcription coupling across species, revealing complex and interactive molecular dynamics along lineage progression and early development.",
    "authors": [
      "Qingyuan Zhu, Ying Liu, Xin Hao, Shengyi Yan, Jitao Ge, Changqing Zheng, Xianwen Ren, Fan Zhou"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.492679"
  },
  {
    "id": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00526-1?rss=yes",
    "journal": "Cell_Reports",
    "title": "Complete reference genome and pangenome improve genome-wide detection and interpretation of DNA methylation using sequencing and array data",
    "link": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00526-1?rss=yes",
    "published": "",
    "summary": "Dong et al. characterized the significant advantages of reference genome updates, specifically the T2T-CHM13 and the human pangenome, in DNA-methylation analyses. Compared to the previous GRCh38 assembly, these updated genomes increase the number of identified CpGs, improve array probe annotation, and facilitate genome-wide discovery of DNA-methylation alterations.",
    "authors": [
      "Zheng Dong, Joanne Whitehead, Maggie Fu, Julia L. MacIsaac, David H. Rehkopf, Luis Rosero-Bixby, Michael S. Kobor, Keegan Korthauer"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.492689"
  },
  {
    "id": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00576-5?rss=yes",
    "journal": "Cell_Reports",
    "title": "Physiological role and mechanisms of action for a long noncoding haplotype region",
    "link": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00576-5?rss=yes",
    "published": "",
    "summary": "Xue et al. developed an integrated approach for investigating the physiological role and mechanisms of action for long noncoding haplotype regions. They applied the approach to study a haplotype containing 11 single-nucleotide polymorphisms spanning 17.4 kbp, demonstrating substantial blood pressure effects and identifying a long-range chromatin interaction mechanism involved.",
    "authors": [
      "Hong Xue, Manoj K. Mishra, Yong Liu, Pengyuan Liu, Michael Grzybowski, Rajan Pandey, Kristie Usa, Mark A. Vanden Avond, Niharika Bala, Abdel A. Alli, Allen W. Cowley, Qiongzi Qiu, Andrew S. Greene, Sridhar Rao, Caitlin C. O'Meara, Aron M. Geurts, Mingyu Liang"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.492698"
  },
  {
    "id": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00513-3?rss=yes",
    "journal": "Cell_Reports",
    "title": "Glycerophospholipid metabolism licenses IgE-mediated mast cell degranulation",
    "link": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00513-3?rss=yes",
    "published": "",
    "summary": "Xia et al. have delineated that glycerophospholipid metabolism licenses IgE-mediated mast cell degranulation dependent on lowered macropinocytosis of FcεRI. Targeting this metabolic cue could clinically manage allergic diseases (e.g., atopic dermatitis).",
    "authors": [
      "Yaoyao Xia, Peng Bin, Youyou Zhou, Muyang Zhao, Jianglin Zhang, Weiming Zhong, Na Wang, Bingfeng Wang, Wenkai Ren"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.492706"
  },
  {
    "id": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00512-1?rss=yes",
    "journal": "Cell_Reports",
    "title": "KSHV miRNAs target STING to evade innate immunity and facilitate KSHV lytic reactivation from latency",
    "link": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00512-1?rss=yes",
    "published": "",
    "summary": "Paulsen et al. demonstrate that multiple KSHV miRNAs suppress STING expression to evade innate immunity. Deletion of these miRNAs restores STING-dependent innate immunity, delaying KSHV lytic reactivation from latency. This study discovers a mechanism of viral immune evasion through miRNA-mediated regulation of the cGAS/STING pathway.",
    "authors": [
      "Kimberly Paulsen, Rosenna Chan, Lauren Gay, Zhe Ma"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.492725"
  },
  {
    "id": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00542-X?rss=yes",
    "journal": "Cell_Reports",
    "title": "Macrophage extracellular traps as key mediators of scleral remodeling in myopia induced by hypoxia and activated platelets",
    "link": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00542-X?rss=yes",
    "published": "",
    "summary": "Macrophages are pivotal in myopic scleral remodeling, yet their precise mechanisms remain elusive. Feng et al. reveal that macrophages contribute to myopic scleral remodeling by releasing METs, and inhibiting METs effectively suppresses myopia progression. Furthermore, they demonstrate that scleral hypoxia and hypoxia-activated platelets stimulate macrophages, inducing MET release following autophagy.",
    "authors": [
      "Qianhong Feng, Jiayue Yuan, Yingying Hu, Chenli Feng, Xinguang Lin, Shichu Liu, Shunmei Ji, Xiuyu Mao, Xueqi Lin, Jing Cong, Xianglian Li, Xinran Li, Hao Li, Dapeng Yan, Jinhui Dai"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.492735"
  },
  {
    "id": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00525-X?rss=yes",
    "journal": "Cell_Reports",
    "title": "Molecular basis of autoimmune disease protection by MDA5 variants",
    "link": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00525-X?rss=yes",
    "published": "",
    "summary": "Loss-of-function MDA5 variants increase the risk of chronic inflammation but protect against autoimmune disease. Singh et al. show that autoimmune-protective variants impair MDA5 signaling via different mechanisms, including loss of RNA binding and increased ATPase activity. By tuning MDA5 signaling, variants offer a trade-off between antiviral activity and autoimmune disease protection.",
    "authors": [
      "Rahul Singh, Joe D. Joiner, Alba Herrero del Valle, Marleen Zwaagstra, Ida Jobe, Brian J. Ferguson, Frank J.M. van Kuppeveld, Yorgo Modis"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.492749"
  },
  {
    "id": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00534-0?rss=yes",
    "journal": "Cell_Reports",
    "title": "Hierarchical progressive learning for zero-shot peptide-HLA binding prediction and automated antigenic peptide design",
    "link": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00534-0?rss=yes",
    "published": "",
    "summary": "Zhu et al. introduce HPL, a machine learning framework enhancing zero-shot HLA-peptide binding prediction by 60.8% through hierarchical progressive learning, and APMS, an automated tool that designs high-affinity peptides with 38.1% success. These advances address HLA diversity and data scarcity, aiding targeted therapy and vaccine development.",
    "authors": [
      "Xinyuan Zhu, Jiadong Lu, Xinting Hu, Tengchuan Jin, Shan Lu, Fuli Feng"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.492758"
  },
  {
    "id": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00551-0?rss=yes",
    "journal": "Cell_Reports",
    "title": "Ocular immune privilege in action: The living eye imposes unique regulatory and anergic gene signatures on uveitogenic T cells",
    "link": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00551-0?rss=yes",
    "published": "",
    "summary": "Peng et al. show that naive retina-specific T cells encountering antigen in the immune-privileged eye differentiate into distinct regulatory vs. anergic phenotypes from a common precursor. These findings reveal a key checkpoint and provide novel insights into ocular immune privilege, suggesting strategies for immunomodulation in autoimmunity, cancer, and beyond.",
    "authors": [
      "Zixuan Peng, Vijayaraj Nagarajan, Reiko Horai, Yingyos Jittayasothorn, Mary J. Mattapallil, Rachel R. Caspi"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.492783"
  },
  {
    "id": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00546-7?rss=yes",
    "journal": "Cell_Reports",
    "title": "KMT2D coordinates antiviral CD4+ T cell responses through opposing effects on T follicular helper and cytotoxic gene expression",
    "link": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00546-7?rss=yes",
    "published": "",
    "summary": "Distinct subsets of T cells confer immune protection against infections. Histone modifiers integrate TCRs and other signaling pathways with transcription factors to specify each subset and its function. Herein, Cohen et al. reveal a central role for KMT2D in advancing TFH formation and antibodies while restricting cytolytic Th subsets.",
    "authors": [
      "Jonathan A. Cohen, Ashlyn A. Buzzelli, Gabrielle Quickstad, Lixin Yang, Ichiro Misumi, Karl B. Shpargel, Jason K. Whitmire"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.492792"
  },
  {
    "id": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00554-6?rss=yes",
    "journal": "Cell_Reports",
    "title": "Pexophagy-driven redox imbalance promotes virus-induced ferroptosis",
    "link": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00554-6?rss=yes",
    "published": "",
    "summary": "Jiang et al. show that virus infection triggers excessive ROS production and peroxisome degradation via pexophagy mediated by the ATM-PEX5-p62 axis. This degradation leads to iron accumulation, enhanced ROS levels, activation of the Fenton reaction, and ferroptosis, highlighting the peroxisome’s role in viral interactions and redox regulation.",
    "authors": [
      "Hui Jiang, Yang Qu, Xianjin Kan, Mengqing Yang, Yabin Gong, Ying Liao, Xusheng Qiu, Lei Tan, Cuiping Song, Venugopal Nair, Chan Ding, Yingjie Sun"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.492801"
  },
  {
    "id": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00556-X?rss=yes",
    "journal": "Cell_Reports",
    "title": "PGK1 phosphorylates NLRP3 and mediates inflammasome activation independent of its glycolytic activity",
    "link": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00556-X?rss=yes",
    "published": "",
    "summary": "Ma et al. identify PGK1 as a kinase regulating NLRP3 inflammasome activation via non-glycolytic functions. Lipopolysaccharide induces CK2-mediated PGK1 S271 phosphorylation, enabling PGK1 to phosphorylate NLRP3 S448/449 and recruit USP14 for deubiquitylation, driving inflammation. It highlights a novel role of PGK1 in NLRP3-driven diseases and potential therapeutic targets.",
    "authors": [
      "Zemeng Ma, Yuxuan Wu, Zebing Rao, Chenhua Han, Naishuang Sun, Jinzhou Li, Qiang Zeng, Zaikui Zhang, Ding Ding, Jiajun Qiao, Wenjing Li, Yifeng Fang, Shuo Yang, Jiahuang Li, Jing Zhang, Yunzi Chen"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.492817"
  },
  {
    "id": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00564-9?rss=yes",
    "journal": "Cell_Reports",
    "title": "RORγt is crucial for gut homeostasis by regulating the expression of HB-EGF rather than IL-22 in activated ILC3s",
    "link": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00564-9?rss=yes",
    "published": "",
    "summary": "Li et al. show that RORγt, the ILC3 master regulator, still plays a crucial role during the ILC3 activation phase. Although it is dispensable for ILC3 maintenance and their IL-22 production, it is required for generating sufficient HB-EGF to alleviate colitis, thereby providing insights for the evaluation of RORγt inhibitors.",
    "authors": [
      "Peng Li, Yime Zhang, Yang Shen, Xingyu Zhao, Rong Mu, Chao Zhong"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.492833"
  },
  {
    "id": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00562-5?rss=yes",
    "journal": "Cell_Reports",
    "title": "Thymically imprinted heterogeneity results in differential Treg induction and stability of effector identity",
    "link": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00562-5?rss=yes",
    "published": "",
    "summary": "Pennock et al. have furthered the link between T cell self-affinity and peripheral Treg differentiation, establishing that thymic genetic programming biases persist through the naive and effector stages of the T cell. This work bolsters the field of intrinsic T cell heterogeneity, with implications for current approaches to cell therapy.",
    "authors": [
      "Nathan D. Pennock, Yamin Qian, Kazumi Ishihara, Yamami Nakamura, Eric Cross, Shimon Sakaguchi, Jason T. White"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.492848"
  },
  {
    "id": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00582-0?rss=yes",
    "journal": "Cell_Reports",
    "title": "Endosymbiont control through non-canonical immune signaling and gut metabolic remodeling",
    "link": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00582-0?rss=yes",
    "published": "",
    "summary": "Burgmer et al. show that the pattern recognition receptors (PRRs) PGRP-LC and PGRP-LE repress key metabolic functions in the Drosophila midgut. These regulations occur independently of canonical immune pathways and restrict parasitic Wolbachia endosymbionts in the intestine and peripheral tissues. Thus, PRRs act beyond canonical immune pathways to control bacteria.",
    "authors": [
      "Sofie Burgmer, Fenja L. Meyer zu Altenschildesche, Akos Gyenis, Hyun Ju Lee, David Vilchez, Patrick Giavalisco, Arnaud Fichant, Mirka Uhlirova, Gilles Storelli"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.492857"
  },
  {
    "id": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00521-2?rss=yes",
    "journal": "Cell_Reports",
    "title": "Molecular landscape of sex- and modality-specific exercise adaptation in human skeletal muscle through large-scale multi-omics integration",
    "link": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00521-2?rss=yes",
    "published": "",
    "summary": "Jacques et al. conducted a thorough meta-analysis integrating multi-omics data from over 1,000 participants to identify distinctive molecular signatures in human skeletal muscle adaptation to various forms of exercise. This study elucidates specific omics markers associated with aerobic and resistance training, offering valuable insights into muscle health, aging, and disease prevention.",
    "authors": [
      "Macsue Jacques, Shanie Landen, Adam P. Sharples, Andrew Garnham, Ralf Schittenhelm, Joel Steele, Aino Heikkinen, Elina Sillanpää, Miina Ollikainen, James Broatch, Navabeh Zarekookandeh, Ola Hanson, Ola Ekström, Olof Asplund, Séverine Lamon, Sarah E. Alexander, Cassandra Smith, Carlie Bauer, Mary N. Woessner, Itamar Levinger, Andrew E. Teschendorff, Linn Gillberg, Ida Blom, Jørn Wulff Helge, Nicholas R. Harvey, Larisa M. Haupt, Lyn R. Griffiths, Atul S. Deshmukh, Kirsi H. Pietiläinen, Päivi Piirilä, Robert A.E. Seaborne, Marie Klevjer, Anja Bye, Ulrik Wisløff, Bernadette Jones-Freeman, Nir Eynon"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.492867"
  },
  {
    "id": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00536-4?rss=yes",
    "journal": "Cell_Reports",
    "title": "Adenosine signaling in glia modulates metabolic state-dependent behavior in Drosophila",
    "link": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00536-4?rss=yes",
    "published": "",
    "summary": "De Backer et al. dissect the roles of adenosine signaling in glia subtypes in the fly nervous system and their relationship to feeding-state-dependent behavior. Their results provide a potentially conserved mechanism used by animals to sense their internal energetic state and adjust their behavior accordingly.",
    "authors": [
      "Jean-François De Backer, Thomas Karges, Julia Papst, Zeynep Nigar Pınar, Cristina Coman, Robert Ahrends, Yanjun Xu, Cristina García-Cáceres, Ilona C. Grunwald Kadow"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.492876"
  },
  {
    "id": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00495-4?rss=yes",
    "journal": "Cell_Reports",
    "title": "Structural basis for the recognition of two different types of receptors by Western equine encephalitis virus",
    "link": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00495-4?rss=yes",
    "published": "",
    "summary": "Ma et al. report that Western equine encephalitis virus engages two distinct receptors (PCDH10 and VLDLR) through different binding modes, as demonstrated by the cryo-EM structural analyses. Further mutagenesis studies identify strain-specific residues that influence receptor usage, suggesting evolutionary drivers of host adaptation.",
    "authors": [
      "Bingting Ma, Ziyi Cao, Weijia Ding, Xinzheng Zhang, Ye Xiang, Duanfang Cao"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.492885"
  },
  {
    "id": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00502-9?rss=yes",
    "journal": "Cell_Reports",
    "title": "Early-life development of the gut virome and plasmidome: A longitudinal study in cesarean-born infants",
    "link": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00502-9?rss=yes",
    "published": "",
    "summary": "This study explores the dynamics of mobile genetic elements in the infant gut after cesarean birth. Fernández-Pato et al. show that early infant gut mobilome is highly individual-specific and shaped by feeding mode. Antibiotic exposure at birth has minimal effect, and early mother–infant strain-sharing is rarely detected.",
    "authors": [
      "Asier Fernández-Pato, Trishla Sinha, Sanzhima Garmaeva, Anastasia Gulyaeva, Nataliia Kuzub, Simon Roux, Jingyuan Fu, Alexander Kurilshikov, Alexandra Zhernakova"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.492894"
  },
  {
    "id": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00519-4?rss=yes",
    "journal": "Cell_Reports",
    "title": "A genome-wide base-editing screen uncovers a pivotal role of paxillin δ ubiquitination in influenza virus infection",
    "link": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00519-4?rss=yes",
    "published": "",
    "summary": "Guo et al. conduct a genome-wide CRISPR base-editing screen to investigate functional lysine residues in host factors involved in influenza A virus replication. They find that paxillin δ is critical for influenza A virus entry and demonstrate how its key lysine residue regulates this process.",
    "authors": [
      "Jiamei Guo, Zhuo Zhou, Ruining Li, Zhifang Xing, Lei Zhang, Shiyi Zhao, Wensheng Wei, Jianwei Wang, Tao Deng"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.492906"
  },
  {
    "id": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00544-3?rss=yes",
    "journal": "Cell_Reports",
    "title": "Unveiling the evolution of antimicrobial peptides in gut microbes via foundation-model-powered framework",
    "link": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00544-3?rss=yes",
    "published": "",
    "summary": "Li et al. introduce AMP-SEMiner, a framework for detecting encrypted antimicrobial peptides (AMPs) from microbiomes. It uncovers evolutionary dynamics shaping the AMPome in human gut microbiota, highlighting conserved and adaptive strategies.",
    "authors": [
      "Wenhui Li, Baicheng Huang, Menghao Guo, Zihan Zeng, Tao Cai, Linqing Feng, Xinpeng Zhang, Ling Guo, Xianyue Jiang, Yanbin Yin, Ercheng Wang, Xingxu Huang, Jinfang Zheng"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.492915"
  },
  {
    "id": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00555-8?rss=yes",
    "journal": "Cell_Reports",
    "title": "Immune imprinting blunts omicron pathogenicity fluctuations and highlights the essential role of cellular immunity in SARS-CoV-2 infection",
    "link": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00555-8?rss=yes",
    "published": "",
    "summary": "Wei et al. report that the virulence of the Omicron variant exhibits a fluctuating resurgence. While antibodies induced by prior immunization or infection may struggle to effectively neutralize the emerging variant, memory T cells play a crucial role in mitigating its pathogenicity.",
    "authors": [
      "Xiaohui Wei, Hekai Yang, Jing Wu, Binbin Zhao, Yameng Mu, Na Rong, Gengxin Zhang, Wanjun Peng, Lihong Zhang, Wei Zhang, Xiaoyue Ding, Gaoying Zhang, Zhihai Chen, Jiangning Liu"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.492924"
  },
  {
    "id": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00494-2?rss=yes",
    "journal": "Cell_Reports",
    "title": "SMIM20 promotes complex IV biogenesis and Ca2+ signaling in mice heart",
    "link": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00494-2?rss=yes",
    "published": "",
    "summary": "Boshnakovska et al. show that loss of the complex IV assembly factor SMIM20 in mice impairs complex IV function and causes a cardiac phenotype. SMIM20−/− mice demonstrate increased complex I activity and ROS levels, affecting Ca2+ handling and fatty acid-based respiration.",
    "authors": [
      "Angela Boshnakovska, Julius Ryan Pronto, Tanja Gall, Abhishek Aich, Jan Prochazka, Zuzana Nichtova, Radislav Sedlacek, Izzatullo Sobitov, Sofia Ainatzi, Christof Lenz, Dörthe M. Katschinski, Henning Urlaub, Niels Voigt, Peter Rehling, Laura S. Kremer"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.492946"
  },
  {
    "id": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00506-6?rss=yes",
    "journal": "Cell_Reports",
    "title": "PUS10-induced tRNA fragmentation impacts retrotransposon-driven inflammation",
    "link": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00506-6?rss=yes",
    "published": "",
    "summary": "Madej et al. reveal that PUS10, a pseudouridine synthase, regulates innate immunity impacting the inflammatory response in vivo. PUS10 loss disrupts tRNA-derived small RNAs, affecting translation and retroelement expression. This drives RNA-DNA hybrids accumulation, possibly activating cGAS-STING-induced inflammation and linking PUS10 dysregulation to human autoimmune disorders.",
    "authors": [
      "Magdalena Madej, Phuong Cao Thi Ngoc, Sowndarya Muthukumar, Anna Konturek-Cieśla, Silvia Tucciarone, Alexandre Germanos, Christian Ashworth, Knut Kotarsky, Sudip Ghosh, Zhimeng Fan, Helena Fritz, Izei Pascual-Gonzalez, Alain Huerta, Nicola Guzzi, Anita Colazzo, Giulia Beneventi, Hang-Mao Lee, Maciej Cieśla, Christopher Douse, Hiroki Kato, Vinay Swaminathan, William W. Agace, Ainara Castellanos-Rubio, Paolo Salomoni, David Bryder, Cristian Bellodi"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.492962"
  },
  {
    "id": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00518-2?rss=yes",
    "journal": "Cell_Reports",
    "title": "A lncRNA-mediated metabolic rewiring of cell senescence",
    "link": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00518-2?rss=yes",
    "published": "",
    "summary": "Grossi et al. describe how sin-lncRNA interacts with the TCA enzyme DLST to maintain mitochondrial function and metabolic balance during senescence. Depletion of sin-lncRNA causes DLST translocation to the nucleus, impairing mitochondrial function and triggering transcriptional changes, leading to metabolic reprogramming in senescence.",
    "authors": [
      "Elena Grossi, Francesco P. Marchese, Jovanna González, Enrique Goñi, José Miguel Fernández-Justel, Alicia Amadoz, Nicolás Herranz, Leonor Puchades-Carrasco, Marta Montes, Maite Huarte"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.492994"
  },
  {
    "id": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00507-8?rss=yes",
    "journal": "Cell_Reports",
    "title": "The deubiquitinase Rpn11 functions as an allosteric ubiquitin sensor to promote substrate engagement by the 26S proteasome",
    "link": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00507-8?rss=yes",
    "published": "",
    "summary": "Htet et al. used single-molecule and biochemical measurements to elucidate how the Rpn11 deubiquitinase subunit of the 26S proteasome functions as an allosteric sensor for ubiquitin chains. Ubiquitin binding to Rpn11 slows the spontaneous conformational transitions of the proteasome, aids substrate engagement by the ATPase motor, and thereby accelerates degradation.",
    "authors": [
      "Zaw Min Htet, Ken C. Dong, Andreas Martin"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.493004"
  },
  {
    "id": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00511-X?rss=yes",
    "journal": "Cell_Reports",
    "title": "MePCE promotes homologous recombination through coordinating R-loop resolution at DNA double-stranded breaks",
    "link": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00511-X?rss=yes",
    "published": "",
    "summary": "Devanathan et al. show that the MePCE 7SK RNA methyltransferase is dynamically recruited at sites of double-stranded breaks to promote R-loop resolution and repair by homologous recombination in a manner epistatic to BRCA1. The findings have high significance for the etiology and treatment of BRCA1-deficient cancers.",
    "authors": [
      "Sravan K. Devanathan, Yi-Ru Li, Samantha B. Shelton, Joshuah Nguyen, Wei-Che Tseng, Nakul M. Shah, Marvin Mercado, Kyle M. Miller, Blerta Xhemalçe"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.493012"
  },
  {
    "id": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00509-1?rss=yes",
    "journal": "Cell_Reports",
    "title": "Large-scale purifications reveal yeast and human stress granule cores are heterogeneous particles with complex transcriptomes and proteomes",
    "link": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00509-1?rss=yes",
    "published": "",
    "summary": "Demeshkina and Ferré-D'Amaré purify stress granule cores from yeast and mammalian cells. These cytoplasmic ribonucleoproteins are a conserved response of eukaryotic cells to stressors; their dysregulation is linked to diseases. These large-scale purifications enabled detailed proteomic and transcriptomic analyses that lay bare the complexity and heterogeneity of the particles.",
    "authors": [
      "Natalia A. Demeshkina, Adrian R. Ferré-D’Amaré"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.493030"
  },
  {
    "id": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00523-6?rss=yes",
    "journal": "Cell_Reports",
    "title": "Identification of RMP24 and RMP64, human ribonuclease MRP-specific protein components",
    "link": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00523-6?rss=yes",
    "published": "",
    "summary": "Che et al. report the forward genetic identification of human ribonuclease MRP-specific protein components RMP24 and RMP64. These components are required for pre-rRNA ITS1 site 2 processing and associate with MRP RNA but are not required for RNase P activity and do not associate with the RNase P-specific H1 RNA.",
    "authors": [
      "Rui Che, Bhoomi Mirani, Monireh Panah, Xiaotong Chen, Hong Luo, Andrei Alexandrov"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.493038"
  },
  {
    "id": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00524-8?rss=yes",
    "journal": "Cell_Reports",
    "title": "Assembly and cooperative mechanism of the hexameric fungal plasma membrane H+-ATPase",
    "link": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00524-8?rss=yes",
    "published": "",
    "summary": "You et al. discovered that the domain-swapped N-terminal extension of Pma1 mediated the cooperative activity of Pma1 hexamer. This work provides novel insights into the Pma1 mechanism and lays a foundation for drug development targeting Pma1.",
    "authors": [
      "Zi-Long You, Yue-Ran Ni, Yinggai Song, Hua Li, Kun-Zhao Liu, Le-Xuan Wang, Chao-Ran Zhao, Peng Zhao, Dan-Dan Chen, Lin Wang, Kai Wang, Pengyan Xia, Yu-Cheng Gu, Caihong Yun, Lin Bai"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.493047"
  },
  {
    "id": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00540-6?rss=yes",
    "journal": "Cell_Reports",
    "title": "Cytoplasmic DIS3 is an exosome-independent endoribonuclease with catalytic activity toward circular RNAs",
    "link": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00540-6?rss=yes",
    "published": "",
    "summary": "CircRNAs are generated during splicing, but their specific degradation pathways are poorly understood. Latini et al. identify and biochemically characterize the exo- and endoribonuclease DIS3 as a candidate for cytoplasmic circRNA degradation. DIS3 uses its catalytic PIN domain to cleave circRNAs and functions in the cytoplasm independently of the exosome.",
    "authors": [
      "Claudia Latini, Julian Eichlinger, Anna-Lisa Fuchs, Si-Nan Zhai, Hung Ho-Xuan, Gerhard Lehmann, Petar Glažar, Nikolaus Rajewsky, Astrid Bruckmann, Li Yang, Remco Sprangers, Gunter Meister"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.493060"
  },
  {
    "id": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00535-2?rss=yes",
    "journal": "Cell_Reports",
    "title": "Functional analysis of pathological mutations in DNA topoisomerase 3A",
    "link": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00535-2?rss=yes",
    "published": "",
    "summary": "Wang et al. show that the C-terminal domain of TOP3A is crucial for mouse embryonic development. Loss of this domain leads to mitochondrial dysfunction in ESCs and compromised TOP3A catalytic activity. These findings highlight the essential role of the C-terminal domain in maintaining TOP3A function in vitro and in vivo.",
    "authors": [
      "Yiqing Wang, Sebastian Kaiser, Javier Martin-Gonzalez, Yuan Li, Lene J. Rasmussen, Andres J. Lopez-Contreras, Anna H. Bizard, Ian D. Hickson"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.493069"
  },
  {
    "id": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00549-2?rss=yes",
    "journal": "Cell_Reports",
    "title": "Landscape and regulation of mRNA translation in the early C. elegans embryo",
    "link": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00549-2?rss=yes",
    "published": "",
    "summary": "Using ribosome profiling, Shukla et al. characterize dynamic translational regulation of maternal mRNAs during the first four cell cycles of C. elegans development. Their findings demonstrate how post-transcriptional mechanisms, including OMA-1-mediated regulation, contribute to protein expression changes in early embryonic development.",
    "authors": [
      "Yash Shukla, Vighnesh Ghatpande, Cindy F. Hu, Daniel J. Dickinson, Can Cenik"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.493096"
  },
  {
    "id": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00538-8?rss=yes",
    "journal": "Cell_Reports",
    "title": "Widespread impact of nucleosome remodelers on transcription at cis-regulatory elements",
    "link": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00538-8?rss=yes",
    "published": "",
    "summary": "Patty et al. systematically investigate the effects of SNF2 remodelers on cis-regulatory element transcription, both coding and non-coding, offering insights into the role of nucleosome remodeling complexes in gene regulatory networks. They define distinct molecular mechanisms for CHD8, SRCAP, and SMARCAL1.",
    "authors": [
      "Benjamin J. Patty, Rinku Dhungana, Sarah J. Hainer"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.493104"
  },
  {
    "id": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00558-3?rss=yes",
    "journal": "Cell_Reports",
    "title": "Three cryo-EM structures of CD109 reveal its mechanism of protease inhibition",
    "link": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00558-3?rss=yes",
    "published": "",
    "summary": "Almeida et al. use cryoelectron microscopy to determine three structures of the 160-kDa GPI-anchored protein CD109. A mechanism for the inhibition of proteases by CD109 is presented based on structures and functional data.",
    "authors": [
      "Ana V. Almeida, Kathrine T. Jensen, Seandean L. Harwood, Martin H. Jørgensen, Nadia S. Nielsen, Ida B. Thøgersen, Jan J. Enghild, Gregers R. Andersen"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.493118"
  },
  {
    "id": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00573-X?rss=yes",
    "journal": "Cell_Reports",
    "title": "RNA m6A dynamics promote transcription and RNA stability of bivalent genes during iPSC-induced generation of human lung progenitors",
    "link": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00573-X?rss=yes",
    "published": "",
    "summary": "Dong et al. show that stage-specific m6A dynamics direct human iPSC differentiation into lung progenitors. The upregulation of RBM15B induces m6A hypermethylation in differentiated stages, while the switch between m6A readers YTHDC1 and IGF2BP2 coordinates chromatin remodeling and mRNA stability control of bivalent genes critical for lung endoderm specification.",
    "authors": [
      "Shenghua Dong, Junjie Pang, Yushuai Wang, Le Han, Xiaoxiao Zhou, Feng Huang, Subo Zhang, Ning Ma, Huilin Huang, Hengyou Weng"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.493128"
  },
  {
    "id": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00498-X?rss=yes",
    "journal": "Cell_Reports",
    "title": "m6A RNA methylation-mediated control of global APC expression is required for local translation of β-actin and axon development",
    "link": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00498-X?rss=yes",
    "published": "",
    "summary": "Broix et al. demonstrate that m6A modifications on Apc mRNA facilitate its recognition by YTHDF readers, driving APC protein translation in the neuronal soma. The identified m6A/YTHDFs/APC pathway regulates the axonal localization and local translation of β-actin mRNA essential for growth cone and axon development.",
    "authors": [
      "Loic Broix, Rohini Roy, Belal Shohayeb, Ikumi Oomoto, Hiroki Umeshima, Dan Ohtan Wang"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.493140"
  },
  {
    "id": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00514-5?rss=yes",
    "journal": "Cell_Reports",
    "title": "Bioactive ketamine metabolite exerts in vivo neuroplastogenic effects to improve hippocampal function in a treatment-resistant depression model",
    "link": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00514-5?rss=yes",
    "published": "",
    "summary": "Riggs et al. investigate whether synaptic plasticity contributes to the effects of rapid-acting antidepressants in vivo, as has long been hypothesized. They show that the bioactive ketamine metabolite, (2R,6R)-hydroxynorketamine, acts as a neuroplastogen by restoring synaptic strength and reversing deficits in CA1-dependent activity and behavior in a treatment-resistant depression model.",
    "authors": [
      "Lace M. Riggs, Sage Aronson, Ta-Chung M. Mou, Edna F.R. Pereira, Scott M. Thompson, Todd D. Gould"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.493150"
  },
  {
    "id": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00517-0?rss=yes",
    "journal": "Cell_Reports",
    "title": "Division of labor among H3K4 methyltransferases defines distinct facets of homeostatic plasticity",
    "link": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00517-0?rss=yes",
    "published": "",
    "summary": "Tsukahara et al. find unique roles for the six histone H3K4 methylation writers in regulating distinct facets of homeostatic synaptic scaling. Among the six enzymes, KMT2A is key for the induction of synaptic downscaling by installing H3K4me1 early after network hyperactivity to elicit transcriptional responses necessary for synaptic adaptations.",
    "authors": [
      "Takao Tsukahara, Saini Kethireddy, Katherine M. Bonefas, Alex Chen, Brendan L.M. Sutton, Kenjiro Bandow, Yali Dou, Shigeki Iwase, Michael A. Sutton"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.493160"
  },
  {
    "id": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00532-7?rss=yes",
    "journal": "Cell_Reports",
    "title": "β-synuclein blocks α-synuclein condensate fusion to disrupt the maturation of phase separation",
    "link": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00532-7?rss=yes",
    "published": "",
    "summary": "α-Syn undergoes initial LLPS and condensate fusion to become a mature condensate. In this work, Xu et al. find that β-Syn co-condenses with α-Syn and inhibits the maturation of α-Syn phase separation by interrupting condensate fusion, thus reducing α-Syn amyloid aggregation and subsequent neurotoxicity.",
    "authors": [
      "Bingkuan Xu, Wenyuan He, Fengshuo Fan, Shuhan Chen, Min Zhu, Yanjun Hou, Lingjun Zheng, Haijia Yu, Yinghui Liu"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.493177"
  },
  {
    "id": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00529-7?rss=yes",
    "journal": "Cell_Reports",
    "title": "Cell-death pathways and tau-associated neuronal vulnerability in Alzheimer’s disease",
    "link": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00529-7?rss=yes",
    "published": "",
    "summary": "Lin et al. characterize a population of tau-vulnerable neurons in AD. Analysis of gene expression in these neurons reveals dysregulation in major coordinated programs including apoptosis, cell-component disassembly, and regulation of vesicle-mediated transport. These biological processes suggest avenues for therapeutic interventions preventing neuronal loss and degeneration in AD.",
    "authors": [
      "Gen Lin, Sarah E. Chancellor, Taekyung Kwon, Maya E. Woodbury, Astrid Doering, Aicha Abdourahman, Rachel E. Bennett, Fan Liao, Timothy Pastika, Joseph Tamm, Nandini Romanul, Kiran Yanamandra, Miwei Hu, Karen Zhao, Matthew P. Frosch, Yelena Grinberg, Huan Li, Sudeshna Das, Tammy Dellovade, Eric H. Karran, Robert V. Talanian, Knut Biber, Alberto Serrano-Pozo, Janina S. Ried, Xavier Langlois, Bradley T. Hyman"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.493187"
  },
  {
    "id": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00539-X?rss=yes",
    "journal": "Cell_Reports",
    "title": "Vasopressin and oxytocin excite BNST neurons via oxytocin receptors, which reduce anxious arousal",
    "link": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00539-X?rss=yes",
    "published": "",
    "summary": "AVP and OT regulate essential physiological functions. Francesconi and Olivera-Pasilio et al., demonstrate that AVP and OT inputs excite the BNST via OTR. The OTR-expressing BNST neurons reduce anxious arousal, helping to balance external-threat risk with internal physiological demands.",
    "authors": [
      "Walter Francesconi, Valentina Olivera-Pasilio, Fulvia Berton, Susan L. Olson, Rachel Chudoba, Lorena M. Monroy, Quirin Krabichler, Valery Grinevich, Joanna Dabrowska"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.493196"
  },
  {
    "id": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00548-0?rss=yes",
    "journal": "Cell_Reports",
    "title": "Astrocyte induction of disease-associated microglia is suppressed by acute exposure to fAD neurons in human iPSC triple cultures",
    "link": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00548-0?rss=yes",
    "published": "",
    "summary": "Lish et al. present a co-culture system of iPSC-derived human microglia, astrocytes, and neurons to investigate intercellular communication across different environmental and genetic contexts. Transcriptomic and protein analyses show that co-culture drives distinct cell states, with astrocytes inducing disease-associated microglia. Notably, neurons with familial Alzheimer’s disease mutations disrupt this process.",
    "authors": [
      "Alexandra M. Lish, Nancy Ashour, Richard V. Pearse, Paige C. Galle, Gwendolyn A. Orme, Sarah E. Heuer, Courtney R. Benoit, Kellianne D. Alexander, Elyssa F.L. Grogan, Gizem Terzioglu, Allegra Scarpa, Andrew M. Stern, Nicholas Seyfried, Vilas Menon, Tracy L. Young-Pearse"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.493205"
  },
  {
    "id": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00579-0?rss=yes",
    "journal": "Cell_Reports",
    "title": "Spatio-temporal organization of network activity patterns in the hippocampus",
    "link": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00579-0?rss=yes",
    "published": "",
    "summary": "Lopes-dos-Santos et al. introduce a low-dimensional embedding to map the hippocampal CA1-DG axis using electrophysiological signals. The approach enables comprehensive characterization of multiple gamma rhythms and neuron firing patterns across hippocampal layers, deepening our understanding of hippocampal circuitry.",
    "authors": [
      "Vítor Lopes-dos-Santos, Demi Brizee, David Dupret"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.493213"
  },
  {
    "id": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00553-4?rss=yes",
    "journal": "Cell_Reports",
    "title": "The transcriptome of playfulness is sex biased in the juvenile rat medial amygdala: A role for inhibitory neurons",
    "link": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00553-4?rss=yes",
    "published": "",
    "summary": "Marquardt et al. explore the “transcriptome of playfulness” in the medial amygdala, demonstrating that the gene signatures associated with playfulness are largely distinct in male and female rats. Through integrative analyses, they establish the inhibitory neuron population as central to the sex bias in playfulness and associated gene expression patterns.",
    "authors": [
      "Ashley E. Marquardt, Mahashweta Basu, Jonathan W. VanRyzin, Seth A. Ament, Margaret M. McCarthy"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.493222"
  },
  {
    "id": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00567-4?rss=yes",
    "journal": "Cell_Reports",
    "title": "Combinatorial transcriptional regulation establishes subtype-appropriate synaptic properties in auditory neurons",
    "link": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00567-4?rss=yes",
    "published": "",
    "summary": "Bastille and colleagues demonstrate that two closely related transcription factors, c-Maf and Mafb, have both redundant and independent effects on the diversification and functional differentiation of peripheral auditory neurons. Their data suggest that varying combinations of c-Maf and Mafb generate nuanced differences in synaptic structure and function.",
    "authors": [
      "Isle Bastille, Lucy Lee, Cynthia Moncada-Reid, Wei-Ming Yu, Austen Sitko, Andrea Yung, Mina Zamani, Nele Christophersen, Reza Maroofian, Hamid Galehdari, Norbert Babai, Barbara Vona, Tobias Moser, Lisa Goodrich"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.493231"
  },
  {
    "id": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00530-3?rss=yes",
    "journal": "Cell_Reports",
    "title": "A synthetic chlorophagy receptor promotes plant fitness by mediating chloroplast microautophagy",
    "link": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00530-3?rss=yes",
    "published": "",
    "summary": "Liu et al. design and validate a synthetic chloroplast autophagy receptor that recruits ATG8 to the chloroplasts and promotes both microautophagy of entire chloroplasts and chloroplast division. Moderate induction of this synthetic receptor promotes plant growth but with a clear upper-level limit for the benefits.",
    "authors": [
      "Rui Liu, Xun Weng, Xinjing Li, Yongheng Cao, Qiyun Li, Lin Luan, Danqing Tong, Zhaosheng Kong, Hao Wang, Taotao Wang, Qingqiu Gong"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.493255"
  },
  {
    "id": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00559-5?rss=yes",
    "journal": "Cell_Reports",
    "title": "BKK1/BAK7 and TCP21 form a positive feedback loop to facilitate submergence tolerance in plants",
    "link": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00559-5?rss=yes",
    "published": "",
    "summary": "Guo et al. identify BnaA04.BAK7 and its homologous genes as the key positive regulators of submergence tolerance in Brassica napus. They show that BAK7 and TCP21 physically interact with each other and form a conserved positive feedback module for submergence tolerance in planta.",
    "authors": [
      "Yiyi Guo, Yuanbin Zhang, Yuanyuan Li, Jie Liu, Yiyang Hu, Jiazhi Jiang, Qi Li, Yeke Chen, Weizhen Hu, Lixi Jiang, Ronghui Pan, Dezhi Wu, Jie Dong"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.493269"
  },
  {
    "id": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00541-8?rss=yes",
    "journal": "Cell_Reports",
    "title": "HIPP26L-NF-YC9-SRMT module regulates drought response in poplar",
    "link": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00541-8?rss=yes",
    "published": "",
    "summary": "Chen et al. revealed that drought and ABA induce the expression of the heavy-metal-associated isoprenylated plant protein gene HIPP26L and promote its nuclear translocation via interactions with NF-YC9 in poplar. In the nucleus, the HIPP26L-NF-YC9-SRMT ternary complex enhances the expression of stress-responsive genes, thereby activating the drought response.",
    "authors": [
      "Kai Chen, Shaofei Tong, Heng Huang, Jiacong Li, Wensen Shi, Yiling Li, Weiwei Wang, Li Xu, Tiannan Luo, Lulu Zhao, Lushui Zhang, Qiuxian Bai, Jianquan Liu, Tao Ma, Yuanzhong Jiang"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.493278"
  },
  {
    "id": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00565-0?rss=yes",
    "journal": "Cell_Reports",
    "title": "MYB68 regulates radial endodermal differentiation and suberin patterning",
    "link": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00565-0?rss=yes",
    "published": "",
    "summary": "In this study, Kraska et al. identify MYB68 as a novel regulator of endodermal suberization, linked to the formation of distinct identities in the xylem-pole-associated endodermis. The research uncovers new insights into the patterning of the endodermis with suberin and highlights genes encoding K-transport proteins associated with endodermal passage cells.",
    "authors": [
      "Leonie Kraska, Josep Mercadal Melia, Ryohei Thomas Nakano, David Molina, Pau Formosa-Jordan, Laura Ragni, Tonni Grube Andersen"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.493286"
  },
  {
    "id": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00497-8?rss=yes",
    "journal": "Cell_Reports",
    "title": "Machine-guided cell-fate engineering",
    "link": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00497-8?rss=yes",
    "published": "",
    "summary": "Appleton et al. describe an integrated computational and experimental method to screen transcription factors for cell-fate engineering. They demonstrate the utility of the approach by engineering iPSC lines that differentiate into cell types from each germ layer in 6 days in high efficiency.",
    "authors": [
      "Evan Appleton, Jenhan Tao, Songlei Liu, Christopher Glass, Gregory Fonseca, George Church"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.493294"
  },
  {
    "id": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00478-4?rss=yes",
    "journal": "Cell_Reports",
    "title": "Establishment of bovine extraembryonic endoderm stem cells enables efficient blastoid formation",
    "link": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00478-4?rss=yes",
    "published": "",
    "summary": "Ming et al. report a robust and efficient protocol for the derivation of bovine XENs from blastocysts. Importantly, this study also demonstrates the utility of bovine XENs in elucidating the mechanistic features of bovine pre-implantation development and generating an improved bovine blastoid for the creation of novel assisted reproductive technologies.",
    "authors": [
      "Hao Ming, Giovanna Nascimento Scatolin, Oscar Alejandro Ojeda-Rojas, Zongliang Jiang"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.493303"
  },
  {
    "id": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00528-5?rss=yes",
    "journal": "Cell_Reports",
    "title": "SPT6 regulates H3K14Ac deposition in mouse embryonic stem cells",
    "link": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00528-5?rss=yes",
    "published": "",
    "summary": "Zhang et al. show that histone chaperone and transcriptional elongation factor SPT6 localizes chromatin regions with H3K14Ac in mouse embryonic stem cells. SPT6 loss results in decreased H3K14Ac and gene expression, possibly through the regulation of binding of acetyltransferases KAT7 and KAT6A/B.",
    "authors": [
      "Daixuan Zhang, Li Dong, Ying Cai, Peng Zhao, Qingqing Cai, Jian Zhang, Yajun Hu, Mandi Mu, Siyi Cheng, Jin Wang, Min Zeng, Chenxi He, Lei Zhang, Hui Yang, Fei Xavier Chen, Li Tan, Feizhen Wu, Yujiang Geno Shi, Wenqi Xu, Hongjie Shen"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.493312"
  },
  {
    "id": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00527-3?rss=yes",
    "journal": "Cell_Reports",
    "title": "A platform of functional studies of ESCC-associated gene mutations identifies the roles of TGFBR2 in ESCC progression and metastasis",
    "link": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00527-3?rss=yes",
    "published": "",
    "summary": "(Cell Reports 43, 114952; November 26, 2024)",
    "authors": [
      "Jian Wang, Jiajia Du, Xiangmeng Luo, Linjie Guo, Yixin Liu, Jianfeng Zhou, Yang Zou, Zhenghao Lu, Xiangyu Pan, Xuelan Chen, Ailing Zhong, Xudong Wan, Lu Wang, Hongyu Liu, Siqi Dai, Shiyu Zhang, Xingyu Xiong, Ping Tan, Manli Wang, Baohong Wu, Qi Zhang, Yingjie Wang, Mengsha Zhang, Runda Lu, Huahang Lin, Yuan Li, Yaxin Li, Zongkai Han, Longqi Chen, Bing Hu, Yu Liu, Feifei Na, Chong Chen"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.493321"
  },
  {
    "id": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00574-1?rss=yes",
    "journal": "Cell_Reports",
    "title": "Hierarchical behavioral analysis framework as a platform for standardized quantitative identification of behaviors",
    "link": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00574-1?rss=yes",
    "published": "",
    "summary": "(Cell Reports 44, 115239; February 25, 2025)",
    "authors": [
      "Jialin Ye, Yang Xu, Kang Huang, Xinyu Wang, Liping Wang, Feng Wang"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.493331"
  },
  {
    "id": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00578-9?rss=yes",
    "journal": "Cell_Reports",
    "title": "Selective heterotrophic bacteria can selfishly process polysaccharides in freshwater lakes",
    "link": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00578-9?rss=yes",
    "published": "",
    "summary": "(Cell Reports 44, 115415; April 22, 2025)",
    "authors": [
      "Andrea Čačković, Petra Pjevac, Sandi Orlić, Greta Reintjes"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.493340"
  },
  {
    "id": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00606-0?rss=yes",
    "journal": "Cell_Reports",
    "title": "Bilirubin metabolism in the liver orchestrates antiviral innate immunity in the body",
    "link": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00606-0?rss=yes",
    "published": "",
    "summary": "(Cell Reports 44, 115481; April 22, 2025)",
    "authors": [
      "Qian Du, Wei He, Xiangjie Chen, Jin Liu, Mingcheng Guan, Yichang Chen, Meixia Chen, Yukang Yuan, Yibo Zuo, Ying Miao, Qin Wang, Haiyan Zhou, Yanli Liu, Jingting Jiang, Hui Zheng"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.493349"
  },
  {
    "id": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00592-3?rss=yes",
    "journal": "Cell_Reports",
    "title": "Local Production of Osteoprotegerin by Osteoblasts Suppresses Bone Resorption",
    "link": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00592-3?rss=yes",
    "published": "",
    "summary": "(Cell Reports 32, 108052; September 8, 2020)",
    "authors": [
      "Keisha M. Cawley, Nancy Cecile Bustamante-Gomez, Anveshi G. Guha, Ryan S. MacLeod, Jinhu Xiong, Igor Gubrij, Yu Liu, Robin Mulkey, Michela Palmieri, Jeff D. Thostenson, Joseph J. Goellner, Charles A. O’Brien"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.493362"
  },
  {
    "id": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00612-6?rss=yes",
    "journal": "Cell_Reports",
    "title": "Using hESCs to Probe the Interaction of the Diabetes-Associated Genes CDKAL1 and MT1E",
    "link": "https://www.cell.com/cell-reports/fulltext/S2211-1247(25)00612-6?rss=yes",
    "published": "",
    "summary": "(Cell Reports 19, 1512–1521; May 23, 2017)",
    "authors": [
      "Min Guo, Tuo Zhang, Xue Dong, Jenny Zhaoying Xiang, Minxiang Lei, Todd Evans, Johannes Graumann, Shuibing Chen"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.493381"
  },
  {
    "id": "https://www.cell.com/cell-stem-cell/fulltext/S1934-5909(25)00180-8?rss=yes",
    "journal": "Cell_StemCell",
    "title": "From genes to geometry: Controlling embryo models by programming genomic activation",
    "link": "https://www.cell.com/cell-stem-cell/fulltext/S1934-5909(25)00180-8?rss=yes",
    "published": "",
    "summary": "Embryo-like models derived from stem cells have emerged as powerful tools to study early development. In this issue, Lodewijk et al. demonstrate that activating just two enhancers via CRISPR activation (CRISPRa) in mouse embryonic stem cells (ESCs) can drive self-organization into structured embryo-like models, offering a genome-driven approach in stem cell and developmental biology.",
    "authors": [
      "Harold M. McNamara, Berna Sozen"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.493397"
  },
  {
    "id": "https://www.cell.com/cell-stem-cell/fulltext/S1934-5909(25)00183-3?rss=yes",
    "journal": "Cell_StemCell",
    "title": "On-demand microglia deliver the therapeutic payload in Alzheimer’s disease",
    "link": "https://www.cell.com/cell-stem-cell/fulltext/S1934-5909(25)00183-3?rss=yes",
    "published": "",
    "summary": "In this issue, Chadarevian et al. showed that engraftment of human iPSC-derived microglia (iMG) engineered to express secreted neprilysin (sNEP) under the plaque-responsive CD9 promoter reduces amyloid burden, neuronal damage, and inflammation in an Alzheimer’s disease (AD) mouse model. These findings establish a cell-based strategy to treat neurological diseases.",
    "authors": [
      "Jessica M. Thanos, John R. Lukens"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.493407"
  },
  {
    "id": "https://www.cell.com/cell-stem-cell/fulltext/S1934-5909(25)00186-9?rss=yes",
    "journal": "Cell_StemCell",
    "title": "To play Paneth or goblet: Shapeshifting secretory cells read the room",
    "link": "https://www.cell.com/cell-stem-cell/fulltext/S1934-5909(25)00186-9?rss=yes",
    "published": "",
    "summary": "The intestinal secretory lineage is thought to comprise four distinct cell types derived from one Atoh1+ progenitor, but the mechanisms that distinguish Paneth and goblet cells are unclear. Bhattacharya et al. argue that these cells are instead phenotypic manifestations of a common terminal Atoh1+ cell, actively shaped by niche-derived signals.",
    "authors": [
      "Irene V. Choi, Rachel K. Zwick"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.493416"
  },
  {
    "id": "https://www.cell.com/cell-stem-cell/fulltext/S1934-5909(25)00185-7?rss=yes",
    "journal": "Cell_StemCell",
    "title": "A new era in regenerative medicine: Cell replacement therapy for Parkinson’s disease is on the horizon",
    "link": "https://www.cell.com/cell-stem-cell/fulltext/S1934-5909(25)00185-7?rss=yes",
    "published": "",
    "summary": "Parkinson’s disease (PD), characterized by the selective loss of midbrain dopaminergic neurons (mDANs), is a promising target for cell replacement therapy. Two recent clinical trials published in Nature report the safety and potential efficacy of human pluripotent stem cell-based approaches, representing a major milestone in regenerative medicine for PD.",
    "authors": [
      "Young Cha, Pierre Leblanc, Kwang-Soo Kim"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.493427"
  },
  {
    "id": "https://www.cell.com/cell-stem-cell/fulltext/S1934-5909(25)00189-4?rss=yes",
    "journal": "Cell_StemCell",
    "title": "Prioritizing human tissue research: Q&A with Danilo Tagle",
    "link": "https://www.cell.com/cell-stem-cell/fulltext/S1934-5909(25)00189-4?rss=yes",
    "published": "",
    "summary": "Recently, the US National Institutes of Health (NIH) announced an initiative to expand human-based research technologies and minimize animal use in research. Danilo Tagle, Director of the Office for Special Initiatives at the National Center for Advancing Translational Sciences, shares his perspective on the upcoming changes with Cell Stem Cell.",
    "authors": [
      "Danilo Tagle"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.493443"
  },
  {
    "id": "https://www.cell.com/cell-stem-cell/fulltext/S1934-5909(25)00184-5?rss=yes",
    "journal": "Cell_StemCell",
    "title": "Diversifying the reference iPSC line concept",
    "link": "https://www.cell.com/cell-stem-cell/fulltext/S1934-5909(25)00184-5?rss=yes",
    "published": "",
    "summary": "We discuss how to diversify the reference iPSC line concept. We highlight workflows for generating diverse iPSC lines. We ask whether reference lines can act as inclusive sources of human diversity for use in benchmarking controls for disease models or drug screens, or as clinical-grade lines for cell therapies.",
    "authors": [
      "James Ellis, Knut Woltjen, Seema Mital, Megumu K. Saito, Akitsu Hotta, Jeanne F. Loring"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.493455"
  },
  {
    "id": "https://www.cell.com/cell-stem-cell/fulltext/S1934-5909(25)00188-2?rss=yes",
    "journal": "Cell_StemCell",
    "title": "Hallmarks of MSCs: Key quality attributes for pharmacology and clinical use",
    "link": "https://www.cell.com/cell-stem-cell/fulltext/S1934-5909(25)00188-2?rss=yes",
    "published": "",
    "summary": "Viswanathan and Galipeau highlight challenges in developing the critical quality attributes of mesenchymal stromal cells that inform their pharmacological use. They emphasize the complexity of donor-driven MSC heterogeneity, interactions with host immune effectors, particularly monocytes/macrophages, and exemplify the interdependent donor-host relationship in commercial-use cases of MSCs in COVID-19-ARDS.",
    "authors": [
      "Sowmya Viswanathan, Jacques Galipeau"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.493464"
  },
  {
    "id": "https://www.cell.com/cell-stem-cell/fulltext/S1934-5909(25)00099-2?rss=yes",
    "journal": "Cell_StemCell",
    "title": "Harnessing human iPSC-microglia for CNS-wide delivery of disease-modifying proteins",
    "link": "https://www.cell.com/cell-stem-cell/fulltext/S1934-5909(25)00099-2?rss=yes",
    "published": "",
    "summary": "Chadarevian et al. show that human iPSC-microglia (iMG) can be engineered ex vivo to enable pathology-responsive and CNS-wide delivery of therapeutic proteins. Their findings suggest that iMG could offer a promising new platform technology to deliver biological therapeutics throughout the brain.",
    "authors": [
      "Jean Paul Chadarevian, Hayk Davtyan, Alina L. Chadarevian, Jasmine Nguyen, Joia K. Capocchi, Lauren Le, Adrian Escobar, Talar Chadarevian, Kimiya Mansour, Ekaterina Deynega, Michael Mgerian, Christina Tu, Sepideh Kiani Shabestari, William Carlen-Jones, Ghazaleh Eskandari-Sedighi, Jonathan Hasselmann, Robert C. Spitale, Mathew Blurton-Jones"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.493479"
  },
  {
    "id": "https://www.cell.com/cell-stem-cell/fulltext/S1934-5909(25)00100-6?rss=yes",
    "journal": "Cell_StemCell",
    "title": "An erythroid-biased FOShi hematopoietic multipotent progenitor subpopulation contributes to adaptation to chronic hypoxia",
    "link": "https://www.cell.com/cell-stem-cell/fulltext/S1934-5909(25)00100-6?rss=yes",
    "published": "",
    "summary": "Shi and colleagues characterized the cellular and molecular features of hematopoietic lineage cells under long-term hypoxia exposure using scRNA-seq. They identified a FOShi MPP subset with erythroid-lineage priming, as well as increased CD47 expression in erythrocytes, which enhances survival by evading phagocytosis. These two factors contribute to the hypoxia adaptation.",
    "authors": [
      "Weili Liu, Xiaoru Zhang, Jinhua Liu, Lingling Pu, Lanlan Ai, Hongbao Xu, Guangrui Wang, Ding Wang, Xiaona Song, Yingnan Zhang, Ling Zhang, Jie Gao, Xiaoling Cheng, Xinxing Wang, Jingyuan Tong, Xiaowei Xie, Fang Dong, Yingchi Zhang, Ping Zhu, Zhaoli Chen, Peng Wu, Lihong Shi"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.493488"
  },
  {
    "id": "https://www.cell.com/cell-stem-cell/fulltext/S1934-5909(25)00095-5?rss=yes",
    "journal": "Cell_StemCell",
    "title": "Intestinal secretory differentiation reflects niche-driven phenotypic and epigenetic plasticity of a common signal-responsive terminal cell",
    "link": "https://www.cell.com/cell-stem-cell/fulltext/S1934-5909(25)00095-5?rss=yes",
    "published": "",
    "summary": "Bhattacharya et al. delineate chromatin and mRNA dynamics of intestinal secretory differentiation. They demonstrate that goblet and Paneth cells are phenotypic variants of a facile signal-responsive ATOH1+ cell type and that goblet and Paneth cis-elements and the canonical genes they control interconvert upon modulation of Wnt and BMP signals.",
    "authors": [
      "Swarnabh Bhattacharya, Guodong Tie, Pratik N.P. Singh, Ermanno Malagola, Onur Eskiocak, Ruiyang He, Judith Kraiczy, Wei Gu, Yakov Perlov, Aybuke Alici-Garipcan, Semir Beyaz, Timothy C. Wang, Qiao Zhou, Ramesh A. Shivdasani"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.493498"
  },
  {
    "id": "https://www.cell.com/cell-stem-cell/fulltext/S1934-5909(25)00177-8?rss=yes",
    "journal": "Cell_StemCell",
    "title": "HBO1 functions as an epigenetic barrier to hepatocyte plasticity and reprogramming during liver injury",
    "link": "https://www.cell.com/cell-stem-cell/fulltext/S1934-5909(25)00177-8?rss=yes",
    "published": "",
    "summary": "In the liver, hepatocytes can convert to biliary epithelial cells (BECs) after injury. YAP/TEAD activation triggers chromatin changes during this process. HBO1, a protein that modifies histones, acts as a barrier to reprogramming by limiting chromatin accessibility. Depleting HBO1 accelerates conversion, making it a potential therapeutic target for cholangiopathies.",
    "authors": [
      "Wei-Chien Yuan, Andrew S. Earl, Sai Ma, Karel Alcedo, Jacquelyn O. Russell, Fabiana M. Duarte, Yen-Ting Chu, Pei-Chi Chang, Hsin-Yi Chen, Hsin-Hui Chi, Qian Zhu, Alejo E. Rodriguez-Fraticelli, Sachin H. Patel, Yu-Ru Lee, Jason D. Buenrostro, Fernando D. Camargo"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.493514"
  },
  {
    "id": "https://www.cell.com/cell-stem-cell/fulltext/S1934-5909(25)00142-0?rss=yes",
    "journal": "Cell_StemCell",
    "title": "3D reconstruction of a human Carnegie stage 9 embryo provides a snapshot of early body plan formation",
    "link": "https://www.cell.com/cell-stem-cell/fulltext/S1934-5909(25)00142-0?rss=yes",
    "published": "",
    "summary": "Yu and his colleagues present a 3D spatial transcriptomic map of a CS9 human embryo, investigating several key developmental events during this critical stage of body patterning.",
    "authors": [
      "Yang Yuan, Xiaoyan Wang, Xiaodi Yan, Nannan He, Xiaojian Lu, Jingyu Yang, Xinwei Xie, Huiyao Yuan, Naixin Chen, Yinbo Liu, Hongan Ren, Runzhao Zhang, Lina Cui, Pengcheng Ren, Sirui Lin, Shuhan Cheng, Xiaolong Yang, Yifei Guo, Rong Li, Tianyi Yan, Jingtao Guo, Zhenyu Xiao, Yulei Wei, Leqian Yu"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.493523"
  },
  {
    "id": "https://www.cell.com/cell-stem-cell/fulltext/S1934-5909(25)00144-4?rss=yes",
    "journal": "Cell_StemCell",
    "title": "Induction of Multipotential Hematopoietic Progenitors from Human Pluripotent Stem Cells via Respecification of Lineage-Restricted Precursors",
    "link": "https://www.cell.com/cell-stem-cell/fulltext/S1934-5909(25)00144-4?rss=yes",
    "published": "",
    "summary": "(Cell Stem Cell 13, 459–470; October 3, 2013)",
    "authors": [
      "Sergei Doulatov, Linda T. Vo, Stephanie S. Chou, Peter G. Kim, Natasha Arora, Hu Li, Brandon K. Hadland, Irwin D. Bernstein, James J. Collins, Leonard I. Zon, George Q. Daley"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.493532"
  },
  {
    "id": "https://www.cell.com/cell-stem-cell/fulltext/S1934-5909(25)00182-1?rss=yes",
    "journal": "Cell_StemCell",
    "title": "Vaccination-based immunotherapy to target profibrotic cells in liver and lung",
    "link": "https://www.cell.com/cell-stem-cell/fulltext/S1934-5909(25)00182-1?rss=yes",
    "published": "",
    "summary": "(Cell Stem Cell 29, 1459–1474.e1–e9; October 6, 2022)",
    "authors": [
      "Michal Sobecki, Jing Chen, Ewelina Krzywinska, Shunmugam Nagarajan, Zheng Fan, Eric Nelius, Josep M. Monné Rodriguez, Frauke Seehusen, Amro Hussein, Greta Moschini, Edries Y. Hajam, Ravi Kiran, Dagmar Gotthardt, Julien Debbache, Cécile Badoual, Tatsuyuki Sato, Takayuki Isagawa, Norihiko Takeda, Corinne Tanchot, Eric Tartour, Achim Weber, Sabine Werner, Johannes Loffing, Lukas Sommer, Veronika Sexl, Christian Münz, Carol Feghali-Bostwick, Elena Pachera, Oliver Distler, Jess Snedeker, Colin Jamora, Christian Stockmann"
    ],
    "doi": "",
    "parser_type": "cell",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.493546"
  },
  {
    "id": "https://www.nature.com/articles/s41746-025-01708-w",
    "journal": "Nature_CompBio",
    "title": "SQL on FHIR - Tabular views of FHIR data using FHIRPath",
    "link": "https://www.nature.com/articles/s41746-025-01708-w",
    "published": "2025-06-09T00:00:00+00:00",
    "summary": "",
    "authors": [
      "John Grimes et al."
    ],
    "doi": "",
    "parser_type": "nature",
    "feed_priority": "high",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.493554"
  },
  {
    "id": "https://www.nature.com/articles/s44387-025-00011-z",
    "journal": "Nature_CompBio",
    "title": "Large language models for disease diagnosis: a scoping review",
    "link": "https://www.nature.com/articles/s44387-025-00011-z",
    "published": "2025-06-09T00:00:00+00:00",
    "summary": "",
    "authors": [
      "Shuang Zhou et al."
    ],
    "doi": "",
    "parser_type": "nature",
    "feed_priority": "high",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.493562"
  },
  {
    "id": "https://www.nature.com/articles/s42003-025-08179-5",
    "journal": "Nature_CompBio",
    "title": "Genome-wide identification and analysis of recurring patterns of epigenetic variation across individuals",
    "link": "https://www.nature.com/articles/s42003-025-08179-5",
    "published": "2025-06-07T00:00:00+00:00",
    "summary": "",
    "authors": [
      "Jennifer Zou et al."
    ],
    "doi": "",
    "parser_type": "nature",
    "feed_priority": "high",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.493571"
  },
  {
    "id": "https://www.nature.com/articles/s41531-025-00989-y",
    "journal": "Nature_CompBio",
    "title": "A new LRRK2 variant in a family with Parkinson’s disease affects binding to RAB8A",
    "link": "https://www.nature.com/articles/s41531-025-00989-y",
    "published": "2025-06-07T00:00:00+00:00",
    "summary": "",
    "authors": [
      "Lydia Vela-Desojo et al."
    ],
    "doi": "",
    "parser_type": "nature",
    "feed_priority": "high",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.493609"
  },
  {
    "id": "https://www.nature.com/articles/s41592-025-02713-3",
    "journal": "Nature_CompBio",
    "title": "SpotSweeper: spatially aware quality control for spatial transcriptomics",
    "link": "https://www.nature.com/articles/s41592-025-02713-3",
    "published": "2025-06-06T00:00:00+00:00",
    "summary": "",
    "authors": [
      "Michael Totty et al."
    ],
    "doi": "",
    "parser_type": "nature",
    "feed_priority": "high",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.493649"
  },
  {
    "id": "https://www.nature.com/articles/s41746-025-01745-5",
    "journal": "Nature_CompBio",
    "title": "Author Correction: Small language models learn enhanced reasoning skills from medical textbooks",
    "link": "https://www.nature.com/articles/s41746-025-01745-5",
    "published": "2025-06-06T00:00:00+00:00",
    "summary": "",
    "authors": [
      "Hyunjae Kim et al."
    ],
    "doi": "",
    "parser_type": "nature",
    "feed_priority": "high",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.493658"
  },
  {
    "id": "https://www.nature.com/articles/s41592-025-02662-x",
    "journal": "Nature_CompBio",
    "title": "Spotiflow: accurate and efficient spot detection for fluorescence microscopy with deep stereographic flow regression",
    "link": "https://www.nature.com/articles/s41592-025-02662-x",
    "published": "2025-06-06T00:00:00+00:00",
    "summary": "",
    "authors": [
      "Albert Dominguez Mantes et al."
    ],
    "doi": "",
    "parser_type": "nature",
    "feed_priority": "high",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.493676"
  },
  {
    "id": "https://www.nature.com/articles/s41592-025-02721-3",
    "journal": "Nature_CompBio",
    "title": "CellNEST reveals cell–cell relay networks using attention mechanisms on spatial transcriptomics",
    "link": "https://www.nature.com/articles/s41592-025-02721-3",
    "published": "2025-06-06T00:00:00+00:00",
    "summary": "",
    "authors": [
      "Fatema Tuz Zohora et al."
    ],
    "doi": "",
    "parser_type": "nature",
    "feed_priority": "high",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.493686"
  },
  {
    "id": "https://www.nature.com/articles/s41562-025-02220-7",
    "journal": "Nature_CompBio",
    "title": "End-to-end topographic networks as models of cortical map formation and human visual behaviour",
    "link": "https://www.nature.com/articles/s41562-025-02220-7",
    "published": "2025-06-06T00:00:00+00:00",
    "summary": "",
    "authors": [
      "Zejin Lu et al."
    ],
    "doi": "",
    "parser_type": "nature",
    "feed_priority": "high",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.493702"
  },
  {
    "id": "https://www.nature.com/articles/s41591-025-03747-y",
    "journal": "Nature_CompBio",
    "title": "A multimodal vision foundation model for clinical dermatology",
    "link": "https://www.nature.com/articles/s41591-025-03747-y",
    "published": "2025-06-06T00:00:00+00:00",
    "summary": "",
    "authors": [
      "Siyuan Yan et al."
    ],
    "doi": "",
    "parser_type": "nature",
    "feed_priority": "high",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.493711"
  },
  {
    "id": "https://www.nature.com/articles/s41598-025-03956-y",
    "journal": "Nature_CompBio",
    "title": "Uncovering candidate Nanog-Helper genes in early mouse embryo differentiation using differential entropy and network inference",
    "link": "https://www.nature.com/articles/s41598-025-03956-y",
    "published": "2025-06-06T00:00:00+00:00",
    "summary": "",
    "authors": [
      "Francisco Prista von Bonhorst et al."
    ],
    "doi": "",
    "parser_type": "nature",
    "feed_priority": "high",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.493720"
  },
  {
    "id": "https://www.nature.com/articles/s41467-025-60274-7",
    "journal": "Nature_CompBio",
    "title": "Single-cell microRNA-mRNA co-sequencing techniques convey large potential for understanding microRNA regulations but require careful and systemic approaches",
    "link": "https://www.nature.com/articles/s41467-025-60274-7",
    "published": "2025-06-06T00:00:00+00:00",
    "summary": "",
    "authors": [
      "Louise Velut et al."
    ],
    "doi": "",
    "parser_type": "nature",
    "feed_priority": "high",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.493730"
  },
  {
    "id": "https://www.nature.com/articles/s41598-025-05086-x",
    "journal": "Nature_CompBio",
    "title": "Identification of immune-associated genes and single-cell sequencing analysis in diagnosing Behçet’s disease",
    "link": "https://www.nature.com/articles/s41598-025-05086-x",
    "published": "2025-06-06T00:00:00+00:00",
    "summary": "",
    "authors": [
      "Qiyi Yu et al."
    ],
    "doi": "",
    "parser_type": "nature",
    "feed_priority": "high",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.493746"
  },
  {
    "id": "https://www.nature.com/articles/s43018-025-00991-6",
    "journal": "Nature_CompBio",
    "title": "Development and validation of an autonomous artificial intelligence agent for clinical decision-making in oncology",
    "link": "https://www.nature.com/articles/s43018-025-00991-6",
    "published": "2025-06-06T00:00:00+00:00",
    "summary": "",
    "authors": [
      "Dyke Ferber et al."
    ],
    "doi": "",
    "parser_type": "nature",
    "feed_priority": "high",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.493755"
  },
  {
    "id": "https://www.nature.com/articles/s41598-025-03818-7",
    "journal": "Nature_CompBio",
    "title": "Investigating the mechanism of Gentiopicroside in rheumatoid arthritis through network pharmacology, molecular docking, and experimental validation",
    "link": "https://www.nature.com/articles/s41598-025-03818-7",
    "published": "2025-06-06T00:00:00+00:00",
    "summary": "",
    "authors": [
      "Rongyue Jing et al."
    ],
    "doi": "",
    "parser_type": "nature",
    "feed_priority": "high",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.493766"
  },
  {
    "id": "https://www.nature.com/articles/s41598-025-04792-w",
    "journal": "Nature_CompBio",
    "title": "Advantages of digital twin technology in orthopedic trauma Surgery – Exploring different clinical use cases",
    "link": "https://www.nature.com/articles/s41598-025-04792-w",
    "published": "2025-06-06T00:00:00+00:00",
    "summary": "",
    "authors": [
      "Annchristin Andres et al."
    ],
    "doi": "",
    "parser_type": "nature",
    "feed_priority": "high",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.493790"
  },
  {
    "id": "https://www.nature.com/articles/s41598-025-95535-4",
    "journal": "Nature_CompBio",
    "title": "Toward the standardization of big datasets of urine output for AKI analysis: a multicenter validation study",
    "link": "https://www.nature.com/articles/s41598-025-95535-4",
    "published": "2025-06-06T00:00:00+00:00",
    "summary": "",
    "authors": [
      "Ariel Avraham Hasidim et al."
    ],
    "doi": "",
    "parser_type": "nature",
    "feed_priority": "high",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.493807"
  },
  {
    "id": "https://www.technologyreview.com/?p=1117937",
    "journal": "MIT_TechReview",
    "title": "Why doctors should look for ways to prescribe hope",
    "link": "https://www.technologyreview.com/2025/06/06/1117937/why-doctors-should-look-for-ways-to-prescribe-hope/",
    "published": "Fri, 06 Jun 2025 09:00:00 +0000",
    "summary": "This week, I’ve been thinking about the powerful connection between mind and body. Some new research suggests that people with heart conditions have better outcomes when they are more hopeful and optimistic. Hopelessness, on the other hand, is associated with a significantly higher risk of death. The findings build upon decades of fascinating research into&#8230;",
    "authors": [
      "Jessica Hamzelou"
    ],
    "doi": "",
    "parser_type": "generic",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.493836"
  },
  {
    "id": "https://www.technologyreview.com/?p=1117978",
    "journal": "MIT_TechReview",
    "title": "Inside the race to find GPS alternatives",
    "link": "https://www.technologyreview.com/2025/06/06/1117978/inside-the-race-to-find-gps-alternatives/",
    "published": "Fri, 06 Jun 2025 09:00:00 +0000",
    "summary": "Later this month, an inconspicuous 150-kilogram satellite is set to launch into space aboard the SpaceX Transporter 14 mission. Once in orbit, it will test super-accurate next-generation satnav technology designed to make up for the shortcomings of the US Global Positioning System (GPS).&#160; The satellite is the first of a planned constellation called Pulsar, which&#8230;",
    "authors": [
      "Tereza Pultarova"
    ],
    "doi": "",
    "parser_type": "generic",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.493844"
  },
  {
    "id": "https://www.technologyreview.com/?p=1117855",
    "journal": "MIT_TechReview",
    "title": "Over $1 billion in federal funding got slashed for this polluting industry",
    "link": "https://www.technologyreview.com/2025/06/05/1117855/cement-funding-slash/",
    "published": "Thu, 05 Jun 2025 10:00:00 +0000",
    "summary": "The clean cement industry might be facing the end of the road, before it ever really got rolling.&#160; On Friday, the US Department of Energy announced that it was canceling $3.7 billion in funding for 24 projects related to energy and industry. That included nearly $1.3 billion for cement-related projects. Cement is a massive climate&#8230;",
    "authors": [
      "Casey Crownhart"
    ],
    "doi": "",
    "parser_type": "generic",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.493866"
  },
  {
    "id": "https://www.technologyreview.com/?p=1117864",
    "journal": "MIT_TechReview",
    "title": "MIT Technology Review Insiders Panel",
    "link": "https://www.technologyreview.com/2025/06/04/1117864/mit-technology-review-insiders-panel/",
    "published": "Wed, 04 Jun 2025 20:06:06 +0000",
    "summary": "",
    "authors": [
      "Courtney Dobson"
    ],
    "doi": "",
    "parser_type": "generic",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.493881"
  },
  {
    "id": "https://bio.nikkeibp.co.jp/atcl/news/p1/25/05/28/13364/",
    "journal": "Nikkei_BioTech",
    "title": "特集連動◎「見る」から「測る・迫る」へ進化するバイオイメージング、神戸大・菊田教授、ライブイメージングとオミックス解析の掛け合わせで疾患メカニズムに迫る",
    "link": "https://bio.nikkeibp.co.jp/atcl/news/p1/25/05/28/13364/",
    "published": "",
    "summary": "神戸大学大学院医学研究科未来医学講座免疫学分野の菊田順一教授は、蛍光顕微鏡を使ったライブイメージングと、近年勃興しているシングルセル解析、空間オミックス解析技術を掛け合わせて、免疫応答や疾患のメカニズムを解明している。2025年4月28日、菊田教授が本誌の取材に応じた。",
    "authors": [
      "BTO"
    ],
    "doi": "",
    "parser_type": "generic",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.493920"
  },
  {
    "id": "https://bio.nikkeibp.co.jp/atcl/news/p1/25/06/04/13386/",
    "journal": "Nikkei_BioTech",
    "title": "Roche社、Broad Clinical Labs社と協力し画期的な新シーケンス法であるSBXの市場導入を加速",
    "link": "https://bio.nikkeibp.co.jp/atcl/news/p1/25/06/04/13386/",
    "published": "",
    "summary": "スイスRoche（ロシュ）社は2025年5月23日、2025年5月に発表したばかりの次世代シーケンシング（NGS）技術である「Sequencing By Expansion（SBX）」を用いた画期的なアプリケーションの開発と試験運用を目的として、米Broad Clinical Labs社（BCL社)と戦略的提携を結んだと発表した。",
    "authors": [
      "BTO"
    ],
    "doi": "",
    "parser_type": "generic",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.493930"
  },
  {
    "id": "https://bio.nikkeibp.co.jp/atcl/news/p1/25/06/08/13399/",
    "journal": "Nikkei_BioTech",
    "title": "リプロセル、脊髄小脳変性症に対するMSC製剤は日本と台湾で条件及び期限付き承認目指す",
    "link": "https://bio.nikkeibp.co.jp/atcl/news/p1/25/06/08/13399/",
    "published": "",
    "summary": "リプロセルは2025年6月5日、2025年3月期（2024年4月～2025年3月）の決算説明会を開催した。脊髄小脳変性症に対して開発を進めている他家脂肪由来間葉系幹細胞（MSC）製剤である「ステムカイマル」については承認申請までに時間がかかっていることが度々指摘されている。同社の横山周史代表取締役社長は承認申請の時期について、「明言できないがめどはついている」とコメントするに留めた。",
    "authors": [
      "BTO"
    ],
    "doi": "",
    "parser_type": "generic",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.493938"
  },
  {
    "id": "https://bio.nikkeibp.co.jp/atcl/news/p1/25/06/08/13400/",
    "journal": "Nikkei_BioTech",
    "title": "骨太の方針2025原案、創薬エコシステム発展や創薬力基盤強化を政府全体で",
    "link": "https://bio.nikkeibp.co.jp/atcl/news/p1/25/06/08/13400/",
    "published": "",
    "summary": "政府は2025年6月6日、経済財政諮問会議を開催し、「経済財政運営と改革の基本方針2025」（骨太の方針2025）の原案を示した。バイオテクノロジー関連では、創薬力の強化やスタートアップ支援などの施策が提案された。",
    "authors": [
      "BTO"
    ],
    "doi": "",
    "parser_type": "generic",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.493954"
  },
  {
    "id": "https://bio.nikkeibp.co.jp/atcl/column/16/040700054/060600243/",
    "journal": "Nikkei_BioTech",
    "title": "バイオベンチャー株価週報、レナサイエンス、サンバイオ、キッズウェルが上昇、PRISM BioLab、ステムセル研、DWTIが下落",
    "link": "https://bio.nikkeibp.co.jp/atcl/column/16/040700054/060600243/",
    "published": "",
    "summary": "日本の株式市場に上場するバイオスタートアップの株価を週ごとにウォッチしていく「バイオベンチャー株価週報」。2025年6月6日の終値が、前週の週末（5月30日）の終値に比べて上昇したのは15銘柄、下落したのは40銘柄だった。",
    "authors": [
      "BTO"
    ],
    "doi": "",
    "parser_type": "generic",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.493963"
  },
  {
    "id": "https://bio.nikkeibp.co.jp/atcl/news/p1/25/06/04/13387/",
    "journal": "Nikkei_BioTech",
    "title": "医薬品第一部会、MSDの肺高血圧症治療薬「ソタテルセプト」の新規承認など了承",
    "link": "https://bio.nikkeibp.co.jp/atcl/news/p1/25/06/04/13387/",
    "published": "",
    "summary": "厚生労働省は2025年6月4日、薬事審議会医薬品第一部会を開催した。米Merck(メルク）社の日本法人であるMSDの、肺動脈性肺高血圧症治療薬の組み換え融合蛋白質「エアウィン」（ソタテルセプト〔遺伝子組換え〕）の新規承認などを了承した。同部会における新規承認品目は7品目だった。",
    "authors": [
      "BTO"
    ],
    "doi": "",
    "parser_type": "generic",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.493972"
  },
  {
    "id": "https://bio.nikkeibp.co.jp/atcl/news/p1/25/06/03/13385/",
    "journal": "Nikkei_BioTech",
    "title": "CompleCure、抗体ミメティック薬物複合体のペイロードCMCでスペラファーマと提携",
    "link": "https://bio.nikkeibp.co.jp/atcl/news/p1/25/06/03/13385/",
    "published": "",
    "summary": "抗体ミメティック薬物複合体（Antibody Mimetic Drug Conjugate：AMDC）の開発を進めるCompleCure（コンプリキュア、東京・渋谷、土屋政幸代表取締役社長）は、このほどペイロードの化学・製造・品質管理（CMC）に関して、武田薬品工業のCMC研究部門が分離独立して2017年に設立されたスペラファーマ（大阪市、岩城慶太郎代表取締役社長）と提携したことを明らかにした。",
    "authors": [
      "BTO"
    ],
    "doi": "",
    "parser_type": "generic",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.493981"
  },
  {
    "id": "https://bio.nikkeibp.co.jp/atcl/column/16/112800083/060200045/",
    "journal": "Nikkei_BioTech",
    "title": "Endpoints News、関税が米国投資に悪影響を与える理由を大手製薬会社が（パブコメで）説明",
    "link": "https://bio.nikkeibp.co.jp/atcl/column/16/112800083/060200045/",
    "published": "",
    "summary": "バイオ医薬品業界から、業界別関税に関するコメントの第一弾が届いた。",
    "authors": [
      "BTO"
    ],
    "doi": "",
    "parser_type": "generic",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.493991"
  },
  {
    "id": "https://bio.nikkeibp.co.jp/atcl/news/p1/25/06/02/13377/",
    "journal": "Nikkei_BioTech",
    "title": "米Medera社、左室駆出率が保たれている心不全を対象とする遺伝子治療の第1相中間結果を発表",
    "link": "https://bio.nikkeibp.co.jp/atcl/news/p1/25/06/02/13377/",
    "published": "",
    "summary": "米Medera（メデラ）社は2025年5月19日、欧州心臓病学会（ESC）の心不全会議（Heart Failure 2025 Congress）で、左室駆出率（LVEF）が保たれている心不全（HFpEF）の適応で開発中の遺伝子治療（開発番号：SRD-002）の第1/2a相臨床試験（MUSIC-HFpEF試験）の中間解析結果を発表した。試験責任者である米Duke University Medical CenterのMarat Fudim氏が、Late-Breakingセッションで最新データを報告した。データカットオフまでに治療関連の重篤な有害事象は認められておらず、複数の患者で重症度が改善した。",
    "authors": [
      "BTO"
    ],
    "doi": "",
    "parser_type": "generic",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.493999"
  },
  {
    "id": "https://bio.nikkeibp.co.jp/atcl/news/p1/25/06/02/13379/",
    "journal": "Nikkei_BioTech",
    "title": "米Orionis社、Genentech社とがん治療用の分子のり型低分子薬の探索と開発へ提携",
    "link": "https://bio.nikkeibp.co.jp/atcl/news/p1/25/06/02/13379/",
    "published": "",
    "summary": "米Orionis Biosciences（オリオニス・バイオサイエンス）社は2025年5月21日、米Genentech（ジェネンテック）社との間に2件目となる複数年の協力契約を結び、がん治療を目的として、新規かつ困難な標的に対する1価の分子のり型低分子薬（分子接着剤、Molecular glue）の探索に取り組むと発表した。",
    "authors": [
      "BTO"
    ],
    "doi": "",
    "parser_type": "generic",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.494013"
  },
  {
    "id": "https://bio.nikkeibp.co.jp/atcl/news/p1/25/05/28/13363/",
    "journal": "Nikkei_BioTech",
    "title": "特集連動◎「見る」から「測る・迫る」へ進化するバイオイメージング、ニコン、製薬企業向けイメージング受託サービスを日米欧で展開",
    "link": "https://bio.nikkeibp.co.jp/atcl/news/p1/25/05/28/13363/",
    "published": "",
    "summary": "顕微鏡大手のニコンは近年、共焦点レーザー顕微鏡などを使ったイメージングの受託サービスを製薬企業向けに展開している。日米欧に受託の拠点「Nikon BioImaging Lab（NBIL）」を設け、その近くに自社の開発拠点も置くことで、受託や製品販売による売り上げを伸ばしつつ、顧客のニーズを把握して新たな製品開発も進めているという。2025年4月25日、同社フェロー・ヘルスケア事業部付の清田泰次郎氏、同社ヘルスケア事業部マーケティング統括部ソリューション企画部システム企画課長の坂神純子氏、同部マーケティング統括部マーケティングコミュニケーション部長の笹岡隆治氏、ニコングループのニコンソリューションズバイオサイエンス営業本部本部長付の宮本健司氏が本誌の取材に応じ、NBILの事業内容を語った。",
    "authors": [
      "BTO"
    ],
    "doi": "",
    "parser_type": "generic",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.494022"
  },
  {
    "id": "https://bio.nikkeibp.co.jp/atcl/news/p1/25/06/05/13388/",
    "journal": "Nikkei_BioTech",
    "title": "ペルセウスプロテオミクス、抗TfR抗体のANKL向け医師主導治験を1年延長",
    "link": "https://bio.nikkeibp.co.jp/atcl/news/p1/25/06/05/13388/",
    "published": "",
    "summary": "ペルセウスプロテオミクスは、2025年3月期中の導出を目指していた真性多血症（PV）に対する抗TfR抗体（開発番号：PPMX-T003）について、計画を達成できず、導出活動を継続すると報告した。また、アグレッシブNK細胞白血病（ANKL）を対象としたPPMX-T003の医師主導治験を、2026年3月期まで1年延長するとした。",
    "authors": [
      "BTO"
    ],
    "doi": "",
    "parser_type": "generic",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.494030"
  },
  {
    "id": "https://bio.nikkeibp.co.jp/atcl/column/16/060200103/060200002/",
    "journal": "Nikkei_BioTech",
    "title": "スタートアップを読み解く点と線、成功から凋落へ、米Bluebird Bio社に見る米国流の創薬エコシステム（前編）",
    "link": "https://bio.nikkeibp.co.jp/atcl/column/16/060200103/060200002/",
    "published": "",
    "summary": "新型コロナウイルス感染症（COVID-19）のパンデミックのまっただ中に迎えたピークを境に、2022年以降、米国のバイオスタートアップを取り巻く資金調達環境は厳しい状況が続いている。2025年に入り、政権交代に伴う米食品医薬品局（FDA）の再編、米国立衛生研究所（NIH）の予算カット、そして、「貿易戦争」から来る景気後退の懸念と、先行き不透明感はかつてないほど高まっている。",
    "authors": [
      "BTO"
    ],
    "doi": "",
    "parser_type": "generic",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.494040"
  },
  {
    "id": "https://bio.nikkeibp.co.jp/atcl/news/p1/25/06/02/13378/",
    "journal": "Nikkei_BioTech",
    "title": "米Orna社、環状RNAの抗CD19 in vivo CAR療法が自己免疫疾患前臨床モデルで効果",
    "link": "https://bio.nikkeibp.co.jp/atcl/news/p1/25/06/02/13378/",
    "published": "",
    "summary": "米Orna Therapeutics（オルナ・セラピューティクス）社は2025年5月15日、米遺伝子細胞治療学会（ASGCT）で、他家抗CD19 in vivoキメラ抗原受容体（CAR）療法（CD19 in vivo CAR）の最新データを発表した。同社が保有する環状RNAの基盤技術「oRNA」と脂質ナノ粒子（LNP）を用いた免疫システムへの送達技術「panCAR」により創出されたCD19 in vivo CARが、自己免疫疾患を適応候補として実施した前臨床試験で、ヒト化マウスモデル、非ヒト霊長類（NHP）モデルに強力かつ持続的なB細胞除去効果を示した。同社は2026年の臨床入りを目指すとしている。",
    "authors": [
      "BTO"
    ],
    "doi": "",
    "parser_type": "generic",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.494048"
  },
  {
    "id": "https://bio.nikkeibp.co.jp/atcl/news/p1/25/06/02/13376/",
    "journal": "Nikkei_BioTech",
    "title": "Pfizer社、3SBio社とPD-1・VEGFの二重特異性抗体の独占的ライセンス契約を締結",
    "link": "https://bio.nikkeibp.co.jp/atcl/news/p1/25/06/02/13376/",
    "published": "",
    "summary": "米Pfizer（ファイザー）社は2025年5月19日、中国の大手バイオ医薬品会社である3SBio社と、PD-1及び血管内皮成長因子（VEGF）を標的とする二重特異性抗体（開発番号：SSGJ-707）の、中国以外の世界各国における開発、製造、商業化に関する高額の独占ライセンス契約を結んだと発表した。",
    "authors": [
      "BTO"
    ],
    "doi": "",
    "parser_type": "generic",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.494057"
  },
  {
    "id": "https://bio.nikkeibp.co.jp/atcl/news/p1/25/06/03/13382/",
    "journal": "Nikkei_BioTech",
    "title": "農水省、バイオスティミュラントの効果表示などに関して初のガイドラインを策定",
    "link": "https://bio.nikkeibp.co.jp/atcl/news/p1/25/06/03/13382/",
    "published": "",
    "summary": "農林水産省は2025年5月30日、新しい農業資材の一種であり、農作物にかかるストレスを減らして収量や品質を上げる「バイオスティミュラント」について、適正な製品表示の方法などを定めた「バイオスティミュラントの表示等に係るガイドライン」を策定し公表した。",
    "authors": [
      "BTO"
    ],
    "doi": "",
    "parser_type": "generic",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.494065"
  },
  {
    "id": "https://bio.nikkeibp.co.jp/atcl/news/p1/25/05/28/13362/",
    "journal": "Nikkei_BioTech",
    "title": "特集連動◎「見る」から「測る・迫る」へ進化するバイオイメージング、医薬基盤研、企業向けにライブイメージングの受託・指導拠点を開設",
    "link": "https://bio.nikkeibp.co.jp/atcl/news/p1/25/05/28/13362/",
    "published": "",
    "summary": "医薬基盤・健康・栄養研究所（NIBN：2025年4月にNIBIOHNから略称変更）は2025年4月、同所内に、生きた組織で起こる現象をリアルタイムに観察するライブイメージングの拠点を開設した。「次世代生体イメージング創薬研究プラットフォーム」と名付け、高機能な多光子励起顕微鏡を使った動物のライブイメージングができる。製薬企業などから解析を受託したり、解析技術を指導したりする。NIBN創薬イメージングプロジェクト招へいプロジェクトリーダーで大阪大学医学部長・教授の石井優氏が主導する。2025年4月21日、石井氏やNIBNの担当者らが本誌の取材に応じた。",
    "authors": [
      "BTO"
    ],
    "doi": "",
    "parser_type": "generic",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.494096"
  },
  {
    "id": "https://bio.nikkeibp.co.jp/atcl/column/16/030400099/050400013/",
    "journal": "Nikkei_BioTech",
    "title": "世界で承認済みのウイルス療法：随時更新",
    "link": "https://bio.nikkeibp.co.jp/atcl/column/16/030400099/050400013/",
    "published": "",
    "summary": "これまでに世界で承認を取得し、実用化したウイルス療法を一覧表にまとめました。一部、承認後に承認を取り消された製品も含まれます。下記の「こちら」をクリックいただくとご覧いただけますので、ご利用ください。",
    "authors": [
      "BTO"
    ],
    "doi": "",
    "parser_type": "generic",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.494109"
  },
  {
    "id": "https://bio.nikkeibp.co.jp/atcl/news/p1/25/06/03/13383/",
    "journal": "Nikkei_BioTech",
    "title": "慈恵医大と順天堂大、JCRファーマ、AAVを利用した神経変性疾患治療法を開発",
    "link": "https://bio.nikkeibp.co.jp/atcl/news/p1/25/06/03/13383/",
    "published": "",
    "summary": "東京慈恵会医科大学と順天堂大学は、2025年6月2日、JCRファーマと共同で、治療用蛋白質の遺伝子と血液脳関門（BBB）を通過させるための抗トランスフェリン受容体抗体可変領域の遺伝子を連結して搭載したアデノ随伴ウイルス（AAV）ベクターによるin vivo遺伝子治療により、進行性の神経変性疾患であるGM1ガングリオシドーシス（GM1）のモデルマウスの中枢神経症状が改善したと発表した。結果の詳細は2025年4月8日、The Journal of Clinical Investigation誌に掲載された。",
    "authors": [
      "BTO"
    ],
    "doi": "",
    "parser_type": "generic",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.494131"
  },
  {
    "id": "https://bio.nikkeibp.co.jp/atcl/news/p1/25/06/02/13381/",
    "journal": "Nikkei_BioTech",
    "title": "厚労省、国内初となる軟骨修復用医療機器「モチジェル」などを承認了承",
    "link": "https://bio.nikkeibp.co.jp/atcl/news/p1/25/06/02/13381/",
    "published": "",
    "summary": "厚生労働省は2025年6月2日、薬事審議会医療機器・体外診断薬部会を開催した。持田製薬の「軟骨修復材 モチジェル」（一般名：吸収性軟骨再生用材料、以下モチジェル）などの承認を了承した。厚労省医療機器審査管理課によると、軟骨修復を適応とする医療機器を承認するのは国内初だという。",
    "authors": [
      "BTO"
    ],
    "doi": "",
    "parser_type": "generic",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.494140"
  },
  {
    "id": "https://bio.nikkeibp.co.jp/atcl/news/p1/25/06/03/13384/",
    "journal": "Nikkei_BioTech",
    "title": "東和薬品など、CiRA井上教授らがiPS創薬で見いだした既存薬を家族性ADの第2/3相治験に",
    "link": "https://bio.nikkeibp.co.jp/atcl/news/p1/25/06/03/13384/",
    "published": "",
    "summary": "東和薬品と、京都大学iPS細胞研究所（CiRA）の井上治久教授、三重大学大学院医学系研究科の冨本秀和特定教授、CiRAの坂野晴彦特命准教授らは、プレセニリン（PSEN）1遺伝子に変異がある家族性アルツハイマー病（AD）の患者に「ブロモクリプチン錠『トーワ』」（ブロモクリプチン）を投与する第2/3相治験を2025年5月に開始した。同年6月3日に発表した。ブロモクリプチンはパーキンソン病などの治療薬として認可されており、東和薬品はドラッグリポジショニングとして同薬の新たな適応の開発を進めていく方針だ。",
    "authors": [
      "BTO"
    ],
    "doi": "",
    "parser_type": "generic",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.494148"
  },
  {
    "id": "https://bio.nikkeibp.co.jp/atcl/report/16/082400016/052900398/",
    "journal": "Nikkei_BioTech",
    "title": "特集◎「見る」から「測る・迫る」へ進化するバイオイメージング【後編】、バイオイメージング、オミックス解析との掛け合わせで疾患メカニズムの解明が進む",
    "link": "https://bio.nikkeibp.co.jp/atcl/report/16/082400016/052900398/",
    "published": "",
    "summary": "バイオイメージングは、化合物の薬効をライブで捉えたり、組織の変化を定量したりと進歩している。多様化する技術を研究者が使いこなすのは簡単ではなく、受託解析のニーズが高まっている。オミックス解析と組み合わせて創薬標的の探索に活用するなど、創薬現場での活用も模索されている。特集後編では、バイオイメージングと、近年勃興しているシングルセル解析や空間オミックス解析を組み合わせ、疾患メカニズムの解明などを進める新たな取り組みに焦点を当てる。",
    "authors": [
      "BTO"
    ],
    "doi": "",
    "parser_type": "generic",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.494158"
  },
  {
    "id": "https://bio.nikkeibp.co.jp/atcl/news/p1/25/05/29/13368/",
    "journal": "Nikkei_BioTech",
    "title": "消費者向け全ゲノム検査のジーネックス、リピート配列や大規模な変異を検出しやすい全ゲノム検査を発売",
    "link": "https://bio.nikkeibp.co.jp/atcl/news/p1/25/05/29/13368/",
    "published": "",
    "summary": "一般消費者向け（Direct to Consumer：DTC）遺伝子検査を手掛けるジーネックス（東京・港、八木研代表取締役）は2025年6月3日、ロングリードシーケンサーを使った全ゲノムシーケンスに基づく遺伝子検査を発売した。DTC検査だが、医師を介して結果を返却するなど医療現場での活用を見据えている。従来の遺伝子検査はショートリードシーケンサーを使うのが一般的で、リピート配列や、逆位などの大規模な変異を検出しにくいのが課題だったのに対し、これまで検出できなかった疾患のバリアントを検出できる可能性がある。",
    "authors": [
      "BTO"
    ],
    "doi": "",
    "parser_type": "generic",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.494166"
  },
  {
    "id": "https://bio.nikkeibp.co.jp/atcl/news/p1/25/06/02/13375/",
    "journal": "Nikkei_BioTech",
    "title": "第一三共、NSCLC対象のHER3-DXdの米国承認申請を自主的取り下げ",
    "link": "https://bio.nikkeibp.co.jp/atcl/news/p1/25/06/02/13375/",
    "published": "",
    "summary": "第一三共は、2025年5月30日、EGFR変異陽性の局所進行または転移性非小細胞肺がん（NSCLC）を対象に開発を進めていた抗体薬物複合体（ADC）である、パトリツマブ デルクステカン（HER3-Dxd/U3-1402）の米国における承認申請を自主的に取り下げたと発表した。取り下げの理由は、第3相臨床試験であるHERTHENA-Lung02試験の副次評価項目である全生存期間（OS）に有意な改善が見られなかったことだとしている。",
    "authors": [
      "BTO"
    ],
    "doi": "",
    "parser_type": "generic",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.494175"
  },
  {
    "id": "https://bio.nikkeibp.co.jp/atcl/report/16/082300008/052900198/",
    "journal": "Nikkei_BioTech",
    "title": "パイプライン研究◎多発性骨髄腫治療薬【市場動向編】、多発性骨髄腫治療薬、BCMA標的のCAR-T療法と二重特異性抗体がブロックバスターへ",
    "link": "https://bio.nikkeibp.co.jp/atcl/report/16/082300008/052900198/",
    "published": "",
    "summary": "独自調査と英GlobalData（グローバルデータ）社のデータも含めて市場を分析すると、トップ製品は抗CD38抗体の「ダラザレックス」/「ダラキューロ」（ダラツムマブ/ダラツムマブ・ボルヒアルロニダーゼアルファ、J＆J社/ヤンセンファーマ）で、2期連続となった。多発性骨髄腫向けの売上高は前年比16.2％増の113億2000万ドル（1兆7135億円、1ドル=151.37円、以下同）と推定された。",
    "authors": [
      "BTO"
    ],
    "doi": "",
    "parser_type": "generic",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.494184"
  },
  {
    "id": "https://bio.nikkeibp.co.jp/atcl/news/p1/25/06/02/13380/",
    "journal": "Nikkei_BioTech",
    "title": "科研製薬、ツーセルの軟骨再生用細胞治療製品を導入で最大70億円のライセンス契約",
    "link": "https://bio.nikkeibp.co.jp/atcl/news/p1/25/06/02/13380/",
    "published": "",
    "summary": "科研製薬は2025年6月2日、ツーセル（広島市、松本昌也代表取締役社長）が創出した同種他家の滑膜間葉系幹細胞由来3次元人工組織「gMSC1」についてライセンス契約を締結した。今回の契約で科研製薬は、日本国内の整形外科領域における本製品の共同開発権、独占的販売権を取得する。また、科研製薬はツーセルに対して契約一時金及びgMSC1の開発に係る開発費用、開発と販売マイルストーンとを合わせて、最大約70億円を支払う。さらにgMSC1の上市後、売上額に応じたロイヤルティーを支払うとしている。",
    "authors": [
      "BTO"
    ],
    "doi": "",
    "parser_type": "generic",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.494192"
  },
  {
    "id": "https://bio.nikkeibp.co.jp/atcl/news/p1/25/05/30/13373/",
    "journal": "Nikkei_BioTech",
    "title": "ステラファーマ、中国へのBNCT用製剤輸出開始で2025年3月期は大幅に増収",
    "link": "https://bio.nikkeibp.co.jp/atcl/news/p1/25/05/30/13373/",
    "published": "",
    "summary": "ステラファーマは2025年5月30日、2025年3月期（024年4月～2025年3月）の決算説明会を開催した。2025年第4四半期に中国海南島の医療特区に同社のホウ素中性子捕捉療法（BNCT）用ホウ素医薬品の輸出を始め、大幅な増収を達成した。2025年3月期通期の業績（日本基準）は、売上高が前年同期比256.6%増の9億6100万円だった。営業損益は9000万円の損失、経常損益は1億3700万円の損失、当期純損益は1億4000万円の損失だった。",
    "authors": [
      "BTO"
    ],
    "doi": "",
    "parser_type": "generic",
    "feed_priority": "medium",
    "priority": 3,
    "priority_name": "NORMAL",
    "added_at": "2025-06-09T20:39:59.494201"
  }
]